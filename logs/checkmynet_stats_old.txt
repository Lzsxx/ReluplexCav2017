allLayerSize = 9
Input nodes = 4, relu nodes = 210, output nodes = 3

Inputs are: 
	input[0] = 5.840000
	input[1] = 3.000000
	input[2] = 3.750000
	input[3] = 1.200000

Output using nnet.cpp:
number of layers in nnet.cpp = 8

when compute layer[0] to layer[1]

compute layer: 1, node : 0
2.3546744512 *= 5.8400000000 * 0.4031976800 
2.5201180312 *= 3.0000000000 * 0.0551478600 
1.8222362437 *= 3.7500000000 * -0.1861018100 
2.3042892037 *= 1.2000000000 * 0.4017108000 
tempVal = 2.3042892037 + -0.0066294920(biases), 
now the tempVal = 2.2976597117 

compute layer: 1, node : 1
1.7233335424 *= 5.8400000000 * 0.2950913600 
2.6301501424 *= 3.0000000000 * 0.3022722000 
1.6587217549 *= 3.7500000000 * -0.2590475700 
1.4409937909 *= 1.2000000000 * -0.1814399700 
tempVal = 1.4409937909 + 0.0017830410(biases), 
now the tempVal = 1.4427768319 

compute layer: 1, node : 2
-0.0843027652 *= 5.8400000000 * -0.0144354050 
0.6216111848 *= 3.0000000000 * 0.2353046500 
0.2079089348 *= 3.7500000000 * -0.1103206000 
0.0299714348 *= 1.2000000000 * -0.1482812500 
tempVal = 0.0299714348 + 0.0160203460(biases), 
now the tempVal = 0.0459917808 

compute layer: 1, node : 3
0.9703463680 *= 5.8400000000 * 0.1661552000 
1.4568360880 *= 3.0000000000 * 0.1621632400 
0.4827503380 *= 3.7500000000 * -0.2597562000 
0.1271690980 *= 1.2000000000 * -0.2963177000 
tempVal = 0.1271690980 + 0.0151113890(biases), 
now the tempVal = 0.1422804870 

compute layer: 1, node : 4
2.0876509632 *= 5.8400000000 * 0.3574744800 
2.8190017632 *= 3.0000000000 * 0.2437836000 
4.2953525382 *= 3.7500000000 * 0.3936935400 
3.9373775382 *= 1.2000000000 * -0.2983125000 
tempVal = 3.9373775382 + -0.0014518120(biases), 
now the tempVal = 3.9359257262 

compute layer: 1, node : 5
0.4346790840 *= 5.8400000000 * 0.0744313500 
1.7967989640 *= 3.0000000000 * 0.4540399600 
1.4538437640 *= 3.7500000000 * -0.0914547200 
1.1341999440 *= 1.2000000000 * -0.2663698500 
tempVal = 1.1341999440 + 0.0109210010(biases), 
now the tempVal = 1.1451209450 

compute layer: 1, node : 6
0.3744531496 *= 5.8400000000 * 0.0641186900 
-0.4336636004 *= 3.0000000000 * -0.2693722500 
1.0557094996 *= 3.7500000000 * 0.3971661600 
1.5725424556 *= 1.2000000000 * 0.4306941300 
tempVal = 1.5725424556 + -0.0107563610(biases), 
now the tempVal = 1.5617860946 

compute layer: 1, node : 7
0.5620246056 *= 5.8400000000 * 0.0962370900 
1.3179822456 *= 3.0000000000 * 0.2519858800 
0.4268415456 *= 3.7500000000 * -0.2376375200 
0.3755469396 *= 1.2000000000 * -0.0427455050 
tempVal = 0.3755469396 + 0.0105909840(biases), 
now the tempVal = 0.3861379236 

compute layer: 1, node : 8
0.2733666215 *= 5.8400000000 * 0.0468093530 
1.0969668215 *= 3.0000000000 * 0.2745334000 
0.5780332340 *= 3.7500000000 * -0.1383822900 
0.5709947655 *= 1.2000000000 * -0.0058653904 
tempVal = 0.5709947655 + 0.0055841390(biases), 
now the tempVal = 0.5765789045 

compute layer: 1, node : 9
-1.9130200712 *= 5.8400000000 * -0.3275719300 
-1.1603760512 *= 3.0000000000 * 0.2508813400 
-1.4138243387 *= 3.7500000000 * -0.0675862100 
-1.5217759427 *= 1.2000000000 * -0.0899596700 
tempVal = -1.5217759427 + 0.0000000000(biases), 
now the tempVal = -1.5217759427 
ReLU !!! in layer: 1, node : 9, its linear result is negative,so set it to 0

compute layer: 1, node : 10
-0.0632276418 *= 5.8400000000 * -0.0108266510 
-1.0917076218 *= 3.0000000000 * -0.3428266600 
-0.4626608343 *= 3.7500000000 * 0.1677458100 
-0.0646019223 *= 1.2000000000 * 0.3317157600 
tempVal = -0.0646019223 + -0.0035291803(biases), 
now the tempVal = -0.0681311026 
ReLU !!! in layer: 1, node : 10, its linear result is negative,so set it to 0

compute layer: 1, node : 11
-1.7967075360 *= 5.8400000000 * -0.3076554000 
-1.9088676270 *= 3.0000000000 * -0.0373866970 
-1.8462239108 *= 3.7500000000 * 0.0167049910 
-2.0911699268 *= 1.2000000000 * -0.2041216800 
tempVal = -2.0911699268 + 0.0000000000(biases), 
now the tempVal = -2.0911699268 
ReLU !!! in layer: 1, node : 11, its linear result is negative,so set it to 0

compute layer: 1, node : 12
0.4061703064 *= 5.8400000000 * 0.0695497100 
-0.1225812836 *= 3.0000000000 * -0.1762505300 
0.3575283289 *= 3.7500000000 * 0.1280292300 
0.4665433441 *= 1.2000000000 * 0.0908458460 
tempVal = 0.4665433441 + -0.0085672900(biases), 
now the tempVal = 0.4579760541 

compute layer: 1, node : 13
-2.2715904648 *= 5.8400000000 * -0.3889709700 
-2.0698157148 *= 3.0000000000 * 0.0672582500 
-3.6330566523 *= 3.7500000000 * -0.4168642500 
-3.2514734763 *= 1.2000000000 * 0.3179859800 
tempVal = -3.2514734763 + 0.0000000000(biases), 
now the tempVal = -3.2514734763 
ReLU !!! in layer: 1, node : 13, its linear result is negative,so set it to 0

compute layer: 1, node : 14
-1.7028064680 *= 5.8400000000 * -0.2915764500 
-0.9352459680 *= 3.0000000000 * 0.2558535000 
-0.0752433555 *= 3.7500000000 * 0.2293340300 
-0.1231513875 *= 1.2000000000 * -0.0399233600 
tempVal = -0.1231513875 + -0.0043933033(biases), 
now the tempVal = -0.1275446908 
ReLU !!! in layer: 1, node : 14, its linear result is negative,so set it to 0

compute layer: 1, node : 15
-1.6385362752 *= 5.8400000000 * -0.2805712800 
-2.3282082552 *= 3.0000000000 * -0.2298906600 
-0.9300788802 *= 3.7500000000 * 0.3728345000 
-0.8391669282 *= 1.2000000000 * 0.0757599600 
tempVal = -0.8391669282 + -0.0007829496(biases), 
now the tempVal = -0.8399498778 
ReLU !!! in layer: 1, node : 15, its linear result is negative,so set it to 0

compute layer: 1, node : 16
-0.8363518312 *= 5.8400000000 * -0.1432109300 
-0.6468690532 *= 3.0000000000 * 0.0631609260 
-2.1312921532 *= 3.7500000000 * -0.3958461600 
-1.9963197412 *= 1.2000000000 * 0.1124770100 
tempVal = -1.9963197412 + 0.0000000000(biases), 
now the tempVal = -1.9963197412 
ReLU !!! in layer: 1, node : 16, its linear result is negative,so set it to 0

compute layer: 1, node : 17
0.0232065990 *= 5.8400000000 * 0.0039737327 
0.3103509390 *= 3.0000000000 * 0.0957147800 
1.9666909890 *= 3.7500000000 * 0.4416906800 
2.0812599210 *= 1.2000000000 * 0.0954741100 
tempVal = 2.0812599210 + 0.0096612370(biases), 
now the tempVal = 2.0909211580 

compute layer: 1, node : 18
1.2257018864 *= 5.8400000000 * 0.2098804600 
0.1910870864 *= 3.0000000000 * -0.3448716000 
-1.3425960136 *= 3.7500000000 * -0.4089821600 
-1.1178557416 *= 1.2000000000 * 0.1872835600 
tempVal = -1.1178557416 + 0.0000000000(biases), 
now the tempVal = -1.1178557416 
ReLU !!! in layer: 1, node : 18, its linear result is negative,so set it to 0

compute layer: 1, node : 19
1.5263377280 *= 5.8400000000 * 0.2613592000 
1.5558516560 *= 3.0000000000 * 0.0098379760 
2.1360471185 *= 3.7500000000 * 0.1547187900 
1.6390267745 *= 1.2000000000 * -0.4141836200 
tempVal = 1.6390267745 + 0.0000399492(biases), 
now the tempVal = 1.6390667237 

compute layer: 1, node : 20
1.5215179760 *= 5.8400000000 * 0.2605339000 
1.0189112660 *= 3.0000000000 * -0.1675355700 
0.5764831910 *= 3.7500000000 * -0.1179808200 
0.1508325110 *= 1.2000000000 * -0.3547089000 
tempVal = 0.1508325110 + -0.0187262220(biases), 
now the tempVal = 0.1321062890 

compute layer: 1, node : 21
2.6608056160 *= 5.8400000000 * 0.4556174000 
1.7897442760 *= 3.0000000000 * -0.2903537800 
2.1126028360 *= 3.7500000000 * 0.0860956160 
2.4978544360 *= 1.2000000000 * 0.3210430000 
tempVal = 2.4978544360 + 0.0024065834(biases), 
now the tempVal = 2.5002610194 

compute layer: 1, node : 22
-0.8597324464 *= 5.8400000000 * -0.1472144600 
-0.3462442864 *= 3.0000000000 * 0.1711627200 
-0.2385105326 *= 3.7500000000 * 0.0287290010 
-0.2893533602 *= 1.2000000000 * -0.0423690230 
tempVal = -0.2893533602 + 0.0000000000(biases), 
now the tempVal = -0.2893533602 
ReLU !!! in layer: 1, node : 22, its linear result is negative,so set it to 0

compute layer: 1, node : 23
-0.1057349111 *= 5.8400000000 * -0.0181052930 
0.9517169689 *= 3.0000000000 * 0.3524839600 
2.4158410939 *= 3.7500000000 * 0.3904331000 
2.9364600859 *= 1.2000000000 * 0.4338491600 
tempVal = 2.9364600859 + -0.0083619660(biases), 
now the tempVal = 2.9280981199 

compute layer: 1, node : 24
-2.2571119952 *= 5.8400000000 * -0.3864917800 
-1.9618959152 *= 3.0000000000 * 0.0984053600 
-3.1250462402 *= 3.7500000000 * -0.3101734200 
-3.5175042362 *= 1.2000000000 * -0.3270483300 
tempVal = -3.5175042362 + 0.0000000000(biases), 
now the tempVal = -3.5175042362 
ReLU !!! in layer: 1, node : 24, its linear result is negative,so set it to 0

compute layer: 1, node : 25
-1.8713721696 *= 5.8400000000 * -0.3204404400 
-1.8883588005 *= 3.0000000000 * -0.0056622103 
-2.8916374005 *= 3.7500000000 * -0.2675409600 
-2.5302288405 *= 1.2000000000 * 0.3011738000 
tempVal = -2.5302288405 + 0.0000000000(biases), 
now the tempVal = -2.5302288405 
ReLU !!! in layer: 1, node : 25, its linear result is negative,so set it to 0

compute layer: 1, node : 26
0.2706491177 *= 5.8400000000 * 0.0463440270 
0.6155240477 *= 3.0000000000 * 0.1149583100 
0.3007301102 *= 3.7500000000 * -0.0839450500 
0.3549359102 *= 1.2000000000 * 0.0451715000 
tempVal = 0.3549359102 + 0.0015094965(biases), 
now the tempVal = 0.3564454067 

compute layer: 1, node : 27
2.3014398144 *= 5.8400000000 * 0.3940821600 
2.9368920444 *= 3.0000000000 * 0.2118174100 
3.3786645444 *= 3.7500000000 * 0.1178060000 
2.9029571844 *= 1.2000000000 * -0.3964228000 
tempVal = 2.9029571844 + -0.0041107740(biases), 
now the tempVal = 2.8988464104 

compute layer: 1, node : 28
1.0382715832 *= 5.8400000000 * 0.1777862300 
1.6000266832 *= 3.0000000000 * 0.1872517000 
1.2226153432 *= 3.7500000000 * -0.1006430240 
0.9870237232 *= 1.2000000000 * -0.1963263500 
tempVal = 0.9870237232 + -0.0033160916(biases), 
now the tempVal = 0.9837076316 

compute layer: 1, node : 29
0.3029726417 *= 5.8400000000 * 0.0518788770 
0.0799783217 *= 3.0000000000 * -0.0743314400 
0.7392517592 *= 3.7500000000 * 0.1758062500 
0.3103112792 *= 1.2000000000 * -0.3574504000 
tempVal = 0.3103112792 + 0.0022753936(biases), 
now the tempVal = 0.3125866728 

now we get all result in layer: 1
	node: 0, val: 2.2976597117
	node: 1, val: 1.4427768319
	node: 2, val: 0.0459917808
	node: 3, val: 0.1422804870
	node: 4, val: 3.9359257262
	node: 5, val: 1.1451209450
	node: 6, val: 1.5617860946
	node: 7, val: 0.3861379236
	node: 8, val: 0.5765789045
	node: 9, val: 0.0000000000
	node: 10, val: 0.0000000000
	node: 11, val: 0.0000000000
	node: 12, val: 0.4579760541
	node: 13, val: 0.0000000000
	node: 14, val: 0.0000000000
	node: 15, val: 0.0000000000
	node: 16, val: 0.0000000000
	node: 17, val: 2.0909211580
	node: 18, val: 0.0000000000
	node: 19, val: 1.6390667237
	node: 20, val: 0.1321062890
	node: 21, val: 2.5002610194
	node: 22, val: 0.0000000000
	node: 23, val: 2.9280981199
	node: 24, val: 0.0000000000
	node: 25, val: 0.0000000000
	node: 26, val: 0.3564454067
	node: 27, val: 2.8988464104
	node: 28, val: 0.9837076316
	node: 29, val: 0.3125866728

when compute layer[1] to layer[2]

compute layer: 2, node : 0
0.4128388098 *= 2.2976597117 * 0.1796779600 
0.8210448419 *= 1.4427768319 * 0.2829308200 
0.8298867296 *= 0.0459917808 * 0.1922493000 
0.8586965846 *= 0.1422804870 * 0.2024863400 
0.5003430635 *= 3.9359257262 * -0.0910468200 
0.1863963960 *= 1.1451209450 * -0.2741602700 
0.1838572619 *= 1.5617860946 * -0.0016257887 
0.1773189776 *= 0.3861379236 * -0.0169325100 
0.0424068192 *= 0.5765789045 * -0.2339873300 
0.0424068192 *= 0.0000000000 * -0.1231780700 
0.0424068192 *= 0.0000000000 * 0.0703137200 
0.0424068192 *= 0.0000000000 * -0.2982768700 
0.0096931729 *= 0.4579760541 * -0.0714309100 
0.0096931729 *= 0.0000000000 * 0.2539954200 
0.0096931729 *= 0.0000000000 * 0.1419763000 
0.0096931729 *= 0.0000000000 * 0.0850035500 
0.0096931729 *= 0.0000000000 * 0.2269975200 
-0.6252757153 *= 2.0909211580 * -0.3036790200 
-0.6252757153 *= 0.0000000000 * -0.2815151500 
-0.2646929848 *= 1.6390667237 * 0.2199927100 
-0.2669172032 *= 0.1321062890 * -0.0168365820 
-0.6151891617 *= 2.5002610194 * -0.1392942400 
-0.6151891617 *= 0.0000000000 * 0.0772643240 
0.0527031384 *= 2.9280981199 * 0.2280976500 
0.0527031384 *= 0.0000000000 * 0.1111339400 
0.0527031384 *= 0.0000000000 * -0.2616619500 
-0.0399440555 *= 0.3564454067 * -0.2599197300 
-0.5160256308 *= 2.8988464104 * -0.1642313900 
-0.6488988866 *= 0.9837076316 * -0.1350739300 
-0.6358845015 *= 0.3125866728 * 0.0416344850 
tempVal = -0.6358845015 + -0.0031063948(biases), 
now the tempVal = -0.6389908963 
ReLU !!! in layer: 2, node : 0, its linear result is negative,so set it to 0

compute layer: 2, node : 1
0.4500994289 *= 2.2976597117 * 0.1958947300 
0.2759963889 *= 1.4427768319 * -0.1206721900 
0.2638456823 *= 0.0459917808 * -0.2641930000 
0.2342733134 *= 0.1422804870 * -0.2078455700 
0.6811043982 *= 3.9359257262 * 0.1135263000 
0.5303546880 *= 1.1451209450 * -0.1316452300 
0.8381850699 *= 1.5617860946 * 0.1971015000 
0.7296581761 *= 0.3861379236 * -0.2810573300 
0.5507641003 *= 0.5765789045 * -0.3102681600 
0.5507641003 *= 0.0000000000 * -0.2459269600 
0.5507641003 *= 0.0000000000 * 0.0980587800 
0.5507641003 *= 0.0000000000 * 0.0048651365 
0.5218665505 *= 0.4579760541 * -0.0630983860 
0.5218665505 *= 0.0000000000 * -0.1576372500 
0.5218665505 *= 0.0000000000 * -0.2741417000 
0.5218665505 *= 0.0000000000 * -0.2652336000 
0.5218665505 *= 0.0000000000 * 0.2184654300 
0.8097133371 *= 2.0909211580 * 0.1376650600 
0.8097133371 *= 0.0000000000 * -0.0404486250 
0.9313461020 *= 1.6390667237 * 0.0742085500 
0.9519974063 *= 0.1321062890 * 0.1563234000 
1.6385178769 *= 2.5002610194 * 0.2745795200 
1.6385178769 *= 0.0000000000 * -0.0728020600 
2.5657862912 *= 2.9280981199 * 0.3166794200 
2.5657862912 *= 0.0000000000 * 0.2181518200 
2.5657862912 *= 0.0000000000 * 0.3103984000 
2.5460541054 *= 0.3564454067 * -0.0553582270 
1.9974831361 *= 2.8988464104 * -0.1892376800 
2.2246245925 *= 0.9837076316 * 0.2309034200 
2.2279283376 *= 0.3125866728 * 0.0105690530 
tempVal = 2.2279283376 + -0.0126146080(biases), 
now the tempVal = 2.2153137296 

compute layer: 2, node : 2
-0.6191842760 *= 2.2976597117 * -0.2694847600 
-0.8270463172 *= 1.4427768319 * -0.1440708200 
-0.8284952699 *= 0.0459917808 * -0.0315046000 
-0.8598328160 *= 0.1422804870 * -0.2202518900 
-1.5110818318 *= 3.9359257262 * -0.1654627300 
-1.8015514930 *= 1.1451209450 * -0.2536585000 
-1.6587612948 *= 1.5617860946 * 0.0914275000 
-1.7800674503 *= 0.3861379236 * -0.3141524000 
-1.7705720318 *= 0.5765789045 * 0.0164685500 
-1.7705720318 *= 0.0000000000 * 0.2076194700 
-1.7705720318 *= 0.0000000000 * 0.2186232400 
-1.7705720318 *= 0.0000000000 * -0.0514056420 
-1.6333718403 *= 0.4579760541 * 0.2995794000 
-1.6333718403 *= 0.0000000000 * -0.0160541630 
-1.6333718403 *= 0.0000000000 * -0.1174571700 
-1.6333718403 *= 0.0000000000 * 0.1099776500 
-1.6333718403 *= 0.0000000000 * 0.0787695000 
-2.1484550038 *= 2.0909211580 * -0.2463427000 
-2.1484550038 *= 0.0000000000 * -0.1240211350 
-1.9362182527 *= 1.6390667237 * 0.1294863400 
-1.9173975532 *= 0.1321062890 * 0.1424663400 
-2.6726870031 *= 2.5002610194 * -0.3020842400 
-2.6726870031 *= 0.0000000000 * 0.2449666300 
-3.0366100701 *= 2.9280981199 * -0.1242865000 
-3.0366100701 *= 0.0000000000 * -0.2082068600 
-3.0366100701 *= 0.0000000000 * 0.0027072683 
-2.9563337382 *= 0.3564454067 * 0.2252135400 
-2.8807650446 *= 2.8988464104 * 0.0260685400 
-2.6336080890 *= 0.9837076316 * 0.2512504200 
-2.7024048053 *= 0.3125866728 * -0.2200884500 
tempVal = -2.7024048053 + 0.0000000000(biases), 
now the tempVal = -2.7024048053 
ReLU !!! in layer: 2, node : 2, its linear result is negative,so set it to 0

compute layer: 2, node : 3
0.5970797326 *= 2.2976597117 * 0.2598643000 
0.3093597773 *= 1.4427768319 * -0.1994209700 
0.3018679305 *= 0.0459917808 * -0.1628953400 
0.2620449426 *= 0.1422804870 * -0.2798907200 
1.2727135249 *= 3.9359257262 * 0.2567804000 
0.9452947844 *= 1.1451209450 * -0.2859250300 
1.4242434623 *= 1.5617860946 * 0.3066672700 
1.3998794838 *= 0.3861379236 * -0.0630965700 
1.5093946330 *= 0.5765789045 * 0.1899395700 
1.5093946330 *= 0.0000000000 * 0.1644536600 
1.5093946330 *= 0.0000000000 * 0.1152744400 
1.5093946330 *= 0.0000000000 * 0.1194199900 
1.4454455909 *= 0.4579760541 * -0.1396340300 
1.4454455909 *= 0.0000000000 * -0.1022604300 
1.4454455909 *= 0.0000000000 * -0.0698967500 
1.4454455909 *= 0.0000000000 * 0.1394481700 
1.4454455909 *= 0.0000000000 * 0.1891660100 
2.0103351865 *= 2.0909211580 * 0.2701630300 
2.0103351865 *= 0.0000000000 * 0.2537862700 
2.3398922359 *= 1.6390667237 * 0.2010638400 
2.3083910580 *= 0.1321062890 * -0.2384532800 
3.0005337405 *= 2.5002610194 * 0.2768281700 
3.0005337405 *= 0.0000000000 * 0.1051809000 
3.0790086266 *= 2.9280981199 * 0.0268006340 
3.0790086266 *= 0.0000000000 * 0.1581953800 
3.0790086266 *= 0.0000000000 * -0.2444492600 
3.1841933848 *= 0.3564454067 * 0.2950936000 
2.7181197288 *= 2.8988464104 * -0.1607790100 
2.4476021959 *= 0.9837076316 * -0.2749979000 
2.5468401435 *= 0.3125866728 * 0.3174733800 
tempVal = 2.5468401435 + 0.0071175450(biases), 
now the tempVal = 2.5539576885 

compute layer: 2, node : 4
0.2817893664 *= 2.2976597117 * 0.1226419060 
0.3084327943 *= 1.4427768319 * 0.0184667700 
0.3015304131 *= 0.0459917808 * -0.1500785800 
0.2813081487 *= 0.1422804870 * -0.1421295700 
-0.5556245787 *= 3.9359257262 * -0.2126393600 
-0.2510530966 *= 1.1451209450 * 0.2659732000 
-0.3017509144 *= 1.5617860946 * -0.0324614350 
-0.3032939023 *= 0.3861379236 * -0.0039959503 
-0.1469486397 *= 0.5765789045 * 0.2711602200 
-0.1469486397 *= 0.0000000000 * 0.1815747200 
-0.1469486397 *= 0.0000000000 * -0.1734394400 
-0.1469486397 *= 0.0000000000 * -0.0762120560 
-0.1477410696 *= 0.4579760541 * -0.0017302866 
-0.1477410696 *= 0.0000000000 * 0.2497875400 
-0.1477410696 *= 0.0000000000 * 0.0154520420 
-0.1477410696 *= 0.0000000000 * 0.2686563400 
-0.1477410696 *= 0.0000000000 * -0.2569811600 
-0.4451428641 *= 2.0909211580 * -0.1422348200 
-0.4451428641 *= 0.0000000000 * 0.3100218500 
-0.3514138006 *= 1.6390667237 * 0.0571844100 
-0.3826657507 *= 0.1321062890 * -0.2365667100 
0.3237720742 *= 2.5002610194 * 0.2825456300 
0.3237720742 *= 0.0000000000 * -0.1303538400 
-0.3784785878 *= 2.9280981199 * -0.2398316700 
-0.3784785878 *= 0.0000000000 * 0.1555800100 
-0.3784785878 *= 0.0000000000 * -0.0727127000 
-0.3887823000 *= 0.3564454067 * -0.0289068450 
-0.8968262080 *= 2.8988464104 * -0.1752572700 
-0.8091949253 *= 0.9837076316 * 0.0890826500 
-0.7152398520 *= 0.3125866728 * 0.3005728700 
tempVal = -0.7152398520 + 0.0000000000(biases), 
now the tempVal = -0.7152398520 
ReLU !!! in layer: 2, node : 4, its linear result is negative,so set it to 0

compute layer: 2, node : 5
0.0559842136 *= 2.2976597117 * 0.0243657550 
-0.1583824716 *= 1.4427768319 * -0.1485792400 
-0.1495959272 *= 0.0459917808 * 0.1910459700 
-0.1676059079 *= 0.1422804870 * -0.1265808200 
-0.4794639448 *= 3.9359257262 * -0.0792337200 
-0.1550698695 *= 1.1451209450 * 0.2832836800 
0.1858335507 *= 1.5617860946 * 0.2182779200 
0.1166698310 *= 0.3861379236 * -0.1791166200 
0.2070251825 *= 0.5765789045 * 0.1567094300 
0.2070251825 *= 0.0000000000 * 0.2812507200 
0.2070251825 *= 0.0000000000 * -0.1721058500 
0.2070251825 *= 0.0000000000 * 0.1271396400 
0.3075803055 *= 0.4579760541 * 0.2195641500 
0.3075803055 *= 0.0000000000 * -0.0150713000 
0.3075803055 *= 0.0000000000 * 0.0548167940 
0.3075803055 *= 0.0000000000 * 0.0517494400 
0.3075803055 *= 0.0000000000 * 0.2466448700 
0.7467889166 *= 2.0909211580 * 0.2100550800 
0.7467889166 *= 0.0000000000 * -0.0782276540 
0.8789514559 *= 1.6390667237 * 0.0806328000 
0.8482719554 *= 0.1321062890 * -0.2322334600 
0.3376359466 *= 2.5002610194 * -0.2042330800 
0.3376359466 *= 0.0000000000 * 0.1939293900 
-0.5866000708 *= 2.9280981199 * -0.3156438000 
-0.5866000708 *= 0.0000000000 * 0.0336991900 
-0.5866000708 *= 0.0000000000 * -0.0282195860 
-0.5007224310 *= 0.3564454067 * 0.2409278900 
-0.7266040799 *= 2.8988464104 * -0.0779212200 
-0.4387659149 *= 0.9837076316 * 0.2926054000 
-0.3817377367 *= 0.3125866728 * 0.1824395700 
tempVal = -0.3817377367 + 0.0000000000(biases), 
now the tempVal = -0.3817377367 
ReLU !!! in layer: 2, node : 5, its linear result is negative,so set it to 0

compute layer: 2, node : 6
0.6131404889 *= 2.2976597117 * 0.2668543500 
0.9130839092 *= 1.4427768319 * 0.2078931500 
0.9038286732 *= 0.0459917808 * -0.2012367400 
0.8869590620 *= 0.1422804870 * -0.1185658800 
1.7607035582 *= 3.9359257262 * 0.2219921200 
1.9758835327 *= 1.1451209450 * 0.1879102600 
2.1106680934 *= 1.5617860946 * 0.0863015500 
2.2076029414 *= 0.3861379236 * 0.2510368500 
2.0797322529 *= 0.5765789045 * -0.2217748300 
2.0797322529 *= 0.0000000000 * 0.1431836000 
2.0797322529 *= 0.0000000000 * -0.0865452500 
2.0797322529 *= 0.0000000000 * 0.2815425400 
2.1052233118 *= 0.4579760541 * 0.0556602440 
2.1052233118 *= 0.0000000000 * 0.1619729800 
2.1052233118 *= 0.0000000000 * 0.0656055660 
2.1052233118 *= 0.0000000000 * 0.0804359240 
2.1052233118 *= 0.0000000000 * 0.1446280200 
2.0951861722 *= 2.0909211580 * -0.0048003434 
2.0951861722 *= 0.0000000000 * -0.1388121400 
2.2248527473 *= 1.6390667237 * 0.0791100040 
2.2303864100 *= 0.1321062890 * 0.0418879580 
2.4893659716 *= 2.5002610194 * 0.1035810100 
2.4893659716 *= 0.0000000000 * 0.1213127750 
1.9873540023 *= 2.9280981199 * -0.1714464300 
1.9873540023 *= 0.0000000000 * -0.1293028000 
1.9873540023 *= 0.0000000000 * 0.0910887500 
1.9510140758 *= 0.3564454067 * -0.1019508900 
2.1099645614 *= 2.8988464104 * 0.0548323240 
1.8642963194 *= 0.9837076316 * -0.2497370500 
1.9218159276 *= 0.3125866728 * 0.1840117100 
tempVal = 1.9218159276 + 0.0144207600(biases), 
now the tempVal = 1.9362366876 

compute layer: 2, node : 7
-0.4311787296 *= 2.2976597117 * -0.1876599600 
-0.6241333658 *= 1.4427768319 * -0.1337383800 
-0.6328254127 *= 0.0459917808 * -0.1889913100 
-0.6171288985 *= 0.1422804870 * 0.1103209200 
0.5822858213 *= 3.9359257262 * 0.3047351000 
0.2180447549 *= 1.1451209450 * -0.3180808700 
0.7092623246 *= 1.5617860946 * 0.3145229500 
0.6074689271 *= 0.3861379236 * -0.2636192700 
0.7115968978 *= 0.5765789045 * 0.1805962200 
0.7115968978 *= 0.0000000000 * -0.0663901400 
0.7115968978 *= 0.0000000000 * -0.1829755600 
0.7115968978 *= 0.0000000000 * 0.0787592100 
0.6279748073 *= 0.4579760541 * -0.1825905300 
0.6279748073 *= 0.0000000000 * -0.2827446500 
0.6279748073 *= 0.0000000000 * -0.0086836460 
0.6279748073 *= 0.0000000000 * -0.1819625500 
0.6279748073 *= 0.0000000000 * -0.2484198500 
1.2718612233 *= 2.0909211580 * 0.3079439000 
1.2718612233 *= 0.0000000000 * -0.2199748200 
0.8733405889 *= 1.6390667237 * -0.2431387500 
0.8551566827 *= 0.1321062890 * -0.1376460300 
1.3103719807 *= 2.5002610194 * 0.1820671100 
1.3103719807 *= 0.0000000000 * 0.3071513000 
1.4975955408 *= 2.9280981199 * 0.0639403300 
1.4975955408 *= 0.0000000000 * -0.0002884973 
1.4975955408 *= 0.0000000000 * 0.1677254100 
1.4043522847 *= 0.3564454067 * -0.2615919700 
2.2248377143 *= 2.8988464104 * 0.2830386000 
2.1706738749 *= 0.9837076316 * -0.0550609120 
2.1094981499 *= 0.3125866728 * -0.1957080400 
tempVal = 2.1094981499 + -0.0001227145(biases), 
now the tempVal = 2.1093754354 

compute layer: 2, node : 8
-0.6588578284 *= 2.2976597117 * -0.2867517000 
-1.0595947491 *= 1.4427768319 * -0.2777539200 
-1.0733134750 *= 0.0459917808 * -0.2982864700 
-1.0994706342 *= 0.1422804870 * -0.1838422100 
-0.8794046158 *= 3.9359257262 * 0.0559121370 
-1.0687196863 *= 1.1451209450 * -0.1653232100 
-1.3395804673 *= 1.5617860946 * -0.1734301400 
-1.4489656028 *= 0.3861379236 * -0.2832799600 
-1.4196930015 *= 0.5765789045 * 0.0507694630 
-1.4196930015 *= 0.0000000000 * 0.1268219400 
-1.4196930015 *= 0.0000000000 * 0.2649391300 
-1.4196930015 *= 0.0000000000 * -0.2156950000 
-1.4902554468 *= 0.4579760541 * -0.1540745300 
-1.4902554468 *= 0.0000000000 * -0.0585299580 
-1.4902554468 *= 0.0000000000 * -0.2100373400 
-1.4902554468 *= 0.0000000000 * 0.2159965500 
-1.4902554468 *= 0.0000000000 * 0.1034958300 
-1.0432467379 *= 2.0909211580 * 0.2137855400 
-1.0432467379 *= 0.0000000000 * 0.2464287100 
-0.5978486641 *= 1.6390667237 * 0.2717388300 
-0.5992810244 *= 0.1321062890 * -0.0108424840 
-0.4629938140 *= 2.5002610194 * 0.0545091930 
-0.4629938140 *= 0.0000000000 * -0.2498400700 
0.2044193614 *= 2.9280981199 * 0.2279340200 
0.2044193614 *= 0.0000000000 * -0.3017967000 
0.2044193614 *= 0.0000000000 * -0.0150284385 
0.3144926972 *= 0.3564454067 * 0.3088084000 
-0.3676685942 *= 2.8988464104 * -0.2353216400 
-0.5039016838 *= 0.9837076316 * -0.1384894100 
-0.5731037500 *= 0.3125866728 * -0.2213852100 
tempVal = -0.5731037500 + -0.0035445557(biases), 
now the tempVal = -0.5766483057 
ReLU !!! in layer: 2, node : 8, its linear result is negative,so set it to 0

compute layer: 2, node : 9
-0.3755234834 *= 2.2976597117 * -0.1634373800 
-0.0926338439 *= 1.4427768319 * 0.1960730400 
-0.0998149978 *= 0.0459917808 * -0.1561399400 
-0.0816936186 *= 0.1422804870 * 0.1273637700 
-0.5156576899 *= 3.9359257262 * -0.1102571800 
-0.1843321745 *= 1.1451209450 * 0.2893367000 
-0.5843586941 *= 1.5617860946 * -0.2561340000 
-0.5962580462 *= 0.3861379236 * -0.0308163260 
-0.5806768985 *= 0.5765789045 * 0.0270234440 
-0.5806768985 *= 0.0000000000 * 0.1280324300 
-0.5806768985 *= 0.0000000000 * 0.1414850500 
-0.5806768985 *= 0.0000000000 * -0.1485825300 
-0.6930689439 *= 0.4579760541 * -0.2454103100 
-0.6930689439 *= 0.0000000000 * 0.2108393500 
-0.6930689439 *= 0.0000000000 * 0.1446570200 
-0.6930689439 *= 0.0000000000 * -0.1430520400 
-0.6930689439 *= 0.0000000000 * -0.2057748100 
-0.2529302283 *= 2.0909211580 * 0.2104999100 
-0.2529302283 *= 0.0000000000 * 0.0233358650 
-0.1605168928 *= 1.6390667237 * 0.0563816800 
-0.1796779377 *= 0.1321062890 * -0.1450426400 
0.1501366689 *= 2.5002610194 * 0.1319120700 
0.1501366689 *= 0.0000000000 * 0.0673061700 
-0.0689657396 *= 2.9280981199 * -0.0748275500 
-0.0689657396 *= 0.0000000000 * -0.1432979600 
-0.0689657396 *= 0.0000000000 * -0.2430196300 
0.0024713949 *= 0.3564454067 * 0.2004153600 
0.3176544860 *= 2.8988464104 * 0.1087270750 
0.5870415814 *= 0.9837076316 * 0.2738487400 
0.5208080633 *= 0.3125866728 * -0.2118884900 
tempVal = 0.5208080633 + 0.0208568900(biases), 
now the tempVal = 0.5416649533 

compute layer: 2, node : 10
-0.6495366824 *= 2.2976597117 * -0.2826949000 
-1.0178884717 *= 1.4427768319 * -0.2553075300 
-1.0077235983 *= 0.0459917808 * 0.2210150000 
-1.0122578415 *= 0.1422804870 * -0.0318683420 
-0.8420455847 *= 3.9359257262 * 0.0432458000 
-1.1852313925 *= 1.1451209450 * -0.2996939400 
-1.4457876807 *= 1.5617860946 * -0.1668322500 
-1.3745969763 *= 0.3861379236 * 0.1843660000 
-1.3319454167 *= 0.5765789045 * 0.0739735000 
-1.3319454167 *= 0.0000000000 * -0.2382500300 
-1.3319454167 *= 0.0000000000 * -0.2333497100 
-1.3319454167 *= 0.0000000000 * -0.1784216900 
-1.4484760955 *= 0.4579760541 * -0.2544471000 
-1.4484760955 *= 0.0000000000 * 0.0222043060 
-1.4484760955 *= 0.0000000000 * 0.1421338200 
-1.4484760955 *= 0.0000000000 * 0.1475157000 
-1.4484760955 *= 0.0000000000 * 0.1600137500 
-0.8745346723 *= 2.0909211580 * 0.2744921400 
-0.8745346723 *= 0.0000000000 * -0.0890534500 
-0.3661975673 *= 1.6390667237 * 0.3101381400 
-0.3722503785 *= 0.1321062890 * -0.0458177370 
-0.9786701868 *= 2.5002610194 * -0.2425426000 
-0.9786701868 *= 0.0000000000 * -0.0713712600 
-1.6118105886 *= 2.9280981199 * -0.2162292300 
-1.6118105886 *= 0.0000000000 * -0.0032721057 
-1.6118105886 *= 0.0000000000 * -0.2514814700 
-1.6676105558 *= 0.3564454067 * -0.1565456200 
-2.2539038947 *= 2.8988464104 * -0.2022505700 
-2.0673798641 *= 0.9837076316 * 0.1896132800 
-2.1578969123 *= 0.3125866728 * -0.2895742400 
tempVal = -2.1578969123 + 0.0000000000(biases), 
now the tempVal = -2.1578969123 
ReLU !!! in layer: 2, node : 10, its linear result is negative,so set it to 0

compute layer: 2, node : 11
0.6789605127 *= 2.2976597117 * 0.2955009000 
0.4941376553 *= 1.4427768319 * -0.1281021800 
0.4914727959 *= 0.0459917808 * -0.0579420780 
0.4879111851 *= 0.1422804870 * -0.0250323210 
1.8840134809 *= 3.9359257262 * 0.3547074800 
1.5409579650 *= 1.1451209450 * -0.2995801600 
1.2770392763 *= 1.5617860946 * -0.1689851700 
1.3259703960 *= 0.3861379236 * 0.1267192800 
1.3069294715 *= 0.5765789045 * -0.0330239700 
1.3069294715 *= 0.0000000000 * -0.1043385500 
1.3069294715 *= 0.0000000000 * 0.0957048300 
1.3069294715 *= 0.0000000000 * -0.1069726900 
1.3509794540 *= 0.4579760541 * 0.0961840300 
1.3509794540 *= 0.0000000000 * 0.1472951000 
1.3509794540 *= 0.0000000000 * 0.0350316900 
1.3509794540 *= 0.0000000000 * 0.1922731300 
1.3509794540 *= 0.0000000000 * 0.1676344400 
1.0192598096 *= 2.0909211580 * -0.1586476100 
1.0192598096 *= 0.0000000000 * -0.2024558300 
1.5332058338 *= 1.6390667237 * 0.3135601600 
1.5062865115 *= 0.1321062890 * -0.2037701800 
1.7260286019 *= 2.5002610194 * 0.0878876600 
1.7260286019 *= 0.0000000000 * -0.1529011700 
1.3271719188 *= 2.9280981199 * -0.1362169800 
1.3271719188 *= 0.0000000000 * -0.1744269000 
1.3271719188 *= 0.0000000000 * 0.2521501800 
1.2703313414 *= 0.3564454067 * -0.1594650300 
2.2376093382 *= 2.8988464104 * 0.3336768700 
2.1848694176 *= 0.9837076316 * -0.0536134100 
2.2231069637 *= 0.3125866728 * 0.1223262200 
tempVal = 2.2231069637 + 0.0093604600(biases), 
now the tempVal = 2.2324674237 

compute layer: 2, node : 12
0.6000293303 *= 2.2976597117 * 0.2611480400 
0.3949497563 *= 1.4427768319 * -0.1421422700 
0.4092832227 *= 0.0459917808 * 0.3116527800 
0.4432635307 *= 0.1422804870 * 0.2388262000 
0.5044710723 *= 3.9359257262 * 0.0155509900 
0.7122226816 *= 1.1451209450 * 0.1814232900 
1.0881079551 *= 1.5617860946 * 0.2406765400 
0.9922963244 *= 0.3861379236 * -0.2481280000 
0.9102015785 *= 0.5765789045 * -0.1423825000 
0.9102015785 *= 0.0000000000 * -0.0890109100 
0.9102015785 *= 0.0000000000 * 0.0203789380 
0.9102015785 *= 0.0000000000 * -0.0951307300 
0.8188097686 *= 0.4579760541 * -0.1995558700 
0.8188097686 *= 0.0000000000 * -0.1871898800 
0.8188097686 *= 0.0000000000 * 0.2770354700 
0.8188097686 *= 0.0000000000 * -0.2156212300 
0.8188097686 *= 0.0000000000 * -0.2203951200 
0.7725831462 *= 2.0909211580 * -0.0221082570 
0.7725831462 *= 0.0000000000 * 0.2460570500 
1.1356611263 *= 1.6390667237 * 0.2215150700 
1.1483720255 *= 0.1321062890 * 0.0962172150 
1.4754290692 *= 2.5002610194 * 0.1308091600 
1.4754290692 *= 0.0000000000 * -0.0724161900 
1.9565245503 *= 2.9280981199 * 0.1643030600 
1.9565245503 *= 0.0000000000 * -0.2510309200 
1.9565245503 *= 0.0000000000 * -0.1723058200 
2.0048886528 *= 0.3564454067 * 0.1356844600 
2.5399394895 *= 2.8988464104 * 0.1845737100 
2.8457560231 *= 0.9837076316 * 0.3108815300 
2.7944873700 *= 0.3125866728 * -0.1640142000 
tempVal = 2.7944873700 + 0.0084300220(biases), 
now the tempVal = 2.8029173920 

compute layer: 2, node : 13
-0.3086671921 *= 2.2976597117 * -0.1343398200 
-0.5371157543 *= 1.4427768319 * -0.1583395000 
-0.5395349334 *= 0.0459917808 * -0.0526002500 
-0.5821540189 *= 0.1422804870 * -0.2995427300 
-0.2932703898 *= 3.9359257262 * 0.0733966160 
-0.5678462533 *= 1.1451209450 * -0.2397789200 
-0.1468686388 *= 1.5617860946 * 0.2695488300 
-0.2190670357 *= 0.3861379236 * -0.1869756700 
-0.2237326402 *= 0.5765789045 * -0.0080918750 
-0.2237326402 *= 0.0000000000 * -0.0755485150 
-0.2237326402 *= 0.0000000000 * -0.0946308300 
-0.2237326402 *= 0.0000000000 * 0.3161260000 
-0.0973661241 *= 0.4579760541 * 0.2759238500 
-0.0973661241 *= 0.0000000000 * 0.0141116400 
-0.0973661241 *= 0.0000000000 * -0.1483579700 
-0.0973661241 *= 0.0000000000 * -0.1319868300 
-0.0973661241 *= 0.0000000000 * 0.1435397000 
-0.2076218479 *= 2.0909211580 * -0.0527306940 
-0.2076218479 *= 0.0000000000 * 0.0200707520 
-0.2203870364 *= 1.6390667237 * -0.0077880835 
-0.1881866753 *= 0.1321062890 * 0.2437458600 
0.4155736803 *= 2.5002610194 * 0.2414789300 
0.4155736803 *= 0.0000000000 * -0.3123240800 
-0.0902180537 *= 2.9280981199 * -0.1727372900 
-0.0902180537 *= 0.0000000000 * 0.2173375200 
-0.0902180537 *= 0.0000000000 * 0.2384426100 
-0.0173362175 *= 0.3564454067 * 0.2044684400 
-0.5049552306 *= 2.8988464104 * -0.1682114000 
-0.4729968676 *= 0.9837076316 * 0.0324876640 
-0.3857694190 *= 0.3125866728 * 0.2790504400 
tempVal = -0.3857694190 + -0.0094779720(biases), 
now the tempVal = -0.3952473910 
ReLU !!! in layer: 2, node : 13, its linear result is negative,so set it to 0

compute layer: 2, node : 14
0.3091708851 *= 2.2976597117 * 0.1345590400 
-0.0535132296 *= 1.4427768319 * -0.2513792200 
-0.0614330234 *= 0.0459917808 * -0.1722002000 
-0.0958753162 *= 0.1422804870 * -0.2420732000 
0.1364745217 *= 3.9359257262 * 0.0590330850 
-0.0705267013 *= 1.1451209450 * -0.1807680000 
-0.1830595116 *= 1.5617860946 * -0.0720539200 
-0.1885655681 *= 0.3861379236 * -0.0142593000 
-0.0169790187 *= 0.5765789045 * 0.2975942200 
-0.0169790187 *= 0.0000000000 * 0.1052712600 
-0.0169790187 *= 0.0000000000 * -0.2881412000 
-0.0169790187 *= 0.0000000000 * 0.2350095200 
0.0868712833 *= 0.4579760541 * 0.2267592400 
0.0868712833 *= 0.0000000000 * -0.2649733700 
0.0868712833 *= 0.0000000000 * -0.0164043510 
0.0868712833 *= 0.0000000000 * -0.1269062200 
0.0868712833 *= 0.0000000000 * 0.1673794500 
0.1734283017 *= 2.0909211580 * 0.0413965960 
0.1734283017 *= 0.0000000000 * 0.2559967300 
0.0530779262 *= 1.6390667237 * -0.0734261600 
0.0564789658 *= 0.1321062890 * 0.0257447210 
-0.6584239179 *= 2.5002610194 * -0.2859313000 
-0.6584239179 *= 0.0000000000 * 0.3091102800 
-1.0196441453 *= 2.9280981199 * -0.1233634300 
-1.0196441453 *= 0.0000000000 * -0.2017066600 
-1.0196441453 *= 0.0000000000 * 0.3157442000 
-1.0289867477 *= 0.3564454067 * -0.0262104720 
-0.4533021431 *= 2.8988464104 * 0.1985909300 
-0.3374602996 *= 0.9837076316 * 0.1177604400 
-0.4080038002 *= 0.3125866728 * -0.2256766100 
tempVal = -0.4080038002 + 0.0000000000(biases), 
now the tempVal = -0.4080038002 
ReLU !!! in layer: 2, node : 14, its linear result is negative,so set it to 0

compute layer: 2, node : 15
-0.6436253325 *= 2.2976597117 * -0.2801221300 
-0.3067172194 *= 1.4427768319 * 0.2335136700 
-0.3138844516 *= 0.0459917808 * -0.1558372400 
-0.3355972735 *= 0.1422804870 * -0.1526057600 
-0.0785452705 *= 3.9359257262 * 0.0653091600 
-0.4356698454 *= 1.1451209450 * -0.3118662500 
-0.3432832698 *= 1.5617860946 * 0.0591544360 
-0.3106172989 *= 0.3861379236 * 0.0845966400 
-0.2507397215 *= 0.5765789045 * 0.1038497540 
-0.2507397215 *= 0.0000000000 * -0.2658895300 
-0.2507397215 *= 0.0000000000 * -0.1368562100 
-0.2507397215 *= 0.0000000000 * 0.0156559850 
-0.1548846510 *= 0.4579760541 * 0.2093014900 
-0.1548846510 *= 0.0000000000 * 0.1700489500 
-0.1548846510 *= 0.0000000000 * 0.0927003300 
-0.1548846510 *= 0.0000000000 * -0.2412170800 
-0.1548846510 *= 0.0000000000 * 0.2946268300 
0.5317144751 *= 2.0909211580 * 0.3283716000 
0.5317144751 *= 0.0000000000 * -0.2031963200 
0.1050745201 *= 1.6390667237 * -0.2602944400 
0.0663573202 *= 0.1321062890 * -0.2930761300 
0.6397944352 *= 2.5002610194 * 0.2293509000 
0.6397944352 *= 0.0000000000 * 0.1376462100 
1.4642073126 *= 2.9280981199 * 0.2815523400 
1.4642073126 *= 0.0000000000 * 0.2671082000 
1.4642073126 *= 0.0000000000 * 0.2166216500 
1.3909251882 *= 0.3564454067 * -0.2055914400 
1.6971551371 *= 2.8988464104 * 0.1056385560 
1.7643582886 *= 0.9837076316 * 0.0683161840 
1.7907734160 *= 0.3125866728 * 0.0845049700 
tempVal = 1.7907734160 + 0.0047249250(biases), 
now the tempVal = 1.7954983410 

compute layer: 2, node : 16
-0.2796303796 *= 2.2976597117 * -0.1217022600 
0.1498386915 *= 1.4427768319 * 0.2976684000 
0.1361633924 *= 0.0459917808 * -0.2973422400 
0.1001508978 *= 0.1422804870 * -0.2531091600 
-0.4780798866 *= 3.9359257262 * -0.1469110000 
-0.2111600842 *= 1.1451209450 * 0.2330931100 
-0.3796591712 *= 1.5617860946 * -0.1078887100 
-0.3221567318 *= 0.3861379236 * 0.1489168400 
-0.1711435671 *= 0.5765789045 * 0.2619124000 
-0.1711435671 *= 0.0000000000 * 0.1563158800 
-0.1711435671 *= 0.0000000000 * -0.0255390630 
-0.1711435671 *= 0.0000000000 * 0.2188428500 
-0.2235609370 *= 0.4579760541 * -0.1144543900 
-0.2235609370 *= 0.0000000000 * 0.0281102640 
-0.2235609370 *= 0.0000000000 * -0.2746119800 
-0.2235609370 *= 0.0000000000 * -0.0335616880 
-0.2235609370 *= 0.0000000000 * -0.2591547000 
-0.2959003544 *= 2.0909211580 * -0.0345969130 
-0.2959003544 *= 0.0000000000 * 0.3142493700 
-0.5924380114 *= 1.6390667237 * -0.1809186000 
-0.6106868029 *= 0.1321062890 * -0.1381371900 
-1.1633814775 *= 2.5002610194 * -0.2210547900 
-1.1633814775 *= 0.0000000000 * -0.3129470300 
-0.7999918222 *= 2.9280981199 * 0.1241043300 
-0.7999918222 *= 0.0000000000 * -0.1458044500 
-0.7999918222 *= 0.0000000000 * 0.1207640540 
-0.6948105927 *= 0.3564454067 * 0.2950837000 
-1.1453525485 *= 2.8988464104 * -0.1554211200 
-1.3412028358 *= 0.9837076316 * -0.1990940000 
-1.2985556732 *= 0.3125866728 * 0.1364330800 
tempVal = -1.2985556732 + 0.0000000000(biases), 
now the tempVal = -1.2985556732 
ReLU !!! in layer: 2, node : 16, its linear result is negative,so set it to 0

compute layer: 2, node : 17
-0.1712172591 *= 2.2976597117 * -0.0745181100 
0.2381972429 *= 1.4427768319 * 0.2837684200 
0.2313624457 *= 0.0459917808 * -0.1486091000 
0.2645712592 *= 0.1422804870 * 0.2334038500 
0.7197197028 *= 3.9359257262 * 0.1156394900 
1.0638391964 *= 1.1451209450 * 0.3005093000 
0.6491506759 *= 1.5617860946 * -0.2655219700 
0.7258420695 *= 0.3861379236 * 0.1986114000 
0.7404557074 *= 0.5765789045 * 0.0253454260 
0.7404557074 *= 0.0000000000 * 0.2725902800 
0.7404557074 *= 0.0000000000 * -0.1250904500 
0.7404557074 *= 0.0000000000 * 0.0746794200 
0.7950111362 *= 0.4579760541 * 0.1191228850 
0.7950111362 *= 0.0000000000 * 0.0503614660 
0.7950111362 *= 0.0000000000 * -0.1078470600 
0.7950111362 *= 0.0000000000 * -0.2345464000 
0.7950111362 *= 0.0000000000 * 0.0055865496 
1.4286066237 *= 2.0909211580 * 0.3030221800 
1.4286066237 *= 0.0000000000 * -0.1936805400 
1.4277173869 *= 1.6390667237 * -0.0005425263 
1.4338053792 *= 0.1321062890 * 0.0460840460 
0.6997446956 *= 2.5002610194 * -0.2935936200 
0.6997446956 *= 0.0000000000 * -0.0341691040 
1.5729959072 *= 2.9280981199 * 0.2982315400 
1.5729959072 *= 0.0000000000 * 0.2662086000 
1.5729959072 *= 0.0000000000 * -0.1105619200 
1.6063576481 *= 0.3564454067 * 0.0935956540 
1.2491670403 *= 2.8988464104 * -0.1232181900 
1.2204765629 *= 0.9837076316 * -0.0291656550 
1.2937602296 *= 0.3125866728 * 0.2344427100 
tempVal = 1.2937602296 + 0.0111615470(biases), 
now the tempVal = 1.3049217766 

compute layer: 2, node : 18
0.4882341007 *= 2.2976597117 * 0.2124919100 
0.7970625159 *= 1.4427768319 * 0.2140514100 
0.7946474474 *= 0.0459917808 * -0.0525108700 
0.8255167969 *= 0.1422804870 * 0.2169612300 
-0.2744895457 *= 3.9359257262 * -0.2794784300 
-0.5725700013 *= 1.1451209450 * -0.2603047800 
-0.5613100212 *= 1.5617860946 * 0.0072096814 
-0.5309691388 *= 0.3861379236 * 0.0785752460 
-0.6220109767 *= 0.5765789045 * -0.1579000500 
-0.6220109767 *= 0.0000000000 * -0.3010818000 
-0.6220109767 *= 0.0000000000 * -0.0037707277 
-0.6220109767 *= 0.0000000000 * -0.1684177700 
-0.6140535131 *= 0.4579760541 * 0.0173752830 
-0.6140535131 *= 0.0000000000 * -0.1968935900 
-0.6140535131 *= 0.0000000000 * -0.0136640220 
-0.6140535131 *= 0.0000000000 * 0.2075465900 
-0.6140535131 *= 0.0000000000 * -0.1653104600 
-0.5323298597 *= 2.0909211580 * 0.0390850000 
-0.5323298597 *= 0.0000000000 * -0.1828656600 
-0.1779896296 *= 1.6390667237 * 0.2161841400 
-0.1923647794 *= 0.1321062890 * -0.1088150300 
-0.8013110015 *= 2.5002610194 * -0.2435530600 
-0.8013110015 *= 0.0000000000 * 0.2179920000 
-0.6919603866 *= 2.9280981199 * 0.0373452700 
-0.6919603866 *= 0.0000000000 * -0.1614015300 
-0.6919603866 *= 0.0000000000 * 0.1990394400 
-0.6725561802 *= 0.3564454067 * 0.0544380880 
-0.8922160930 *= 2.8988464104 * -0.0757749400 
-1.0864050948 *= 0.9837076316 * -0.1974052000 
-1.0207396779 *= 0.3125866728 * 0.2100710700 
tempVal = -1.0207396779 + 0.0000000000(biases), 
now the tempVal = -1.0207396779 
ReLU !!! in layer: 2, node : 18, its linear result is negative,so set it to 0

compute layer: 2, node : 19
0.5221997838 *= 2.2976597117 * 0.2272746400 
0.4179723245 *= 1.4427768319 * -0.0722408740 
0.4237876959 *= 0.0459917808 * 0.1264437100 
0.3975720836 *= 0.1422804870 * -0.1842530400 
-0.5817831002 *= 3.9359257262 * -0.2488246100 
-0.4116918277 *= 1.1451209450 * 0.1485356400 
-0.5546836837 *= 1.5617860946 * -0.0915566200 
-0.5529530498 *= 0.3861379236 * 0.0044819060 
-0.6470939705 *= 0.5765789045 * -0.1632750000 
-0.6470939705 *= 0.0000000000 * -0.0984841400 
-0.6470939705 *= 0.0000000000 * 0.1358927200 
-0.6470939705 *= 0.0000000000 * 0.2335132000 
-0.6034406914 *= 0.4579760541 * 0.0953178200 
-0.6034406914 *= 0.0000000000 * -0.1337142700 
-0.6034406914 *= 0.0000000000 * 0.2792729700 
-0.6034406914 *= 0.0000000000 * -0.2954300000 
-0.6034406914 *= 0.0000000000 * 0.2156552100 
-0.3554691094 *= 2.0909211580 * 0.1185944200 
-0.3554691094 *= 0.0000000000 * 0.0059818430 
-0.4520107787 *= 1.6390667237 * -0.0589003900 
-0.4703176732 *= 0.1321062890 * -0.1385770100 
-0.7801063142 *= 2.5002610194 * -0.1239025200 
-0.7801063142 *= 0.0000000000 * 0.0341580400 
-1.1732553141 *= 2.9280981199 * -0.1342677000 
-1.1732553141 *= 0.0000000000 * 0.1647678300 
-1.1732553141 *= 0.0000000000 * 0.2839270200 
-1.0837995577 *= 0.3564454067 * 0.2509662200 
-1.0750090741 *= 2.8988464104 * 0.0030324075 
-1.1546815226 *= 0.9837076316 * -0.0809920000 
-1.1815512136 *= 0.3125866728 * -0.0859591700 
tempVal = -1.1815512136 + 0.0000000000(biases), 
now the tempVal = -1.1815512136 
ReLU !!! in layer: 2, node : 19, its linear result is negative,so set it to 0

compute layer: 2, node : 20
0.2252419941 *= 2.2976597117 * 0.0980310500 
0.5112554041 *= 1.4427768319 * 0.1982381500 
0.5249651382 *= 0.0459917808 * 0.2980909600 
0.5266420843 *= 0.1422804870 * 0.0117861990 
0.0315373428 *= 3.9359257262 * -0.1257911800 
0.0989622794 *= 1.1451209450 * 0.0588801880 
0.5397465744 *= 1.5617860946 * 0.2822309000 
0.5716508458 *= 0.3861379236 * 0.0826240300 
0.3959650626 *= 0.5765789045 * -0.3047038000 
0.3959650626 *= 0.0000000000 * -0.0364468320 
0.3959650626 *= 0.0000000000 * -0.0332377800 
0.3959650626 *= 0.0000000000 * 0.1175910300 
0.4394123258 *= 0.4579760541 * 0.0948679800 
0.4394123258 *= 0.0000000000 * 0.1937647000 
0.4394123258 *= 0.0000000000 * -0.0024082048 
0.4394123258 *= 0.0000000000 * -0.2277438500 
0.4394123258 *= 0.0000000000 * -0.0016952470 
0.3642887067 *= 2.0909211580 * -0.0359284800 
0.3642887067 *= 0.0000000000 * 0.1472710800 
0.4628222322 *= 1.6390667237 * 0.0601156280 
0.4998485760 *= 0.1321062890 * 0.2802769200 
0.1982176617 *= 2.5002610194 * -0.1206397700 
0.1982176617 *= 0.0000000000 * 0.2862647800 
-0.7307121555 *= 2.9280981199 * -0.3172468200 
-0.7307121555 *= 0.0000000000 * -0.0915937600 
-0.7307121555 *= 0.0000000000 * -0.1175181300 
-0.7977050752 *= 0.3564454067 * -0.1879472100 
-0.7278988709 *= 2.8988464104 * 0.0240806840 
-0.9242900989 *= 0.9837076316 * -0.1996439000 
-0.9459139634 *= 0.3125866728 * -0.0691771800 
tempVal = -0.9459139634 + -0.0221108440(biases), 
now the tempVal = -0.9680248074 
ReLU !!! in layer: 2, node : 20, its linear result is negative,so set it to 0

compute layer: 2, node : 21
0.0079951421 *= 2.2976597117 * 0.0034796894 
-0.3623986236 *= 1.4427768319 * -0.2567228400 
-0.3734731446 *= 0.0459917808 * -0.2407934800 
-0.4102338922 *= 0.1422804870 * -0.2583681600 
-0.3114612064 *= 3.9359257262 * 0.0250951600 
0.0158494004 *= 1.1451209450 * 0.2858306000 
0.2560179767 *= 1.5617860946 * 0.1537781500 
0.1478185858 *= 0.3861379236 * -0.2802091800 
0.0500460887 *= 0.5765789045 * -0.1695734900 
0.0500460887 *= 0.0000000000 * 0.2109660000 
0.0500460887 *= 0.0000000000 * 0.0133077690 
0.0500460887 *= 0.0000000000 * -0.0273861180 
0.0188803831 *= 0.4579760541 * -0.0680509500 
0.0188803831 *= 0.0000000000 * 0.0712311340 
0.0188803831 *= 0.0000000000 * -0.1643662300 
0.0188803831 *= 0.0000000000 * 0.1468776200 
0.0188803831 *= 0.0000000000 * 0.1499120100 
0.5014495345 *= 2.0909211580 * 0.2307926100 
0.5014495345 *= 0.0000000000 * -0.1686482600 
0.7045408259 *= 1.6390667237 * 0.1239066650 
0.7405081912 *= 0.1321062890 * 0.2722608100 
1.4029089187 *= 2.5002610194 * 0.2649326300 
1.4029089187 *= 0.0000000000 * -0.2780499000 
0.8491822859 *= 2.9280981199 * -0.1891079500 
0.8491822859 *= 0.0000000000 * -0.0363660270 
0.8491822859 *= 0.0000000000 * 0.0543852750 
0.8718903784 *= 0.3564454067 * 0.0637070700 
1.0119632747 *= 2.8988464104 * 0.0483202200 
1.1119734112 *= 0.9837076316 * 0.1016665250 
1.1640981766 *= 0.3125866728 * 0.1667530000 
tempVal = 1.1640981766 + 0.0037858580(biases), 
now the tempVal = 1.1678840346 

compute layer: 2, node : 22
0.3050234484 *= 2.2976597117 * 0.1327539700 
0.6045812001 *= 1.4427768319 * 0.2076258400 
0.6060775730 *= 0.0459917808 * 0.0325356600 
0.5909431037 *= 0.1422804870 * -0.1063706600 
0.6299032266 *= 3.9359257262 * 0.0098985920 
0.2828239046 *= 1.1451209450 * -0.3030940300 
-0.0303861901 *= 1.5617860946 * -0.2005460900 
-0.0831992045 *= 0.3861379236 * -0.1367724100 
-0.0138196379 *= 0.5765789045 * 0.1203297000 
-0.0138196379 *= 0.0000000000 * 0.1533552700 
-0.0138196379 *= 0.0000000000 * -0.0526164030 
-0.0138196379 *= 0.0000000000 * -0.1390700600 
-0.0865030253 *= 0.4579760541 * -0.1587056500 
-0.0865030253 *= 0.0000000000 * 0.1337085500 
-0.0865030253 *= 0.0000000000 * -0.0946636600 
-0.0865030253 *= 0.0000000000 * 0.1725517500 
-0.0865030253 *= 0.0000000000 * -0.2439135900 
0.5646717564 *= 2.0909211580 * 0.3114296200 
0.5646717564 *= 0.0000000000 * 0.0627497000 
0.2156779653 *= 1.6390667237 * -0.2129222600 
0.2006558302 *= 0.1321062890 * -0.1137124900 
0.5067537609 *= 2.5002610194 * 0.1224263900 
0.5067537609 *= 0.0000000000 * 0.3043729400 
-0.3124931901 *= 2.9280981199 * -0.2797880800 
-0.3124931901 *= 0.0000000000 * -0.0184833950 
-0.3124931901 *= 0.0000000000 * 0.1611348200 
-0.2522499527 *= 0.3564454067 * 0.1690111200 
-0.7357442842 *= 2.8988464104 * -0.1667885300 
-0.6117964045 *= 0.9837076316 * 0.1260007300 
-0.6823941296 *= 0.3125866728 * -0.2258500800 
tempVal = -0.6823941296 + 0.0000000000(biases), 
now the tempVal = -0.6823941296 
ReLU !!! in layer: 2, node : 22, its linear result is negative,so set it to 0

compute layer: 2, node : 23
0.3982707741 *= 2.2976597117 * 0.1733375800 
0.2209189902 *= 1.4427768319 * -0.1229239200 
0.2234360565 *= 0.0459917808 * 0.0547286100 
0.2469858290 *= 0.1422804870 * 0.1655165300 
-0.1498401066 *= 3.9359257262 * -0.1008215000 
-0.3129704179 *= 1.1451209450 * -0.1424568400 
0.2087954224 *= 1.5617860946 * 0.3340827800 
0.2060940598 *= 0.3861379236 * -0.0069958490 
0.1981360514 *= 0.5765789045 * -0.0138021150 
0.1981360514 *= 0.0000000000 * -0.2412465500 
0.1981360514 *= 0.0000000000 * -0.0423334000 
0.1981360514 *= 0.0000000000 * 0.1865641300 
0.3176278569 *= 0.4579760541 * 0.2609127800 
0.3176278569 *= 0.0000000000 * 0.2810501000 
0.3176278569 *= 0.0000000000 * 0.2026444800 
0.3176278569 *= 0.0000000000 * -0.0682601600 
0.3176278569 *= 0.0000000000 * 0.1290528200 
0.3218709807 *= 2.0909211580 * 0.0020293084 
0.3218709807 *= 0.0000000000 * -0.1301024900 
0.3002216810 *= 1.6390667237 * -0.0132083090 
0.2946792660 *= 0.1321062890 * -0.0419542100 
-0.1376627442 *= 2.5002610194 * -0.1729187500 
-0.1376627442 *= 0.0000000000 * 0.0720806050 
0.5436478584 *= 2.9280981199 * 0.2326802500 
0.5436478584 *= 0.0000000000 * -0.1686625600 
0.5436478584 *= 0.0000000000 * 0.1502154300 
0.6321980402 *= 0.3564454067 * 0.2484256500 
1.2965880697 *= 2.8988464104 * 0.2291911800 
1.3392122738 *= 0.9837076316 * 0.0433301550 
1.3841444199 *= 0.3125866728 * 0.1437430000 
tempVal = 1.3841444199 + -0.0189021550(biases), 
now the tempVal = 1.3652422649 

compute layer: 2, node : 24
0.0237625392 *= 2.2976597117 * 0.0103420620 
-0.0872130702 *= 1.4427768319 * -0.0769180700 
-0.0965531017 *= 0.0459917808 * -0.2030804500 
-0.0772748640 *= 0.1422804870 * 0.1354946000 
0.6856997330 *= 3.9359257262 * 0.1938488300 
1.0413568354 *= 1.1451209450 * 0.3105847500 
1.2069455247 *= 1.5617860946 * 0.1060252040 
1.1426713034 *= 0.3861379236 * -0.1664540500 
0.9745537526 *= 0.5765789045 * -0.2915777000 
0.9745537526 *= 0.0000000000 * 0.0156406800 
0.9745537526 *= 0.0000000000 * -0.2604795700 
0.9745537526 *= 0.0000000000 * 0.0841005400 
1.1125158330 *= 0.4579760541 * 0.3012430000 
1.1125158330 *= 0.0000000000 * -0.0707291960 
1.1125158330 *= 0.0000000000 * -0.2851084000 
1.1125158330 *= 0.0000000000 * 0.2694641000 
1.1125158330 *= 0.0000000000 * -0.2224467500 
1.3947017225 *= 2.0909211580 * 0.1349576900 
1.3947017225 *= 0.0000000000 * 0.2350384000 
0.8823229412 *= 1.6390667237 * -0.3126039800 
0.9128746976 *= 0.1321062890 * 0.2312664800 
0.9765220922 *= 2.5002610194 * 0.0254563000 
0.9765220922 *= 0.0000000000 * -0.0548668540 
0.0588848368 *= 2.9280981199 * -0.3133902000 
0.0588848368 *= 0.0000000000 * -0.2017222300 
0.0588848368 *= 0.0000000000 * -0.1819579300 
0.0074409889 *= 0.3564454067 * -0.1443246200 
-0.7817670475 *= 2.8988464104 * -0.2722490000 
-0.7989909644 *= 0.9837076316 * -0.0175091830 
-0.7121176265 *= 0.3125866728 * 0.2779176000 
tempVal = -0.7121176265 + 0.0000000000(biases), 
now the tempVal = -0.7121176265 
ReLU !!! in layer: 2, node : 24, its linear result is negative,so set it to 0

compute layer: 2, node : 25
0.0924719252 *= 2.2976597117 * 0.0402461360 
-0.1114999713 *= 1.4427768319 * -0.1413745300 
-0.1049851987 *= 0.0459917808 * 0.1416508000 
-0.1213126210 *= 0.1422804870 * -0.1147551760 
-0.5981459688 *= 3.9359257262 * -0.1211489700 
-0.6716650924 *= 1.1451209450 * -0.0642020600 
-0.7068253297 *= 1.5617860946 * -0.0225128380 
-0.6107468391 *= 0.3861379236 * 0.2488191000 
-0.6227959031 *= 0.5765789045 * -0.0208975110 
-0.6227959031 *= 0.0000000000 * -0.1713644400 
-0.6227959031 *= 0.0000000000 * -0.0987632950 
-0.6227959031 *= 0.0000000000 * 0.2044826700 
-0.6231076057 *= 0.4579760541 * -0.0006806090 
-0.6231076057 *= 0.0000000000 * -0.1649114600 
-0.6231076057 *= 0.0000000000 * -0.0390921600 
-0.6231076057 *= 0.0000000000 * -0.0658310350 
-0.6231076057 *= 0.0000000000 * -0.1226903050 
-0.7407856020 *= 2.0909211580 * -0.0562804560 
-0.7407856020 *= 0.0000000000 * 0.1185739860 
-0.2313294077 *= 1.6390667237 * 0.3108209000 
-0.2509234482 *= 0.1321062890 * -0.1483202700 
-0.4951336680 *= 2.5002610194 * -0.0976738900 
-0.4951336680 *= 0.0000000000 * 0.0864149260 
-0.2689333447 *= 2.9280981199 * 0.0772516200 
-0.2689333447 *= 0.0000000000 * -0.3022630800 
-0.2689333447 *= 0.0000000000 * 0.0164973510 
-0.2077155855 *= 0.3564454067 * 0.1717451200 
-0.5359139607 *= 2.8988464104 * -0.1132168900 
-0.2471616362 *= 0.9837076316 * 0.2935347000 
-0.1661460913 *= 0.3125866728 * 0.2591778600 
tempVal = -0.1661460913 + -0.0000472211(biases), 
now the tempVal = -0.1661933124 
ReLU !!! in layer: 2, node : 25, its linear result is negative,so set it to 0

compute layer: 2, node : 26
0.6250296142 *= 2.2976597117 * 0.2720288000 
0.7864335201 *= 1.4427768319 * 0.1118703200 
0.7943017649 *= 0.0459917808 * 0.1710793700 
0.7509502380 *= 0.1422804870 * -0.3046906000 
-0.1570580266 *= 3.9359257262 * -0.2306975100 
0.0647879374 *= 1.1451209450 * 0.1937314700 
0.4733885064 *= 1.5617860946 * 0.2616239000 
0.4379817942 *= 0.3861379236 * -0.0916944700 
0.4220315916 *= 0.5765789045 * -0.0276635210 
0.4220315916 *= 0.0000000000 * 0.2768834500 
0.4220315916 *= 0.0000000000 * -0.2293612200 
0.4220315916 *= 0.0000000000 * 0.2979695000 
0.3774000436 *= 0.4579760541 * -0.0974538900 
0.3774000436 *= 0.0000000000 * 0.1520161200 
0.3774000436 *= 0.0000000000 * 0.1536842600 
0.3774000436 *= 0.0000000000 * -0.2375865600 
0.3774000436 *= 0.0000000000 * 0.1507029700 
0.5670387098 *= 2.0909211580 * 0.0906962300 
0.5670387098 *= 0.0000000000 * 0.2724009500 
0.8586676406 *= 1.6390667237 * 0.1779237700 
0.8776489034 *= 0.1321062890 * 0.1436817500 
1.2954153919 *= 2.5002610194 * 0.1670891500 
1.2954153919 *= 0.0000000000 * -0.2379642900 
0.6457937506 *= 2.9280981199 * -0.2218578800 
0.6457937506 *= 0.0000000000 * -0.3093050000 
0.6457937506 *= 0.0000000000 * -0.2121191600 
0.6374133648 *= 0.3564454067 * -0.0235109940 
0.3426558673 *= 2.8988464104 * -0.1016809640 
0.2242256529 *= 0.9837076316 * -0.1203916800 
0.2714063443 *= 0.3125866728 * 0.1509363500 
tempVal = 0.2714063443 + 0.0015470808(biases), 
now the tempVal = 0.2729534251 

compute layer: 2, node : 27
0.6750929540 *= 2.2976597117 * 0.2938176400 
1.1300936925 *= 1.4427768319 * 0.3153646000 
1.1435433192 *= 0.0459917808 * 0.2924354400 
1.1463781208 *= 0.1422804870 * 0.0199240370 
0.0517667517 *= 3.9359257262 * -0.2781077300 
0.2948016558 *= 1.1451209450 * 0.2122351400 
-0.2097800395 *= 1.5617860946 * -0.3230799000 
-0.0833367901 *= 0.3861379236 * 0.3274561800 
-0.1471240026 *= 0.5765789045 * -0.1106305000 
-0.1471240026 *= 0.0000000000 * -0.1011260100 
-0.1471240026 *= 0.0000000000 * 0.1780992300 
-0.1471240026 *= 0.0000000000 * -0.2338124500 
-0.0990589348 *= 0.4579760541 * 0.1049510500 
-0.0990589348 *= 0.0000000000 * -0.0683001000 
-0.0990589348 *= 0.0000000000 * -0.2570339000 
-0.0990589348 *= 0.0000000000 * 0.2785750000 
-0.0990589348 *= 0.0000000000 * -0.2807027400 
0.2144298007 *= 2.0909211580 * 0.1499285300 
0.2144298007 *= 0.0000000000 * -0.1632858200 
0.3838221901 *= 1.6390667237 * 0.1033468540 
0.3992516017 *= 0.1321062890 * 0.1167954360 
-0.2303467514 *= 2.5002610194 * -0.2518130500 
-0.2303467514 *= 0.0000000000 * 0.1748096600 
0.0899718397 *= 2.9280981199 * 0.1093947600 
0.0899718397 *= 0.0000000000 * 0.2088906200 
0.0899718397 *= 0.0000000000 * -0.0227616220 
0.1480108080 *= 0.3564454067 * 0.1628270900 
0.1950764668 *= 2.8988464104 * 0.0162359960 
-0.0735716282 *= 0.9837076316 * -0.2730975000 
-0.1550147104 *= 0.3125866728 * -0.2605456000 
tempVal = -0.1550147104 + 0.0052009290(biases), 
now the tempVal = -0.1498137814 
ReLU !!! in layer: 2, node : 27, its linear result is negative,so set it to 0

compute layer: 2, node : 28
0.1689223796 *= 2.2976597117 * 0.0735193200 
-0.2483764650 *= 1.4427768319 * -0.2892331200 
-0.2460481099 *= 0.0459917808 * 0.0506254600 
-0.2461294648 *= 0.1422804870 * -0.0005717924 
0.6745977438 *= 3.9359257262 * 0.2339290100 
0.5851726955 *= 1.1451209450 * -0.0780922300 
0.4557803887 *= 1.5617860946 * -0.0828489300 
0.3839088421 *= 0.3861379236 * -0.1861292100 
0.2404334029 *= 0.5765789045 * -0.2488392100 
0.2404334029 *= 0.0000000000 * -0.1537714900 
0.2404334029 *= 0.0000000000 * 0.3025418800 
0.2404334029 *= 0.0000000000 * 0.2787238700 
0.1722444002 *= 0.4579760541 * -0.1488920700 
0.1722444002 *= 0.0000000000 * -0.2947445500 
0.1722444002 *= 0.0000000000 * -0.2751652000 
0.1722444002 *= 0.0000000000 * -0.2203811900 
0.1722444002 *= 0.0000000000 * 0.1105712350 
0.2925097525 *= 2.0909211580 * 0.0575178800 
0.2925097525 *= 0.0000000000 * 0.1785091000 
0.1275935363 *= 1.6390667237 * -0.1006159260 
0.1548515197 *= 0.1321062890 * 0.2063337300 
-0.2627875805 *= 2.5002610194 * -0.1670382000 
-0.2627875805 *= 0.0000000000 * 0.0526135750 
-0.6862694809 *= 2.9280981199 * -0.1446269500 
-0.6862694809 *= 0.0000000000 * -0.1882319200 
-0.6862694809 *= 0.0000000000 * 0.0196304100 
-0.6015463286 *= 0.3564454067 * 0.2376890000 
-0.7504831726 *= 2.8988464104 * -0.0513779700 
-0.5843066031 *= 0.9837076316 * 0.1689288200 
-0.6404630583 *= 0.3125866728 * -0.1796508300 
tempVal = -0.6404630583 + 0.0000000000(biases), 
now the tempVal = -0.6404630583 
ReLU !!! in layer: 2, node : 28, its linear result is negative,so set it to 0

compute layer: 2, node : 29
0.5154596220 *= 2.2976597117 * 0.2243411500 
0.0647780813 *= 1.4427768319 * -0.3123709300 
0.0679434132 *= 0.0459917808 * 0.0688238600 
0.0842898974 *= 0.1422804870 * 0.1148891500 
-0.9143122388 *= 3.9359257262 * -0.2537146800 
-1.1027770684 *= 1.1451209450 * -0.1645807200 
-1.4316861588 *= 1.5617860946 * -0.2105980400 
-1.3978809381 *= 0.3861379236 * 0.0875470100 
-1.3516284645 *= 0.5765789045 * 0.0802188100 
-1.3516284645 *= 0.0000000000 * -0.1805923100 
-1.3516284645 *= 0.0000000000 * -0.2711275500 
-1.3516284645 *= 0.0000000000 * 0.1276542800 
-1.2354857097 *= 0.4579760541 * 0.2536000600 
-1.2354857097 *= 0.0000000000 * 0.1683033100 
-1.2354857097 *= 0.0000000000 * -0.1087097000 
-1.2354857097 *= 0.0000000000 * -0.1265220000 
-1.2354857097 *= 0.0000000000 * -0.0824837400 
-1.5001221425 *= 2.0909211580 * -0.1265645200 
-1.5001221425 *= 0.0000000000 * -0.2777863400 
-1.8980166370 *= 1.6390667237 * -0.2427567400 
-1.8595769038 *= 0.1321062890 * 0.2909758000 
-2.3566406457 *= 2.5002610194 * -0.1988047400 
-2.3566406457 *= 0.0000000000 * -0.3123579600 
-3.1237161206 *= 2.9280981199 * -0.2619705500 
-3.1237161206 *= 0.0000000000 * -0.1191635700 
-3.1237161206 *= 0.0000000000 * 0.2584886800 
-3.1994438919 *= 0.3564454067 * -0.2124526500 
-4.0921642258 *= 2.8988464104 * -0.3079571000 
-4.0024301451 *= 0.9837076316 * 0.0912202750 
-4.0336334677 *= 0.3125866728 * -0.0998229460 
tempVal = -4.0336334677 + 0.0000000000(biases), 
now the tempVal = -4.0336334677 
ReLU !!! in layer: 2, node : 29, its linear result is negative,so set it to 0

now we get all result in layer: 2
	node: 0, val: 0.0000000000
	node: 1, val: 2.2153137296
	node: 2, val: 0.0000000000
	node: 3, val: 2.5539576885
	node: 4, val: 0.0000000000
	node: 5, val: 0.0000000000
	node: 6, val: 1.9362366876
	node: 7, val: 2.1093754354
	node: 8, val: 0.0000000000
	node: 9, val: 0.5416649533
	node: 10, val: 0.0000000000
	node: 11, val: 2.2324674237
	node: 12, val: 2.8029173920
	node: 13, val: 0.0000000000
	node: 14, val: 0.0000000000
	node: 15, val: 1.7954983410
	node: 16, val: 0.0000000000
	node: 17, val: 1.3049217766
	node: 18, val: 0.0000000000
	node: 19, val: 0.0000000000
	node: 20, val: 0.0000000000
	node: 21, val: 1.1678840346
	node: 22, val: 0.0000000000
	node: 23, val: 1.3652422649
	node: 24, val: 0.0000000000
	node: 25, val: 0.0000000000
	node: 26, val: 0.2729534251
	node: 27, val: 0.0000000000
	node: 28, val: 0.0000000000
	node: 29, val: 0.0000000000

when compute layer[2] to layer[3]

compute layer: 3, node : 0
0.0000000000 *= 0.0000000000 * -0.1948650800 
0.1182127228 *= 2.2153137296 * 0.0533616170 
0.1182127228 *= 0.0000000000 * -0.1953479500 
0.9741875532 *= 2.5539576885 * 0.3351562300 
0.9741875532 *= 0.0000000000 * 0.0621286330 
0.9741875532 *= 0.0000000000 * 0.2385372400 
1.5972805240 *= 1.9362366876 * 0.3218062000 
2.2093968066 *= 2.1093754354 * 0.2901884000 
2.2093968066 *= 0.0000000000 * 0.0137059310 
2.2232948086 *= 0.5416649533 * 0.0256579310 
2.2232948086 *= 0.0000000000 * -0.0134179910 
1.9552652251 *= 2.2324674237 * -0.1200597960 
2.0844998334 *= 2.8029173920 * 0.0461071770 
2.0844998334 *= 0.0000000000 * 0.0522659350 
2.0844998334 *= 0.0000000000 * -0.0008472465 
2.3217514181 *= 1.7954983410 * 0.1321369000 
2.3217514181 *= 0.0000000000 * 0.2158097300 
2.1031323270 *= 1.3049217766 * -0.1675342500 
2.1031323270 *= 0.0000000000 * 0.1450318000 
2.1031323270 *= 0.0000000000 * -0.1564419700 
2.1031323270 *= 0.0000000000 * 0.0171897600 
2.1184146116 *= 1.1678840346 * 0.0130854470 
2.1184146116 *= 0.0000000000 * 0.2493456900 
2.5664813616 *= 1.3652422649 * 0.3281957800 
2.5664813616 *= 0.0000000000 * 0.2612748700 
2.5664813616 *= 0.0000000000 * -0.0294852030 
2.6265600482 *= 0.2729534251 * 0.2201060000 
2.6265600482 *= 0.0000000000 * -0.2397510300 
2.6265600482 *= 0.0000000000 * 0.0543007180 
2.6265600482 *= 0.0000000000 * -0.2114616600 
tempVal = 2.6265600482 + 0.0328206800(biases), 
now the tempVal = 2.6593807282 

compute layer: 3, node : 1
0.0000000000 *= 0.0000000000 * -0.2346922000 
0.4090805422 *= 2.2153137296 * 0.1846603200 
0.4090805422 *= 0.0000000000 * -0.1802298300 
1.0767119752 *= 2.5539576885 * 0.2614105300 
1.0767119752 *= 0.0000000000 * -0.3036995000 
1.0767119752 *= 0.0000000000 * 0.1867749100 
1.1794749763 *= 1.9362366876 * 0.0530735740 
1.1123454256 *= 2.1093754354 * -0.0318243730 
1.1123454256 *= 0.0000000000 * 0.0435047670 
1.1511678149 *= 0.5416649533 * 0.0716723300 
1.1511678149 *= 0.0000000000 * 0.1474201800 
1.2593612343 *= 2.2324674237 * 0.0484636050 
0.4523295625 *= 2.8029173920 * -0.2879256000 
0.4523295625 *= 0.0000000000 * 0.0848163700 
0.4523295625 *= 0.0000000000 * 0.0302568230 
0.4988397870 *= 1.7954983410 * 0.0259037970 
0.4988397870 *= 0.0000000000 * 0.2184289700 
0.2630457982 *= 1.3049217766 * -0.1806958800 
0.2630457982 *= 0.0000000000 * 0.2438211900 
0.2630457982 *= 0.0000000000 * 0.2723578200 
0.2630457982 *= 0.0000000000 * -0.1084939200 
0.0359910397 *= 1.1678840346 * -0.1944155000 
0.0359910397 *= 0.0000000000 * 0.0440590050 
0.0674789832 *= 1.3652422649 * 0.0230639970 
0.0674789832 *= 0.0000000000 * -0.2304730300 
0.0674789832 *= 0.0000000000 * -0.1520309200 
-0.0017193776 *= 0.2729534251 * -0.2535171000 
-0.0017193776 *= 0.0000000000 * 0.1064853740 
-0.0017193776 *= 0.0000000000 * 0.1604117600 
-0.0017193776 *= 0.0000000000 * -0.1349500000 
tempVal = -0.0017193776 + -0.0019442321(biases), 
now the tempVal = -0.0036636097 
ReLU !!! in layer: 3, node : 1, its linear result is negative,so set it to 0

compute layer: 3, node : 2
0.0000000000 *= 0.0000000000 * -0.3082922700 
0.5342134687 *= 2.2153137296 * 0.2411457400 
0.5342134687 *= 0.0000000000 * -0.2759066500 
1.0941423095 *= 2.5539576885 * 0.2192396700 
1.0941423095 *= 0.0000000000 * -0.2206899100 
1.0941423095 *= 0.0000000000 * 0.2845672400 
1.0373514922 *= 1.9362366876 * -0.0293305140 
1.4280073588 *= 2.1093754354 * 0.1851997800 
1.4280073588 *= 0.0000000000 * 0.1924210500 
1.5143575110 *= 0.5416649533 * 0.1594161700 
1.5143575110 *= 0.0000000000 * -0.1476545800 
1.7703263768 *= 2.2324674237 * 0.1146573800 
1.4978645032 *= 2.8029173920 * -0.0972065300 
1.4978645032 *= 0.0000000000 * -0.2255312200 
1.4978645032 *= 0.0000000000 * -0.1675659000 
1.9200013172 *= 1.7954983410 * 0.2351084400 
1.9200013172 *= 0.0000000000 * 0.0795266100 
2.1134401027 *= 1.3049217766 * 0.1482378400 
2.1134401027 *= 0.0000000000 * 0.2612503500 
2.1134401027 *= 0.0000000000 * -0.1829548000 
2.1134401027 *= 0.0000000000 * -0.1106266300 
2.2409491678 *= 1.1678840346 * 0.1091795600 
2.2409491678 *= 0.0000000000 * 0.0117824760 
2.3212828692 *= 1.3652422649 * 0.0588420850 
2.3212828692 *= 0.0000000000 * -0.0079484920 
2.3212828692 *= 0.0000000000 * -0.2078286100 
2.3032814789 *= 0.2729534251 * -0.0659504100 
2.3032814789 *= 0.0000000000 * -0.0846254300 
2.3032814789 *= 0.0000000000 * 0.2027942100 
2.3032814789 *= 0.0000000000 * -0.2580226400 
tempVal = 2.3032814789 + -0.0659265800(biases), 
now the tempVal = 2.2373548989 

compute layer: 3, node : 3
0.0000000000 *= 0.0000000000 * -0.1963427400 
-0.1032464598 *= 2.2153137296 * -0.0466057960 
-0.1032464598 *= 0.0000000000 * -0.0348731200 
-0.8364780837 *= 2.5539576885 * -0.2870962300 
-0.8364780837 *= 0.0000000000 * -0.2982679300 
-0.8364780837 *= 0.0000000000 * -0.3112996500 
-0.6001464938 *= 1.9362366876 * 0.1220571800 
-0.7618565430 *= 2.1093754354 * -0.0766625260 
-0.7618565430 *= 0.0000000000 * -0.2114403700 
-0.6611102091 *= 0.5416649533 * 0.1859938200 
-0.6611102091 *= 0.0000000000 * -0.1087069660 
-1.0421193074 *= 2.2324674237 * -0.1706672600 
-1.3988123522 *= 2.8029173920 * -0.1272577800 
-1.3988123522 *= 0.0000000000 * -0.1210969200 
-1.3988123522 *= 0.0000000000 * 0.2560781500 
-0.8400672015 *= 1.7954983410 * 0.3111922400 
-0.8400672015 *= 0.0000000000 * -0.2186482100 
-0.9349191599 *= 1.3049217766 * -0.0726878500 
-0.9349191599 *= 0.0000000000 * -0.0279249810 
-0.9349191599 *= 0.0000000000 * 0.2642839300 
-0.9349191599 *= 0.0000000000 * 0.2807201700 
-0.9706119453 *= 1.1678840346 * -0.0305619260 
-0.9706119453 *= 0.0000000000 * 0.1538329000 
-0.9299121730 *= 1.3652422649 * 0.0298113920 
-0.9299121730 *= 0.0000000000 * -0.0876222900 
-0.9299121730 *= 0.0000000000 * -0.2821429000 
-0.9433247740 *= 0.2729534251 * -0.0491387900 
-0.9433247740 *= 0.0000000000 * -0.1566600500 
-0.9433247740 *= 0.0000000000 * -0.0309495480 
-0.9433247740 *= 0.0000000000 * -0.0111825230 
tempVal = -0.9433247740 + 0.0000000000(biases), 
now the tempVal = -0.9433247740 
ReLU !!! in layer: 3, node : 3, its linear result is negative,so set it to 0

compute layer: 3, node : 4
0.0000000000 *= 0.0000000000 * 0.2645544400 
-0.3202321507 *= 2.2153137296 * -0.1445538600 
-0.3202321507 *= 0.0000000000 * -0.1178672760 
-1.0444508324 *= 2.5539576885 * -0.2835672200 
-1.0444508324 *= 0.0000000000 * -0.2252086800 
-1.0444508324 *= 0.0000000000 * 0.1656472400 
-0.2881498699 *= 1.9362366876 * 0.3906035700 
-0.6053909072 *= 2.1093754354 * -0.1503957200 
-0.6053909072 *= 0.0000000000 * 0.0059910403 
-0.4675296204 *= 0.5416649533 * 0.2545139500 
-0.4675296204 *= 0.0000000000 * 0.0790034100 
-0.3189921436 *= 2.2324674237 * 0.0665351150 
0.4127021540 *= 2.8029173920 * 0.2610474000 
0.4127021540 *= 0.0000000000 * -0.1972919100 
0.4127021540 *= 0.0000000000 * 0.1023569900 
0.9440744297 *= 1.7954983410 * 0.2959469600 
0.9440744297 *= 0.0000000000 * -0.1767837100 
1.2490969198 *= 1.3049217766 * 0.2337477200 
1.2490969198 *= 0.0000000000 * 0.2532421000 
1.2490969198 *= 0.0000000000 * 0.2420037000 
1.2490969198 *= 0.0000000000 * 0.3171653700 
1.3620551891 *= 1.1678840346 * 0.0967204500 
1.3620551891 *= 0.0000000000 * -0.1022890660 
1.4152768243 *= 1.3652422649 * 0.0389832900 
1.4152768243 *= 0.0000000000 * -0.0987764300 
1.4152768243 *= 0.0000000000 * 0.2824064200 
1.4443668683 *= 0.2729534251 * 0.1065751200 
1.4443668683 *= 0.0000000000 * 0.2636799800 
1.4443668683 *= 0.0000000000 * 0.1262985000 
1.4443668683 *= 0.0000000000 * -0.0756200250 
tempVal = 1.4443668683 + 0.0964481000(biases), 
now the tempVal = 1.5408149683 

compute layer: 3, node : 5
0.0000000000 *= 0.0000000000 * -0.1931785600 
-0.5733155282 *= 2.2153137296 * -0.2587965400 
-0.5733155282 *= 0.0000000000 * -0.1905742600 
-0.0925991920 *= 2.5539576885 * 0.1882240800 
-0.0925991920 *= 0.0000000000 * 0.2583391400 
-0.0925991920 *= 0.0000000000 * -0.2788337800 
0.2701516148 *= 1.9362366876 * 0.1873483800 
0.8044739204 *= 2.1093754354 * 0.2533083000 
0.8044739204 *= 0.0000000000 * 0.1507800700 
0.9682523477 *= 0.5416649533 * 0.3023611300 
0.9682523477 *= 0.0000000000 * 0.3099202500 
0.4635099704 *= 2.2324674237 * -0.2260917100 
1.2335476173 *= 2.8029173920 * 0.2747272000 
1.2335476173 *= 0.0000000000 * -0.1675955700 
1.2335476173 *= 0.0000000000 * 0.0775966640 
0.9226495385 *= 1.7954983410 * -0.1731542000 
0.9226495385 *= 0.0000000000 * -0.1717590800 
0.5574576795 *= 1.3049217766 * -0.2798572800 
0.5574576795 *= 0.0000000000 * -0.2898041300 
0.5574576795 *= 0.0000000000 * 0.1167530940 
0.5574576795 *= 0.0000000000 * 0.0769335900 
0.5298877646 *= 1.1678840346 * -0.0236067230 
0.5298877646 *= 0.0000000000 * -0.0780030800 
0.3306385744 *= 1.3652422649 * -0.1459442000 
0.3306385744 *= 0.0000000000 * -0.2047019500 
0.3306385744 *= 0.0000000000 * 0.1634298300 
0.3242495675 *= 0.2729534251 * -0.0234069490 
0.3242495675 *= 0.0000000000 * 0.2528347400 
0.3242495675 *= 0.0000000000 * 0.0571957200 
0.3242495675 *= 0.0000000000 * -0.0483722170 
tempVal = 0.3242495675 + 0.0132898940(biases), 
now the tempVal = 0.3375394615 

compute layer: 3, node : 6
0.0000000000 *= 0.0000000000 * 0.2467026600 
-0.0044610490 *= 2.2153137296 * -0.0020137324 
-0.0044610490 *= 0.0000000000 * -0.2025508100 
-0.3321971586 *= 2.5539576885 * -0.1283248000 
-0.3321971586 *= 0.0000000000 * 0.2880750300 
-0.3321971586 *= 0.0000000000 * 0.1606821300 
0.0042024349 *= 1.9362366876 * 0.1737388800 
-0.2657810622 *= 2.1093754354 * -0.1279921500 
-0.2657810622 *= 0.0000000000 * -0.2278363300 
-0.1620346954 *= 0.5416649533 * 0.1915323600 
-0.1620346954 *= 0.0000000000 * -0.0273535480 
-0.7661752960 *= 2.2324674237 * -0.2706156400 
-1.1115348004 *= 2.8029173920 * -0.1232143000 
-1.1115348004 *= 0.0000000000 * -0.1111836800 
-1.1115348004 *= 0.0000000000 * 0.2613110200 
-1.6695024644 *= 1.7954983410 * -0.3107592200 
-1.6695024644 *= 0.0000000000 * -0.1821274200 
-1.9426298998 *= 1.3049217766 * -0.2093056000 
-1.9426298998 *= 0.0000000000 * -0.0728675200 
-1.9426298998 *= 0.0000000000 * -0.1258126600 
-1.9426298998 *= 0.0000000000 * -0.1726347200 
-1.5821956604 *= 1.1678840346 * 0.3086216000 
-1.5821956604 *= 0.0000000000 * -0.2940293600 
-1.4060201977 *= 1.3652422649 * 0.1290433700 
-1.4060201977 *= 0.0000000000 * 0.2403034700 
-1.4060201977 *= 0.0000000000 * -0.0814487900 
-1.3779754627 *= 0.2729534251 * 0.1027454960 
-1.3779754627 *= 0.0000000000 * 0.1566474100 
-1.3779754627 *= 0.0000000000 * -0.1885695300 
-1.3779754627 *= 0.0000000000 * -0.2031441800 
tempVal = -1.3779754627 + -0.0053323884(biases), 
now the tempVal = -1.3833078511 
ReLU !!! in layer: 3, node : 6, its linear result is negative,so set it to 0

compute layer: 3, node : 7
0.0000000000 *= 0.0000000000 * 0.1866975300 
-0.2021826678 *= 2.2153137296 * -0.0912659300 
-0.2021826678 *= 0.0000000000 * 0.2531286500 
-0.0740721659 *= 2.5539576885 * 0.0501615600 
-0.0740721659 *= 0.0000000000 * 0.1715017000 
-0.0740721659 *= 0.0000000000 * 0.2758502000 
-0.0080665253 *= 1.9362366876 * 0.0340896550 
0.2123845124 *= 2.1093754354 * 0.1045101000 
0.2123845124 *= 0.0000000000 * 0.2132125800 
0.3045918233 *= 0.5416649533 * 0.1702294200 
0.3045918233 *= 0.0000000000 * 0.0045985790 
1.1015175055 *= 2.2324674237 * 0.3569708000 
1.8456899148 *= 2.8029173920 * 0.2654992300 
1.8456899148 *= 0.0000000000 * 0.3046218200 
1.8456899148 *= 0.0000000000 * -0.1341849400 
2.2868749732 *= 1.7954983410 * 0.2457173300 
2.2868749732 *= 0.0000000000 * -0.2720099000 
2.7668507139 *= 1.3049217766 * 0.3678195500 
2.7668507139 *= 0.0000000000 * 0.2365659800 
2.7668507139 *= 0.0000000000 * 0.2205984900 
2.7668507139 *= 0.0000000000 * -0.2832465800 
2.8491042842 *= 1.1678840346 * 0.0704295700 
2.8491042842 *= 0.0000000000 * 0.2790266600 
2.9873156962 *= 1.3652422649 * 0.1012358140 
2.9873156962 *= 0.0000000000 * -0.3037312300 
2.9873156962 *= 0.0000000000 * -0.2375122300 
2.9236708131 *= 0.2729534251 * -0.2331712200 
2.9236708131 *= 0.0000000000 * -0.0010778566 
2.9236708131 *= 0.0000000000 * 0.2712117700 
2.9236708131 *= 0.0000000000 * -0.0273389970 
tempVal = 2.9236708131 + 0.0579197400(biases), 
now the tempVal = 2.9815905531 

compute layer: 3, node : 8
0.0000000000 *= 0.0000000000 * -0.2643777400 
-0.0415722607 *= 2.2153137296 * -0.0187658570 
-0.0415722607 *= 0.0000000000 * 0.0776207150 
0.2567162468 *= 2.5539576885 * 0.1167946160 
0.2567162468 *= 0.0000000000 * -0.3055879800 
0.2567162468 *= 0.0000000000 * -0.2472482900 
0.0390547030 *= 1.9362366876 * -0.1124147400 
0.3402884285 *= 2.1093754354 * 0.1428070700 
0.3402884285 *= 0.0000000000 * -0.2688612300 
0.3003422578 *= 0.5416649533 * -0.0737470100 
0.3003422578 *= 0.0000000000 * -0.0159253890 
0.1965721310 *= 2.2324674237 * -0.0464822580 
-0.0456795458 *= 2.8029173920 * -0.0864284040 
-0.0456795458 *= 0.0000000000 * 0.3083582800 
-0.0456795458 *= 0.0000000000 * -0.1075941100 
0.2995033764 *= 1.7954983410 * 0.1922490900 
0.2995033764 *= 0.0000000000 * -0.1286853400 
0.3779185662 *= 1.3049217766 * 0.0600918700 
0.3779185662 *= 0.0000000000 * -0.1396838700 
0.3779185662 *= 0.0000000000 * 0.2378425400 
0.3779185662 *= 0.0000000000 * 0.0279665050 
0.7100288148 *= 1.1678840346 * 0.2843692000 
0.7100288148 *= 0.0000000000 * 0.2464342600 
0.7164594530 *= 1.3652422649 * 0.0047102543 
0.7164594530 *= 0.0000000000 * -0.1258317000 
0.7164594530 *= 0.0000000000 * 0.0265597740 
0.7519323901 *= 0.2729534251 * 0.1299596700 
0.7519323901 *= 0.0000000000 * 0.1856081200 
0.7519323901 *= 0.0000000000 * -0.2169941400 
0.7519323901 *= 0.0000000000 * 0.2793050000 
tempVal = 0.7519323901 + -0.0052858180(biases), 
now the tempVal = 0.7466465721 

compute layer: 3, node : 9
0.0000000000 *= 0.0000000000 * 0.0022253839 
-0.4874932332 *= 2.2153137296 * -0.2200560700 
-0.4874932332 *= 0.0000000000 * -0.1227590900 
-1.0730180167 *= 2.5539576885 * -0.2292617400 
-1.0730180167 *= 0.0000000000 * 0.0687563900 
-1.0730180167 *= 0.0000000000 * -0.1805560300 
-0.8662187607 *= 1.9362366876 * 0.1068047400 
-0.3225787743 *= 2.1093754354 * 0.2577255700 
-0.3225787743 *= 0.0000000000 * -0.2721977200 
-0.2252320109 *= 0.5416649533 * 0.1797176700 
-0.2252320109 *= 0.0000000000 * 0.0392397100 
-0.2141724767 *= 2.2324674237 * 0.0049539510 
-0.9184137401 *= 2.8029173920 * -0.2512529500 
-0.9184137401 *= 0.0000000000 * 0.2356906800 
-0.9184137401 *= 0.0000000000 * 0.2217674900 
-0.8711051526 *= 1.7954983410 * 0.0263484440 
-0.8711051526 *= 0.0000000000 * 0.2625760000 
-0.8773524152 *= 1.3049217766 * -0.0047874614 
-0.8773524152 *= 0.0000000000 * -0.2362650200 
-0.8773524152 *= 0.0000000000 * 0.1658922300 
-0.8773524152 *= 0.0000000000 * -0.3083122000 
-1.1381159625 *= 1.1678840346 * -0.2232786300 
-1.1381159625 *= 0.0000000000 * -0.1391223700 
-1.2300263927 *= 1.3652422649 * -0.0673217000 
-1.2300263927 *= 0.0000000000 * 0.2385278200 
-1.2300263927 *= 0.0000000000 * -0.2991951000 
-1.2075340396 *= 0.2729534251 * 0.0824036300 
-1.2075340396 *= 0.0000000000 * -0.2073586600 
-1.2075340396 *= 0.0000000000 * -0.0317760600 
-1.2075340396 *= 0.0000000000 * -0.1418813300 
tempVal = -1.2075340396 + 0.0000000000(biases), 
now the tempVal = -1.2075340396 
ReLU !!! in layer: 3, node : 9, its linear result is negative,so set it to 0

compute layer: 3, node : 10
0.0000000000 *= 0.0000000000 * 0.2388126000 
-0.2183339442 *= 2.2153137296 * -0.0985566700 
-0.2183339442 *= 0.0000000000 * -0.1186246350 
-0.6306182356 *= 2.5539576885 * -0.1614295700 
-0.6306182356 *= 0.0000000000 * 0.2238839300 
-0.6306182356 *= 0.0000000000 * 0.2978970400 
-1.1573520641 *= 1.9362366876 * -0.2720400000 
-1.7792971925 *= 2.1093754354 * -0.2948480000 
-1.7792971925 *= 0.0000000000 * 0.2272277500 
-1.9219869078 *= 0.5416649533 * -0.2634280000 
-1.9219869078 *= 0.0000000000 * -0.2884193000 
-1.4041567125 *= 2.2324674237 * 0.2319542000 
-0.8426291835 *= 2.8029173920 * 0.2003368100 
-0.8426291835 *= 0.0000000000 * 0.1458412100 
-0.8426291835 *= 0.0000000000 * -0.0941856700 
-0.9248025962 *= 1.7954983410 * -0.0457663540 
-0.9248025962 *= 0.0000000000 * -0.0057933377 
-0.7287405656 *= 1.3049217766 * 0.1502481100 
-0.7287405656 *= 0.0000000000 * 0.2129247200 
-0.7287405656 *= 0.0000000000 * -0.3082482800 
-0.7287405656 *= 0.0000000000 * 0.1101409940 
-0.8909282302 *= 1.1678840346 * -0.1388730900 
-0.8909282302 *= 0.0000000000 * 0.2520695300 
-0.8660681516 *= 1.3652422649 * 0.0182092800 
-0.8660681516 *= 0.0000000000 * -0.2166876800 
-0.8660681516 *= 0.0000000000 * 0.0748567900 
-0.8248468536 *= 0.2729534251 * 0.1510195300 
-0.8248468536 *= 0.0000000000 * -0.2967161800 
-0.8248468536 *= 0.0000000000 * -0.0163605850 
-0.8248468536 *= 0.0000000000 * -0.2874556200 
tempVal = -0.8248468536 + 0.0044505415(biases), 
now the tempVal = -0.8203963121 
ReLU !!! in layer: 3, node : 10, its linear result is negative,so set it to 0

compute layer: 3, node : 11
0.0000000000 *= 0.0000000000 * -0.1016127840 
0.4427489467 *= 2.2153137296 * 0.1998583500 
0.4427489467 *= 0.0000000000 * 0.0330264050 
0.0055760567 *= 2.5539576885 * -0.1711746800 
0.0055760567 *= 0.0000000000 * 0.0162547680 
0.0055760567 *= 0.0000000000 * 0.0430887530 
0.0891668739 *= 1.9362366876 * 0.0431717970 
0.7569108883 *= 2.1093754354 * 0.3165600600 
0.7569108883 *= 0.0000000000 * -0.0977973100 
0.9134812555 *= 0.5416649533 * 0.2890539000 
0.9134812555 *= 0.0000000000 * 0.0523610800 
1.0445245215 *= 2.2324674237 * 0.0586988480 
0.5872693314 *= 2.8029173920 * -0.1631354500 
0.5872693314 *= 0.0000000000 * 0.0714329850 
0.5872693314 *= 0.0000000000 * 0.1358334000 
0.4552063060 *= 1.7954983410 * -0.0735522960 
0.4552063060 *= 0.0000000000 * 0.0377370200 
0.7324594865 *= 1.3049217766 * 0.2124672800 
0.7324594865 *= 0.0000000000 * -0.1421797900 
0.7324594865 *= 0.0000000000 * 0.1012354300 
0.7324594865 *= 0.0000000000 * -0.1348154800 
0.8082800071 *= 1.1678840346 * 0.0649212750 
0.8082800071 *= 0.0000000000 * 0.0338195560 
1.0721203924 *= 1.3652422649 * 0.1932553600 
1.0721203924 *= 0.0000000000 * 0.1821820100 
1.0721203924 *= 0.0000000000 * -0.2953098000 
1.0689916715 *= 0.2729534251 * -0.0114624720 
1.0689916715 *= 0.0000000000 * -0.0542770550 
1.0689916715 *= 0.0000000000 * 0.1506274600 
1.0689916715 *= 0.0000000000 * -0.1910836100 
tempVal = 1.0689916715 + -0.0448433120(biases), 
now the tempVal = 1.0241483595 

compute layer: 3, node : 12
0.0000000000 *= 0.0000000000 * 0.0070243995 
-0.6434567029 *= 2.2153137296 * -0.2904585000 
-0.6434567029 *= 0.0000000000 * 0.2158456600 
0.1012668878 *= 2.5539576885 * 0.2915959000 
0.1012668878 *= 0.0000000000 * -0.3039987000 
0.1012668878 *= 0.0000000000 * 0.1623016000 
-0.3251212807 *= 1.9362366876 * -0.2202149000 
-0.6777033848 *= 2.1093754354 * -0.1671500000 
-0.6777033848 *= 0.0000000000 * 0.1367843200 
-0.5069246312 *= 0.5416649533 * 0.3152848500 
-0.5069246312 *= 0.0000000000 * -0.3042746800 
0.1186192821 *= 2.2324674237 * 0.2802029300 
0.1719777225 *= 2.8029173920 * 0.0190367510 
0.1719777225 *= 0.0000000000 * 0.1621747000 
0.1719777225 *= 0.0000000000 * 0.1244661500 
0.6133045355 *= 1.7954983410 * 0.2457962800 
0.6133045355 *= 0.0000000000 * 0.2720959800 
0.8737854651 *= 1.3049217766 * 0.1996142100 
0.8737854651 *= 0.0000000000 * -0.1299532500 
0.8737854651 *= 0.0000000000 * -0.2972988200 
0.8737854651 *= 0.0000000000 * 0.1478714300 
0.7807162795 *= 1.1678840346 * -0.0796904340 
0.7807162795 *= 0.0000000000 * 0.0369805100 
0.5143522574 *= 1.3652422649 * -0.1951038500 
0.5143522574 *= 0.0000000000 * 0.1282607200 
0.5143522574 *= 0.0000000000 * 0.0630959400 
0.4529940470 *= 0.2729534251 * -0.2247937000 
0.4529940470 *= 0.0000000000 * -0.1063525160 
0.4529940470 *= 0.0000000000 * 0.2084105000 
0.4529940470 *= 0.0000000000 * 0.1637104600 
tempVal = 0.4529940470 + 0.0022937346(biases), 
now the tempVal = 0.4552877816 

compute layer: 3, node : 13
0.0000000000 *= 0.0000000000 * 0.1934181900 
-0.2986952251 *= 2.2153137296 * -0.1348320200 
-0.2986952251 *= 0.0000000000 * 0.2679922000 
-0.1591227910 *= 2.5539576885 * 0.0546494700 
-0.1591227910 *= 0.0000000000 * 0.1986943300 
-0.1591227910 *= 0.0000000000 * -0.1852642000 
-0.5547678388 *= 1.9362366876 * -0.2043371300 
-0.9547275908 *= 2.1093754354 * -0.1896105100 
-0.9547275908 *= 0.0000000000 * 0.2724198700 
-1.0001967746 *= 0.5416649533 * -0.0839433740 
-1.0001967746 *= 0.0000000000 * -0.1098257500 
-0.4497771315 *= 2.2324674237 * 0.2465521500 
0.0467882462 *= 2.8029173920 * 0.1771601900 
0.0467882462 *= 0.0000000000 * 0.0761899200 
0.0467882462 *= 0.0000000000 * 0.1785282800 
0.0428780969 *= 1.7954983410 * -0.0021777516 
0.0428780969 *= 0.0000000000 * -0.2900580200 
0.0813235913 *= 1.3049217766 * 0.0294619150 
0.0813235913 *= 0.0000000000 * 0.2917317200 
0.0813235913 *= 0.0000000000 * -0.1759504500 
0.0813235913 *= 0.0000000000 * 0.0870648400 
0.4026358761 *= 1.1678840346 * 0.2751234500 
0.4026358761 *= 0.0000000000 * 0.2603757700 
0.7611292996 *= 1.3652422649 * 0.2625859400 
0.7611292996 *= 0.0000000000 * 0.1671375200 
0.7611292996 *= 0.0000000000 * -0.2535096400 
0.7667607147 *= 0.2729534251 * 0.0206314140 
0.7667607147 *= 0.0000000000 * 0.0648376940 
0.7667607147 *= 0.0000000000 * -0.0957188760 
0.7667607147 *= 0.0000000000 * 0.2566022000 
tempVal = 0.7667607147 + -0.0104252290(biases), 
now the tempVal = 0.7563354857 

compute layer: 3, node : 14
0.0000000000 *= 0.0000000000 * -0.1786382300 
0.4783070139 *= 2.2153137296 * 0.2159093800 
0.4783070139 *= 0.0000000000 * 0.0901167600 
0.6347939266 *= 2.5539576885 * 0.0612723200 
0.6347939266 *= 0.0000000000 * 0.1055154600 
0.6347939266 *= 0.0000000000 * 0.1179760700 
1.1232374161 *= 1.9362366876 * 0.2522643500 
1.4817856987 *= 2.1093754354 * 0.1699784100 
1.4817856987 *= 0.0000000000 * -0.2311718900 
1.6349335288 *= 0.5416649533 * 0.2827353500 
1.6349335288 *= 0.0000000000 * 0.2007644800 
1.6571311801 *= 2.2324674237 * 0.0099431020 
2.6169334259 *= 2.8029173920 * 0.3424297300 
2.6169334259 *= 0.0000000000 * -0.0286374300 
2.6169334259 *= 0.0000000000 * -0.2769094700 
2.3736137570 *= 1.7954983410 * -0.1355165100 
2.3736137570 *= 0.0000000000 * -0.1199892600 
2.6952704764 *= 1.3049217766 * 0.2464950200 
2.6952704764 *= 0.0000000000 * 0.2475647200 
2.6952704764 *= 0.0000000000 * 0.3124154000 
2.6952704764 *= 0.0000000000 * -0.2151120300 
2.7733536497 *= 1.1678840346 * 0.0668586700 
2.7733536497 *= 0.0000000000 * 0.1455052600 
2.9204773577 *= 1.3652422649 * 0.1077638100 
2.9204773577 *= 0.0000000000 * -0.1099468900 
2.9204773577 *= 0.0000000000 * 0.1937722900 
2.9815352374 *= 0.2729534251 * 0.2236934000 
2.9815352374 *= 0.0000000000 * 0.0865936600 
2.9815352374 *= 0.0000000000 * 0.0124396520 
2.9815352374 *= 0.0000000000 * 0.0812793100 
tempVal = 2.9815352374 + 0.0162227770(biases), 
now the tempVal = 2.9977580144 

compute layer: 3, node : 15
0.0000000000 *= 0.0000000000 * 0.1588763900 
-0.5670020170 *= 2.2153137296 * -0.2559466000 
-0.5670020170 *= 0.0000000000 * 0.2200822000 
-0.8303469894 *= 2.5539576885 * -0.1031125040 
-0.8303469894 *= 0.0000000000 * 0.1394850500 
-0.8303469894 *= 0.0000000000 * -0.2638531600 
-1.2750088370 *= 1.9362366876 * -0.2296526300 
-1.8475765028 *= 2.1093754354 * -0.2714394300 
-1.8475765028 *= 0.0000000000 * -0.1127769000 
-1.7535985001 *= 0.5416649533 * 0.1734984000 
-1.7535985001 *= 0.0000000000 * -0.0363085750 
-1.2763501869 *= 2.2324674237 * 0.2137761600 
-1.3358388404 *= 2.8029173920 * -0.0212238340 
-1.3358388404 *= 0.0000000000 * -0.1135689600 
-1.3358388404 *= 0.0000000000 * -0.2826869500 
-1.1090611516 *= 1.7954983410 * 0.1263034800 
-1.1090611516 *= 0.0000000000 * 0.0767931400 
-1.0492728459 *= 1.3049217766 * 0.0458175400 
-1.0492728459 *= 0.0000000000 * -0.3000426000 
-1.0492728459 *= 0.0000000000 * -0.1906291700 
-1.0492728459 *= 0.0000000000 * 0.1072035000 
-0.7285826345 *= 1.1678840346 * 0.2745908000 
-0.7285826345 *= 0.0000000000 * 0.1761182500 
-1.1547651790 *= 1.3652422649 * -0.3121662400 
-1.1547651790 *= 0.0000000000 * -0.0085155720 
-1.1547651790 *= 0.0000000000 * -0.0216965270 
-1.0932908898 *= 0.2729534251 * 0.2252189700 
-1.0932908898 *= 0.0000000000 * -0.1479500400 
-1.0932908898 *= 0.0000000000 * -0.0611654100 
-1.0932908898 *= 0.0000000000 * 0.2937884600 
tempVal = -1.0932908898 + -0.0113105610(biases), 
now the tempVal = -1.1046014508 
ReLU !!! in layer: 3, node : 15, its linear result is negative,so set it to 0

compute layer: 3, node : 16
0.0000000000 *= 0.0000000000 * -0.1753188400 
-0.6605263598 *= 2.2153137296 * -0.2981638000 
-0.6605263598 *= 0.0000000000 * -0.0905402700 
0.0454639597 *= 2.5539576885 * 0.2764299200 
0.0454639597 *= 0.0000000000 * 0.0231663030 
0.0454639597 *= 0.0000000000 * 0.0089319950 
-0.5750867710 *= 1.9362366876 * -0.3204932200 
-1.1498937920 *= 2.1093754354 * -0.2725010500 
-1.1498937920 *= 0.0000000000 * 0.1506688000 
-1.1226089745 *= 0.5416649533 * 0.0503721300 
-1.1226089745 *= 0.0000000000 * 0.1899560200 
-0.6932225974 *= 2.2324674237 * 0.1923371300 
-0.7116514794 *= 2.8029173920 * -0.0065748930 
-0.7116514794 *= 0.0000000000 * -0.0407674830 
-0.7116514794 *= 0.0000000000 * -0.2608025400 
-0.7926068188 *= 1.7954983410 * -0.0450879500 
-0.7926068188 *= 0.0000000000 * -0.2755731300 
-1.0318561360 *= 1.3049217766 * -0.1833438000 
-1.0318561360 *= 0.0000000000 * 0.1145500700 
-1.0318561360 *= 0.0000000000 * 0.0006601926 
-1.0318561360 *= 0.0000000000 * 0.1747069800 
-0.8390787272 *= 1.1678840346 * 0.1650655400 
-0.8390787272 *= 0.0000000000 * 0.0065650960 
-0.6284553488 *= 1.3652422649 * 0.1542754600 
-0.6284553488 *= 0.0000000000 * 0.0898803250 
-0.6284553488 *= 0.0000000000 * -0.2680774600 
-0.6356182324 *= 0.2729534251 * -0.0262421460 
-0.6356182324 *= 0.0000000000 * -0.1924816800 
-0.6356182324 *= 0.0000000000 * -0.3112283600 
-0.6356182324 *= 0.0000000000 * 0.2635972500 
tempVal = -0.6356182324 + -0.0107425160(biases), 
now the tempVal = -0.6463607484 
ReLU !!! in layer: 3, node : 16, its linear result is negative,so set it to 0

compute layer: 3, node : 17
0.0000000000 *= 0.0000000000 * 0.2756050800 
0.8014833830 *= 2.2153137296 * 0.3617922700 
0.8014833830 *= 0.0000000000 * 0.0098830220 
1.7468581487 *= 2.5539576885 * 0.3701607000 
1.7468581487 *= 0.0000000000 * 0.0288597600 
1.7468581487 *= 0.0000000000 * 0.1392776000 
2.1970042512 *= 1.9362366876 * 0.2324850600 
2.9026093609 *= 2.1093754354 * 0.3345090200 
2.9026093609 *= 0.0000000000 * -0.1715301700 
2.8407945044 *= 0.5416649533 * -0.1141200960 
2.8407945044 *= 0.0000000000 * -0.2051934500 
3.4703409416 *= 2.2324674237 * 0.2819958000 
3.4701343774 *= 2.8029173920 * -0.0000736961 
3.4701343774 *= 0.0000000000 * -0.1900721600 
3.4701343774 *= 0.0000000000 * 0.0180641250 
3.9707160829 *= 1.7954983410 * 0.2787982000 
3.9707160829 *= 0.0000000000 * -0.2214314000 
3.9922041881 *= 1.3049217766 * 0.0164669680 
3.9922041881 *= 0.0000000000 * 0.1228098400 
3.9922041881 *= 0.0000000000 * 0.0001896927 
3.9922041881 *= 0.0000000000 * -0.1409955300 
4.0733375124 *= 1.1678840346 * 0.0694703600 
4.0733375124 *= 0.0000000000 * 0.0258825810 
4.2189601844 *= 1.3652422649 * 0.1066643450 
4.2189601844 *= 0.0000000000 * 0.2506659300 
4.2189601844 *= 0.0000000000 * 0.2404818000 
4.1564610014 *= 0.2729534251 * -0.2289738000 
4.1564610014 *= 0.0000000000 * -0.3049411000 
4.1564610014 *= 0.0000000000 * 0.1468677200 
4.1564610014 *= 0.0000000000 * -0.2705935500 
tempVal = 4.1564610014 + -0.0103874095(biases), 
now the tempVal = 4.1460735919 

compute layer: 3, node : 18
0.0000000000 *= 0.0000000000 * 0.3126629300 
0.8493286877 *= 2.2153137296 * 0.3833898000 
0.8493286877 *= 0.0000000000 * 0.2316185100 
1.1796664629 *= 2.5539576885 * 0.1293434800 
1.1796664629 *= 0.0000000000 * 0.0828318000 
1.1796664629 *= 0.0000000000 * -0.2060668600 
1.7015025420 *= 1.9362366876 * 0.2695104800 
1.8265031073 *= 2.1093754354 * 0.0592595150 
1.8265031073 *= 0.0000000000 * -0.1254899700 
1.6926672848 *= 0.5416649533 * -0.2470823000 
1.6926672848 *= 0.0000000000 * 0.0194011350 
2.2993175360 *= 2.2324674237 * 0.2717398000 
2.2676735909 *= 2.8029173920 * -0.0112896460 
2.2676735909 *= 0.0000000000 * -0.1830182700 
2.2676735909 *= 0.0000000000 * -0.1083529500 
2.6779676389 *= 1.7954983410 * 0.2285126300 
2.6779676389 *= 0.0000000000 * 0.2983255000 
2.9862627554 *= 1.3049217766 * 0.2362556300 
2.9862627554 *= 0.0000000000 * -0.1005966100 
2.9862627554 *= 0.0000000000 * 0.1556957200 
2.9862627554 *= 0.0000000000 * 0.1017859500 
3.3180301716 *= 1.1678840346 * 0.2840756500 
3.3180301716 *= 0.0000000000 * 0.2772408000 
3.4833521495 *= 1.3652422649 * 0.1210935100 
3.4833521495 *= 0.0000000000 * -0.0498951100 
3.4833521495 *= 0.0000000000 * 0.1267129300 
3.4131518586 *= 0.2729534251 * -0.2571878000 
3.4131518586 *= 0.0000000000 * 0.1529914700 
3.4131518586 *= 0.0000000000 * 0.0879652650 
3.4131518586 *= 0.0000000000 * -0.1329562500 
tempVal = 3.4131518586 + 0.0058082673(biases), 
now the tempVal = 3.4189601259 

compute layer: 3, node : 19
0.0000000000 *= 0.0000000000 * -0.1959942900 
-0.1850356521 *= 2.2153137296 * -0.0835257100 
-0.1850356521 *= 0.0000000000 * 0.2886257800 
-0.3862897144 *= 2.5539576885 * -0.0788008600 
-0.3862897144 *= 0.0000000000 * -0.2930289500 
-0.3862897144 *= 0.0000000000 * 0.3056185500 
-0.1408866233 *= 1.9362366876 * 0.1267423000 
0.4105764671 *= 2.1093754354 * 0.2614343000 
0.4105764671 *= 0.0000000000 * -0.0897273000 
0.4488975292 *= 0.5416649533 * 0.0707468000 
0.4488975292 *= 0.0000000000 * -0.2437960700 
-0.0168740261 *= 2.2324674237 * -0.2086353200 
-0.5866622292 *= 2.8029173920 * -0.2032839800 
-0.5866622292 *= 0.0000000000 * -0.3060158200 
-0.5866622292 *= 0.0000000000 * -0.1662473000 
-0.0690687873 *= 1.7954983410 * 0.2882728600 
-0.0690687873 *= 0.0000000000 * 0.1796561500 
-0.1551890638 *= 1.3049217766 * -0.0659965050 
-0.1551890638 *= 0.0000000000 * 0.0024942034 
-0.1551890638 *= 0.0000000000 * 0.1442325400 
-0.1551890638 *= 0.0000000000 * 0.1256933800 
-0.4602581722 *= 1.1678840346 * -0.2612152400 
-0.4602581722 *= 0.0000000000 * -0.2339577100 
-0.3935238443 *= 1.3652422649 * 0.0488809420 
-0.3935238443 *= 0.0000000000 * -0.0392894150 
-0.3935238443 *= 0.0000000000 * -0.1866563900 
-0.3543303992 *= 0.2729534251 * 0.1435902300 
-0.3543303992 *= 0.0000000000 * -0.1354189400 
-0.3543303992 *= 0.0000000000 * -0.2795318700 
-0.3543303992 *= 0.0000000000 * -0.0035790936 
tempVal = -0.3543303992 + -0.0044173360(biases), 
now the tempVal = -0.3587477352 
ReLU !!! in layer: 3, node : 19, its linear result is negative,so set it to 0

compute layer: 3, node : 20
0.0000000000 *= 0.0000000000 * -0.2188217000 
-0.2584228596 *= 2.2153137296 * -0.1166529400 
-0.2584228596 *= 0.0000000000 * -0.2419021900 
-0.0259026088 *= 2.5539576885 * 0.0910431100 
-0.0259026088 *= 0.0000000000 * 0.2081265000 
-0.0259026088 *= 0.0000000000 * -0.2784782400 
0.2954972689 *= 1.9362366876 * 0.1659920400 
0.1729261030 *= 2.1093754354 * -0.0581078000 
0.1729261030 *= 0.0000000000 * 0.1590381900 
0.1375278216 *= 0.5416649533 * -0.0653508800 
0.1375278216 *= 0.0000000000 * 0.2484947100 
-0.0306135209 *= 2.2324674237 * -0.0753163700 
-0.0563097033 *= 2.8029173920 * -0.0091676560 
-0.0563097033 *= 0.0000000000 * 0.0475419900 
-0.0563097033 *= 0.0000000000 * 0.2172156100 
0.4037990457 *= 1.7954983410 * 0.2562568500 
0.4037990457 *= 0.0000000000 * -0.0578383600 
0.4176798797 *= 1.3049217766 * 0.0106372920 
0.4176798797 *= 0.0000000000 * 0.2049695400 
0.4176798797 *= 0.0000000000 * -0.0521675600 
0.4176798797 *= 0.0000000000 * 0.1823163800 
0.2568050568 *= 1.1678840346 * -0.1377489700 
0.2568050568 *= 0.0000000000 * 0.2830276000 
0.2153463764 *= 1.3652422649 * -0.0303672700 
0.2153463764 *= 0.0000000000 * -0.1672591700 
0.2153463764 *= 0.0000000000 * -0.2162274100 
0.1556862447 *= 0.2729534251 * -0.2185725700 
0.1556862447 *= 0.0000000000 * -0.2459143100 
0.1556862447 *= 0.0000000000 * -0.1823557300 
0.1556862447 *= 0.0000000000 * 0.1075948400 
tempVal = 0.1556862447 + -0.0685351400(biases), 
now the tempVal = 0.0871511047 

compute layer: 3, node : 21
0.0000000000 *= 0.0000000000 * -0.0027107836 
-0.1961676479 *= 2.2153137296 * -0.0885507300 
-0.1961676479 *= 0.0000000000 * -0.0730592460 
-0.6098917075 *= 2.5539576885 * -0.1619933100 
-0.6098917075 *= 0.0000000000 * -0.0818672300 
-0.6098917075 *= 0.0000000000 * -0.2609110500 
-0.0088284633 *= 1.9362366876 * 0.3104286000 
-0.1997381705 *= 2.1093754354 * -0.0905053240 
-0.1997381705 *= 0.0000000000 * -0.1683273900 
-0.2756351750 *= 0.5416649533 * -0.1401179900 
-0.2756351750 *= 0.0000000000 * -0.0843038200 
-0.3625275310 *= 2.2324674237 * -0.0389221160 
0.2786431859 *= 2.8029173920 * 0.2287512000 
0.2786431859 *= 0.0000000000 * 0.1874008600 
0.2786431859 *= 0.0000000000 * -0.0306019990 
0.2098783645 *= 1.7954983410 * -0.0382984600 
0.2098783645 *= 0.0000000000 * 0.1759350400 
0.4552215359 *= 1.3049217766 * 0.1880137000 
0.4552215359 *= 0.0000000000 * -0.1362159800 
0.4552215359 *= 0.0000000000 * 0.1568851300 
0.4552215359 *= 0.0000000000 * -0.2445508200 
0.1103158914 *= 1.1678840346 * -0.2953252500 
0.1103158914 *= 0.0000000000 * -0.2650387600 
0.4434587593 *= 1.3652422649 * 0.2440174000 
0.4434587593 *= 0.0000000000 * -0.0004112963 
0.4434587593 *= 0.0000000000 * -0.1478346300 
0.4751835272 *= 0.2729534251 * 0.1162277700 
0.4751835272 *= 0.0000000000 * 0.0467987540 
0.4751835272 *= 0.0000000000 * 0.0571056980 
0.4751835272 *= 0.0000000000 * -0.2283173400 
tempVal = 0.4751835272 + 0.0205596630(biases), 
now the tempVal = 0.4957431902 

compute layer: 3, node : 22
0.0000000000 *= 0.0000000000 * 0.0349784980 
0.4543457597 *= 2.2153137296 * 0.2050931900 
0.4543457597 *= 0.0000000000 * 0.2066882300 
0.7314496836 *= 2.5539576885 * 0.1084998100 
0.7314496836 *= 0.0000000000 * 0.0070133540 
0.7314496836 *= 0.0000000000 * -0.2688838200 
0.8770443508 *= 1.9362366876 * 0.0751946640 
0.8962229736 *= 2.1093754354 * 0.0090920860 
0.8962229736 *= 0.0000000000 * 0.1437173200 
1.0513024623 *= 0.5416649533 * 0.2863015000 
1.0513024623 *= 0.0000000000 * 0.3003435000 
1.5246728009 *= 2.2324674237 * 0.2120390800 
1.9737664561 *= 2.8029173920 * 0.1602236500 
1.9737664561 *= 0.0000000000 * 0.1578694000 
1.9737664561 *= 0.0000000000 * -0.3152272400 
1.5746399768 *= 1.7954983410 * -0.2222928700 
1.5746399768 *= 0.0000000000 * 0.2680102300 
1.8268702513 *= 1.3049217766 * 0.1932914900 
1.8268702513 *= 0.0000000000 * -0.0621955840 
1.8268702513 *= 0.0000000000 * 0.1241424460 
1.8268702513 *= 0.0000000000 * 0.0856658600 
1.5633487926 *= 1.1678840346 * -0.2256400900 
1.5633487926 *= 0.0000000000 * 0.2493968000 
1.8816434222 *= 1.3652422649 * 0.2331415000 
1.8816434222 *= 0.0000000000 * 0.1546989200 
1.8816434222 *= 0.0000000000 * -0.1945328600 
1.8602342466 *= 0.2729534251 * -0.0784352700 
1.8602342466 *= 0.0000000000 * -0.2999258600 
1.8602342466 *= 0.0000000000 * 0.1477096200 
1.8602342466 *= 0.0000000000 * 0.1115780550 
tempVal = 1.8602342466 + 0.0264123120(biases), 
now the tempVal = 1.8866465586 

compute layer: 3, node : 23
0.0000000000 *= 0.0000000000 * -0.1170595900 
0.2490446169 *= 2.2153137296 * 0.1124195700 
0.2490446169 *= 0.0000000000 * -0.1635526700 
0.0696019050 *= 2.5539576885 * -0.0702606440 
0.0696019050 *= 0.0000000000 * -0.1871586000 
0.0696019050 *= 0.0000000000 * 0.1584591900 
-0.0278234841 *= 1.9362366876 * -0.0503168800 
0.0579811752 *= 2.1093754354 * 0.0406777560 
0.0579811752 *= 0.0000000000 * 0.0904405800 
0.1814431876 *= 0.5416649533 * 0.2279305900 
0.1814431876 *= 0.0000000000 * 0.3050288600 
0.4968380813 *= 2.2324674237 * 0.1412763700 
0.3979914337 *= 2.8029173920 * -0.0352656300 
0.3979914337 *= 0.0000000000 * -0.1301356700 
0.3979914337 *= 0.0000000000 * -0.0193592160 
0.9047053765 *= 1.7954983410 * 0.2822135400 
0.9047053765 *= 0.0000000000 * 0.3018856000 
0.7858213915 *= 1.3049217766 * -0.0911043000 
0.7858213915 *= 0.0000000000 * 0.1388134400 
0.7858213915 *= 0.0000000000 * -0.2825657400 
0.7858213915 *= 0.0000000000 * -0.0721351700 
0.9116632963 *= 1.1678840346 * 0.1077520550 
0.9116632963 *= 0.0000000000 * 0.1643028400 
1.1585312902 *= 1.3652422649 * 0.1808235800 
1.1585312902 *= 0.0000000000 * 0.0961793140 
1.1585312902 *= 0.0000000000 * 0.1414004600 
1.1978643564 *= 0.2729534251 * 0.1441017500 
1.1978643564 *= 0.0000000000 * -0.3038598000 
1.1978643564 *= 0.0000000000 * 0.2897829400 
1.1978643564 *= 0.0000000000 * 0.0428113000 
tempVal = 1.1978643564 + 0.0205718190(biases), 
now the tempVal = 1.2184361754 

compute layer: 3, node : 24
0.0000000000 *= 0.0000000000 * -0.0768668060 
-0.0360359679 *= 2.2153137296 * -0.0162667560 
-0.0360359679 *= 0.0000000000 * -0.1972749000 
0.2542013004 *= 2.5539576885 * 0.1136421600 
0.2542013004 *= 0.0000000000 * 0.1640082300 
0.2542013004 *= 0.0000000000 * 0.1954206200 
-0.1941635999 *= 1.9362366876 * -0.2315651300 
-0.4510660162 *= 2.1093754354 * -0.1217907500 
-0.4510660162 *= 0.0000000000 * -0.2733920800 
-0.4550412556 *= 0.5416649533 * -0.0073389267 
-0.4550412556 *= 0.0000000000 * -0.2016720800 
-1.0048533327 *= 2.2324674237 * -0.2462800000 
-1.8819174372 *= 2.8029173920 * -0.3129111500 
-1.8819174372 *= 0.0000000000 * 0.0244498940 
-1.8819174372 *= 0.0000000000 * 0.2851632500 
-2.0102385328 *= 1.7954983410 * -0.0714682340 
-2.0102385328 *= 0.0000000000 * -0.1881534000 
-1.6044268077 *= 1.3049217766 * 0.3109854800 
-1.6044268077 *= 0.0000000000 * 0.0573527300 
-1.6044268077 *= 0.0000000000 * 0.2175674000 
-1.6044268077 *= 0.0000000000 * 0.2596247200 
-1.3001575714 *= 1.1678840346 * 0.2605303500 
-1.3001575714 *= 0.0000000000 * -0.1553529600 
-1.3574987227 *= 1.3652422649 * -0.0420007150 
-1.3574987227 *= 0.0000000000 * 0.2005960800 
-1.3574987227 *= 0.0000000000 * -0.0554686930 
-1.4155050923 *= 0.2729534251 * -0.2125138000 
-1.4155050923 *= 0.0000000000 * -0.1203019540 
-1.4155050923 *= 0.0000000000 * -0.2971245000 
-1.4155050923 *= 0.0000000000 * -0.0822607200 
tempVal = -1.4155050923 + 0.0000000000(biases), 
now the tempVal = -1.4155050923 
ReLU !!! in layer: 3, node : 24, its linear result is negative,so set it to 0

compute layer: 3, node : 25
0.0000000000 *= 0.0000000000 * -0.0787207560 
0.6455618048 *= 2.2153137296 * 0.2914087500 
0.6455618048 *= 0.0000000000 * -0.0772561600 
1.3620210523 *= 2.5539576885 * 0.2805290200 
1.3620210523 *= 0.0000000000 * 0.1935620800 
1.3620210523 *= 0.0000000000 * 0.0479772600 
1.4873359171 *= 1.9362366876 * 0.0647208400 
1.4013862383 *= 2.1093754354 * -0.0407465060 
1.4013862383 *= 0.0000000000 * 0.0998829900 
1.5268070032 *= 0.5416649533 * 0.2315467600 
1.5268070032 *= 0.0000000000 * -0.0019428993 
1.2248404680 *= 2.2324674237 * -0.1352613400 
0.4078630642 *= 2.8029173920 * -0.2914739500 
0.4078630642 *= 0.0000000000 * 0.2290264800 
0.4078630642 *= 0.0000000000 * -0.2829910500 
0.1475669406 *= 1.7954983410 * -0.1449715200 
0.1475669406 *= 0.0000000000 * 0.0217462830 
0.4012734862 *= 1.3049217766 * 0.1944228000 
0.4012734862 *= 0.0000000000 * 0.1121527500 
0.4012734862 *= 0.0000000000 * 0.1855822000 
0.4012734862 *= 0.0000000000 * 0.0947437200 
0.1933554418 *= 1.1678840346 * -0.1780297000 
0.1933554418 *= 0.0000000000 * 0.0293211770 
-0.0194966673 *= 1.3652422649 * -0.1559079400 
-0.0194966673 *= 0.0000000000 * -0.0500528550 
-0.0194966673 *= 0.0000000000 * 0.1781071300 
-0.0391241547 *= 0.2729534251 * -0.0719078260 
-0.0391241547 *= 0.0000000000 * -0.2982733000 
-0.0391241547 *= 0.0000000000 * -0.0704429000 
-0.0391241547 *= 0.0000000000 * -0.2903272200 
tempVal = -0.0391241547 + -0.0028317275(biases), 
now the tempVal = -0.0419558822 
ReLU !!! in layer: 3, node : 25, its linear result is negative,so set it to 0

compute layer: 3, node : 26
0.0000000000 *= 0.0000000000 * 0.2550146000 
0.0719156033 *= 2.2153137296 * 0.0324629430 
0.0719156033 *= 0.0000000000 * -0.0525798950 
0.2082610710 *= 2.5539576885 * 0.0533859540 
0.2082610710 *= 0.0000000000 * 0.2868617800 
0.2082610710 *= 0.0000000000 * -0.0840293240 
0.2509148434 *= 1.9362366876 * 0.0220292140 
-0.3272752994 *= 2.1093754354 * -0.2741049000 
-0.3272752994 *= 0.0000000000 * 0.1647154200 
-0.3859438701 *= 0.5416649533 * -0.1083115500 
-0.3859438701 *= 0.0000000000 * 0.0047082026 
-0.8512062666 *= 2.2324674237 * -0.2084072500 
-1.1281335519 *= 2.8029173920 * -0.0987996600 
-1.1281335519 *= 0.0000000000 * -0.1413757700 
-1.1281335519 *= 0.0000000000 * 0.2825212000 
-1.4566814333 *= 1.7954983410 * -0.1829842300 
-1.4566814333 *= 0.0000000000 * -0.0953411500 
-1.4482919693 *= 1.3049217766 * 0.0064290934 
-1.4482919693 *= 0.0000000000 * -0.2288307500 
-1.4482919693 *= 0.0000000000 * -0.3029644800 
-1.4482919693 *= 0.0000000000 * -0.2174635800 
-1.3351174312 *= 1.1678840346 * 0.0969056300 
-1.3351174312 *= 0.0000000000 * 0.0960980360 
-1.6226163182 *= 1.3652422649 * -0.2105845200 
-1.6226163182 *= 0.0000000000 * 0.2843436300 
-1.6226163182 *= 0.0000000000 * -0.2915212500 
-1.6231483560 *= 0.2729534251 * -0.0019491888 
-1.6231483560 *= 0.0000000000 * 0.2702469000 
-1.6231483560 *= 0.0000000000 * -0.2813649800 
-1.6231483560 *= 0.0000000000 * 0.0772135400 
tempVal = -1.6231483560 + -0.0094404160(biases), 
now the tempVal = -1.6325887720 
ReLU !!! in layer: 3, node : 26, its linear result is negative,so set it to 0

compute layer: 3, node : 27
0.0000000000 *= 0.0000000000 * 0.2533825300 
-0.6725275561 *= 2.2153137296 * -0.3035811800 
-0.6725275561 *= 0.0000000000 * 0.1978998200 
-1.0592809797 *= 2.5539576885 * -0.1514329800 
-1.0592809797 *= 0.0000000000 * 0.2933893800 
-1.0592809797 *= 0.0000000000 * 0.1007714050 
-0.7924981954 *= 1.9362366876 * 0.1377841800 
-0.3643783445 *= 2.1093754354 * 0.2029604800 
-0.3643783445 *= 0.0000000000 * -0.1714704500 
-0.4692799094 *= 0.5416649533 * -0.1936650400 
-0.4692799094 *= 0.0000000000 * -0.0288201220 
-1.1319450007 *= 2.2324674237 * -0.2968308000 
-0.7521426027 *= 2.8029173920 * 0.1355025300 
-0.7521426027 *= 0.0000000000 * 0.2049403600 
-0.7521426027 *= 0.0000000000 * 0.1895505200 
-0.7685247547 *= 1.7954983410 * -0.0091240140 
-0.7685247547 *= 0.0000000000 * 0.0397427040 
-0.6658843055 *= 1.3049217766 * 0.0786564000 
-0.6658843055 *= 0.0000000000 * 0.1241734700 
-0.6658843055 *= 0.0000000000 * 0.0472157800 
-0.6658843055 *= 0.0000000000 * -0.1183571140 
-0.5649411336 *= 1.1678840346 * 0.0864325300 
-0.5649411336 *= 0.0000000000 * -0.1635989000 
-0.8384969379 *= 1.3652422649 * -0.2003716200 
-0.8384969379 *= 0.0000000000 * -0.2738440600 
-0.8384969379 *= 0.0000000000 * -0.1425668600 
-0.8552546992 *= 0.2729534251 * -0.0613942150 
-0.8552546992 *= 0.0000000000 * -0.1130703800 
-0.8552546992 *= 0.0000000000 * 0.0217667150 
-0.8552546992 *= 0.0000000000 * -0.0955983000 
tempVal = -0.8552546992 + -0.0105176010(biases), 
now the tempVal = -0.8657723002 
ReLU !!! in layer: 3, node : 27, its linear result is negative,so set it to 0

compute layer: 3, node : 28
0.0000000000 *= 0.0000000000 * -0.3137276800 
0.4820081385 *= 2.2153137296 * 0.2175800800 
0.4820081385 *= 0.0000000000 * 0.2773075400 
0.9635151290 *= 2.5539576885 * 0.1885336600 
0.9635151290 *= 0.0000000000 * -0.1092558800 
0.9635151290 *= 0.0000000000 * 0.2677191200 
1.0961360267 *= 1.9362366876 * 0.0684941560 
1.6724067222 *= 2.1093754354 * 0.2731949400 
1.6724067222 *= 0.0000000000 * -0.0448005530 
1.6539508734 *= 0.5416649533 * -0.0340724440 
1.6539508734 *= 0.0000000000 * 0.2904397000 
1.1828153686 *= 2.2324674237 * -0.2110380200 
1.4058013917 *= 2.8029173920 * 0.0795549750 
1.4058013917 *= 0.0000000000 * -0.0591847670 
1.4058013917 *= 0.0000000000 * 0.1378028100 
1.6238904306 *= 1.7954983410 * 0.1214643500 
1.6238904306 *= 0.0000000000 * 0.0848371400 
1.2943507048 *= 1.3049217766 * -0.2525360000 
1.2943507048 *= 0.0000000000 * 0.1466563600 
1.2943507048 *= 0.0000000000 * 0.0929839400 
1.2943507048 *= 0.0000000000 * 0.2899979000 
1.2411688583 *= 1.1678840346 * -0.0455369240 
1.2411688583 *= 0.0000000000 * -0.2514321800 
1.6243488654 *= 1.3652422649 * 0.2806681400 
1.6243488654 *= 0.0000000000 * 0.2771608800 
1.6243488654 *= 0.0000000000 * 0.1260886600 
1.6942598803 *= 0.2729534251 * 0.2561280000 
1.6942598803 *= 0.0000000000 * 0.1925888200 
1.6942598803 *= 0.0000000000 * 0.1742260000 
1.6942598803 *= 0.0000000000 * -0.1796901400 
tempVal = 1.6942598803 + -0.0858412100(biases), 
now the tempVal = 1.6084186703 

compute layer: 3, node : 29
0.0000000000 *= 0.0000000000 * -0.2868288800 
0.5149808902 *= 2.2153137296 * 0.2324640900 
0.5149808902 *= 0.0000000000 * -0.0695585460 
-0.0149652024 *= 2.5539576885 * -0.2074999500 
-0.0149652024 *= 0.0000000000 * -0.2582322700 
-0.0149652024 *= 0.0000000000 * -0.1424491700 
-0.2108978915 *= 1.9362366876 * -0.1011925300 
-0.3446079520 *= 2.1093754354 * -0.0633884600 
-0.3446079520 *= 0.0000000000 * -0.1794022300 
-0.2887231871 *= 0.5416649533 * 0.1031722000 
-0.2887231871 *= 0.0000000000 * -0.0057335880 
-0.5481705831 *= 2.2324674237 * -0.1162155350 
-1.2918188188 *= 2.8029173920 * -0.2653122200 
-1.2918188188 *= 0.0000000000 * -0.2010769200 
-1.2918188188 *= 0.0000000000 * 0.1750553400 
-1.0733005768 *= 1.7954983410 * 0.1217033940 
-1.0733005768 *= 0.0000000000 * -0.2827947400 
-0.8889865220 *= 1.3049217766 * 0.1412452900 
-0.8889865220 *= 0.0000000000 * 0.2839560500 
-0.8889865220 *= 0.0000000000 * 0.2076507500 
-0.8889865220 *= 0.0000000000 * -0.0585733280 
-0.6041001315 *= 1.1678840346 * 0.2439338000 
-0.6041001315 *= 0.0000000000 * 0.0016625634 
-0.4695079276 *= 1.3652422649 * 0.0985848500 
-0.4695079276 *= 0.0000000000 * 0.0142294440 
-0.4695079276 *= 0.0000000000 * 0.1629325400 
-0.4133257467 *= 0.2729534251 * 0.2058306500 
-0.4133257467 *= 0.0000000000 * -0.0106774550 
-0.4133257467 *= 0.0000000000 * -0.0479437670 
-0.4133257467 *= 0.0000000000 * -0.0606520700 
tempVal = -0.4133257467 + 0.0000000000(biases), 
now the tempVal = -0.4133257467 
ReLU !!! in layer: 3, node : 29, its linear result is negative,so set it to 0

now we get all result in layer: 3
	node: 0, val: 2.6593807282
	node: 1, val: 0.0000000000
	node: 2, val: 2.2373548989
	node: 3, val: 0.0000000000
	node: 4, val: 1.5408149683
	node: 5, val: 0.3375394615
	node: 6, val: 0.0000000000
	node: 7, val: 2.9815905531
	node: 8, val: 0.7466465721
	node: 9, val: 0.0000000000
	node: 10, val: 0.0000000000
	node: 11, val: 1.0241483595
	node: 12, val: 0.4552877816
	node: 13, val: 0.7563354857
	node: 14, val: 2.9977580144
	node: 15, val: 0.0000000000
	node: 16, val: 0.0000000000
	node: 17, val: 4.1460735919
	node: 18, val: 3.4189601259
	node: 19, val: 0.0000000000
	node: 20, val: 0.0871511047
	node: 21, val: 0.4957431902
	node: 22, val: 1.8866465586
	node: 23, val: 1.2184361754
	node: 24, val: 0.0000000000
	node: 25, val: 0.0000000000
	node: 26, val: 0.0000000000
	node: 27, val: 0.0000000000
	node: 28, val: 1.6084186703
	node: 29, val: 0.0000000000

when compute layer[3] to layer[4]

compute layer: 4, node : 0
-0.4952780140 *= 2.6593807282 * -0.1862381000 
-0.4952780140 *= 0.0000000000 * -0.1991015400 
-1.1685106770 *= 2.2373548989 * -0.3009056200 
-1.1685106770 *= 0.0000000000 * -0.0452501660 
-1.3979708606 *= 1.5408149683 * -0.1489213100 
-1.4536751835 *= 0.3375394615 * -0.1650305500 
-1.4536751835 *= 0.0000000000 * -0.0918414500 
-2.2031847333 *= 2.9815905531 * -0.2513791000 
-2.3207175062 *= 0.7466465721 * -0.1574142000 
-2.3207175062 *= 0.0000000000 * -0.3053705700 
-2.3207175062 *= 0.0000000000 * -0.1690834000 
-2.3093156359 *= 1.0241483595 * 0.0111330260 
-2.3343164837 *= 0.4552877816 * -0.0549121870 
-2.5010524416 *= 0.7563354857 * -0.2204523800 
-2.9342575229 *= 2.9977580144 * -0.1445096900 
-2.9342575229 *= 0.0000000000 * -0.2357813000 
-2.9342575229 *= 0.0000000000 * 0.0297685300 
-1.9680911113 *= 4.1460735919 * 0.2330316600 
-1.4432593635 *= 3.4189601259 * 0.1535062500 
-1.4432593635 *= 0.0000000000 * -0.1436769700 
-1.4259014745 *= 0.0871511047 * 0.1991700400 
-1.5361738610 *= 0.4957431902 * -0.2224385300 
-2.0537934184 *= 1.8866465586 * -0.2743595800 
-1.8900758048 *= 1.2184361754 * 0.1343670000 
-1.8900758048 *= 0.0000000000 * 0.2237286400 
-1.8900758048 *= 0.0000000000 * 0.0525859450 
-1.8900758048 *= 0.0000000000 * 0.1523402800 
-1.8900758048 *= 0.0000000000 * -0.1122301740 
-2.3342872647 *= 1.6084186703 * -0.2761790000 
-2.3342872647 *= 0.0000000000 * 0.0565932770 
tempVal = -2.3342872647 + 0.0000000000(biases), 
now the tempVal = -2.3342872647 
ReLU !!! in layer: 4, node : 0, its linear result is negative,so set it to 0

compute layer: 4, node : 1
-0.1852721144 *= 2.6593807282 * -0.0696673900 
-0.1852721144 *= 0.0000000000 * 0.3120484000 
0.2883247494 *= 2.2373548989 * 0.2116771300 
0.2883247494 *= 0.0000000000 * 0.2234507800 
0.6146947215 *= 1.5408149683 * 0.2118164600 
0.6142330768 *= 0.3375394615 * -0.0013676764 
0.6142330768 *= 0.0000000000 * 0.1121436950 
0.8242431069 *= 2.9815905531 * 0.0704355700 
0.8754577008 *= 0.7466465721 * 0.0685928200 
0.8754577008 *= 0.0000000000 * 0.0217707100 
0.8754577008 *= 0.0000000000 * -0.0732906900 
0.6540048413 *= 1.0241483595 * -0.2162312300 
0.7548333333 *= 0.4552877816 * 0.2214610100 
0.8907943407 *= 0.7563354857 * 0.1797628300 
0.3466819255 *= 2.9977580144 * -0.1815064500 
0.3466819255 *= 0.0000000000 * 0.1950782200 
0.3466819255 *= 0.0000000000 * 0.2027440800 
0.5193873009 *= 4.1460735919 * 0.0416551640 
-0.4248597391 *= 3.4189601259 * -0.2761796000 
-0.4248597391 *= 0.0000000000 * 0.0710073600 
-0.4385770031 *= 0.0871511047 * -0.1573963300 
-0.4822611246 *= 0.4957431902 * -0.0881184500 
-0.6412474529 *= 1.8866465586 * -0.0842692700 
-0.8845851186 *= 1.2184361754 * -0.1997131000 
-0.8845851186 *= 0.0000000000 * -0.2479136600 
-0.8845851186 *= 0.0000000000 * 0.2841022600 
-0.8845851186 *= 0.0000000000 * -0.0843677000 
-0.8845851186 *= 0.0000000000 * 0.0892544300 
-0.9785305885 *= 1.6084186703 * -0.0584085920 
-0.9785305885 *= 0.0000000000 * -0.1609159300 
tempVal = -0.9785305885 + 0.0000000000(biases), 
now the tempVal = -0.9785305885 
ReLU !!! in layer: 4, node : 1, its linear result is negative,so set it to 0

compute layer: 4, node : 2
-0.8124952500 *= 2.6593807282 * -0.3055204700 
-0.8124952500 *= 0.0000000000 * 0.3130954200 
-1.3089103594 *= 2.2373548989 * -0.2218758900 
-1.3089103594 *= 0.0000000000 * -0.2226907200 
-1.1366750423 *= 1.5408149683 * 0.1117819600 
-1.1825241041 *= 0.3375394615 * -0.1358331900 
-1.1825241041 *= 0.0000000000 * 0.2280898500 
-0.9481591453 *= 2.9815905531 * 0.0786040050 
-1.1480896238 *= 0.7466465721 * -0.2677712400 
-1.1480896238 *= 0.0000000000 * -0.1268990300 
-1.1480896238 *= 0.0000000000 * 0.0918172600 
-1.2935677578 *= 1.0241483595 * -0.1420479100 
-1.2443578140 *= 0.4552877816 * 0.1080853600 
-1.1591662467 *= 0.7563354857 * 0.1126372740 
-1.8534946672 *= 2.9977580144 * -0.2316159000 
-1.8534946672 *= 0.0000000000 * -0.0097016880 
-1.8534946672 *= 0.0000000000 * -0.1516117000 
-1.6893343411 *= 4.1460735919 * 0.0395941660 
-1.2276265122 *= 3.4189601259 * 0.1350433500 
-1.2276265122 *= 0.0000000000 * 0.1230909150 
-1.2518637547 *= 0.0871511047 * -0.2781059700 
-1.2005850062 *= 0.4957431902 * 0.1034381300 
-0.9887242573 *= 1.8866465586 * 0.1122948800 
-0.8436735294 *= 1.2184361754 * 0.1190466360 
-0.8436735294 *= 0.0000000000 * -0.0958622000 
-0.8436735294 *= 0.0000000000 * 0.0537420060 
-0.8436735294 *= 0.0000000000 * 0.0382597300 
-0.8436735294 *= 0.0000000000 * -0.1617966100 
-1.1629559909 *= 1.6084186703 * -0.1985070600 
-1.1629559909 *= 0.0000000000 * -0.0034644373 
tempVal = -1.1629559909 + -0.0599668850(biases), 
now the tempVal = -1.2229228759 
ReLU !!! in layer: 4, node : 2, its linear result is negative,so set it to 0

compute layer: 4, node : 3
0.6572194078 *= 2.6593807282 * 0.2471325000 
0.6572194078 *= 0.0000000000 * -0.0614644200 
0.8693471425 *= 2.2373548989 * 0.0948118400 
0.8693471425 *= 0.0000000000 * 0.1714307500 
0.7294479384 *= 1.5408149683 * -0.0907955900 
0.7756375978 *= 0.3375394615 * 0.1368422500 
0.7756375978 *= 0.0000000000 * 0.2875811800 
-0.0803326840 *= 2.9815905531 * -0.2870851200 
0.0716707750 *= 0.7466465721 * 0.2035815400 
0.0716707750 *= 0.0000000000 * -0.2408958400 
0.0716707750 *= 0.0000000000 * 0.2750270000 
0.2460693020 *= 1.0241483595 * 0.1702863900 
0.3144057899 *= 0.4552877816 * 0.1500951500 
0.0924493622 *= 0.7563354857 * -0.2934629300 
0.6305652121 *= 2.9977580144 * 0.1795061000 
0.6305652121 *= 0.0000000000 * 0.2133433000 
0.6305652121 *= 0.0000000000 * -0.2232706400 
0.1545654901 *= 4.1460735919 * -0.1148073500 
0.9776059148 *= 3.4189601259 * 0.2407282900 
0.9776059148 *= 0.0000000000 * 0.1849199000 
0.9507429027 *= 0.0871511047 * -0.3082349000 
0.8118659309 *= 0.4957431902 * -0.2801389400 
1.1772864277 *= 1.8866465586 * 0.1936878400 
1.5644461307 *= 1.2184361754 * 0.3177513200 
1.5644461307 *= 0.0000000000 * -0.2814149600 
1.5644461307 *= 0.0000000000 * -0.2798517000 
1.5644461307 *= 0.0000000000 * -0.1977198600 
1.5644461307 *= 0.0000000000 * -0.2722249000 
1.7704163172 *= 1.6084186703 * 0.1280575700 
1.7704163172 *= 0.0000000000 * -0.2732687300 
tempVal = 1.7704163172 + -0.0150430060(biases), 
now the tempVal = 1.7553733112 

compute layer: 4, node : 4
-0.8083738215 *= 2.6593807282 * -0.3039707000 
-0.8083738215 *= 0.0000000000 * 0.0992383000 
-0.4316350941 *= 2.2373548989 * 0.1683857700 
-0.4316350941 *= 0.0000000000 * -0.3156493000 
-0.5397300437 *= 1.5408149683 * -0.0701544000 
-0.5374160759 *= 0.3375394615 * 0.0068553993 
-0.5374160759 *= 0.0000000000 * -0.3017294000 
0.2404976559 *= 2.9815905531 * 0.2609056200 
0.4010891632 *= 0.7466465721 * 0.2150837000 
0.4010891632 *= 0.0000000000 * 0.2865980300 
0.4010891632 *= 0.0000000000 * -0.0561963880 
0.3521980821 *= 1.0241483595 * -0.0477382800 
0.2873292207 *= 0.4552877816 * -0.1424788100 
0.5085285566 *= 0.7563354857 * 0.2924619300 
0.2626971828 *= 2.9977580144 * -0.0820050760 
0.2626971828 *= 0.0000000000 * 0.0153808410 
0.2626971828 *= 0.0000000000 * 0.1232287700 
0.0363263741 *= 4.1460735919 * -0.0545988400 
-0.7253832053 *= 3.4189601259 * -0.2227898400 
-0.7253832053 *= 0.0000000000 * -0.1107307100 
-0.7392837524 *= 0.0871511047 * -0.1594993800 
-0.6460279245 *= 0.4957431902 * 0.1881131800 
-0.6575658685 *= 1.8866465586 * -0.0061155832 
-0.8508352137 *= 1.2184361754 * -0.1586208200 
-0.8508352137 *= 0.0000000000 * 0.1621143200 
-0.8508352137 *= 0.0000000000 * 0.0488632620 
-0.8508352137 *= 0.0000000000 * 0.0757325200 
-0.8508352137 *= 0.0000000000 * 0.0002183055 
-0.9726309386 *= 1.6084186703 * -0.0757238940 
-0.9726309386 *= 0.0000000000 * 0.0424993200 
tempVal = -0.9726309386 + -0.0087004820(biases), 
now the tempVal = -0.9813314206 
ReLU !!! in layer: 4, node : 4, its linear result is negative,so set it to 0

compute layer: 4, node : 5
-0.5509424694 *= 2.6593807282 * -0.2071694600 
-0.5509424694 *= 0.0000000000 * -0.2118285600 
-0.4006053535 *= 2.2373548989 * 0.0671941300 
-0.4006053535 *= 0.0000000000 * 0.0050963340 
0.0996567433 *= 1.5408149683 * 0.3246737000 
0.1472630625 *= 0.3375394615 * 0.1410392700 
0.1472630625 *= 0.0000000000 * -0.2664683000 
1.0573004340 *= 2.9815905531 * 0.3052187600 
1.1015828401 *= 0.7466465721 * 0.0593083900 
1.1015828401 *= 0.0000000000 * -0.1765879100 
1.1015828401 *= 0.0000000000 * -0.2922525700 
1.0628445892 *= 1.0241483595 * -0.0378248430 
1.1342490383 *= 0.4552877816 * 0.1568336600 
1.4098600566 *= 0.7563354857 * 0.3644031300 
0.7604035770 *= 2.9977580144 * -0.2166474000 
0.7604035770 *= 0.0000000000 * -0.1876376600 
0.7604035770 *= 0.0000000000 * -0.1735941800 
2.0012238973 *= 4.1460735919 * 0.2992760000 
2.7742047625 *= 3.4189601259 * 0.2260865400 
2.7742047625 *= 0.0000000000 * 0.0559885100 
2.7679580851 *= 0.0871511047 * -0.0716764000 
2.7766931783 *= 0.4957431902 * 0.0176201980 
3.0371985617 *= 1.8866465586 * 0.1380785300 
3.0965314481 *= 1.2184361754 * 0.0486959330 
3.0965314481 *= 0.0000000000 * 0.1272897600 
3.0965314481 *= 0.0000000000 * 0.2565806200 
3.0965314481 *= 0.0000000000 * 0.1005031100 
3.0965314481 *= 0.0000000000 * 0.2704648400 
3.4293547038 *= 1.6084186703 * 0.2069257600 
3.4293547038 *= 0.0000000000 * 0.1044459100 
tempVal = 3.4293547038 + 0.0733638260(biases), 
now the tempVal = 3.5027185298 

compute layer: 4, node : 6
-0.2699707578 *= 2.6593807282 * -0.1015164000 
-0.2699707578 *= 0.0000000000 * 0.2220900800 
-0.3294789747 *= 2.2373548989 * -0.0265975760 
-0.3294789747 *= 0.0000000000 * 0.1259880200 
0.2608266231 *= 1.5408149683 * 0.3831125800 
0.2195170991 *= 0.3375394615 * -0.1223842800 
0.2195170991 *= 0.0000000000 * 0.0329982600 
0.9767364458 *= 2.9815905531 * 0.2539649000 
0.7703345127 *= 0.7466465721 * -0.2764386000 
0.7703345127 *= 0.0000000000 * 0.0625411940 
0.7703345127 *= 0.0000000000 * -0.1255216200 
0.6554678762 *= 1.0241483595 * -0.1121582000 
0.5763725510 *= 0.4552877816 * -0.1737260000 
0.7773431800 *= 0.7563354857 * 0.2657162500 
0.5563177921 *= 2.9977580144 * -0.0737302300 
0.5563177921 *= 0.0000000000 * -0.2319493000 
0.5563177921 *= 0.0000000000 * 0.2875266700 
1.3278751796 *= 4.1460735919 * 0.1860935100 
1.3564117388 *= 3.4189601259 * 0.0083465610 
1.3564117388 *= 0.0000000000 * -0.0077701095 
1.3321370065 *= 0.0871511047 * -0.2785361400 
1.3899194992 *= 0.4957431902 * 0.1165573100 
1.7999198882 *= 1.8866465586 * 0.2173170100 
1.6415947076 *= 1.2184361754 * -0.1299413000 
1.6415947076 *= 0.0000000000 * -0.2889710700 
1.6415947076 *= 0.0000000000 * 0.2081496600 
1.6415947076 *= 0.0000000000 * -0.0878370900 
1.6415947076 *= 0.0000000000 * -0.1823327400 
1.3518704616 *= 1.6084186703 * -0.1801298700 
1.3518704616 *= 0.0000000000 * -0.2075516700 
tempVal = 1.3518704616 + 0.0520855260(biases), 
now the tempVal = 1.4039559876 

compute layer: 4, node : 7
0.0985534851 *= 2.6593807282 * 0.0370588100 
0.0985534851 *= 0.0000000000 * 0.2136440600 
0.7590871007 *= 2.2373548989 * 0.2952297000 
0.7590871007 *= 0.0000000000 * 0.0661576840 
0.9245474622 *= 1.5408149683 * 0.1073849650 
0.9756272954 *= 0.3375394615 * 0.1513299600 
0.9756272954 *= 0.0000000000 * -0.1724963600 
1.9085961394 *= 2.9815905531 * 0.3129097800 
1.8309365185 *= 0.7466465721 * -0.1040112200 
1.8309365185 *= 0.0000000000 * -0.2064762000 
1.8309365185 *= 0.0000000000 * -0.1079708040 
1.7447425847 *= 1.0241483595 * -0.0841615700 
1.7547818382 *= 0.4552877816 * 0.0220503470 
1.7629934301 *= 0.7563354857 * 0.0108570760 
1.3481904460 *= 2.9977580144 * -0.1383710700 
1.3481904460 *= 0.0000000000 * -0.0330632300 
1.3481904460 *= 0.0000000000 * 0.2491443000 
2.0797125591 *= 4.1460735919 * 0.1764373200 
2.6122159406 *= 3.4189601259 * 0.1557501000 
2.6122159406 *= 0.0000000000 * 0.0295978080 
2.6095105213 *= 0.0871511047 * -0.0310428570 
2.5879361118 *= 0.4957431902 * -0.0435193260 
2.8951192253 *= 1.8866465586 * 0.1628196400 
2.5692304129 *= 1.2184361754 * -0.2674648200 
2.5692304129 *= 0.0000000000 * -0.1642923000 
2.5692304129 *= 0.0000000000 * -0.2283628400 
2.5692304129 *= 0.0000000000 * -0.0729895500 
2.5692304129 *= 0.0000000000 * 0.3095883700 
2.2749362957 *= 1.6084186703 * -0.1829710900 
2.2749362957 *= 0.0000000000 * 0.1583985400 
tempVal = 2.2749362957 + 0.0303873180(biases), 
now the tempVal = 2.3053236137 

compute layer: 4, node : 8
-0.6041569437 *= 2.6593807282 * -0.2271795600 
-0.6041569437 *= 0.0000000000 * 0.2827533800 
-1.0305745929 *= 2.2373548989 * -0.1905900800 
-1.0305745929 *= 0.0000000000 * -0.2526804000 
-1.0513140856 *= 1.5408149683 * -0.0134600800 
-1.0655086650 *= 0.3375394615 * -0.0420530960 
-1.0655086650 *= 0.0000000000 * 0.2313944300 
-0.3167533383 *= 2.9815905531 * 0.2511261400 
-0.3067538823 *= 0.7466465721 * 0.0133924890 
-0.3067538823 *= 0.0000000000 * -0.0444086300 
-0.3067538823 *= 0.0000000000 * 0.0545586800 
-0.1261805089 *= 1.0241483595 * 0.1763156400 
-0.1482718652 *= 0.4552877816 * -0.0485217420 
-0.1495203255 *= 0.7563354857 * -0.0016506700 
-0.7420947365 *= 2.9977580144 * -0.1976725300 
-0.7420947365 *= 0.0000000000 * -0.2317329300 
-0.7420947365 *= 0.0000000000 * -0.2408432200 
-0.4434178389 *= 4.1460735919 * 0.0720384940 
-0.6202456190 *= 3.4189601259 * -0.0517197550 
-0.6202456190 *= 0.0000000000 * -0.2284916000 
-0.6285592823 *= 0.0871511047 * -0.0953936650 
-0.6351612158 *= 0.4957431902 * -0.0133172450 
-1.0325326003 *= 1.8866465586 * -0.2106231200 
-0.9813576644 *= 1.2184361754 * 0.0420005060 
-0.9813576644 *= 0.0000000000 * 0.2510766000 
-0.9813576644 *= 0.0000000000 * 0.1799768000 
-0.9813576644 *= 0.0000000000 * 0.1551925000 
-0.9813576644 *= 0.0000000000 * -0.2833575300 
-1.3264180107 *= 1.6084186703 * -0.2145339100 
-1.3264180107 *= 0.0000000000 * 0.0734299400 
tempVal = -1.3264180107 + 0.0000000000(biases), 
now the tempVal = -1.3264180107 
ReLU !!! in layer: 4, node : 8, its linear result is negative,so set it to 0

compute layer: 4, node : 9
-0.2672959526 *= 2.6593807282 * -0.1005106000 
-0.2672959526 *= 0.0000000000 * 0.2419457900 
0.4394463802 *= 2.2373548989 * 0.3158829800 
0.4394463802 *= 0.0000000000 * -0.2461568600 
0.0537739838 *= 1.5408149683 * -0.2503041600 
-0.0420496653 *= 0.3375394615 * -0.2838887300 
-0.0420496653 *= 0.0000000000 * -0.1950503300 
-0.8022446393 *= 2.9815905531 * -0.2549629000 
-0.9344016425 *= 0.7466465721 * -0.1770007500 
-0.9344016425 *= 0.0000000000 * -0.3007105000 
-0.9344016425 *= 0.0000000000 * -0.2542782000 
-1.2468657020 *= 1.0241483595 * -0.3050964800 
-1.2174302087 *= 0.4552877816 * 0.0646525000 
-1.0652846506 *= 0.7563354857 * 0.2011614700 
-1.7009137316 *= 2.9977580144 * -0.2120348200 
-1.7009137316 *= 0.0000000000 * 0.1404063000 
-1.7009137316 *= 0.0000000000 * 0.2968392000 
-2.8193144710 *= 4.1460735919 * -0.2697493700 
-2.5736813663 *= 3.4189601259 * 0.0718443900 
-2.5736813663 *= 0.0000000000 * 0.1577000500 
-2.5882171727 *= 0.0871511047 * -0.1667885500 
-2.6073872679 *= 0.4957431902 * -0.0386694070 
-2.0559597210 *= 1.8866465586 * 0.2922792000 
-2.3020343478 *= 1.2184361754 * -0.2019593900 
-2.3020343478 *= 0.0000000000 * -0.2371202900 
-2.3020343478 *= 0.0000000000 * -0.0433155600 
-2.3020343478 *= 0.0000000000 * -0.1298798800 
-2.3020343478 *= 0.0000000000 * 0.1076831700 
-2.0554544690 *= 1.6084186703 * 0.1533057800 
-2.0554544690 *= 0.0000000000 * -0.1549455500 
tempVal = -2.0554544690 + 0.0000000000(biases), 
now the tempVal = -2.0554544690 
ReLU !!! in layer: 4, node : 9, its linear result is negative,so set it to 0

compute layer: 4, node : 10
-0.1167114708 *= 2.6593807282 * -0.0438867100 
-0.1167114708 *= 0.0000000000 * 0.2160930200 
-0.4003662334 *= 2.2373548989 * -0.1267813000 
-0.4003662334 *= 0.0000000000 * -0.0738395450 
-0.0423892311 *= 1.5408149683 * 0.2323296500 
-0.0332819085 *= 0.3375394615 * 0.0269815050 
-0.0332819085 *= 0.0000000000 * -0.2716942400 
0.8186431897 *= 2.9815905531 * 0.2857284000 
0.7274285259 *= 0.7466465721 * -0.1221657840 
0.7274285259 *= 0.0000000000 * -0.1389782900 
0.7274285259 *= 0.0000000000 * 0.1925280700 
0.6167464305 *= 1.0241483595 * -0.1080723260 
0.6543545603 *= 0.4552877816 * 0.0826029850 
0.4751050545 *= 0.7563354857 * -0.2369973500 
0.3746910728 *= 2.9977580144 * -0.0334963600 
0.3746910728 *= 0.0000000000 * 0.1616940300 
0.3746910728 *= 0.0000000000 * -0.0568599300 
0.6297515084 *= 4.1460735919 * 0.0615185500 
-0.2872264869 *= 3.4189601259 * -0.2682037700 
-0.2872264869 *= 0.0000000000 * 0.1442440300 
-0.2987852899 *= 0.0871511047 * -0.1326294500 
-0.2508994375 *= 0.4957431902 * 0.0965940700 
-0.8175212433 *= 1.8866465586 * -0.3003327800 
-0.8711855187 *= 1.2184361754 * -0.0440435670 
-0.8711855187 *= 0.0000000000 * 0.0285771820 
-0.8711855187 *= 0.0000000000 * 0.0297748260 
-0.8711855187 *= 0.0000000000 * -0.1718380000 
-0.8711855187 *= 0.0000000000 * -0.0361545940 
-1.2214184429 *= 1.6084186703 * -0.2177498500 
-1.2214184429 *= 0.0000000000 * 0.1853276600 
tempVal = -1.2214184429 + 0.0127779840(biases), 
now the tempVal = -1.2086404589 
ReLU !!! in layer: 4, node : 10, its linear result is negative,so set it to 0

compute layer: 4, node : 11
-0.8597945967 *= 2.6593807282 * -0.3233063200 
-0.8597945967 *= 0.0000000000 * 0.2269812800 
-0.7223690098 *= 2.2373548989 * 0.0614232400 
-0.7223690098 *= 0.0000000000 * 0.0011690683 
-0.3659811732 *= 1.5408149683 * 0.2312982700 
-0.3780986414 *= 0.3375394615 * -0.0358994120 
-0.3780986414 *= 0.0000000000 * 0.1588516200 
-1.0920358481 *= 2.9815905531 * -0.2394484400 
-0.9779769754 *= 0.7466465721 * 0.1527615300 
-0.9779769754 *= 0.0000000000 * 0.1584426500 
-0.9779769754 *= 0.0000000000 * -0.3023417600 
-0.9605211705 *= 1.0241483595 * 0.0170442150 
-0.9407003385 *= 0.4552877816 * 0.0435347330 
-1.1044061744 *= 0.7563354857 * -0.2164460600 
-0.7580899400 *= 2.9977580144 * 0.1155250800 
-0.7580899400 *= 0.0000000000 * -0.3037888700 
-0.7580899400 *= 0.0000000000 * 0.2092865100 
0.4032464181 *= 4.1460735919 * 0.2801051000 
-0.1767178738 *= 3.4189601259 * -0.1696317800 
-0.1767178738 *= 0.0000000000 * 0.0380101700 
-0.1705930101 *= 0.0871511047 * 0.0702786700 
-0.3043062019 *= 0.4957431902 * -0.2697227000 
-0.3390900158 *= 1.8866465586 * -0.0184368470 
-0.2723107762 *= 1.2184361754 * 0.0548073350 
-0.2723107762 *= 0.0000000000 * 0.2479610000 
-0.2723107762 *= 0.0000000000 * 0.2429381000 
-0.2723107762 *= 0.0000000000 * -0.2550080400 
-0.2723107762 *= 0.0000000000 * 0.0936269000 
-0.1452478646 *= 1.6084186703 * 0.0789986550 
-0.1452478646 *= 0.0000000000 * 0.2122147200 
tempVal = -0.1452478646 + -0.0121005260(biases), 
now the tempVal = -0.1573483906 
ReLU !!! in layer: 4, node : 11, its linear result is negative,so set it to 0

compute layer: 4, node : 12
0.1561294821 *= 2.6593807282 * 0.0587089620 
0.1561294821 *= 0.0000000000 * -0.2994636000 
0.6621139374 *= 2.2373548989 * 0.2261529700 
0.6621139374 *= 0.0000000000 * -0.0468602330 
0.8488295471 *= 1.5408149683 * 0.1211797740 
0.8337846099 *= 0.3375394615 * -0.0445723800 
0.8337846099 *= 0.0000000000 * 0.1095361000 
1.1258345055 *= 2.9815905531 * 0.0979510400 
1.2587049295 *= 0.7466465721 * 0.1779562500 
1.2587049295 *= 0.0000000000 * 0.1983661800 
1.2587049295 *= 0.0000000000 * 0.2547558800 
1.2953841127 *= 1.0241483595 * 0.0358143260 
1.3820262608 *= 0.4552877816 * 0.1903019400 
1.4501720654 *= 0.7563354857 * 0.0900999700 
1.7756538217 *= 2.9977580144 * 0.1085750600 
1.7756538217 *= 0.0000000000 * -0.0401305150 
1.7756538217 *= 0.0000000000 * -0.2534373700 
3.2784613398 *= 4.1460735919 * 0.3624652300 
3.3430155362 *= 3.4189601259 * 0.0188812370 
3.3430155362 *= 0.0000000000 * 0.0353254700 
3.3449680270 *= 0.0871511047 * 0.0224035120 
3.3187153584 *= 0.4957431902 * -0.0529561860 
3.8516706356 *= 1.8866465586 * 0.2824881400 
4.1054407590 *= 1.2184361754 * 0.2082752700 
4.1054407590 *= 0.0000000000 * -0.0123995990 
4.1054407590 *= 0.0000000000 * -0.3100036000 
4.1054407590 *= 0.0000000000 * 0.0777350500 
4.1054407590 *= 0.0000000000 * -0.0951027900 
4.5583407358 *= 1.6084186703 * 0.2815809000 
4.5583407358 *= 0.0000000000 * 0.0746597400 
tempVal = 4.5583407358 + 0.0396470430(biases), 
now the tempVal = 4.5979877788 

compute layer: 4, node : 13
-0.0563339705 *= 2.6593807282 * -0.0211831160 
-0.0563339705 *= 0.0000000000 * -0.0805714100 
-0.0531863730 *= 2.2373548989 * 0.0014068387 
-0.0531863730 *= 0.0000000000 * 0.1896846400 
0.4828673147 *= 1.5408149683 * 0.3479027000 
0.5590294859 *= 0.3375394615 * 0.2256393100 
0.5590294859 *= 0.0000000000 * -0.2460162600 
0.9450061924 *= 2.9815905531 * 0.1294532900 
0.8413539527 *= 0.7466465721 * -0.1388237000 
0.8413539527 *= 0.0000000000 * -0.0625554250 
0.8413539527 *= 0.0000000000 * -0.2225427800 
1.0493970129 *= 1.0241483595 * 0.2031376200 
1.1800416142 *= 0.4552877816 * 0.2869495000 
1.4213669844 *= 0.7563354857 * 0.3190718600 
2.8644283370 *= 2.9977580144 * 0.4813802000 
2.8644283370 *= 0.0000000000 * -0.1942859000 
2.8644283370 *= 0.0000000000 * -0.0982460300 
1.5897585598 *= 4.1460735919 * -0.3074402200 
1.7548570843 *= 3.4189601259 * 0.0482891050 
1.7548570843 *= 0.0000000000 * 0.1355423600 
1.7413659128 *= 0.0871511047 * -0.1548020700 
1.9161951525 *= 0.4957431902 * 0.3526609000 
2.3423952699 *= 1.8866465586 * 0.2259035300 
2.3977638243 *= 1.2184361754 * 0.0454423100 
2.3977638243 *= 0.0000000000 * 0.1506645200 
2.3977638243 *= 0.0000000000 * 0.0894509200 
2.3977638243 *= 0.0000000000 * -0.1875414100 
2.3977638243 *= 0.0000000000 * -0.1695731400 
2.0100259061 *= 1.6084186703 * -0.2410677800 
2.0100259061 *= 0.0000000000 * -0.1853001300 
tempVal = 2.0100259061 + 0.0919639900(biases), 
now the tempVal = 2.1019898961 

compute layer: 4, node : 14
0.0687426143 *= 2.6593807282 * 0.0258491060 
0.0687426143 *= 0.0000000000 * 0.1354033800 
-0.5896788935 *= 2.2373548989 * -0.2942856800 
-0.5896788935 *= 0.0000000000 * -0.0083854600 
-0.1441912742 *= 1.5408149683 * 0.2891246700 
-0.2209309991 *= 0.3375394615 * -0.2273503800 
-0.2209309991 *= 0.0000000000 * -0.1786556400 
-1.1446922740 *= 2.9815905531 * -0.3098216400 
-1.2044492589 *= 0.7466465721 * -0.0800338300 
-1.2044492589 *= 0.0000000000 * 0.0682747200 
-1.2044492589 *= 0.0000000000 * -0.0994900800 
-1.0677166042 *= 1.0241483595 * 0.1335086400 
-1.0360306808 *= 0.4552877816 * 0.0695953740 
-1.2600252284 *= 0.7563354857 * -0.2961576600 
-1.5969959522 *= 2.9977580144 * -0.1124075800 
-1.5969959522 *= 0.0000000000 * -0.0640349460 
-1.5969959522 *= 0.0000000000 * -0.2404638400 
-0.6122093998 *= 4.1460735919 * 0.2375226900 
-0.9198430898 *= 3.4189601259 * -0.0899787300 
-0.9198430898 *= 0.0000000000 * 0.2587193800 
-0.9112735199 *= 0.0871511047 * 0.0983300200 
-0.9611082082 *= 0.4957431902 * -0.1005252100 
-0.7514588732 *= 1.8866465586 * 0.1111227400 
-1.1195277893 *= 1.2184361754 * -0.3020830500 
-1.1195277893 *= 0.0000000000 * 0.2903377700 
-1.1195277893 *= 0.0000000000 * -0.0436734200 
-1.1195277893 *= 0.0000000000 * 0.0165396090 
-1.1195277893 *= 0.0000000000 * -0.0620954600 
-0.8001074542 *= 1.6084186703 * 0.1985927800 
-0.8001074542 *= 0.0000000000 * -0.0508520380 
tempVal = -0.8001074542 + 0.0000000000(biases), 
now the tempVal = -0.8001074542 
ReLU !!! in layer: 4, node : 14, its linear result is negative,so set it to 0

compute layer: 4, node : 15
0.2176747272 *= 2.6593807282 * 0.0818516600 
0.2176747272 *= 0.0000000000 * 0.0535100400 
0.5353503952 *= 2.2373548989 * 0.1419871600 
0.5353503952 *= 0.0000000000 * 0.1334916800 
1.0570678319 *= 1.5408149683 * 0.3385983700 
1.0546558281 *= 0.3375394615 * -0.0071458425 
1.0546558281 *= 0.0000000000 * -0.1259169700 
1.6091552230 *= 2.9815905531 * 0.1859743600 
1.7418090150 *= 0.7466465721 * 0.1776661100 
1.7418090150 *= 0.0000000000 * 0.2401207500 
1.7418090150 *= 0.0000000000 * -0.2612610500 
1.5573334519 *= 1.0241483595 * -0.1801258200 
1.5554124494 *= 0.4552877816 * -0.0042193150 
1.4187059146 *= 0.7563354857 * -0.1807485400 
0.7775663848 *= 2.9977580144 * -0.2138730100 
0.7775663848 *= 0.0000000000 * -0.2023189800 
0.7775663848 *= 0.0000000000 * -0.0172120910 
-0.2548547803 *= 4.1460735919 * -0.2490117800 
0.4541367588 *= 3.4189601259 * 0.2073705200 
0.4541367588 *= 0.0000000000 * -0.2154075200 
0.4548194388 *= 0.0871511047 * 0.0078332910 
0.4542938523 *= 0.4957431902 * -0.0010601990 
0.3228881083 *= 1.8866465586 * -0.0696504300 
0.4918364806 *= 1.2184361754 * 0.1386600100 
0.4918364806 *= 0.0000000000 * 0.0473857930 
0.4918364806 *= 0.0000000000 * -0.2166860300 
0.4918364806 *= 0.0000000000 * -0.0610481700 
0.4918364806 *= 0.0000000000 * -0.0284386690 
0.5752250350 *= 1.6084186703 * 0.0518450550 
0.5752250350 *= 0.0000000000 * -0.2227641600 
tempVal = 0.5752250350 + 0.0268041680(biases), 
now the tempVal = 0.6020292030 

compute layer: 4, node : 16
0.1109147388 *= 2.6593807282 * 0.0417069800 
0.1109147388 *= 0.0000000000 * 0.2131812900 
-0.1021806295 *= 2.2373548989 * -0.0952443300 
-0.1021806295 *= 0.0000000000 * -0.1407422900 
0.2939406495 *= 1.5408149683 * 0.2570855600 
0.3792613565 *= 0.3375394615 * 0.2527725400 
0.3792613565 *= 0.0000000000 * 0.0835735300 
0.3202095632 *= 2.9815905531 * -0.0198054670 
0.4509015712 *= 0.7466465721 * 0.1750386500 
0.4509015712 *= 0.0000000000 * -0.2379052600 
0.4509015712 *= 0.0000000000 * -0.2323124000 
0.2631591798 *= 1.0241483595 * -0.1833156200 
0.3552272063 *= 0.4552877816 * 0.2022194100 
0.2774561251 *= 0.7563354857 * -0.1028261700 
0.6051931847 *= 2.9977580144 * 0.1093273900 
0.6051931847 *= 0.0000000000 * -0.0261248280 
0.6051931847 *= 0.0000000000 * -0.0248184060 
0.0075363447 *= 4.1460735919 * -0.1441500800 
-0.8448063119 *= 3.4189601259 * -0.2492988000 
-0.8448063119 *= 0.0000000000 * -0.2682913000 
-0.8242370528 *= 0.0871511047 * 0.2360183400 
-0.8173365649 *= 0.4957431902 * 0.0139194810 
-1.3214918050 *= 1.8866465586 * -0.2672229400 
-1.2447084551 *= 1.2184361754 * 0.0630179500 
-1.2447084551 *= 0.0000000000 * 0.0538355700 
-1.2447084551 *= 0.0000000000 * 0.2596340500 
-1.2447084551 *= 0.0000000000 * -0.2323371300 
-1.2447084551 *= 0.0000000000 * -0.0750861200 
-1.0609568515 *= 1.6084186703 * 0.1142436400 
-1.0609568515 *= 0.0000000000 * -0.2080372700 
tempVal = -1.0609568515 + 0.0172124860(biases), 
now the tempVal = -1.0437443655 
ReLU !!! in layer: 4, node : 16, its linear result is negative,so set it to 0

compute layer: 4, node : 17
-0.7099666289 *= 2.6593807282 * -0.2669669000 
-0.7099666289 *= 0.0000000000 * -0.2209881700 
-0.8538429687 *= 2.2373548989 * -0.0643064450 
-0.8538429687 *= 0.0000000000 * -0.0517985970 
-0.5995810108 *= 1.5408149683 * 0.1650178400 
-0.6183065430 *= 0.3375394615 * -0.0554765720 
-0.6183065430 *= 0.0000000000 * 0.1734855900 
-1.3903369407 *= 2.9815905531 * -0.2589324000 
-1.4629663887 *= 0.7466465721 * -0.0972742000 
-1.4629663887 *= 0.0000000000 * 0.2768161600 
-1.4629663887 *= 0.0000000000 * 0.0320885070 
-1.7234670449 *= 1.0241483595 * -0.2543583200 
-1.7729677400 *= 0.4552877816 * -0.1087239700 
-1.6799250730 *= 0.7563354857 * 0.1230177200 
-2.2277588750 *= 2.9977580144 * -0.1827478400 
-2.2277588750 *= 0.0000000000 * 0.1202621100 
-2.2277588750 *= 0.0000000000 * 0.1261622200 
-2.9551314317 *= 4.1460735919 * -0.1754364800 
-1.9951017880 *= 3.4189601259 * 0.2807958000 
-1.9951017880 *= 0.0000000000 * -0.2215286500 
-1.9782212125 *= 0.0871511047 * 0.1936931900 
-2.0556010978 *= 0.4957431902 * -0.1560886500 
-1.4986123962 *= 1.8866465586 * 0.2952268400 
-1.3196801579 *= 1.2184361754 * 0.1468540100 
-1.3196801579 *= 0.0000000000 * 0.1240216300 
-1.3196801579 *= 0.0000000000 * 0.2695563400 
-1.3196801579 *= 0.0000000000 * -0.1754380800 
-1.3196801579 *= 0.0000000000 * -0.0440943840 
-1.0394249621 *= 1.6084186703 * 0.1742426900 
-1.0394249621 *= 0.0000000000 * 0.1312240400 
tempVal = -1.0394249621 + 0.0025425262(biases), 
now the tempVal = -1.0368824359 
ReLU !!! in layer: 4, node : 17, its linear result is negative,so set it to 0

compute layer: 4, node : 18
0.5900583432 *= 2.6593807282 * 0.2218781000 
0.5900583432 *= 0.0000000000 * 0.1494834100 
0.7700644407 *= 2.2373548989 * 0.0804548700 
0.7700644407 *= 0.0000000000 * -0.0000888525 
1.0957547593 *= 1.5408149683 * 0.2113753600 
1.0016238977 *= 0.3375394615 * -0.2788736500 
1.0016238977 *= 0.0000000000 * 0.2844811700 
0.6699886468 *= 2.9815905531 * -0.1112276300 
0.7671429036 *= 0.7466465721 * 0.1301208100 
0.7671429036 *= 0.0000000000 * 0.2392010100 
0.7671429036 *= 0.0000000000 * -0.0683941700 
0.7220000497 *= 1.0241483595 * -0.0440784320 
0.6686788709 *= 0.4552877816 * -0.1171153300 
0.8109450766 *= 0.7563354857 * 0.1880993400 
0.3769409429 *= 2.9977580144 * -0.1447762400 
0.3769409429 *= 0.0000000000 * -0.1963296800 
0.3769409429 *= 0.0000000000 * -0.2669312000 
-1.0187675655 *= 4.1460735919 * -0.3366338000 
-0.8514772208 *= 3.4189601259 * 0.0489301830 
-0.8514772208 *= 0.0000000000 * 0.2488333400 
-0.8527927464 *= 0.0871511047 * -0.0150947670 
-0.7803773822 *= 0.4957431902 * 0.1460743500 
-1.0247786336 *= 1.8866465586 * -0.1295426800 
-1.3274165036 *= 1.2184361754 * -0.2483822100 
-1.3274165036 *= 0.0000000000 * 0.3112861000 
-1.3274165036 *= 0.0000000000 * -0.2360583500 
-1.3274165036 *= 0.0000000000 * -0.2815902800 
-1.3274165036 *= 0.0000000000 * -0.1527054900 
-1.2189101674 *= 1.6084186703 * 0.0674615000 
-1.2189101674 *= 0.0000000000 * -0.2743774000 
tempVal = -1.2189101674 + -0.0477866100(biases), 
now the tempVal = -1.2666967774 
ReLU !!! in layer: 4, node : 18, its linear result is negative,so set it to 0

compute layer: 4, node : 19
0.4867679957 *= 2.6593807282 * 0.1830381000 
0.4867679957 *= 0.0000000000 * -0.1275689000 
0.1645850867 *= 2.2373548989 * -0.1440017000 
0.1645850867 *= 0.0000000000 * 0.0277298220 
0.0452956449 *= 1.5408149683 * -0.0774197060 
0.0617045047 *= 0.3375394615 * 0.0486131600 
0.0617045047 *= 0.0000000000 * -0.2908234000 
0.1988332688 *= 2.9815905531 * 0.0459918160 
0.3673708503 *= 0.7466465721 * 0.2257260500 
0.3673708503 *= 0.0000000000 * 0.0039380850 
0.3673708503 *= 0.0000000000 * -0.2802591000 
0.0512053958 *= 1.0241483595 * -0.3087106000 
-0.0580551397 *= 0.4552877816 * -0.2399812600 
-0.1953205535 *= 0.7563354857 * -0.1814874700 
0.0557854625 *= 2.9977580144 * 0.0837646050 
0.0557854625 *= 0.0000000000 * -0.0791209860 
0.0557854625 *= 0.0000000000 * 0.2428808500 
-1.2588990661 *= 4.1460735919 * -0.3170914600 
-0.9256865455 *= 3.4189601259 * 0.0974601950 
-0.9256865455 *= 0.0000000000 * -0.1987678100 
-0.9083522378 *= 0.0871511047 * 0.1988994600 
-1.0415915983 *= 0.4957431902 * -0.2687669000 
-1.1543306122 *= 1.8866465586 * -0.0597562980 
-1.1106565961 *= 1.2184361754 * 0.0358443200 
-1.1106565961 *= 0.0000000000 * 0.1095111800 
-1.1106565961 *= 0.0000000000 * 0.0969428200 
-1.1106565961 *= 0.0000000000 * 0.0187256370 
-1.1106565961 *= 0.0000000000 * 0.2273733300 
-0.7330456035 *= 1.6084186703 * 0.2347715800 
-0.7330456035 *= 0.0000000000 * 0.1372513300 
tempVal = -0.7330456035 + -0.0201519780(biases), 
now the tempVal = -0.7531975815 
ReLU !!! in layer: 4, node : 19, its linear result is negative,so set it to 0

compute layer: 4, node : 20
-0.2609653766 *= 2.6593807282 * -0.0981301300 
-0.2609653766 *= 0.0000000000 * -0.1120606100 
0.5624053896 *= 2.2373548989 * 0.3680108000 
0.5624053896 *= 0.0000000000 * -0.0151612830 
0.3646278749 *= 1.5408149683 * -0.1283590300 
0.3652912536 *= 0.3375394615 * 0.0019653367 
0.3652912536 *= 0.0000000000 * -0.1696710600 
0.0915978185 *= 2.9815905531 * -0.0917944400 
0.0147508813 *= 0.7466465721 * -0.1029227750 
0.0147508813 *= 0.0000000000 * 0.2624219700 
0.0147508813 *= 0.0000000000 * 0.2676015200 
0.1744312083 *= 1.0241483595 * 0.1559152300 
0.2510620926 *= 0.4552877816 * 0.1683130700 
0.3232009658 *= 0.7563354857 * 0.0953794640 
1.4787891060 *= 2.9977580144 * 0.3854841300 
1.4787891060 *= 0.0000000000 * 0.1716145900 
1.4787891060 *= 0.0000000000 * -0.0176358900 
0.6508621995 *= 4.1460735919 * -0.1996893900 
1.7002071848 *= 3.4189601259 * 0.3069193400 
1.7002071848 *= 0.0000000000 * -0.1666171600 
1.6964209010 *= 0.0871511047 * -0.0434450470 
1.7589725969 *= 0.4957431902 * 0.1261776200 
1.9118784330 *= 1.8866465586 * 0.0810463600 
1.9226628360 *= 1.2184361754 * 0.0088510200 
1.9226628360 *= 0.0000000000 * -0.3042342000 
1.9226628360 *= 0.0000000000 * 0.3089178200 
1.9226628360 *= 0.0000000000 * 0.0872469000 
1.9226628360 *= 0.0000000000 * 0.2234070700 
2.0756100213 *= 1.6084186703 * 0.0950916500 
2.0756100213 *= 0.0000000000 * 0.2486593000 
tempVal = 2.0756100213 + 0.0798029100(biases), 
now the tempVal = 2.1554129313 

compute layer: 4, node : 21
-0.5198719138 *= 2.6593807282 * -0.1954860800 
-0.5198719138 *= 0.0000000000 * -0.0830631850 
-0.7039518453 *= 2.2373548989 * -0.0822756960 
-0.7039518453 *= 0.0000000000 * 0.2028848100 
-0.5051811058 *= 1.5408149683 * 0.1290036400 
-0.4945030821 *= 0.3375394615 * 0.0316348900 
-0.4945030821 *= 0.0000000000 * -0.2878861400 
0.2420236982 *= 2.9815905531 * 0.2470247900 
0.1579181580 *= 0.7466465721 * -0.1126443800 
0.1579181580 *= 0.0000000000 * -0.0113176680 
0.1579181580 *= 0.0000000000 * -0.0657187300 
-0.0217171775 *= 1.0241483595 * -0.1753997200 
0.0725153919 *= 0.4552877816 * 0.2069736400 
-0.1200327230 *= 0.7563354857 * -0.2545803000 
0.3231676031 *= 2.9977580144 * 0.1478439300 
0.3231676031 *= 0.0000000000 * 0.3010772800 
0.3231676031 *= 0.0000000000 * 0.2936483000 
-0.0224361972 *= 4.1460735919 * -0.0833568900 
-0.6332437490 *= 3.4189601259 * -0.1786530200 
-0.6332437490 *= 0.0000000000 * -0.0209397080 
-0.6343108369 *= 0.0871511047 * -0.0122441120 
-0.7715558816 *= 0.4957431902 * -0.2768470600 
-0.6840588251 *= 1.8866465586 * 0.0463770260 
-0.5096723285 *= 1.2184361754 * 0.1431232100 
-0.5096723285 *= 0.0000000000 * 0.0548763570 
-0.5096723285 *= 0.0000000000 * 0.1505581600 
-0.5096723285 *= 0.0000000000 * -0.1890323600 
-0.5096723285 *= 0.0000000000 * 0.1276736900 
-0.1453129044 *= 1.6084186703 * 0.2265327000 
-0.1453129044 *= 0.0000000000 * 0.2171349100 
tempVal = -0.1453129044 + -0.0075555540(biases), 
now the tempVal = -0.1528684584 
ReLU !!! in layer: 4, node : 21, its linear result is negative,so set it to 0

compute layer: 4, node : 22
-0.7713959303 *= 2.6593807282 * -0.2900660000 
-0.7713959303 *= 0.0000000000 * -0.2963336400 
-0.9236284886 *= 2.2373548989 * -0.0680413100 
-0.9236284886 *= 0.0000000000 * 0.1369354700 
-0.8497775815 *= 1.5408149683 * 0.0479297700 
-0.9317259757 *= 0.3375394615 * -0.2427816700 
-0.9317259757 *= 0.0000000000 * -0.0092700360 
-0.8025525215 *= 2.9815905531 * 0.0433236730 
-0.9169737194 *= 0.7466465721 * -0.1532468000 
-0.9169737194 *= 0.0000000000 * 0.1180876600 
-0.9169737194 *= 0.0000000000 * -0.1939131900 
-1.1374513234 *= 1.0241483595 * -0.2152789700 
-1.1644061512 *= 0.4552877816 * -0.0592039340 
-1.0886727020 *= 0.7563354857 * 0.1001320850 
-1.2906337729 *= 2.9977580144 * -0.0673707050 
-1.2906337729 *= 0.0000000000 * 0.3040505600 
-1.2906337729 *= 0.0000000000 * -0.0057411460 
-2.0486707729 *= 4.1460735919 * -0.1828325000 
-1.1808792714 *= 3.4189601259 * 0.2538173800 
-1.1808792714 *= 0.0000000000 * 0.2326041000 
-1.2020922486 *= 0.0871511047 * -0.2434045700 
-1.2257357816 *= 0.4957431902 * -0.0476931070 
-1.0837702126 *= 1.8866465586 * 0.0752475700 
-1.2562099772 *= 1.2184361754 * -0.1415254800 
-1.2562099772 *= 0.0000000000 * 0.2144255600 
-1.2562099772 *= 0.0000000000 * 0.2164644900 
-1.2562099772 *= 0.0000000000 * 0.2918579000 
-1.2562099772 *= 0.0000000000 * -0.1430509700 
-1.3370186522 *= 1.6084186703 * -0.0502410700 
-1.3370186522 *= 0.0000000000 * 0.3126387300 
tempVal = -1.3370186522 + -0.0120435270(biases), 
now the tempVal = -1.3490621792 
ReLU !!! in layer: 4, node : 22, its linear result is negative,so set it to 0

compute layer: 4, node : 23
-0.3334712646 *= 2.6593807282 * -0.1253943300 
-0.3334712646 *= 0.0000000000 * 0.0334677660 
-0.5158692176 *= 2.2373548989 * -0.0815239250 
-0.5158692176 *= 0.0000000000 * 0.0273370170 
-0.2189225557 *= 1.5408149683 * 0.1927205200 
-0.2004749359 *= 0.3375394615 * 0.0546532240 
-0.2004749359 *= 0.0000000000 * -0.2331910100 
-0.4737179421 *= 2.9815905531 * -0.0916433700 
-0.5580262312 *= 0.7466465721 * -0.1129159260 
-0.5580262312 *= 0.0000000000 * -0.0504155230 
-0.5580262312 *= 0.0000000000 * 0.1422368700 
-0.5850233791 *= 1.0241483595 * -0.0263605830 
-0.6394155267 *= 0.4552877816 * -0.1194676200 
-0.8511163251 *= 0.7563354857 * -0.2799033000 
-1.3885933228 *= 2.9977580144 * -0.1792929900 
-1.3885933228 *= 0.0000000000 * -0.2227011000 
-1.3885933228 *= 0.0000000000 * -0.2348804900 
-2.4665779710 *= 4.1460735919 * -0.2600013300 
-1.7175525285 *= 3.4189601259 * 0.2190799000 
-1.7175525285 *= 0.0000000000 * -0.1474400500 
-1.7331591248 *= 0.0871511047 * -0.1790751400 
-1.8151439091 *= 0.4957431902 * -0.1653775300 
-1.8259364481 *= 1.8866465586 * -0.0057204880 
-1.8419919790 *= 1.2184361754 * -0.0131771620 
-1.8419919790 *= 0.0000000000 * 0.0618336160 
-1.8419919790 *= 0.0000000000 * -0.1016283800 
-1.8419919790 *= 0.0000000000 * 0.0404736550 
-1.8419919790 *= 0.0000000000 * 0.2622279800 
-1.4667440912 *= 1.6084186703 * 0.2333023700 
-1.4667440912 *= 0.0000000000 * 0.2120519100 
tempVal = -1.4667440912 + 0.0000000000(biases), 
now the tempVal = -1.4667440912 
ReLU !!! in layer: 4, node : 23, its linear result is negative,so set it to 0

compute layer: 4, node : 24
0.7490577970 *= 2.6593807282 * 0.2816662500 
0.7490577970 *= 0.0000000000 * -0.1885056000 
1.3180342860 *= 2.2373548989 * 0.2543076600 
1.3180342860 *= 0.0000000000 * -0.1408613500 
0.8434840305 *= 1.5408149683 * -0.3079865300 
0.9001222948 *= 0.3375394615 * 0.1677974600 
0.9001222948 *= 0.0000000000 * -0.0641870200 
0.0209858595 *= 2.9815905531 * -0.2948548500 
0.1836736816 *= 0.7466465721 * 0.2178913400 
0.1836736816 *= 0.0000000000 * -0.0979652600 
0.1836736816 *= 0.0000000000 * 0.1556178200 
0.3719439499 *= 1.0241483595 * 0.1838310500 
0.4219302249 *= 0.4552877816 * 0.1097905040 
0.5362305705 *= 0.7563354857 * 0.1511238700 
1.3822656315 *= 2.9977580144 * 0.2822226000 
1.3822656315 *= 0.0000000000 * 0.2637498000 
1.3822656315 *= 0.0000000000 * -0.3106486500 
2.6758089991 *= 4.1460735919 * 0.3119923800 
3.6663036289 *= 3.4189601259 * 0.2897064000 
3.6663036289 *= 0.0000000000 * -0.3047417400 
3.6664397187 *= 0.0871511047 * 0.0015615382 
3.6136009060 *= 0.4957431902 * -0.1065850500 
4.0209085410 *= 1.8866465586 * 0.2158897400 
4.3170702765 *= 1.2184361754 * 0.2430670900 
4.3170702765 *= 0.0000000000 * 0.3045021300 
4.3170702765 *= 0.0000000000 * -0.1747357100 
4.3170702765 *= 0.0000000000 * -0.2812042200 
4.3170702765 *= 0.0000000000 * 0.0136091710 
4.3691871590 *= 1.6084186703 * 0.0324025600 
4.3691871590 *= 0.0000000000 * -0.1060295200 
tempVal = 4.3691871590 + -0.0297173240(biases), 
now the tempVal = 4.3394698350 

compute layer: 4, node : 25
-0.5529128844 *= 2.6593807282 * -0.2079103900 
-0.5529128844 *= 0.0000000000 * 0.2003560500 
-0.2888769163 *= 2.2373548989 * 0.1180125550 
-0.2888769163 *= 0.0000000000 * -0.0279032300 
-0.0110376235 *= 1.5408149683 * 0.1803197000 
-0.0687138419 *= 0.3375394615 * -0.1708725200 
-0.0687138419 *= 0.0000000000 * -0.2803926800 
0.5621550295 *= 2.9815905531 * 0.2115880300 
0.3331718386 *= 0.7466465721 * -0.3066821700 
0.3331718386 *= 0.0000000000 * -0.0818330300 
0.3331718386 *= 0.0000000000 * -0.2214053900 
-0.0222808073 *= 1.0241483595 * -0.3470714400 
0.0926527688 *= 0.4552877816 * 0.2524416000 
0.1747584692 *= 0.7563354857 * 0.1085572500 
-0.7227531931 *= 2.9977580144 * -0.2993943000 
-0.7227531931 *= 0.0000000000 * 0.0090996350 
-0.7227531931 *= 0.0000000000 * 0.1320921200 
-1.0100931334 *= 4.1460735919 * -0.0693041100 
-2.5145280033 *= 3.4189601259 * -0.4400270300 
-2.5145280033 *= 0.0000000000 * 0.0239417350 
-2.4951814420 *= 0.0871511047 * 0.2219887100 
-2.4829014519 *= 0.4957431902 * 0.0247708700 
-2.6577230273 *= 1.8866465586 * -0.0926626000 
-2.8214861129 *= 1.2184361754 * -0.1344043200 
-2.8214861129 *= 0.0000000000 * -0.2909481800 
-2.8214861129 *= 0.0000000000 * 0.0857629500 
-2.8214861129 *= 0.0000000000 * 0.2612727300 
-2.8214861129 *= 0.0000000000 * 0.2550085000 
-3.2640265063 *= 1.6084186703 * -0.2751400500 
-3.2640265063 *= 0.0000000000 * 0.0981377200 
tempVal = -3.2640265063 + -0.1227489900(biases), 
now the tempVal = -3.3867754963 
ReLU !!! in layer: 4, node : 25, its linear result is negative,so set it to 0

compute layer: 4, node : 26
-0.0009306095 *= 2.6593807282 * -0.0003499346 
-0.0009306095 *= 0.0000000000 * 0.1669185600 
0.3878860085 *= 2.2373548989 * 0.1737840600 
0.3878860085 *= 0.0000000000 * -0.1236753900 
-0.0600847265 *= 1.5408149683 * -0.2907362300 
-0.1417524161 *= 0.3375394615 * -0.2419500500 
-0.1417524161 *= 0.0000000000 * -0.1837978800 
0.6841704098 *= 2.9815905531 * 0.2770074600 
0.7807414310 *= 0.7466465721 * 0.1293396700 
0.7807414310 *= 0.0000000000 * 0.1800694200 
0.7807414310 *= 0.0000000000 * 0.1022577660 
0.6177939171 *= 1.0241483595 * -0.1591053800 
0.6888792460 *= 0.4552877816 * 0.1561327400 
0.7237556450 *= 0.7563354857 * 0.0461123400 
1.3407132502 *= 2.9977580144 * 0.2058063400 
1.3407132502 *= 0.0000000000 * -0.0171382610 
1.3407132502 *= 0.0000000000 * 0.1248954800 
0.2442187882 *= 4.1460735919 * -0.2644657500 
-0.7704217347 *= 3.4189601259 * -0.2967687500 
-0.7704217347 *= 0.0000000000 * -0.1325675200 
-0.7664991579 *= 0.0871511047 * 0.0450089160 
-0.8730669993 *= 0.4957431902 * -0.2149658200 
-0.4336909574 *= 1.8866465586 * 0.2328873100 
-0.1109551167 *= 1.2184361754 * 0.2648771000 
-0.1109551167 *= 0.0000000000 * 0.2656712500 
-0.1109551167 *= 0.0000000000 * 0.3002086000 
-0.1109551167 *= 0.0000000000 * -0.0364062100 
-0.1109551167 *= 0.0000000000 * 0.0410117840 
-0.1108467122 *= 1.6084186703 * 0.0000673982 
-0.1108467122 *= 0.0000000000 * 0.2499931800 
tempVal = -0.1108467122 + 0.0026062573(biases), 
now the tempVal = -0.1082404549 
ReLU !!! in layer: 4, node : 26, its linear result is negative,so set it to 0

compute layer: 4, node : 27
-0.0252170459 *= 2.6593807282 * -0.0094823000 
-0.0252170459 *= 0.0000000000 * 0.1913799600 
0.4957376406 *= 2.2373548989 * 0.2328440100 
0.4957376406 *= 0.0000000000 * -0.0069021470 
0.6471931727 *= 1.5408149683 * 0.0982957300 
0.6455135203 *= 0.3375394615 * -0.0049761660 
0.6455135203 *= 0.0000000000 * 0.1901654800 
0.3894998736 *= 2.9815905531 * -0.0858647900 
0.2833239460 *= 0.7466465721 * -0.1422037300 
0.2833239460 *= 0.0000000000 * -0.0704017200 
0.2833239460 *= 0.0000000000 * 0.2079350200 
0.2489783483 *= 1.0241483595 * -0.0335357640 
0.1390537893 *= 0.4552877816 * -0.2414397300 
0.2066150032 *= 0.7563354857 * 0.0893270450 
-0.3437457888 *= 2.9977580144 * -0.1835908000 
-0.3437457888 *= 0.0000000000 * 0.0653809460 
-0.3437457888 *= 0.0000000000 * 0.0040678180 
0.8339773861 *= 4.1460735919 * 0.2840574700 
1.7052474060 *= 3.4189601259 * 0.2548348000 
1.7052474060 *= 0.0000000000 * -0.2965342700 
1.7121502764 *= 0.0871511047 * 0.0792057700 
1.6665935593 *= 0.4957431902 * -0.0918958000 
1.9618401241 *= 1.8866465586 * 0.1564927800 
2.2427408734 *= 1.2184361754 * 0.2305420300 
2.2427408734 *= 0.0000000000 * -0.0497811500 
2.2427408734 *= 0.0000000000 * -0.1854753800 
2.2427408734 *= 0.0000000000 * 0.2032911800 
2.2427408734 *= 0.0000000000 * 0.1074581700 
2.7680200925 *= 1.6084186703 * 0.3265811500 
2.7680200925 *= 0.0000000000 * 0.0026250130 
tempVal = 2.7680200925 + -0.0035258445(biases), 
now the tempVal = 2.7644942480 

compute layer: 4, node : 28
-0.6532001793 *= 2.6593807282 * -0.2456211600 
-0.6532001793 *= 0.0000000000 * 0.2527714700 
-0.5445475805 *= 2.2373548989 * 0.0485629700 
-0.5445475805 *= 0.0000000000 * -0.1668911400 
-1.0411856034 *= 1.5408149683 * -0.3223216500 
-1.1411517967 *= 0.3375394615 * -0.2961615000 
-1.1411517967 *= 0.0000000000 * 0.0892495000 
-2.0586432041 *= 2.9815905531 * -0.3077187800 
-2.0738831850 *= 0.7466465721 * -0.0204112380 
-2.0738831850 *= 0.0000000000 * -0.1731104400 
-2.0738831850 *= 0.0000000000 * 0.1794899400 
-1.9725154793 *= 1.0241483595 * 0.0989775600 
-2.0156798342 *= 0.4552877816 * -0.0948067500 
-2.0699173326 *= 0.7563354857 * -0.0717109000 
-3.0823726300 *= 2.9977580144 * -0.3377375000 
-3.0823726300 *= 0.0000000000 * 0.0454275700 
-3.0823726300 *= 0.0000000000 * 0.0914441900 
-2.6390256008 *= 4.1460735919 * 0.1069317800 
-3.1233379188 *= 3.4189601259 * -0.1416548600 
-3.1233379188 *= 0.0000000000 * 0.1870669400 
-3.1372846421 *= 0.0871511047 * -0.1600292200 
-3.2537682099 *= 0.4957431902 * -0.2349675600 
-3.9132595888 *= 1.8866465586 * -0.3495574600 
-3.5730466946 *= 1.2184361754 * 0.2792209400 
-3.5730466946 *= 0.0000000000 * 0.1086690300 
-3.5730466946 *= 0.0000000000 * 0.2491579500 
-3.5730466946 *= 0.0000000000 * -0.2139662400 
-3.5730466946 *= 0.0000000000 * 0.2647020200 
-3.4870927847 *= 1.6084186703 * 0.0534400100 
-3.4870927847 *= 0.0000000000 * 0.0396546050 
tempVal = -3.4870927847 + -0.1069021900(biases), 
now the tempVal = -3.5939949747 
ReLU !!! in layer: 4, node : 28, its linear result is negative,so set it to 0

compute layer: 4, node : 29
0.2402280841 *= 2.6593807282 * 0.0903323400 
0.2402280841 *= 0.0000000000 * 0.3040666000 
0.3116532229 *= 2.2373548989 * 0.0319239200 
0.3116532229 *= 0.0000000000 * 0.2344811300 
0.6857696303 *= 1.5408149683 * 0.2428042400 
0.6944328999 *= 0.3375394615 * 0.0256659460 
0.6944328999 *= 0.0000000000 * -0.0425962620 
1.5754460974 *= 2.9815905531 * 0.2954843000 
1.7204546054 *= 0.7466465721 * 0.1942130500 
1.7204546054 *= 0.0000000000 * 0.1015773400 
1.7204546054 *= 0.0000000000 * 0.1340673600 
1.6530282885 *= 1.0241483595 * -0.0658364740 
1.6047796303 *= 0.4552877816 * -0.1059739800 
1.7519727490 *= 0.7563354857 * 0.1946135300 
1.7338128196 *= 2.9977580144 * -0.0060578370 
1.7338128196 *= 0.0000000000 * -0.0718840360 
1.7338128196 *= 0.0000000000 * 0.2175762400 
3.3307492269 *= 4.1460735919 * 0.3851683700 
4.3483584328 *= 3.4189601259 * 0.2976370500 
4.3483584328 *= 0.0000000000 * -0.3138330300 
4.3409385194 *= 0.0871511047 * -0.0851384900 
4.4198521895 *= 0.4957431902 * 0.1591825600 
4.3896693726 *= 1.8866465586 * -0.0159981300 
4.1601803793 *= 1.2184361754 * -0.1883471600 
4.1601803793 *= 0.0000000000 * 0.2847573500 
4.1601803793 *= 0.0000000000 * -0.0804281700 
4.1601803793 *= 0.0000000000 * 0.2909029400 
4.1601803793 *= 0.0000000000 * -0.2874182500 
4.6024584235 *= 1.6084186703 * 0.2749769400 
4.6024584235 *= 0.0000000000 * -0.2001948800 
tempVal = 4.6024584235 + 0.1085559350(biases), 
now the tempVal = 4.7110143585 

now we get all result in layer: 4
	node: 0, val: 0.0000000000
	node: 1, val: 0.0000000000
	node: 2, val: 0.0000000000
	node: 3, val: 1.7553733112
	node: 4, val: 0.0000000000
	node: 5, val: 3.5027185298
	node: 6, val: 1.4039559876
	node: 7, val: 2.3053236137
	node: 8, val: 0.0000000000
	node: 9, val: 0.0000000000
	node: 10, val: 0.0000000000
	node: 11, val: 0.0000000000
	node: 12, val: 4.5979877788
	node: 13, val: 2.1019898961
	node: 14, val: 0.0000000000
	node: 15, val: 0.6020292030
	node: 16, val: 0.0000000000
	node: 17, val: 0.0000000000
	node: 18, val: 0.0000000000
	node: 19, val: 0.0000000000
	node: 20, val: 2.1554129313
	node: 21, val: 0.0000000000
	node: 22, val: 0.0000000000
	node: 23, val: 0.0000000000
	node: 24, val: 4.3394698350
	node: 25, val: 0.0000000000
	node: 26, val: 0.0000000000
	node: 27, val: 2.7644942480
	node: 28, val: 0.0000000000
	node: 29, val: 4.7110143585

when compute layer[4] to layer[5]

compute layer: 5, node : 0
0.0000000000 *= 0.0000000000 * 0.3003202700 
0.0000000000 *= 0.0000000000 * 0.1937291200 
0.0000000000 *= 0.0000000000 * 0.1596140400 
-0.0617103594 *= 1.7553733112 * -0.0351551200 
-0.0617103594 *= 0.0000000000 * 0.2447984000 
0.9013250416 *= 3.5027185298 * 0.2749394200 
0.7228712847 *= 1.4039559876 * -0.1271078000 
0.6429620506 *= 2.3053236137 * -0.0346629140 
0.6429620506 *= 0.0000000000 * -0.0303249970 
0.6429620506 *= 0.0000000000 * 0.3110013000 
0.6429620506 *= 0.0000000000 * -0.0531673300 
0.6429620506 *= 0.0000000000 * 0.1898743400 
2.0408868955 *= 4.5979877788 * 0.3040297000 
1.7129110578 *= 2.1019898961 * -0.1560311200 
1.7129110578 *= 0.0000000000 * -0.0897618400 
1.5263908518 *= 0.6020292030 * -0.3098192000 
1.5263908518 *= 0.0000000000 * -0.1279418800 
1.5263908518 *= 0.0000000000 * -0.1570194400 
1.5263908518 *= 0.0000000000 * -0.1051980400 
1.5263908518 *= 0.0000000000 * 0.2121408400 
2.2995446262 *= 2.1554129313 * 0.3587033200 
2.2995446262 *= 0.0000000000 * 0.0714561200 
2.2995446262 *= 0.0000000000 * 0.0720416700 
2.2995446262 *= 0.0000000000 * -0.1787540200 
3.9653323987 *= 4.3394698350 * 0.3838689600 
3.9653323987 *= 0.0000000000 * -0.1868228300 
3.9653323987 *= 0.0000000000 * -0.2790489500 
4.9034492293 *= 2.7644942480 * 0.3393448300 
4.9034492293 *= 0.0000000000 * 0.2042480000 
4.2922132537 *= 4.7110143585 * -0.1297461500 
tempVal = 4.2922132537 + 0.1421547400(biases), 
now the tempVal = 4.4343679937 

compute layer: 5, node : 1
0.0000000000 *= 0.0000000000 * -0.0404628180 
0.0000000000 *= 0.0000000000 * 0.2647287000 
0.0000000000 *= 0.0000000000 * -0.2261040400 
-0.1398066196 *= 1.7553733112 * -0.0796449500 
-0.1398066196 *= 0.0000000000 * 0.3163947000 
0.5211211997 *= 3.5027185298 * 0.1886899600 
0.1044665418 *= 1.4039559876 * -0.2967718800 
-0.0479765093 *= 2.3053236137 * -0.0661265300 
-0.0479765093 *= 0.0000000000 * -0.0129970630 
-0.0479765093 *= 0.0000000000 * 0.1865698000 
-0.0479765093 *= 0.0000000000 * -0.1443910700 
-0.0479765093 *= 0.0000000000 * -0.2226334700 
0.9592692689 *= 4.5979877788 * 0.2190623000 
0.7438955060 *= 2.1019898961 * -0.1024618450 
0.7438955060 *= 0.0000000000 * -0.1700331700 
0.5583410451 *= 0.6020292030 * -0.3082150500 
0.5583410451 *= 0.0000000000 * -0.1894078000 
0.5583410451 *= 0.0000000000 * -0.0153866730 
0.5583410451 *= 0.0000000000 * -0.2119812700 
0.5583410451 *= 0.0000000000 * -0.1969564400 
0.7641797900 *= 2.1554129313 * 0.0954985200 
0.7641797900 *= 0.0000000000 * 0.1020117300 
0.7641797900 *= 0.0000000000 * 0.0048466315 
0.7641797900 *= 0.0000000000 * 0.2698107000 
2.6351665104 *= 4.3394698350 * 0.4311556000 
2.6351665104 *= 0.0000000000 * -0.0818985000 
2.6351665104 *= 0.0000000000 * -0.1845918000 
3.2939259447 *= 2.7644942480 * 0.2382929300 
3.2939259447 *= 0.0000000000 * 0.0756253450 
3.0266745143 *= 4.7110143585 * -0.0567290630 
tempVal = 3.0266745143 + 0.0165575870(biases), 
now the tempVal = 3.0432321013 

compute layer: 5, node : 2
0.0000000000 *= 0.0000000000 * 0.0351953540 
0.0000000000 *= 0.0000000000 * 0.0366087780 
0.0000000000 *= 0.0000000000 * -0.0845000700 
0.0207704512 *= 1.7553733112 * 0.0118324980 
0.0207704512 *= 0.0000000000 * -0.2370224400 
0.8889269448 *= 3.5027185298 * 0.2478522000 
1.2328719014 *= 1.4039559876 * 0.2449827200 
1.7852527517 *= 2.3053236137 * 0.2396109800 
1.7852527517 *= 0.0000000000 * 0.2087581200 
1.7852527517 *= 0.0000000000 * -0.0198542000 
1.7852527517 *= 0.0000000000 * -0.0919465050 
1.7852527517 *= 0.0000000000 * 0.0636971500 
3.3795986688 *= 4.5979877788 * 0.3467486200 
4.1085247280 *= 2.1019898961 * 0.3467790500 
4.1085247280 *= 0.0000000000 * -0.1276494900 
4.1541050995 *= 0.6020292030 * 0.0757112300 
4.1541050995 *= 0.0000000000 * 0.1472569400 
4.1541050995 *= 0.0000000000 * 0.2148537500 
4.1541050995 *= 0.0000000000 * -0.0545559670 
4.1541050995 *= 0.0000000000 * -0.1459771000 
4.1657658679 *= 2.1554129313 * 0.0054099928 
4.1657658679 *= 0.0000000000 * -0.2879809700 
4.1657658679 *= 0.0000000000 * 0.1145789300 
4.1657658679 *= 0.0000000000 * -0.2628933200 
4.7394291127 *= 4.3394698350 * 0.1321966200 
4.7394291127 *= 0.0000000000 * -0.3073283000 
4.7394291127 *= 0.0000000000 * -0.1113592100 
4.3047204645 *= 2.7644942480 * -0.1572470800 
4.3047204645 *= 0.0000000000 * -0.1108119800 
3.1175589792 *= 4.7110143585 * -0.2519970000 
tempVal = 3.1175589792 + 0.0504004550(biases), 
now the tempVal = 3.1679594342 

compute layer: 5, node : 3
0.0000000000 *= 0.0000000000 * 0.2100210800 
0.0000000000 *= 0.0000000000 * -0.0337056930 
0.0000000000 *= 0.0000000000 * 0.2504422000 
-0.0192886897 *= 1.7553733112 * -0.0109883690 
-0.0192886897 *= 0.0000000000 * 0.1851496500 
-0.5199295520 *= 3.5027185298 * -0.1429292300 
-0.2931627213 *= 1.4039559876 * 0.1615199000 
-0.5354759318 *= 2.3053236137 * -0.1051102800 
-0.5354759318 *= 0.0000000000 * 0.2094828800 
-0.5354759318 *= 0.0000000000 * -0.0480555970 
-0.5354759318 *= 0.0000000000 * 0.2385102700 
-0.5354759318 *= 0.0000000000 * -0.1367633300 
0.4736074781 *= 4.5979877788 * 0.2194619600 
0.8645206559 *= 2.1019898961 * 0.1859729100 
0.8645206559 *= 0.0000000000 * -0.1402154400 
0.9813688170 *= 0.6020292030 * 0.1940905200 
0.9813688170 *= 0.0000000000 * 0.2086249300 
0.9813688170 *= 0.0000000000 * -0.0162547960 
0.9813688170 *= 0.0000000000 * -0.2900286300 
0.9813688170 *= 0.0000000000 * -0.2582027600 
1.3242460218 *= 2.1554129313 * 0.1590772700 
1.3242460218 *= 0.0000000000 * -0.1949050600 
1.3242460218 *= 0.0000000000 * 0.1423503600 
1.3242460218 *= 0.0000000000 * -0.1514481800 
0.2609252458 *= 4.3394698350 * -0.2450347200 
0.2609252458 *= 0.0000000000 * 0.0496894750 
0.2609252458 *= 0.0000000000 * -0.1716274800 
0.4994807251 *= 2.7644942480 * 0.0862926300 
0.4994807251 *= 0.0000000000 * 0.1073372200 
0.5189261859 *= 4.7110143585 * 0.0041276590 
tempVal = 0.5189261859 + -0.0161608380(biases), 
now the tempVal = 0.5027653479 

compute layer: 5, node : 4
0.0000000000 *= 0.0000000000 * -0.2337753600 
0.0000000000 *= 0.0000000000 * 0.1330972500 
0.0000000000 *= 0.0000000000 * -0.2579558800 
-0.4882137639 *= 1.7553733112 * -0.2781253200 
-0.4882137639 *= 0.0000000000 * -0.2181684200 
-1.3443098372 *= 3.5027185298 * -0.2444090400 
-1.4361742154 *= 1.4039559876 * -0.0654325200 
-0.9044471052 *= 2.3053236137 * 0.2306518300 
-0.9044471052 *= 0.0000000000 * 0.1921750500 
-0.9044471052 *= 0.0000000000 * -0.2846613000 
-0.9044471052 *= 0.0000000000 * 0.2000678800 
-0.9044471052 *= 0.0000000000 * 0.0490641100 
-2.3571618944 *= 4.5979877788 * -0.3159457700 
-1.7013126699 *= 2.1019898961 * 0.3120135000 
-1.7013126699 *= 0.0000000000 * 0.0537771020 
-1.7558919752 *= 0.6020292030 * -0.0906589000 
-1.7558919752 *= 0.0000000000 * -0.1034646200 
-1.7558919752 *= 0.0000000000 * 0.0126906410 
-1.7558919752 *= 0.0000000000 * -0.0613336380 
-1.7558919752 *= 0.0000000000 * -0.1138597000 
-2.1090758258 *= 2.1554129313 * -0.1638590200 
-2.1090758258 *= 0.0000000000 * 0.1185665300 
-2.1090758258 *= 0.0000000000 * 0.2404099300 
-2.1090758258 *= 0.0000000000 * 0.1906991900 
-1.3183258292 *= 4.3394698350 * 0.1822227200 
-1.3183258292 *= 0.0000000000 * -0.2008117900 
-1.3183258292 *= 0.0000000000 * -0.2693239700 
-1.0802568069 *= 2.7644942480 * 0.0861166640 
-1.0802568069 *= 0.0000000000 * -0.0701881400 
-2.4146269382 *= 4.7110143585 * -0.2832447600 
tempVal = -2.4146269382 + 0.0000000000(biases), 
now the tempVal = -2.4146269382 
ReLU !!! in layer: 5, node : 4, its linear result is negative,so set it to 0

compute layer: 5, node : 5
0.0000000000 *= 0.0000000000 * -0.1774202400 
0.0000000000 *= 0.0000000000 * -0.0513626100 
0.0000000000 *= 0.0000000000 * 0.3173782200 
-0.4477259205 *= 1.7553733112 * -0.2550602300 
-0.4477259205 *= 0.0000000000 * -0.0027952688 
0.3220676867 *= 3.5027185298 * 0.2197703300 
0.2765631678 *= 1.4039559876 * -0.0324116420 
-0.0103722784 *= 2.3053236137 * -0.1244664500 
-0.0103722784 *= 0.0000000000 * 0.1321846700 
-0.0103722784 *= 0.0000000000 * 0.2629803700 
-0.0103722784 *= 0.0000000000 * -0.2376452700 
-0.0103722784 *= 0.0000000000 * -0.1554355800 
0.1145416050 *= 4.5979877788 * 0.0271670760 
0.6002075266 *= 2.1019898961 * 0.2310505500 
0.6002075266 *= 0.0000000000 * 0.1252375800 
0.5723765774 *= 0.6020292030 * -0.0462285700 
0.5723765774 *= 0.0000000000 * -0.1157475200 
0.5723765774 *= 0.0000000000 * 0.1563160000 
0.5723765774 *= 0.0000000000 * 0.1346292800 
0.5723765774 *= 0.0000000000 * 0.0329560640 
0.9198320733 *= 2.1554129313 * 0.1612013600 
0.9198320733 *= 0.0000000000 * 0.3523343800 
0.9198320733 *= 0.0000000000 * -0.2324649000 
0.9198320733 *= 0.0000000000 * 0.2607309800 
-0.2191429330 *= 4.3394698350 * -0.2624687000 
-0.2191429330 *= 0.0000000000 * -0.2373917500 
-0.2191429330 *= 0.0000000000 * -0.2063610400 
-0.1359063389 *= 2.7644942480 * 0.0301091580 
-0.1359063389 *= 0.0000000000 * -0.0946131200 
0.1333040302 *= 4.7110143585 * 0.0571448840 
tempVal = 0.1333040302 + 0.0476414080(biases), 
now the tempVal = 0.1809454382 

compute layer: 5, node : 6
0.0000000000 *= 0.0000000000 * -0.0439674600 
0.0000000000 *= 0.0000000000 * -0.1214719100 
0.0000000000 *= 0.0000000000 * 0.0127382530 
0.1541500031 *= 1.7553733112 * 0.0878160800 
0.1541500031 *= 0.0000000000 * 0.0299590500 
-0.5146239057 *= 3.5027185298 * -0.1909299600 
-0.5925353944 *= 1.4039559876 * -0.0554942530 
-1.2522165410 *= 2.3053236137 * -0.2861555500 
-1.2522165410 *= 0.0000000000 * -0.1210251200 
-1.2522165410 *= 0.0000000000 * -0.2732431300 
-1.2522165410 *= 0.0000000000 * -0.1396530300 
-1.2522165410 *= 0.0000000000 * -0.1580739200 
-0.0720423736 *= 4.5979877788 * 0.2566718800 
-0.6198068993 *= 2.1019898961 * -0.2605933200 
-0.6198068993 *= 0.0000000000 * 0.2204534700 
-0.5505225310 *= 0.6020292030 * 0.1150847300 
-0.5505225310 *= 0.0000000000 * 0.2017690400 
-0.5505225310 *= 0.0000000000 * -0.1181588300 
-0.5505225310 *= 0.0000000000 * -0.0872825160 
-0.5505225310 *= 0.0000000000 * -0.0432041320 
-0.2803247079 *= 2.1554129313 * 0.1253578000 
-0.2803247079 *= 0.0000000000 * 0.0286952870 
-0.2803247079 *= 0.0000000000 * 0.0877297100 
-0.2803247079 *= 0.0000000000 * 0.1137326800 
-0.4171414526 *= 4.3394698350 * -0.0315284470 
-0.4171414526 *= 0.0000000000 * 0.2888632000 
-0.4171414526 *= 0.0000000000 * 0.0997844400 
-0.3660146527 *= 2.7644942480 * 0.0184940880 
-0.3660146527 *= 0.0000000000 * -0.2336202100 
-1.2247308594 *= 4.7110143585 * -0.1822784100 
tempVal = -1.2247308594 + -0.0789410900(biases), 
now the tempVal = -1.3036719494 
ReLU !!! in layer: 5, node : 6, its linear result is negative,so set it to 0

compute layer: 5, node : 7
0.0000000000 *= 0.0000000000 * 0.1619475500 
0.0000000000 *= 0.0000000000 * 0.1518401800 
0.0000000000 *= 0.0000000000 * 0.0338675680 
0.0716786856 *= 1.7553733112 * 0.0408338700 
0.0716786856 *= 0.0000000000 * 0.2602901000 
-0.3545877633 *= 3.5027185298 * -0.1216958900 
-0.4664891768 *= 1.4039559876 * -0.0797043600 
-0.6749303043 *= 2.3053236137 * -0.0904172960 
-0.6749303043 *= 0.0000000000 * -0.2760956000 
-0.6749303043 *= 0.0000000000 * -0.0084446445 
-0.6749303043 *= 0.0000000000 * -0.0184647900 
-0.6749303043 *= 0.0000000000 * 0.1846689300 
-1.3167277840 *= 4.5979877788 * -0.1395822500 
-1.6591818759 *= 2.1019898961 * -0.1629190000 
-1.6591818759 *= 0.0000000000 * 0.1345969100 
-1.8220964566 *= 0.6020292030 * -0.2706091000 
-1.8220964566 *= 0.0000000000 * -0.0410440530 
-1.8220964566 *= 0.0000000000 * -0.1767410800 
-1.8220964566 *= 0.0000000000 * 0.0652874700 
-1.8220964566 *= 0.0000000000 * -0.2313815700 
-1.3219306443 *= 2.1554129313 * 0.2320510400 
-1.3219306443 *= 0.0000000000 * 0.0090524680 
-1.3219306443 *= 0.0000000000 * -0.2493066200 
-1.3219306443 *= 0.0000000000 * -0.1998749400 
-0.0963868600 *= 4.3394698350 * 0.2824178600 
-0.0963868600 *= 0.0000000000 * -0.2083169000 
-0.0963868600 *= 0.0000000000 * 0.0720156650 
-0.2583177409 *= 2.7644942480 * -0.0585752280 
-0.2583177409 *= 0.0000000000 * -0.2131155400 
-0.5942190665 *= 4.7110143585 * -0.0713012740 
tempVal = -0.5942190665 + 0.0405311900(biases), 
now the tempVal = -0.5536878765 
ReLU !!! in layer: 5, node : 7, its linear result is negative,so set it to 0

compute layer: 5, node : 8
0.0000000000 *= 0.0000000000 * 0.1310508800 
0.0000000000 *= 0.0000000000 * -0.0367871400 
0.0000000000 *= 0.0000000000 * 0.2437977500 
0.5402960411 *= 1.7553733112 * 0.3077955200 
0.5402960411 *= 0.0000000000 * -0.2193212800 
0.1964896286 *= 3.5027185298 * -0.0981541650 
0.4907670448 *= 1.4039559876 * 0.2096058700 
-0.0963277142 *= 2.3053236137 * -0.2546691300 
-0.0963277142 *= 0.0000000000 * -0.2148060000 
-0.0963277142 *= 0.0000000000 * -0.0293755740 
-0.0963277142 *= 0.0000000000 * -0.0564914570 
-0.0963277142 *= 0.0000000000 * -0.1397437900 
0.7103193521 *= 4.5979877788 * 0.1754348000 
0.0963291965 *= 2.1019898961 * -0.2920994800 
0.0963291965 *= 0.0000000000 * 0.0830693240 
0.2046379586 *= 0.6020292030 * 0.1799061600 
0.2046379586 *= 0.0000000000 * -0.2670695200 
0.2046379586 *= 0.0000000000 * 0.0106402490 
0.2046379586 *= 0.0000000000 * 0.1805487000 
0.2046379586 *= 0.0000000000 * -0.0581769400 
0.6032977459 *= 2.1554129313 * 0.1849575000 
0.6032977459 *= 0.0000000000 * 0.0531737950 
0.6032977459 *= 0.0000000000 * 0.0645750200 
0.6032977459 *= 0.0000000000 * 0.2094470700 
0.0133036875 *= 4.3394698350 * -0.1359599400 
0.0133036875 *= 0.0000000000 * -0.1536169600 
0.0133036875 *= 0.0000000000 * 0.1590176700 
0.2789348998 *= 2.7644942480 * 0.0960867300 
0.2789348998 *= 0.0000000000 * 0.0229811720 
-0.0786208671 *= 4.7110143585 * -0.0758978300 
tempVal = -0.0786208671 + -0.0674170900(biases), 
now the tempVal = -0.1460379571 
ReLU !!! in layer: 5, node : 8, its linear result is negative,so set it to 0

compute layer: 5, node : 9
0.0000000000 *= 0.0000000000 * -0.1068917140 
0.0000000000 *= 0.0000000000 * -0.0423384460 
0.0000000000 *= 0.0000000000 * 0.0628377900 
-0.0416346534 *= 1.7553733112 * -0.0237184040 
-0.0416346534 *= 0.0000000000 * -0.2384969300 
-0.2018280071 *= 3.5027185298 * -0.0457340070 
-0.5909650153 *= 1.4039559876 * -0.2771718000 
-0.3074602594 *= 2.3053236137 * 0.1229782900 
-0.3074602594 *= 0.0000000000 * -0.1965615300 
-0.3074602594 *= 0.0000000000 * 0.2069151300 
-0.3074602594 *= 0.0000000000 * 0.2765794700 
-0.3074602594 *= 0.0000000000 * -0.2235797600 
0.7578667486 *= 4.5979877788 * 0.2316941800 
0.7512496689 *= 2.1019898961 * -0.0031480074 
0.7512496689 *= 0.0000000000 * -0.1286077200 
0.6604805640 *= 0.6020292030 * -0.1507719300 
0.6604805640 *= 0.0000000000 * 0.1953529100 
0.6604805640 *= 0.0000000000 * -0.3150557000 
0.6604805640 *= 0.0000000000 * -0.1841895700 
0.6604805640 *= 0.0000000000 * -0.0901734100 
0.4071145760 *= 2.1554129313 * -0.1175487000 
0.4071145760 *= 0.0000000000 * -0.0732706300 
0.4071145760 *= 0.0000000000 * 0.2682530000 
0.4071145760 *= 0.0000000000 * -0.1434719600 
-0.9442859407 *= 4.3394698350 * -0.3114206500 
-0.9442859407 *= 0.0000000000 * 0.0032994552 
-0.9442859407 *= 0.0000000000 * -0.1787897500 
-1.2014714573 *= 2.7644942480 * -0.0930316700 
-1.2014714573 *= 0.0000000000 * 0.0155196340 
-0.8493382092 *= 4.7110143585 * 0.0747468000 
tempVal = -0.8493382092 + 0.0032668274(biases), 
now the tempVal = -0.8460713818 
ReLU !!! in layer: 5, node : 9, its linear result is negative,so set it to 0

compute layer: 5, node : 10
0.0000000000 *= 0.0000000000 * -0.1275963500 
0.0000000000 *= 0.0000000000 * 0.1491951200 
0.0000000000 *= 0.0000000000 * 0.2851123800 
-0.0659912655 *= 1.7553733112 * -0.0375938640 
-0.0659912655 *= 0.0000000000 * -0.1238150100 
-0.7509235301 *= 3.5027185298 * -0.1955430500 
-1.0957482617 *= 1.4039559876 * -0.2456093600 
-1.4955758895 *= 2.3053236137 * -0.1734366600 
-1.4955758895 *= 0.0000000000 * 0.0828946000 
-1.4955758895 *= 0.0000000000 * 0.0786462650 
-1.4955758895 *= 0.0000000000 * 0.1827474700 
-1.4955758895 *= 0.0000000000 * -0.1180345800 
-2.7570943461 *= 4.5979877788 * -0.2743631600 
-2.8637356505 *= 2.1019898961 * -0.0507335000 
-2.8637356505 *= 0.0000000000 * -0.2080963600 
-2.9958890676 *= 0.6020292030 * -0.2195133000 
-2.9958890676 *= 0.0000000000 * 0.1152974140 
-2.9958890676 *= 0.0000000000 * 0.0310031920 
-2.9958890676 *= 0.0000000000 * -0.0733093100 
-2.9958890676 *= 0.0000000000 * -0.1452529600 
-2.3486848433 *= 2.1554129313 * 0.3002692500 
-2.3486848433 *= 0.0000000000 * 0.2051789800 
-2.3486848433 *= 0.0000000000 * -0.2158190200 
-2.3486848433 *= 0.0000000000 * 0.1842367000 
-2.1337781542 *= 4.3394698350 * 0.0495237200 
-2.1337781542 *= 0.0000000000 * 0.2540041200 
-2.1337781542 *= 0.0000000000 * -0.0852041600 
-2.3052956819 *= 2.7644942480 * -0.0620430040 
-2.3052956819 *= 0.0000000000 * -0.2862336600 
-2.8972368502 *= 4.7110143585 * -0.1256504700 
tempVal = -2.8972368502 + 0.0000000000(biases), 
now the tempVal = -2.8972368502 
ReLU !!! in layer: 5, node : 10, its linear result is negative,so set it to 0

compute layer: 5, node : 11
0.0000000000 *= 0.0000000000 * -0.2623289800 
0.0000000000 *= 0.0000000000 * -0.0567066150 
0.0000000000 *= 0.0000000000 * -0.2777215800 
0.2200769272 *= 1.7553733112 * 0.1253732900 
0.2200769272 *= 0.0000000000 * -0.0135964570 
0.1943744795 *= 3.5027185298 * -0.0073378570 
-0.2523955959 *= 1.4039559876 * -0.3182222800 
-0.8677164376 *= 2.3053236137 * -0.2669130000 
-0.8677164376 *= 0.0000000000 * 0.2486479100 
-0.8677164376 *= 0.0000000000 * -0.2398265300 
-0.8677164376 *= 0.0000000000 * -0.1485797800 
-0.8677164376 *= 0.0000000000 * 0.1000362860 
-1.2333608863 *= 4.5979877788 * -0.0795227100 
-1.2580631478 *= 2.1019898961 * -0.0117518460 
-1.2580631478 *= 0.0000000000 * -0.0478541250 
-1.2242666516 *= 0.6020292030 * 0.0561376360 
-1.2242666516 *= 0.0000000000 * 0.1660929500 
-1.2242666516 *= 0.0000000000 * -0.2257073400 
-1.2242666516 *= 0.0000000000 * -0.0503660030 
-1.2242666516 *= 0.0000000000 * -0.0795791200 
-1.1570240188 *= 2.1554129313 * 0.0311971000 
-1.1570240188 *= 0.0000000000 * -0.1376763100 
-1.1570240188 *= 0.0000000000 * -0.0642030100 
-1.1570240188 *= 0.0000000000 * 0.1401734400 
-0.5753391773 *= 4.3394698350 * 0.1340451400 
-0.5753391773 *= 0.0000000000 * 0.0954514500 
-0.5753391773 *= 0.0000000000 * 0.2505126000 
-1.0968179187 *= 2.7644942480 * -0.1886344100 
-1.0968179187 *= 0.0000000000 * -0.1714571400 
0.1733610616 *= 4.7110143585 * 0.2696190000 
tempVal = 0.1733610616 + -0.0216231380(biases), 
now the tempVal = 0.1517379236 

compute layer: 5, node : 12
0.0000000000 *= 0.0000000000 * -0.2425785700 
0.0000000000 *= 0.0000000000 * -0.2323599600 
0.0000000000 *= 0.0000000000 * 0.0107047470 
-0.4148857998 *= 1.7553733112 * -0.2363518900 
-0.4148857998 *= 0.0000000000 * -0.0102931690 
-1.0559353761 *= 3.5027185298 * -0.1830148700 
-1.0809467496 *= 1.4039559876 * -0.0178149270 
-0.9317405111 *= 2.3053236137 * 0.0647224700 
-0.9317405111 *= 0.0000000000 * -0.1995108300 
-0.9317405111 *= 0.0000000000 * 0.1154679600 
-0.9317405111 *= 0.0000000000 * 0.0554247760 
-0.9317405111 *= 0.0000000000 * 0.2478059400 
-1.2297780787 *= 4.5979877788 * -0.0648191300 
-0.9176923597 *= 2.1019898961 * 0.1484715600 
-0.9176923597 *= 0.0000000000 * 0.2490671100 
-0.8768764775 *= 0.6020292030 * 0.0677971800 
-0.8768764775 *= 0.0000000000 * 0.1686944500 
-0.8768764775 *= 0.0000000000 * 0.2892387800 
-0.8768764775 *= 0.0000000000 * 0.2549261500 
-0.8768764775 *= 0.0000000000 * 0.2698244800 
-1.1936908387 *= 2.1554129313 * -0.1469854600 
-1.1936908387 *= 0.0000000000 * 0.2608236400 
-1.1936908387 *= 0.0000000000 * 0.0569629000 
-1.1936908387 *= 0.0000000000 * -0.0486152130 
-0.6201424163 *= 4.3394698350 * 0.1321701600 
-0.6201424163 *= 0.0000000000 * -0.2768589300 
-0.6201424163 *= 0.0000000000 * -0.1870304500 
-1.4301097614 *= 2.7644942480 * -0.2929893400 
-1.4301097614 *= 0.0000000000 * -0.0101799450 
-2.6331459518 *= 4.7110143585 * -0.2553667000 
tempVal = -2.6331459518 + 0.0000000000(biases), 
now the tempVal = -2.6331459518 
ReLU !!! in layer: 5, node : 12, its linear result is negative,so set it to 0

compute layer: 5, node : 13
0.0000000000 *= 0.0000000000 * 0.0685083000 
0.0000000000 *= 0.0000000000 * 0.2637758000 
0.0000000000 *= 0.0000000000 * 0.2228993000 
0.5326055400 *= 1.7553733112 * 0.3034144000 
0.5326055400 *= 0.0000000000 * 0.3102390200 
1.2282059644 *= 3.5027185298 * 0.1985887300 
1.1458138848 *= 1.4039559876 * -0.0586856570 
0.7414734017 *= 2.3053236137 * -0.1753942400 
0.7414734017 *= 0.0000000000 * 0.1421679000 
0.7414734017 *= 0.0000000000 * -0.2719440500 
0.7414734017 *= 0.0000000000 * -0.2362463200 
0.7414734017 *= 0.0000000000 * 0.0167838500 
0.1726966579 *= 4.5979877788 * -0.1237012300 
0.1771357449 *= 2.1019898961 * 0.0021118498 
0.1771357449 *= 0.0000000000 * -0.0049162730 
0.0259930324 *= 0.6020292030 * -0.2510554500 
0.0259930324 *= 0.0000000000 * -0.3103854700 
0.0259930324 *= 0.0000000000 * 0.1664479700 
0.0259930324 *= 0.0000000000 * -0.0987430300 
0.0259930324 *= 0.0000000000 * -0.0261153620 
0.5830718334 *= 2.1554129313 * 0.2584557200 
0.5830718334 *= 0.0000000000 * 0.0625343800 
0.5830718334 *= 0.0000000000 * 0.3040684500 
0.5830718334 *= 0.0000000000 * 0.2148810600 
-0.2089724969 *= 4.3394698350 * -0.1825209900 
-0.2089724969 *= 0.0000000000 * -0.2029531300 
-0.2089724969 *= 0.0000000000 * -0.3045938300 
-0.9178836995 *= 2.7644942480 * -0.2564343200 
-0.9178836995 *= 0.0000000000 * 0.3123867500 
-1.7315760825 *= 4.7110143585 * -0.1727212700 
tempVal = -1.7315760825 + -0.0045705307(biases), 
now the tempVal = -1.7361466132 
ReLU !!! in layer: 5, node : 13, its linear result is negative,so set it to 0

compute layer: 5, node : 14
0.0000000000 *= 0.0000000000 * 0.0172408170 
0.0000000000 *= 0.0000000000 * -0.0575493950 
0.0000000000 *= 0.0000000000 * -0.2172798800 
-0.1528763218 *= 1.7553733112 * -0.0870904900 
-0.1528763218 *= 0.0000000000 * -0.3010929500 
0.7445348769 *= 3.5027185298 * 0.2562042000 
0.6560352196 *= 1.4039559876 * -0.0630359200 
1.2518379928 *= 2.3053236137 * 0.2584464800 
1.2518379928 *= 0.0000000000 * 0.1811190200 
1.2518379928 *= 0.0000000000 * -0.0258529500 
1.2518379928 *= 0.0000000000 * 0.1009628400 
1.2518379928 *= 0.0000000000 * 0.1900640600 
1.3138225327 *= 4.5979877788 * 0.0134807970 
1.0095353223 *= 2.1019898961 * -0.1447615000 
1.0095353223 *= 0.0000000000 * 0.2126800600 
0.8943981463 *= 0.6020292030 * -0.1912484900 
0.8943981463 *= 0.0000000000 * 0.1681259100 
0.8943981463 *= 0.0000000000 * -0.1222004440 
0.8943981463 *= 0.0000000000 * 0.1173007640 
0.8943981463 *= 0.0000000000 * -0.1538528200 
1.4163972571 *= 2.1554129313 * 0.2421805600 
1.4163972571 *= 0.0000000000 * -0.2516259300 
1.4163972571 *= 0.0000000000 * 0.0503657400 
1.4163972571 *= 0.0000000000 * -0.2185072900 
3.3009849174 *= 4.3394698350 * 0.4342898400 
3.3009849174 *= 0.0000000000 * 0.0206587910 
3.3009849174 *= 0.0000000000 * 0.0206340570 
4.1584570552 *= 2.7644942480 * 0.3101732400 
4.1584570552 *= 0.0000000000 * -0.1390119000 
3.5361913701 *= 4.7110143585 * -0.1320874100 
tempVal = 3.5361913701 + 0.0635533850(biases), 
now the tempVal = 3.5997447551 

compute layer: 5, node : 15
0.0000000000 *= 0.0000000000 * 0.0346484800 
0.0000000000 *= 0.0000000000 * -0.0647443160 
0.0000000000 *= 0.0000000000 * -0.1649089500 
-0.1342099453 *= 1.7553733112 * -0.0764566400 
-0.1342099453 *= 0.0000000000 * 0.1814760900 
-0.6512905719 *= 3.5027185298 * -0.1476226600 
-0.7964244730 *= 1.4039559876 * -0.1033749650 
-0.0871712611 *= 2.3053236137 * 0.3076588500 
-0.0871712611 *= 0.0000000000 * 0.1322593800 
-0.0871712611 *= 0.0000000000 * 0.2449866100 
-0.0871712611 *= 0.0000000000 * -0.1045068000 
-0.0871712611 *= 0.0000000000 * -0.1503991800 
1.1857996795 *= 4.5979877788 * 0.2768539200 
1.3556278722 *= 2.1019898961 * 0.0807940100 
1.3556278722 *= 0.0000000000 * -0.0032725770 
1.3296014111 *= 0.6020292030 * -0.0432312270 
1.3296014111 *= 0.0000000000 * 0.2883615200 
1.3296014111 *= 0.0000000000 * 0.3107018800 
1.3296014111 *= 0.0000000000 * -0.0392146450 
1.3296014111 *= 0.0000000000 * 0.0553710160 
2.0620746978 *= 2.1554129313 * 0.3398296800 
2.0620746978 *= 0.0000000000 * -0.2148710500 
2.0620746978 *= 0.0000000000 * -0.0195949710 
2.0620746978 *= 0.0000000000 * -0.0260401740 
0.5582614990 *= 4.3394698350 * -0.3465430700 
0.5582614990 *= 0.0000000000 * -0.2815398600 
0.5582614990 *= 0.0000000000 * 0.0941682700 
0.0652603381 *= 2.7644942480 * -0.1783332200 
0.0652603381 *= 0.0000000000 * 0.1970794500 
0.5928647379 *= 4.7110143585 * 0.1119938000 
tempVal = 0.5928647379 + 0.0484103450(biases), 
now the tempVal = 0.6412750829 

compute layer: 5, node : 16
0.0000000000 *= 0.0000000000 * -0.0582377460 
0.0000000000 *= 0.0000000000 * 0.3058712800 
0.0000000000 *= 0.0000000000 * 0.1990012400 
-0.5558642364 *= 1.7553733112 * -0.3166644000 
-0.5558642364 *= 0.0000000000 * 0.0748932400 
0.0974082164 *= 3.5027185298 * 0.1865044100 
0.3666087043 *= 1.4039559876 * 0.1917442500 
0.3774406039 *= 2.3053236137 * 0.0046986460 
0.3774406039 *= 0.0000000000 * -0.1772646600 
0.3774406039 *= 0.0000000000 * -0.0882776400 
0.3774406039 *= 0.0000000000 * 0.2500222000 
0.3774406039 *= 0.0000000000 * -0.2276363700 
-0.0181549993 *= 4.5979877788 * -0.0860366800 
-0.5250075917 *= 2.1019898961 * -0.2411298900 
-0.5250075917 *= 0.0000000000 * 0.1967262800 
-0.4578240344 *= 0.6020292030 * 0.1115951800 
-0.4578240344 *= 0.0000000000 * -0.0603929400 
-0.4578240344 *= 0.0000000000 * -0.1429324400 
-0.4578240344 *= 0.0000000000 * -0.0711067900 
-0.4578240344 *= 0.0000000000 * 0.1085364450 
-0.4717570799 *= 2.1554129313 * -0.0064642117 
-0.4717570799 *= 0.0000000000 * 0.2791763800 
-0.4717570799 *= 0.0000000000 * 0.0988223300 
-0.4717570799 *= 0.0000000000 * 0.0075838650 
-1.1099393452 *= 4.3394698350 * -0.1470645700 
-1.1099393452 *= 0.0000000000 * 0.2679635300 
-1.1099393452 *= 0.0000000000 * 0.1157611900 
-0.7448543741 *= 2.7644942480 * 0.1320621200 
-0.7448543741 *= 0.0000000000 * 0.0818187500 
-0.4857935463 *= 4.7110143585 * 0.0549904560 
tempVal = -0.4857935463 + -0.1333834100(biases), 
now the tempVal = -0.6191769563 
ReLU !!! in layer: 5, node : 16, its linear result is negative,so set it to 0

compute layer: 5, node : 17
0.0000000000 *= 0.0000000000 * 0.2612756500 
0.0000000000 *= 0.0000000000 * -0.1073556700 
0.0000000000 *= 0.0000000000 * 0.2185741000 
0.3570144418 *= 1.7553733112 * 0.2033837700 
0.3570144418 *= 0.0000000000 * -0.1979299000 
-0.3245393107 *= 3.5027185298 * -0.1945785100 
-0.5541772595 *= 1.4039559876 * -0.1635649200 
-0.7552761019 *= 2.3053236137 * -0.0872323700 
-0.7552761019 *= 0.0000000000 * 0.1512731500 
-0.7552761019 *= 0.0000000000 * -0.2861353200 
-0.7552761019 *= 0.0000000000 * 0.0474934900 
-0.7552761019 *= 0.0000000000 * 0.2136679400 
-1.3601688442 *= 4.5979877788 * -0.1315559700 
-1.6880622419 *= 2.1019898961 * -0.1559919000 
-1.6880622419 *= 0.0000000000 * -0.1272296800 
-1.6989730375 *= 0.6020292030 * -0.0181233660 
-1.6989730375 *= 0.0000000000 * 0.2237020300 
-1.6989730375 *= 0.0000000000 * -0.2077195800 
-1.6989730375 *= 0.0000000000 * -0.3756120000 
-1.6989730375 *= 0.0000000000 * 0.0905974600 
-1.7271644247 *= 2.1554129313 * -0.0130793440 
-1.7271644247 *= 0.0000000000 * -0.1435343800 
-1.7271644247 *= 0.0000000000 * -0.3005773000 
-1.7271644247 *= 0.0000000000 * 0.0562863830 
-1.1876492925 *= 4.3394698350 * 0.1243274300 
-1.1876492925 *= 0.0000000000 * -0.0340249050 
-1.1876492925 *= 0.0000000000 * -0.2736890300 
-0.7983594879 *= 2.7644942480 * 0.1408177300 
-0.7983594879 *= 0.0000000000 * -0.0948154700 
-1.5292115571 *= 4.7110143585 * -0.1551368800 
tempVal = -1.5292115571 + -0.1026517800(biases), 
now the tempVal = -1.6318633371 
ReLU !!! in layer: 5, node : 17, its linear result is negative,so set it to 0

compute layer: 5, node : 18
0.0000000000 *= 0.0000000000 * -0.2139945500 
0.0000000000 *= 0.0000000000 * -0.2784257200 
0.0000000000 *= 0.0000000000 * 0.2410061000 
0.4997547817 *= 1.7553733112 * 0.2847000000 
0.4997547817 *= 0.0000000000 * 0.1466258200 
-0.2582527030 *= 3.5027185298 * -0.2164054800 
-0.6267866571 *= 1.4039559876 * -0.2624968000 
-0.5133586262 *= 2.3053236137 * 0.0492026500 
-0.5133586262 *= 0.0000000000 * 0.0321695840 
-0.5133586262 *= 0.0000000000 * -0.1086155550 
-0.5133586262 *= 0.0000000000 * -0.2877578000 
-0.5133586262 *= 0.0000000000 * -0.0011602094 
-1.5175814114 *= 4.5979877788 * -0.2184048400 
-1.3140126024 *= 2.1019898961 * 0.0968457600 
-1.3140126024 *= 0.0000000000 * 0.2823320300 
-1.4383517767 *= 0.6020292030 * -0.2065334600 
-1.4383517767 *= 0.0000000000 * -0.2366832800 
-1.4383517767 *= 0.0000000000 * 0.2839290200 
-1.4383517767 *= 0.0000000000 * 0.1320753800 
-1.4383517767 *= 0.0000000000 * -0.1258226600 
-1.7902309990 *= 2.1554129313 * -0.1632537400 
-1.7902309990 *= 0.0000000000 * 0.3118288800 
-1.7902309990 *= 0.0000000000 * -0.2139673500 
-1.7902309990 *= 0.0000000000 * -0.1001718900 
-2.7642513006 *= 4.3394698350 * -0.2244560600 
-2.7642513006 *= 0.0000000000 * 0.2755014600 
-2.7642513006 *= 0.0000000000 * 0.2950537200 
-3.3077550441 *= 2.7644942480 * -0.1966015100 
-3.3077550441 *= 0.0000000000 * -0.3065150700 
-2.3230808705 *= 4.7110143585 * 0.2090153200 
tempVal = -2.3230808705 + 0.0000000000(biases), 
now the tempVal = -2.3230808705 
ReLU !!! in layer: 5, node : 18, its linear result is negative,so set it to 0

compute layer: 5, node : 19
0.0000000000 *= 0.0000000000 * -0.0018591359 
0.0000000000 *= 0.0000000000 * 0.0065624192 
0.0000000000 *= 0.0000000000 * -0.2478026900 
-0.2711877106 *= 1.7553733112 * -0.1544900500 
-0.2711877106 *= 0.0000000000 * -0.1003424150 
0.4846288937 *= 3.5027185298 * 0.2157800000 
0.6182227750 *= 1.4039559876 * 0.0951553200 
0.2221663339 *= 2.3053236137 * -0.1718008000 
0.2221663339 *= 0.0000000000 * 0.2183116200 
0.2221663339 *= 0.0000000000 * 0.0616005700 
0.2221663339 *= 0.0000000000 * -0.1581100500 
0.2221663339 *= 0.0000000000 * -0.2642029500 
-0.3569353293 *= 4.5979877788 * -0.1259467600 
0.0724259762 *= 2.1019898961 * 0.2042642100 
0.0724259762 *= 0.0000000000 * -0.0065763104 
0.1663570408 *= 0.6020292030 * 0.1560241000 
0.1663570408 *= 0.0000000000 * -0.0347877330 
0.1663570408 *= 0.0000000000 * -0.3100356800 
0.1663570408 *= 0.0000000000 * 0.2670281800 
0.1663570408 *= 0.0000000000 * 0.0755492400 
0.6883340370 *= 2.1554129313 * 0.2421703000 
0.6883340370 *= 0.0000000000 * 0.1828007400 
0.6883340370 *= 0.0000000000 * 0.1176524300 
0.6883340370 *= 0.0000000000 * -0.0163362510 
0.4118679760 *= 4.3394698350 * -0.0637096400 
0.4118679760 *= 0.0000000000 * 0.0045732260 
0.4118679760 *= 0.0000000000 * -0.2277561100 
0.5204481596 *= 2.7644942480 * 0.0392766900 
0.5204481596 *= 0.0000000000 * -0.0828535800 
0.2777315507 *= 4.7110143585 * -0.0515210930 
tempVal = 0.2777315507 + 0.0633117200(biases), 
now the tempVal = 0.3410432707 

compute layer: 5, node : 20
0.0000000000 *= 0.0000000000 * 0.0834315200 
0.0000000000 *= 0.0000000000 * -0.2537866000 
0.0000000000 *= 0.0000000000 * 0.2406032500 
0.3295166417 *= 1.7553733112 * 0.1877188400 
0.3295166417 *= 0.0000000000 * 0.2228406400 
-0.6539598540 *= 3.5027185298 * -0.2807752000 
-0.7784262524 *= 1.4039559876 * -0.0886540600 
-0.7972576445 *= 2.3053236137 * -0.0081686545 
-0.7972576445 *= 0.0000000000 * 0.0704214700 
-0.7972576445 *= 0.0000000000 * 0.0850268300 
-0.7972576445 *= 0.0000000000 * -0.1525466700 
-0.7972576445 *= 0.0000000000 * -0.3060314000 
-0.9710175936 *= 4.5979877788 * -0.0377904330 
-1.8395179470 *= 2.1019898961 * -0.4131800800 
-1.8395179470 *= 0.0000000000 * -0.2654777500 
-1.8664115475 *= 0.6020292030 * -0.0446715880 
-1.8664115475 *= 0.0000000000 * 0.0068158580 
-1.8664115475 *= 0.0000000000 * -0.0551838350 
-1.8664115475 *= 0.0000000000 * -0.3765395000 
-1.8664115475 *= 0.0000000000 * -0.2103326300 
-2.5160456766 *= 2.1554129313 * -0.3013966000 
-2.5160456766 *= 0.0000000000 * -0.1628588700 
-2.5160456766 *= 0.0000000000 * 0.2915757600 
-2.5160456766 *= 0.0000000000 * -0.3094384700 
-3.2960805676 *= 4.3394698350 * -0.1797535000 
-3.2960805676 *= 0.0000000000 * -0.1014351840 
-3.2960805676 *= 0.0000000000 * -0.0467573630 
-3.6310579184 *= 2.7644942480 * -0.1211712960 
-3.6310579184 *= 0.0000000000 * 0.2735258600 
-3.4599054006 *= 4.7110143585 * 0.0363302900 
tempVal = -3.4599054006 + -0.2094142900(biases), 
now the tempVal = -3.6693196906 
ReLU !!! in layer: 5, node : 20, its linear result is negative,so set it to 0

compute layer: 5, node : 21
0.0000000000 *= 0.0000000000 * 0.1655580400 
0.0000000000 *= 0.0000000000 * 0.2333080200 
0.0000000000 *= 0.0000000000 * 0.2239407600 
0.0350374461 *= 1.7553733112 * 0.0199601110 
0.0350374461 *= 0.0000000000 * -0.1041065900 
-0.8988790851 *= 3.5027185298 * -0.2666262000 
-1.0424910769 *= 1.4039559876 * -0.1022909500 
-1.1520919617 *= 2.3053236137 * -0.0475425160 
-1.1520919617 *= 0.0000000000 * 0.2835437700 
-1.1520919617 *= 0.0000000000 * -0.1538214700 
-1.1520919617 *= 0.0000000000 * -0.2976741800 
-1.1520919617 *= 0.0000000000 * 0.2209880800 
-0.2452910657 *= 4.5979877788 * 0.1972169000 
-0.0244164057 *= 2.1019898961 * 0.1050788400 
-0.0244164057 *= 0.0000000000 * -0.2815447400 
-0.1569680410 *= 0.6020292030 * -0.2201747600 
-0.1569680410 *= 0.0000000000 * 0.2755856000 
-0.1569680410 *= 0.0000000000 * -0.1513674100 
-0.1569680410 *= 0.0000000000 * 0.1941494600 
-0.1569680410 *= 0.0000000000 * -0.2956854700 
-0.8214453350 *= 2.1554129313 * -0.3082830600 
-0.8214453350 *= 0.0000000000 * 0.2408793700 
-0.8214453350 *= 0.0000000000 * -0.1238134350 
-0.8214453350 *= 0.0000000000 * 0.1611515300 
0.0252134364 *= 4.3394698350 * 0.1951065000 
0.0252134364 *= 0.0000000000 * 0.2221888000 
0.0252134364 *= 0.0000000000 * -0.2779943600 
0.2988987152 *= 2.7644942480 * 0.0990001260 
0.2988987152 *= 0.0000000000 * 0.2626727000 
0.3296901001 *= 4.7110143585 * 0.0065360414 
tempVal = 0.3296901001 + -0.0750943500(biases), 
now the tempVal = 0.2545957501 

compute layer: 5, node : 22
0.0000000000 *= 0.0000000000 * 0.1287327300 
0.0000000000 *= 0.0000000000 * -0.2941886500 
0.0000000000 *= 0.0000000000 * 0.2894164300 
0.3482483708 *= 1.7553733112 * 0.1983899200 
0.3482483708 *= 0.0000000000 * 0.1763476300 
-0.4949313228 *= 3.5027185298 * -0.2407215100 
-0.9549105462 *= 1.4039559876 * -0.3276308000 
-1.5849859201 *= 2.3053236137 * -0.2733132000 
-1.5849859201 *= 0.0000000000 * 0.0130834840 
-1.5849859201 *= 0.0000000000 * -0.3034813700 
-1.5849859201 *= 0.0000000000 * -0.2690012500 
-1.5849859201 *= 0.0000000000 * 0.0426243700 
-0.1637352992 *= 4.5979877788 * 0.3091027400 
-0.7502943816 *= 2.1019898961 * -0.2790494300 
-0.7502943816 *= 0.0000000000 * 0.0634559540 
-0.8958397516 *= 0.6020292030 * -0.2417579900 
-0.8958397516 *= 0.0000000000 * 0.0527244100 
-0.8958397516 *= 0.0000000000 * 0.3168845800 
-0.8958397516 *= 0.0000000000 * 0.0564903900 
-0.8958397516 *= 0.0000000000 * -0.1216419800 
-0.2154086515 *= 2.1554129313 * 0.3156848000 
-0.2154086515 *= 0.0000000000 * 0.1250008200 
-0.2154086515 *= 0.0000000000 * 0.2439345000 
-0.2154086515 *= 0.0000000000 * 0.2417834300 
1.0456470974 *= 4.3394698350 * 0.2906013400 
1.0456470974 *= 0.0000000000 * 0.2152824100 
1.0456470974 *= 0.0000000000 * 0.1287446600 
2.3018324544 *= 2.7644942480 * 0.4543997000 
2.3018324544 *= 0.0000000000 * 0.1217144400 
3.0953310743 *= 4.7110143585 * 0.1684347700 
tempVal = 3.0953310743 + 0.1316451100(biases), 
now the tempVal = 3.2269761843 

compute layer: 5, node : 23
0.0000000000 *= 0.0000000000 * 0.2136451500 
0.0000000000 *= 0.0000000000 * 0.3131565000 
0.0000000000 *= 0.0000000000 * -0.1848432900 
0.3049415909 *= 1.7553733112 * 0.1737189400 
0.3049415909 *= 0.0000000000 * -0.2941329800 
1.3271587491 *= 3.5027185298 * 0.2918353700 
1.2956849269 *= 1.4039559876 * -0.0224179550 
1.4588514905 *= 2.3053236137 * 0.0707781600 
1.4588514905 *= 0.0000000000 * 0.2123483000 
1.4588514905 *= 0.0000000000 * 0.0531159300 
1.4588514905 *= 0.0000000000 * 0.2385563100 
1.4588514905 *= 0.0000000000 * 0.0188695660 
0.2144341459 *= 4.5979877788 * -0.2706439000 
-0.2667738965 *= 2.1019898961 * -0.2289297600 
-0.2667738965 *= 0.0000000000 * 0.3006460700 
-0.2260983834 *= 0.6020292030 * 0.0675640200 
-0.2260983834 *= 0.0000000000 * -0.3092620400 
-0.2260983834 *= 0.0000000000 * -0.2202176200 
-0.2260983834 *= 0.0000000000 * 0.0140898890 
-0.2260983834 *= 0.0000000000 * -0.1007370650 
-0.3130385590 *= 2.1554129313 * -0.0403357400 
-0.3130385590 *= 0.0000000000 * 0.2442825000 
-0.3130385590 *= 0.0000000000 * 0.2139201900 
-0.3130385590 *= 0.0000000000 * -0.0375731330 
-0.1674302784 *= 4.3394698350 * 0.0335543940 
-0.1674302784 *= 0.0000000000 * -0.0596008450 
-0.1674302784 *= 0.0000000000 * -0.0560789200 
-0.9662354251 *= 2.7644942480 * -0.2889516400 
-0.9662354251 *= 0.0000000000 * 0.0247046540 
-1.1064342797 *= 4.7110143585 * -0.0297598020 
tempVal = -1.1064342797 + 0.0000000000(biases), 
now the tempVal = -1.1064342797 
ReLU !!! in layer: 5, node : 23, its linear result is negative,so set it to 0

compute layer: 5, node : 24
0.0000000000 *= 0.0000000000 * -0.1229246100 
0.0000000000 *= 0.0000000000 * 0.1553229000 
0.0000000000 *= 0.0000000000 * 0.0715619850 
-0.4021473189 *= 1.7553733112 * -0.2290950400 
-0.4021473189 *= 0.0000000000 * -0.2012228700 
0.2092230228 *= 3.5027185298 * 0.1745416700 
-0.2521359805 *= 1.4039559876 * -0.3286135800 
0.1149835545 *= 2.3053236137 * 0.1592485900 
0.1149835545 *= 0.0000000000 * 0.1638278800 
0.1149835545 *= 0.0000000000 * 0.0999332800 
0.1149835545 *= 0.0000000000 * -0.2367016000 
0.1149835545 *= 0.0000000000 * 0.2085060800 
0.8084060914 *= 4.5979877788 * 0.1508100000 
0.3897339930 *= 2.1019898961 * -0.1991789300 
0.3897339930 *= 0.0000000000 * 0.0155698840 
0.3633118801 *= 0.6020292030 * -0.0438884240 
0.3633118801 *= 0.0000000000 * 0.1716483100 
0.3633118801 *= 0.0000000000 * 0.2049639500 
0.3633118801 *= 0.0000000000 * -0.1649508900 
0.3633118801 *= 0.0000000000 * 0.1425154800 
0.1172500821 *= 2.1554129313 * -0.1141599340 
0.1172500821 *= 0.0000000000 * -0.1638655200 
0.1172500821 *= 0.0000000000 * -0.3110785800 
0.1172500821 *= 0.0000000000 * -0.0896702200 
2.1810178801 *= 4.3394698350 * 0.4755806300 
2.1810178801 *= 0.0000000000 * -0.0473873840 
2.1810178801 *= 0.0000000000 * -0.1290890300 
3.0146220381 *= 2.7644942480 * 0.3015394800 
3.0146220381 *= 0.0000000000 * -0.2253653600 
4.3611653363 *= 4.7110143585 * 0.2858287400 
tempVal = 4.3611653363 + 0.0295612890(biases), 
now the tempVal = 4.3907266253 

compute layer: 5, node : 25
0.0000000000 *= 0.0000000000 * -0.2076134200 
0.0000000000 *= 0.0000000000 * -0.1193586960 
0.0000000000 *= 0.0000000000 * 0.0891382000 
0.5377394101 *= 1.7553733112 * 0.3063390600 
0.5377394101 *= 0.0000000000 * -0.0518817270 
1.7329131033 *= 3.5027185298 * 0.3412131700 
2.1390648787 *= 1.4039559876 * 0.2892909600 
1.7945534911 *= 2.3053236137 * -0.1494416600 
1.7945534911 *= 0.0000000000 * 0.2198576600 
1.7945534911 *= 0.0000000000 * 0.2509612000 
1.7945534911 *= 0.0000000000 * -0.1505066000 
1.7945534911 *= 0.0000000000 * 0.0530531800 
2.1668257553 *= 4.5979877788 * 0.0809641700 
3.0670321459 *= 2.1019898961 * 0.4282639000 
3.0670321459 *= 0.0000000000 * -0.1918090100 
2.9065262539 *= 0.6020292030 * -0.2666081500 
2.9065262539 *= 0.0000000000 * -0.2620916400 
2.9065262539 *= 0.0000000000 * -0.2929892500 
2.9065262539 *= 0.0000000000 * -0.1885001700 
2.9065262539 *= 0.0000000000 * 0.0736257800 
3.3737714099 *= 2.1554129313 * 0.2167775600 
3.3737714099 *= 0.0000000000 * -0.0607079830 
3.3737714099 *= 0.0000000000 * 0.0741011200 
3.3737714099 *= 0.0000000000 * 0.0043278370 
4.3892171151 *= 4.3394698350 * 0.2340022500 
4.3892171151 *= 0.0000000000 * 0.1003089900 
4.3892171151 *= 0.0000000000 * 0.2871646600 
3.7676654788 *= 2.7644942480 * -0.2248337600 
3.7676654788 *= 0.0000000000 * -0.3047493000 
4.9521809758 *= 4.7110143585 * 0.2514353400 
tempVal = 4.9521809758 + 0.0971086840(biases), 
now the tempVal = 5.0492896598 

compute layer: 5, node : 26
0.0000000000 *= 0.0000000000 * -0.2811881000 
0.0000000000 *= 0.0000000000 * 0.1663179400 
0.0000000000 *= 0.0000000000 * -0.0917851500 
0.0897410504 *= 1.7553733112 * 0.0511236270 
0.0897410504 *= 0.0000000000 * 0.3037712600 
-0.3986184051 *= 3.5027185298 * -0.1394229800 
-0.5078608439 *= 1.4039559876 * -0.0778104440 
-0.8488870433 *= 2.3053236137 * -0.1479298600 
-0.8488870433 *= 0.0000000000 * -0.2115840300 
-0.8488870433 *= 0.0000000000 * 0.0853713900 
-0.8488870433 *= 0.0000000000 * -0.2291343400 
-0.8488870433 *= 0.0000000000 * -0.1408192700 
-0.8222931142 *= 4.5979877788 * 0.0057838190 
-0.6206283423 *= 2.1019898961 * 0.0959399340 
-0.6206283423 *= 0.0000000000 * -0.0515091750 
-0.6475265718 *= 0.6020292030 * -0.0446792770 
-0.6475265718 *= 0.0000000000 * -0.1030098350 
-0.6475265718 *= 0.0000000000 * 0.1985856400 
-0.6475265718 *= 0.0000000000 * -0.2417641900 
-0.6475265718 *= 0.0000000000 * -0.1247744800 
-1.2673002137 *= 2.1554129313 * -0.2875428800 
-1.2673002137 *= 0.0000000000 * -0.1258212800 
-1.2673002137 *= 0.0000000000 * -0.2536960000 
-1.2673002137 *= 0.0000000000 * 0.2292806400 
-1.4089118252 *= 4.3394698350 * -0.0326333900 
-1.4089118252 *= 0.0000000000 * -0.0112769360 
-1.4089118252 *= 0.0000000000 * 0.2387924800 
-1.6181770567 *= 2.7644942480 * -0.0756974740 
-1.6181770567 *= 0.0000000000 * -0.0037387040 
-0.7891686949 *= 4.7110143585 * 0.1759723700 
tempVal = -0.7891686949 + 0.0000000000(biases), 
now the tempVal = -0.7891686949 
ReLU !!! in layer: 5, node : 26, its linear result is negative,so set it to 0

compute layer: 5, node : 27
0.0000000000 *= 0.0000000000 * 0.2216839500 
0.0000000000 *= 0.0000000000 * -0.0222538950 
0.0000000000 *= 0.0000000000 * -0.0951987060 
0.4963279946 *= 1.7553733112 * 0.2827478300 
0.4963279946 *= 0.0000000000 * 0.2472795500 
1.4619091014 *= 3.5027185298 * 0.2756662000 
1.7382214827 *= 1.4039559876 * 0.1968098600 
1.8280215373 *= 2.3053236137 * 0.0389533400 
1.8280215373 *= 0.0000000000 * -0.0445896900 
1.8280215373 *= 0.0000000000 * 0.1733069400 
1.8280215373 *= 0.0000000000 * -0.2682082000 
1.8280215373 *= 0.0000000000 * -0.0936626200 
1.8329606879 *= 4.5979877788 * 0.0010741983 
1.3892402059 *= 2.1019898961 * -0.2110954400 
1.3892402059 *= 0.0000000000 * -0.1410555500 
1.2825329017 *= 0.6020292030 * -0.1772460600 
1.2825329017 *= 0.0000000000 * -0.2619681700 
1.2825329017 *= 0.0000000000 * 0.3099163200 
1.2825329017 *= 0.0000000000 * 0.0180400090 
1.2825329017 *= 0.0000000000 * -0.2117987100 
1.4229104713 *= 2.1554129313 * 0.0651279240 
1.4229104713 *= 0.0000000000 * -0.2617750500 
1.4229104713 *= 0.0000000000 * -0.0262490570 
1.4229104713 *= 0.0000000000 * 0.2953361300 
3.6082770270 *= 4.3394698350 * 0.5036022000 
3.6082770270 *= 0.0000000000 * 0.1536413100 
3.6082770270 *= 0.0000000000 * -0.0035879682 
4.8974078571 *= 2.7644942480 * 0.4663170600 
4.8974078571 *= 0.0000000000 * 0.1466108300 
5.6130871624 *= 4.7110143585 * 0.1519161800 
tempVal = 5.6130871624 + 0.0733594900(biases), 
now the tempVal = 5.6864466524 

compute layer: 5, node : 28
0.0000000000 *= 0.0000000000 * 0.2438950400 
0.0000000000 *= 0.0000000000 * -0.0943376300 
0.0000000000 *= 0.0000000000 * -0.2985767400 
-0.7059638209 *= 1.7553733112 * -0.4021730400 
-0.7059638209 *= 0.0000000000 * 0.2033823400 
-0.1700852248 *= 3.5027185298 * 0.1529893400 
0.0051157766 *= 1.4039559876 * 0.1247909500 
-0.4782830826 *= 2.3053236137 * -0.2096880700 
-0.4782830826 *= 0.0000000000 * 0.2770481400 
-0.4782830826 *= 0.0000000000 * 0.1781735100 
-0.4782830826 *= 0.0000000000 * -0.1741763400 
-0.4782830826 *= 0.0000000000 * -0.0144630160 
-2.2403646054 *= 4.5979877788 * -0.3832288400 
-2.5314353441 *= 2.1019898961 * -0.1384739000 
-2.5314353441 *= 0.0000000000 * 0.1405713700 
-2.3547049758 *= 0.6020292030 * 0.2935578000 
-2.3547049758 *= 0.0000000000 * -0.0871573200 
-2.3547049758 *= 0.0000000000 * 0.2776010600 
-2.3547049758 *= 0.0000000000 * -0.1753903000 
-2.3547049758 *= 0.0000000000 * 0.2697302000 
-2.3256030473 *= 2.1554129313 * 0.0135017880 
-2.3256030473 *= 0.0000000000 * -0.0640727600 
-2.3256030473 *= 0.0000000000 * -0.1846044700 
-2.3256030473 *= 0.0000000000 * 0.2809562000 
-3.1681590235 *= 4.3394698350 * -0.1941610400 
-3.1681590235 *= 0.0000000000 * 0.0034089640 
-3.1681590235 *= 0.0000000000 * 0.1944444800 
-3.7881572905 *= 2.7644942480 * -0.2242718600 
-3.7881572905 *= 0.0000000000 * 0.1885154800 
-4.6635706983 *= 4.7110143585 * -0.1858227000 
tempVal = -4.6635706983 + -0.2614387300(biases), 
now the tempVal = -4.9250094283 
ReLU !!! in layer: 5, node : 28, its linear result is negative,so set it to 0

compute layer: 5, node : 29
0.0000000000 *= 0.0000000000 * 0.0888732000 
0.0000000000 *= 0.0000000000 * 0.3007944500 
0.0000000000 *= 0.0000000000 * -0.0973625200 
0.1689557625 *= 1.7553733112 * 0.0962506160 
0.1689557625 *= 0.0000000000 * 0.2490255200 
-0.8992309335 *= 3.5027185298 * -0.3049593300 
-0.7803086731 *= 1.4039559876 * 0.0847051200 
-0.7378487087 *= 2.3053236137 * 0.0184182230 
-0.7378487087 *= 0.0000000000 * 0.1304555000 
-0.7378487087 *= 0.0000000000 * -0.0655032400 
-0.7378487087 *= 0.0000000000 * -0.1587730200 
-0.7378487087 *= 0.0000000000 * 0.1222478600 
0.4086067590 *= 4.5979877788 * 0.2493385200 
0.0681497677 *= 2.1019898961 * -0.1619689000 
0.0681497677 *= 0.0000000000 * 0.1702510900 
-0.0963219736 *= 0.6020292030 * -0.2731956200 
-0.0963219736 *= 0.0000000000 * -0.2748774300 
-0.0963219736 *= 0.0000000000 * -0.1161798500 
-0.0963219736 *= 0.0000000000 * 0.1062298400 
-0.0963219736 *= 0.0000000000 * -0.2725539000 
-0.7321036302 *= 2.1554129313 * -0.2949697700 
-0.7321036302 *= 0.0000000000 * -0.2031927000 
-0.7321036302 *= 0.0000000000 * 0.1102269100 
-0.7321036302 *= 0.0000000000 * -0.1626939000 
-1.3749122043 *= 4.3394698350 * -0.1481306700 
-1.3749122043 *= 0.0000000000 * -0.2924829000 
-1.3749122043 *= 0.0000000000 * -0.1145811200 
-0.6494244583 *= 2.7644942480 * 0.2624305500 
-0.6494244583 *= 0.0000000000 * 0.0407945440 
-1.5044196704 *= 4.7110143585 * -0.1814885600 
tempVal = -1.5044196704 + -0.0015452546(biases), 
now the tempVal = -1.5059649250 
ReLU !!! in layer: 5, node : 29, its linear result is negative,so set it to 0

now we get all result in layer: 5
	node: 0, val: 4.4343679937
	node: 1, val: 3.0432321013
	node: 2, val: 3.1679594342
	node: 3, val: 0.5027653479
	node: 4, val: 0.0000000000
	node: 5, val: 0.1809454382
	node: 6, val: 0.0000000000
	node: 7, val: 0.0000000000
	node: 8, val: 0.0000000000
	node: 9, val: 0.0000000000
	node: 10, val: 0.0000000000
	node: 11, val: 0.1517379236
	node: 12, val: 0.0000000000
	node: 13, val: 0.0000000000
	node: 14, val: 3.5997447551
	node: 15, val: 0.6412750829
	node: 16, val: 0.0000000000
	node: 17, val: 0.0000000000
	node: 18, val: 0.0000000000
	node: 19, val: 0.3410432707
	node: 20, val: 0.0000000000
	node: 21, val: 0.2545957501
	node: 22, val: 3.2269761843
	node: 23, val: 0.0000000000
	node: 24, val: 4.3907266253
	node: 25, val: 5.0492896598
	node: 26, val: 0.0000000000
	node: 27, val: 5.6864466524
	node: 28, val: 0.0000000000
	node: 29, val: 0.0000000000

when compute layer[5] to layer[6]

compute layer: 6, node : 0
-1.5888074459 *= 4.4343679937 * -0.3582940000 
-1.2693756840 *= 3.0432321013 * 0.1049646400 
-0.9174071225 *= 3.1679594342 * 0.1111026100 
-0.8334790700 *= 0.5027653479 * 0.1669328500 
-0.8334790700 *= 0.0000000000 * -0.0600139500 
-0.7810580873 *= 0.1809454382 * 0.2897060200 
-0.7810580873 *= 0.0000000000 * 0.2139963700 
-0.7810580873 *= 0.0000000000 * 0.0686809940 
-0.7810580873 *= 0.0000000000 * 0.2181119900 
-0.7810580873 *= 0.0000000000 * 0.0160647220 
-0.7810580873 *= 0.0000000000 * -0.1467383400 
-0.8276529374 *= 0.1517379236 * -0.3070745200 
-0.8276529374 *= 0.0000000000 * 0.0435300360 
-0.8276529374 *= 0.0000000000 * 0.0223161620 
-2.0798812064 *= 3.5997447551 * -0.3478658500 
-1.9111203955 *= 0.6412750829 * 0.2631644600 
-1.9111203955 *= 0.0000000000 * 0.0054367900 
-1.9111203955 *= 0.0000000000 * 0.0721155200 
-1.9111203955 *= 0.0000000000 * 0.0567565450 
-1.8179164345 *= 0.3410432707 * 0.2732907200 
-1.8179164345 *= 0.0000000000 * 0.2865276600 
-1.8069481000 *= 0.2545957501 * 0.0430813730 
-1.4222970566 *= 3.2269761843 * 0.1191986000 
-1.4222970566 *= 0.0000000000 * 0.0038153424 
-1.7297136496 *= 4.3907266253 * -0.0700149700 
-0.3692059794 *= 5.0492896598 * 0.2694453600 
-0.3692059794 *= 0.0000000000 * -0.2186028200 
-0.7092621424 *= 5.6864466524 * -0.0598011700 
-0.7092621424 *= 0.0000000000 * 0.0245094260 
-0.7092621424 *= 0.0000000000 * -0.2005015900 
tempVal = -0.7092621424 + 0.0379915870(biases), 
now the tempVal = -0.6712705554 
ReLU !!! in layer: 6, node : 0, its linear result is negative,so set it to 0

compute layer: 6, node : 1
1.0746097958 *= 4.4343679937 * 0.2423366300 
0.8628343171 *= 3.0432321013 * -0.0695890000 
1.2392634537 *= 3.1679594342 * 0.1188238500 
1.1838408139 *= 0.5027653479 * -0.1102356000 
1.1838408139 *= 0.0000000000 * -0.2581241400 
1.1275225378 *= 0.1809454382 * -0.3112445200 
1.1275225378 *= 0.0000000000 * 0.2579958700 
1.1275225378 *= 0.0000000000 * 0.2419807800 
1.1275225378 *= 0.0000000000 * -0.2905093000 
1.1275225378 *= 0.0000000000 * 0.1778924800 
1.1275225378 *= 0.0000000000 * 0.0178104230 
1.1601048231 *= 0.1517379236 * 0.2147273700 
1.1601048231 *= 0.0000000000 * 0.0108931590 
1.1601048231 *= 0.0000000000 * -0.1567307900 
1.8068654197 *= 3.5997447551 * 0.1796684600 
1.8997653377 *= 0.6412750829 * 0.1448675000 
1.8997653377 *= 0.0000000000 * -0.0709371100 
1.8997653377 *= 0.0000000000 * 0.0766212000 
1.8997653377 *= 0.0000000000 * 0.2084873300 
1.8023152004 *= 0.3410432707 * -0.2857412700 
1.8023152004 *= 0.0000000000 * 0.0580855460 
1.8898325736 *= 0.2545957501 * 0.3437503300 
2.7989732854 *= 3.2269761843 * 0.2817314600 
2.7989732854 *= 0.0000000000 * 0.0724166400 
3.8819201022 *= 4.3907266253 * 0.2466441000 
3.5539653558 *= 5.0492896598 * -0.0649506700 
3.5539653558 *= 0.0000000000 * 0.1239898060 
2.1077268295 *= 5.6864466524 * -0.2543308000 
2.1077268295 *= 0.0000000000 * 0.1346550600 
2.1077268295 *= 0.0000000000 * 0.2297327500 
tempVal = 2.1077268295 + 0.0061439810(biases), 
now the tempVal = 2.1138708105 

compute layer: 6, node : 2
0.9294259714 *= 4.4343679937 * 0.2095960400 
0.9246831334 *= 3.0432321013 * -0.0015584871 
0.9787150892 *= 3.1679594342 * 0.0170557600 
0.8591853376 *= 0.5027653479 * -0.2377446100 
0.8591853376 *= 0.0000000000 * 0.2202770400 
0.8605967421 *= 0.1809454382 * 0.0078001660 
0.8605967421 *= 0.0000000000 * 0.0448144640 
0.8605967421 *= 0.0000000000 * 0.1452784500 
0.8605967421 *= 0.0000000000 * -0.0455337300 
0.8605967421 *= 0.0000000000 * 0.0293906650 
0.8605967421 *= 0.0000000000 * -0.2602891300 
0.8260174750 *= 0.1517379236 * -0.2278881000 
0.8260174750 *= 0.0000000000 * -0.2255267000 
0.8260174750 *= 0.0000000000 * -0.0314069400 
0.5205992911 *= 3.5997447551 * -0.0848444000 
0.4493379758 *= 0.6412750829 * -0.1111244100 
0.4493379758 *= 0.0000000000 * 0.1005659700 
0.4493379758 *= 0.0000000000 * -0.2253541500 
0.4493379758 *= 0.0000000000 * 0.2055442600 
0.4290722673 *= 0.3410432707 * -0.0594226900 
0.4290722673 *= 0.0000000000 * -0.3047985000 
0.3833483269 *= 0.2545957501 * -0.1795942800 
0.9191299271 *= 3.2269761843 * 0.1660320900 
0.9191299271 *= 0.0000000000 * 0.1877381800 
0.8204126803 *= 4.3907266253 * -0.0224831230 
1.0853027431 *= 5.0492896598 * 0.0524608570 
1.0853027431 *= 0.0000000000 * -0.0569763780 
3.4127733190 *= 5.6864466524 * 0.4093014000 
3.4127733190 *= 0.0000000000 * 0.0410474050 
3.4127733190 *= 0.0000000000 * 0.0063231170 
tempVal = 3.4127733190 + -0.0128190230(biases), 
now the tempVal = 3.3999542960 

compute layer: 6, node : 3
0.6345765956 *= 4.4343679937 * 0.1431041800 
0.1191569431 *= 3.0432321013 * -0.1693658700 
0.4327191286 *= 3.1679594342 * 0.0989792300 
0.5539261204 *= 0.5027653479 * 0.2410806400 
0.5539261204 *= 0.0000000000 * -0.0473406870 
0.5360998897 *= 0.1809454382 * -0.0985171600 
0.5360998897 *= 0.0000000000 * 0.2300888400 
0.5360998897 *= 0.0000000000 * 0.2645956600 
0.5360998897 *= 0.0000000000 * -0.3342317300 
0.5360998897 *= 0.0000000000 * -0.1387048400 
0.5360998897 *= 0.0000000000 * -0.1828498100 
0.5659787864 *= 0.1517379236 * 0.1969112000 
0.5659787864 *= 0.0000000000 * -0.3057870600 
0.5659787864 *= 0.0000000000 * -0.3032331200 
0.5856397880 *= 3.5997447551 * 0.0054617766 
0.6426892194 *= 0.6412750829 * 0.0889624950 
0.6426892194 *= 0.0000000000 * 0.1715951100 
0.6426892194 *= 0.0000000000 * 0.0190477730 
0.6426892194 *= 0.0000000000 * 0.1200779200 
0.7324280034 *= 0.3410432707 * 0.2631302000 
0.7324280034 *= 0.0000000000 * -0.0387848020 
0.7471900183 *= 0.2545957501 * 0.0579821730 
-0.4911632219 *= 3.2269761843 * -0.3837503500 
-0.4911632219 *= 0.0000000000 * -0.0637192500 
-1.7086693007 *= 4.3907266253 * -0.2772903400 
-1.7514237569 *= 5.0492896598 * -0.0084674200 
-1.7514237569 *= 0.0000000000 * -0.1122017350 
-0.9807698372 *= 5.6864466524 * 0.1355246900 
-0.9807698372 *= 0.0000000000 * 0.0561753800 
-0.9807698372 *= 0.0000000000 * -0.2742546500 
tempVal = -0.9807698372 + -0.0895383100(biases), 
now the tempVal = -1.0703081472 
ReLU !!! in layer: 6, node : 3, its linear result is negative,so set it to 0

compute layer: 6, node : 4
1.1622518421 *= 4.4343679937 * 0.2621009000 
1.5149505132 *= 3.0432321013 * 0.1158960800 
0.6516103516 *= 3.1679594342 * -0.2725224800 
0.7730065642 *= 0.5027653479 * 0.2414570000 
0.7730065642 *= 0.0000000000 * 0.0155367860 
0.7605882028 *= 0.1809454382 * -0.0686304200 
0.7605882028 *= 0.0000000000 * -0.2860979000 
0.7605882028 *= 0.0000000000 * -0.0750415000 
0.7605882028 *= 0.0000000000 * 0.1075180100 
0.7605882028 *= 0.0000000000 * -0.1012738200 
0.7605882028 *= 0.0000000000 * 0.0792832400 
0.7443479614 *= 0.1517379236 * -0.1070282300 
0.7443479614 *= 0.0000000000 * 0.1261911100 
0.7443479614 *= 0.0000000000 * 0.1824259900 
0.0666173928 *= 3.5997447551 * -0.1882718400 
0.0755573504 *= 0.6412750829 * 0.0139409090 
0.0755573504 *= 0.0000000000 * 0.0640800500 
0.0755573504 *= 0.0000000000 * 0.1748117400 
0.0755573504 *= 0.0000000000 * 0.0065540127 
0.0028597244 *= 0.3410432707 * -0.2131624700 
0.0028597244 *= 0.0000000000 * 0.1664788100 
0.0474182401 *= 0.2545957501 * 0.1750167300 
-0.4211076906 *= 3.2269761843 * -0.1451903900 
-0.4211076906 *= 0.0000000000 * -0.3049696400 
-0.5123564475 *= 4.3907266253 * -0.0207821540 
-1.2450648787 *= 5.0492896598 * -0.1451111900 
-1.2450648787 *= 0.0000000000 * -0.0354147550 
-3.5664001767 *= 5.6864466524 * -0.4082224700 
-3.5664001767 *= 0.0000000000 * 0.0567427350 
-3.5664001767 *= 0.0000000000 * -0.1214995300 
tempVal = -3.5664001767 + -0.1341979800(biases), 
now the tempVal = -3.7005981567 
ReLU !!! in layer: 6, node : 4, its linear result is negative,so set it to 0

compute layer: 6, node : 5
-1.4335777826 *= 4.4343679937 * -0.3232879600 
-0.9928429108 *= 3.0432321013 * 0.1448246000 
-2.0283207376 *= 3.1679594342 * -0.3268595600 
-2.1435395377 *= 0.5027653479 * -0.2291701300 
-2.1435395377 *= 0.0000000000 * -0.1711739000 
-2.1832164717 *= 0.1809454382 * -0.2192756800 
-2.1832164717 *= 0.0000000000 * -0.0193594500 
-2.1832164717 *= 0.0000000000 * -0.0957520500 
-2.1832164717 *= 0.0000000000 * 0.1039590800 
-2.1832164717 *= 0.0000000000 * -0.0547263600 
-2.1832164717 *= 0.0000000000 * 0.0307342200 
-2.1741343522 *= 0.1517379236 * 0.0598539860 
-2.1741343522 *= 0.0000000000 * -0.2577210400 
-2.1741343522 *= 0.0000000000 * -0.0036981227 
-2.1919406372 *= 3.5997447551 * -0.0049465410 
-2.3258980193 *= 0.6412750829 * -0.2088922300 
-2.3258980193 *= 0.0000000000 * 0.1123283900 
-2.3258980193 *= 0.0000000000 * 0.0172129780 
-2.3258980193 *= 0.0000000000 * 0.2924245300 
-2.2699358811 *= 0.3410432707 * 0.1640910200 
-2.2699358811 *= 0.0000000000 * 0.1325281300 
-2.2600027885 *= 0.2545957501 * 0.0390151550 
-2.7114761831 *= 3.2269761843 * -0.1399060200 
-2.7114761831 *= 0.0000000000 * 0.2130779900 
-2.2160592138 *= 4.3907266253 * 0.1128325700 
-1.4605594504 *= 5.0492896598 * 0.1496249600 
-1.4605594504 *= 0.0000000000 * 0.1724636600 
-2.4029575359 *= 5.6864466524 * -0.1657270600 
-2.4029575359 *= 0.0000000000 * 0.1177035600 
-2.4029575359 *= 0.0000000000 * 0.0547794770 
tempVal = -2.4029575359 + -0.0880244800(biases), 
now the tempVal = -2.4909820159 
ReLU !!! in layer: 6, node : 5, its linear result is negative,so set it to 0

compute layer: 6, node : 6
-1.2923858206 *= 4.4343679937 * -0.2914475800 
-0.9651695927 *= 3.0432321013 * 0.1075226000 
-1.0710613739 *= 3.1679594342 * -0.0334258640 
-1.0216144773 *= 0.5027653479 * 0.0983498500 
-1.0216144773 *= 0.0000000000 * -0.2260691100 
-0.9981039651 *= 0.1809454382 * 0.1299315000 
-0.9981039651 *= 0.0000000000 * 0.1523678300 
-0.9981039651 *= 0.0000000000 * 0.0896315300 
-0.9981039651 *= 0.0000000000 * 0.2472458600 
-0.9981039651 *= 0.0000000000 * -0.0797652600 
-0.9981039651 *= 0.0000000000 * 0.0875772100 
-0.9509531852 *= 0.1517379236 * 0.3107382700 
-0.9509531852 *= 0.0000000000 * 0.0157798960 
-0.9509531852 *= 0.0000000000 * 0.2937572300 
-0.4404060663 *= 3.5997447551 * 0.1418287000 
-0.3856523773 *= 0.6412750829 * 0.0853825300 
-0.3856523773 *= 0.0000000000 * 0.0828373800 
-0.3856523773 *= 0.0000000000 * 0.0988454100 
-0.3856523773 *= 0.0000000000 * 0.1350626300 
-0.3982955941 *= 0.3410432707 * -0.0370721780 
-0.3982955941 *= 0.0000000000 * -0.0408136700 
-0.3729899757 *= 0.2545957501 * 0.0993952900 
-0.7001486628 *= 3.2269761843 * -0.1013824300 
-0.7001486628 *= 0.0000000000 * -0.2413756100 
0.3925634374 *= 4.3907266253 * 0.2488681700 
-0.0655844153 *= 5.0492896598 * -0.0907351100 
-0.0655844153 *= 0.0000000000 * 0.2481689800 
-1.2275718032 *= 5.6864466524 * -0.2043433200 
-1.2275718032 *= 0.0000000000 * 0.2602578700 
-1.2275718032 *= 0.0000000000 * -0.1870395700 
tempVal = -1.2275718032 + -0.1204202400(biases), 
now the tempVal = -1.3479920432 
ReLU !!! in layer: 6, node : 6, its linear result is negative,so set it to 0

compute layer: 6, node : 7
1.0023014836 *= 4.4343679937 * 0.2260302900 
0.6236057588 *= 3.0432321013 * -0.1244386600 
1.4453124391 *= 3.1679594342 * 0.2593804300 
1.3740347924 *= 0.5027653479 * -0.1417712000 
1.3740347924 *= 0.0000000000 * 0.0446410500 
1.3492295866 *= 0.1809454382 * -0.1370866600 
1.3492295866 *= 0.0000000000 * 0.3677859600 
1.3492295866 *= 0.0000000000 * 0.0972864400 
1.3492295866 *= 0.0000000000 * 0.2417168900 
1.3492295866 *= 0.0000000000 * 0.1820922300 
1.3492295866 *= 0.0000000000 * -0.2174898400 
1.3336884231 *= 0.1517379236 * -0.1024210900 
1.3336884231 *= 0.0000000000 * -0.1986820000 
1.3336884231 *= 0.0000000000 * 0.1677998300 
2.5293965598 *= 3.5997447551 * 0.3321647000 
2.5035196590 *= 0.6412750829 * -0.0403522630 
2.5035196590 *= 0.0000000000 * 0.3308339400 
2.5035196590 *= 0.0000000000 * -0.0737308300 
2.5035196590 *= 0.0000000000 * -0.2648329400 
2.4940189103 *= 0.3410432707 * -0.0278578980 
2.4940189103 *= 0.0000000000 * -0.1240971460 
2.5096132692 *= 0.2545957501 * 0.0612514500 
1.8667123236 *= 3.2269761843 * -0.1992270500 
1.8667123236 *= 0.0000000000 * 0.0309168270 
3.0227346622 *= 4.3907266253 * 0.2632872500 
2.1814078811 *= 5.0492896598 * -0.1666228000 
2.1814078811 *= 0.0000000000 * 0.2213875400 
3.1856717767 *= 5.6864466524 * 0.1766065800 
3.1856717767 *= 0.0000000000 * -0.2675137000 
3.1856717767 *= 0.0000000000 * -0.1004884240 
tempVal = 3.1856717767 + 0.0803506150(biases), 
now the tempVal = 3.2660223917 

compute layer: 6, node : 8
-1.0727754751 *= 4.4343679937 * -0.2419229700 
-2.3514210921 *= 3.0432321013 * -0.4201604000 
-3.4208405630 *= 3.1679594342 * -0.3375736000 
-3.5229397466 *= 0.5027653479 * -0.2030752200 
-3.5229397466 *= 0.0000000000 * 0.0461220670 
-3.4964401985 *= 0.1809454382 * 0.1464504900 
-3.4964401985 *= 0.0000000000 * -0.1878605000 
-3.4964401985 *= 0.0000000000 * 0.1066730000 
-3.4964401985 *= 0.0000000000 * -0.2360684100 
-3.4964401985 *= 0.0000000000 * -0.0099441670 
-3.4964401985 *= 0.0000000000 * 0.0360408300 
-3.5188413486 *= 0.1517379236 * -0.1476305300 
-3.5188413486 *= 0.0000000000 * -0.1856122900 
-3.5188413486 *= 0.0000000000 * 0.2227856000 
-4.7211404019 *= 3.5997447551 * -0.3339956400 
-4.8977529016 *= 0.6412750829 * -0.2754083300 
-4.8977529016 *= 0.0000000000 * -0.0289174040 
-4.8977529016 *= 0.0000000000 * 0.1005125400 
-4.8977529016 *= 0.0000000000 * -0.3017385600 
-4.9146185861 *= 0.3410432707 * -0.0494532100 
-4.9146185861 *= 0.0000000000 * 0.2320802700 
-4.9439452503 *= 0.2545957501 * -0.1151891350 
-5.8502728133 *= 3.2269761843 * -0.2808597000 
-5.8502728133 *= 0.0000000000 * 0.1513751900 
-5.1154862494 *= 4.3907266253 * 0.1673496500 
-7.0753314740 *= 5.0492896598 * -0.3881427600 
-7.0753314740 *= 0.0000000000 * -0.2292882800 
-9.3177599891 *= 5.6864466524 * -0.3943461800 
-9.3177599891 *= 0.0000000000 * 0.1576229500 
-9.3177599891 *= 0.0000000000 * -0.2517665000 
tempVal = -9.3177599891 + -0.2926911000(biases), 
now the tempVal = -9.6104510891 
ReLU !!! in layer: 6, node : 8, its linear result is negative,so set it to 0

compute layer: 6, node : 9
0.6732255714 *= 4.4343679937 * 0.1518199600 
2.1053020647 *= 3.0432321013 * 0.4705774800 
1.8699379166 *= 3.1679594342 * -0.0742951900 
1.9586744168 *= 0.5027653479 * 0.1764968500 
1.9586744168 *= 0.0000000000 * 0.1652698800 
1.9313557197 *= 0.1809454382 * -0.1509775400 
1.9313557197 *= 0.0000000000 * 0.0117607210 
1.9313557197 *= 0.0000000000 * -0.0247856770 
1.9313557197 *= 0.0000000000 * 0.2902944400 
1.9313557197 *= 0.0000000000 * -0.2506573200 
1.9313557197 *= 0.0000000000 * -0.1888429800 
1.9835670292 *= 0.1517379236 * 0.3440887300 
1.9835670292 *= 0.0000000000 * -0.0084000860 
1.9835670292 *= 0.0000000000 * 0.0488396320 
2.2345143794 *= 3.5997447551 * 0.0697125400 
2.2009206570 *= 0.6412750829 * -0.0523858220 
2.2009206570 *= 0.0000000000 * 0.1461384400 
2.2009206570 *= 0.0000000000 * 0.2242688500 
2.2009206570 *= 0.0000000000 * 0.3017373000 
2.0922192771 *= 0.3410432707 * -0.3187319300 
2.0922192771 *= 0.0000000000 * -0.1237546100 
2.2019077138 *= 0.2545957501 * 0.4308337300 
2.5016087060 *= 3.2269761843 * 0.0928736300 
2.5016087060 *= 0.0000000000 * 0.2625074700 
4.8888603834 *= 4.3907266253 * 0.5437031000 
4.5228086960 *= 5.0492896598 * -0.0724956800 
4.5228086960 *= 0.0000000000 * 0.2110998600 
6.3288384826 *= 5.6864466524 * 0.3176025200 
6.3288384826 *= 0.0000000000 * 0.2471652800 
6.3288384826 *= 0.0000000000 * 0.1183960660 
tempVal = 6.3288384826 + 0.1842147100(biases), 
now the tempVal = 6.5130531926 

compute layer: 6, node : 10
1.4135829512 *= 4.4343679937 * 0.3187789000 
0.8191629107 *= 3.0432321013 * -0.1953252400 
1.9576487125 *= 3.1679594342 * 0.3593751200 
2.0164384623 *= 0.5027653479 * 0.1169327800 
2.0164384623 *= 0.0000000000 * 0.2156543400 
2.0430390340 *= 0.1809454382 * 0.1470088000 
2.0430390340 *= 0.0000000000 * 0.2060428600 
2.0430390340 *= 0.0000000000 * -0.2459761400 
2.0430390340 *= 0.0000000000 * -0.2299578300 
2.0430390340 *= 0.0000000000 * -0.1791434900 
2.0430390340 *= 0.0000000000 * -0.1630880200 
2.0612572111 *= 0.1517379236 * 0.1200634400 
2.0612572111 *= 0.0000000000 * -0.1114198700 
2.0612572111 *= 0.0000000000 * 0.1874571400 
3.0820284439 *= 3.5997447551 * 0.2835676700 
3.3082160413 *= 0.6412750829 * 0.3527154000 
3.3082160413 *= 0.0000000000 * -0.1254309300 
3.3082160413 *= 0.0000000000 * -0.2929668700 
3.3082160413 *= 0.0000000000 * -0.2914232000 
3.4253656803 *= 0.3410432707 * 0.3435037400 
3.4253656803 *= 0.0000000000 * -0.1676268900 
3.3670677675 *= 0.2545957501 * -0.2289822700 
3.1422617624 *= 3.2269761843 * -0.0696646000 
3.1422617624 *= 0.0000000000 * -0.1071804200 
2.7146380074 *= 4.3907266253 * -0.0973924800 
3.8027537690 *= 5.0492896598 * 0.2154987800 
3.8027537690 *= 0.0000000000 * -0.2362147900 
4.1877127873 *= 5.6864466524 * 0.0676976400 
4.1877127873 *= 0.0000000000 * -0.1678349400 
4.1877127873 *= 0.0000000000 * 0.2300180200 
tempVal = 4.1877127873 + 0.0854973200(biases), 
now the tempVal = 4.2732101073 

compute layer: 6, node : 11
-1.4305050760 *= 4.4343679937 * -0.3225950300 
-1.0628354680 *= 3.0432321013 * 0.1208155000 
-0.1638140725 *= 3.1679594342 * 0.2837856400 
-0.1141118536 *= 0.5027653479 * 0.0988576860 
-0.1141118536 *= 0.0000000000 * 0.1661489000 
-0.1628458667 *= 0.1809454382 * -0.2693298800 
-0.1628458667 *= 0.0000000000 * -0.0199222550 
-0.1628458667 *= 0.0000000000 * 0.0854163240 
-0.1628458667 *= 0.0000000000 * 0.1473323400 
-0.1628458667 *= 0.0000000000 * -0.0113647760 
-0.1628458667 *= 0.0000000000 * 0.2031944800 
-0.1518756033 *= 0.1517379236 * 0.0722974400 
-0.1518756033 *= 0.0000000000 * -0.1413825600 
-0.1518756033 *= 0.0000000000 * 0.0831636860 
-0.8975151047 *= 3.5997447551 * -0.2071367700 
-0.7246472347 *= 0.6412750829 * 0.2695689800 
-0.7246472347 *= 0.0000000000 * 0.1091977900 
-0.7246472347 *= 0.0000000000 * -0.1678152800 
-0.7246472347 *= 0.0000000000 * 0.0126529810 
-0.8084278359 *= 0.3410432707 * -0.2456597400 
-0.8084278359 *= 0.0000000000 * 0.0156757300 
-0.8931754211 *= 0.2545957501 * -0.3328711700 
-2.1943641802 *= 3.2269761843 * -0.4032223000 
-2.1943641802 *= 0.0000000000 * -0.0597740450 
-3.9367357879 *= 4.3907266253 * -0.3968299000 
-3.3636645372 *= 5.0492896598 * 0.1134954200 
-3.3636645372 *= 0.0000000000 * 0.2076557000 
-5.4445989341 *= 5.6864466524 * -0.3659463500 
-5.4445989341 *= 0.0000000000 * 0.0258681330 
-5.4445989341 *= 0.0000000000 * 0.2804632000 
tempVal = -5.4445989341 + -0.2233533700(biases), 
now the tempVal = -5.6679523041 
ReLU !!! in layer: 6, node : 11, its linear result is negative,so set it to 0

compute layer: 6, node : 12
0.4643967709 *= 4.4343679937 * 0.1047267100 
-0.2044333073 *= 3.0432321013 * -0.2197762300 
-0.6476123630 *= 3.1679594342 * -0.1398941700 
-0.7816159295 *= 0.5027653479 * -0.2665330200 
-0.7816159295 *= 0.0000000000 * -0.1137736000 
-0.7783404431 *= 0.1809454382 * 0.0181020670 
-0.7783404431 *= 0.0000000000 * -0.2477122800 
-0.7783404431 *= 0.0000000000 * -0.2778463700 
-0.7783404431 *= 0.0000000000 * 0.2441026400 
-0.7783404431 *= 0.0000000000 * -0.2946992800 
-0.7783404431 *= 0.0000000000 * 0.1461595400 
-0.8005513578 *= 0.1517379236 * -0.1463768200 
-0.8005513578 *= 0.0000000000 * -0.2681690500 
-0.8005513578 *= 0.0000000000 * -0.0891970000 
-1.4134868448 *= 3.5997447551 * -0.1702719300 
-1.4669765421 *= 0.6412750829 * -0.0834114700 
-1.4669765421 *= 0.0000000000 * -0.1468032600 
-1.4669765421 *= 0.0000000000 * -0.3002173600 
-1.4669765421 *= 0.0000000000 * -0.0252078180 
-1.5349850448 *= 0.3410432707 * -0.1994131200 
-1.5349850448 *= 0.0000000000 * -0.0854224860 
-1.5531730113 *= 0.2545957501 * -0.0714386100 
-1.0912128477 *= 3.2269761843 * 0.1431557400 
-1.0912128477 *= 0.0000000000 * 0.0769724700 
-1.1356740963 *= 4.3907266253 * -0.0101261710 
-0.0409139745 *= 5.0492896598 * 0.2168146800 
-0.0409139745 *= 0.0000000000 * 0.1185611340 
-0.8726994703 *= 5.6864466524 * -0.1462750900 
-0.8726994703 *= 0.0000000000 * -0.1489634800 
-0.8726994703 *= 0.0000000000 * 0.2167070400 
tempVal = -0.8726994703 + -0.0011165146(biases), 
now the tempVal = -0.8738159849 
ReLU !!! in layer: 6, node : 12, its linear result is negative,so set it to 0

compute layer: 6, node : 13
0.8391801085 *= 4.4343679937 * 0.1892445800 
0.7976988799 *= 3.0432321013 * -0.0136306490 
0.2084396075 *= 3.1679594342 * -0.1860059400 
0.3035197645 *= 0.5027653479 * 0.1891143800 
0.3035197645 *= 0.0000000000 * 0.1485641400 
0.2410467923 *= 0.1809454382 * -0.3452586200 
0.2410467923 *= 0.0000000000 * 0.2764198500 
0.2410467923 *= 0.0000000000 * -0.0575957520 
0.2410467923 *= 0.0000000000 * 0.2875928000 
0.2410467923 *= 0.0000000000 * -0.1978622400 
0.2410467923 *= 0.0000000000 * 0.0683068400 
0.2767770902 *= 0.1517379236 * 0.2354737500 
0.2767770902 *= 0.0000000000 * 0.1117296300 
0.2767770902 *= 0.0000000000 * 0.2840259000 
0.4004378186 *= 3.5997447551 * 0.0343526380 
0.2153874278 *= 0.6412750829 * -0.2885663200 
0.2153874278 *= 0.0000000000 * 0.1375993300 
0.2153874278 *= 0.0000000000 * 0.0156553700 
0.2153874278 *= 0.0000000000 * 0.2024293100 
0.2268331981 *= 0.3410432707 * 0.0335610500 
0.2268331981 *= 0.0000000000 * 0.2680388000 
0.2509376475 *= 0.2545957501 * 0.0946773440 
0.9042824757 *= 3.2269761843 * 0.2024634800 
0.9042824757 *= 0.0000000000 * 0.2820544000 
0.9275788386 *= 4.3907266253 * 0.0053058104 
0.5098589315 *= 5.0492896598 * -0.0827284500 
0.5098589315 *= 0.0000000000 * 0.0427190920 
2.3401012668 *= 5.6864466524 * 0.3218604600 
2.3401012668 *= 0.0000000000 * -0.0687802500 
2.3401012668 *= 0.0000000000 * -0.3149752600 
tempVal = 2.3401012668 + 0.0209947620(biases), 
now the tempVal = 2.3610960288 

compute layer: 6, node : 14
0.8452806460 *= 4.4343679937 * 0.1906203200 
0.6185786311 *= 3.0432321013 * -0.0744938300 
1.5554547343 *= 3.1679594342 * 0.2957348800 
1.3971155652 *= 0.5027653479 * -0.3149365200 
1.3971155652 *= 0.0000000000 * -0.1707078800 
1.4419098045 *= 0.1809454382 * 0.2475566100 
1.4419098045 *= 0.0000000000 * -0.1531221600 
1.4419098045 *= 0.0000000000 * -0.2430712400 
1.4419098045 *= 0.0000000000 * 0.1257745500 
1.4419098045 *= 0.0000000000 * -0.0881601000 
1.4419098045 *= 0.0000000000 * 0.0512564740 
1.4637931595 *= 0.1517379236 * 0.1442181000 
1.4637931595 *= 0.0000000000 * 0.0713392500 
1.4637931595 *= 0.0000000000 * -0.1172854400 
0.9036514212 *= 3.5997447551 * -0.1556059600 
0.7353680139 *= 0.6412750829 * -0.2624200000 
0.7353680139 *= 0.0000000000 * 0.0532020330 
0.7353680139 *= 0.0000000000 * 0.2339505900 
0.7353680139 *= 0.0000000000 * -0.2653098400 
0.7675350856 *= 0.3410432707 * 0.0943196200 
0.7675350856 *= 0.0000000000 * 0.3187729400 
0.8158592964 *= 0.2545957501 * 0.1898076100 
0.2553601558 *= 3.2269761843 * -0.1736917500 
0.2553601558 *= 0.0000000000 * 0.1464396400 
-0.1426081926 *= 4.3907266253 * -0.0906383800 
-1.6857819445 *= 5.0492896598 * -0.3056219500 
-1.6857819445 *= 0.0000000000 * -0.2354098000 
-0.7981913103 *= 5.6864466524 * 0.1560888000 
-0.7981913103 *= 0.0000000000 * -0.2176936400 
-0.7981913103 *= 0.0000000000 * -0.0811252700 
tempVal = -0.7981913103 + 0.0028368116(biases), 
now the tempVal = -0.7953544987 
ReLU !!! in layer: 6, node : 14, its linear result is negative,so set it to 0

compute layer: 6, node : 15
0.3453691992 *= 4.4343679937 * 0.0778846500 
1.3056659579 *= 3.0432321013 * 0.3155516000 
0.7305500720 *= 3.1679594342 * -0.1815414300 
0.6142213822 *= 0.5027653479 * -0.2313777000 
0.6142213822 *= 0.0000000000 * -0.1517030700 
0.6398562554 *= 0.1809454382 * 0.1416718400 
0.6398562554 *= 0.0000000000 * -0.0490834100 
0.6398562554 *= 0.0000000000 * -0.0426189450 
0.6398562554 *= 0.0000000000 * -0.0868255400 
0.6398562554 *= 0.0000000000 * 0.0516054370 
0.6398562554 *= 0.0000000000 * -0.1028268500 
0.6593333049 *= 0.1517379236 * 0.1283598000 
0.6593333049 *= 0.0000000000 * 0.2060578900 
0.6593333049 *= 0.0000000000 * 0.1389992800 
1.1709541917 *= 3.5997447551 * 0.1421269900 
1.0469923322 *= 0.6412750829 * -0.1933052800 
1.0469923322 *= 0.0000000000 * 0.1467714600 
1.0469923322 *= 0.0000000000 * 0.1848147500 
1.0469923322 *= 0.0000000000 * 0.2679104800 
1.0660683089 *= 0.3410432707 * 0.0559341830 
1.0660683089 *= 0.0000000000 * 0.0759332900 
1.1631601244 *= 0.2545957501 * 0.3813567800 
1.8381573174 *= 3.2269761843 * 0.2091732800 
1.8381573174 *= 0.0000000000 * -0.2480937400 
3.0248583216 *= 4.3907266253 * 0.2702744000 
2.6704140927 *= 5.0492896598 * -0.0701968500 
2.6704140927 *= 0.0000000000 * 0.0862182600 
2.4195448699 *= 5.6864466524 * -0.0441170450 
2.4195448699 *= 0.0000000000 * 0.1822898100 
2.4195448699 *= 0.0000000000 * -0.3010363000 
tempVal = 2.4195448699 + 0.0514808860(biases), 
now the tempVal = 2.4710257559 

compute layer: 6, node : 16
0.8688494005 *= 4.4343679937 * 0.1959353400 
0.5203604324 *= 3.0432321013 * -0.1145127800 
0.1083033152 *= 3.1679594342 * -0.1300702000 
-0.0383633318 *= 0.5027653479 * -0.2917198800 
-0.0383633318 *= 0.0000000000 * 0.0353922100 
-0.0670856806 *= 0.1809454382 * -0.1587348600 
-0.0670856806 *= 0.0000000000 * -0.2882045500 
-0.0670856806 *= 0.0000000000 * 0.1885081000 
-0.0670856806 *= 0.0000000000 * 0.0661793650 
-0.0670856806 *= 0.0000000000 * -0.2780770700 
-0.0670856806 *= 0.0000000000 * 0.0600261050 
-0.0406769923 *= 0.1517379236 * 0.1740414500 
-0.0406769923 *= 0.0000000000 * 0.1874458000 
-0.0406769923 *= 0.0000000000 * -0.0522103640 
-0.4358339332 *= 3.5997447551 * -0.1097736000 
-0.4615142171 *= 0.6412750829 * -0.0400456600 
-0.4615142171 *= 0.0000000000 * -0.3112921000 
-0.4615142171 *= 0.0000000000 * -0.2939442700 
-0.4615142171 *= 0.0000000000 * 0.0919977800 
-0.4064754434 *= 0.3410432707 * 0.1613835500 
-0.4064754434 *= 0.0000000000 * -0.1163348260 
-0.3340351440 *= 0.2545957501 * 0.2845306700 
-0.1598997450 *= 3.2269761843 * 0.0539624060 
-0.1598997450 *= 0.0000000000 * 0.0185373780 
-0.1228597684 *= 4.3907266253 * 0.0084359560 
-0.2815632848 *= 5.0492896598 * -0.0314308600 
-0.2815632848 *= 0.0000000000 * 0.0275564900 
-0.8333014617 *= 5.6864466524 * -0.0970268800 
-0.8333014617 *= 0.0000000000 * -0.1369435000 
-0.8333014617 *= 0.0000000000 * 0.1898177600 
tempVal = -0.8333014617 + -0.0186092310(biases), 
now the tempVal = -0.8519106927 
ReLU !!! in layer: 6, node : 16, its linear result is negative,so set it to 0

compute layer: 6, node : 17
0.9962285723 *= 4.4343679937 * 0.2246607800 
0.6319249190 *= 3.0432321013 * -0.1197094540 
1.4192680147 *= 3.1679594342 * 0.2485332000 
1.4713601287 *= 0.5027653479 * 0.1036111860 
1.4713601287 *= 0.0000000000 * 0.0134448130 
1.4191003357 *= 0.1809454382 * -0.2888152000 
1.4191003357 *= 0.0000000000 * 0.0758203900 
1.4191003357 *= 0.0000000000 * 0.0406527560 
1.4191003357 *= 0.0000000000 * 0.1667621700 
1.4191003357 *= 0.0000000000 * 0.1484152500 
1.4191003357 *= 0.0000000000 * 0.0797413400 
1.4497357355 *= 0.1517379236 * 0.2018967900 
1.4497357355 *= 0.0000000000 * 0.1270619500 
1.4497357355 *= 0.0000000000 * -0.0300796310 
1.1665004386 *= 3.5997447551 * -0.0786820500 
1.2378380079 *= 0.6412750829 * 0.1112433200 
1.2378380079 *= 0.0000000000 * -0.0197791000 
1.2378380079 *= 0.0000000000 * 0.0025885487 
1.2378380079 *= 0.0000000000 * -0.1175600100 
1.1884482817 *= 0.3410432707 * -0.1448195300 
1.1884482817 *= 0.0000000000 * -0.2721460000 
1.1560277127 *= 0.2545957501 * -0.1273413600 
1.7623987393 *= 3.2269761843 * 0.1879068800 
1.7623987393 *= 0.0000000000 * 0.0599089040 
1.6747438668 *= 4.3907266253 * -0.0199636370 
0.4712076047 *= 5.0492896598 * -0.2383575400 
0.4712076047 *= 0.0000000000 * 0.0913489300 
0.9468076160 *= 5.6864466524 * 0.0836374700 
0.9468076160 *= 0.0000000000 * -0.0970111600 
0.9468076160 *= 0.0000000000 * 0.1626305400 
tempVal = 0.9468076160 + 0.0145703520(biases), 
now the tempVal = 0.9613779680 

compute layer: 6, node : 18
-0.2632318221 *= 4.4343679937 * -0.0593617450 
-0.1887474565 *= 3.0432321013 * 0.0244754140 
0.4454846750 *= 3.1679594342 * 0.2002021000 
0.3678402744 *= 0.5027653479 * -0.1544346700 
0.3678402744 *= 0.0000000000 * -0.0852148100 
0.3451677929 *= 0.1809454382 * -0.1253001000 
0.3451677929 *= 0.0000000000 * -0.0716344600 
0.3451677929 *= 0.0000000000 * 0.2847304600 
0.3451677929 *= 0.0000000000 * 0.1637511400 
0.3451677929 *= 0.0000000000 * -0.1274024200 
0.3451677929 *= 0.0000000000 * 0.0585314850 
0.3065331173 *= 0.1517379236 * -0.2546145000 
0.3065331173 *= 0.0000000000 * 0.2085092800 
0.3065331173 *= 0.0000000000 * 0.1616774400 
1.2529680010 *= 3.5997447551 * 0.2629172200 
1.2173173619 *= 0.6412750829 * -0.0555933640 
1.2173173619 *= 0.0000000000 * -0.1621263600 
1.2173173619 *= 0.0000000000 * -0.0935386940 
1.2173173619 *= 0.0000000000 * 0.0737538340 
1.1682450140 *= 0.3410432707 * -0.1438889200 
1.1682450140 *= 0.0000000000 * 0.2724093800 
1.1915662775 *= 0.2545957501 * 0.0916011500 
1.8628065603 *= 3.2269761843 * 0.2080090600 
1.8628065603 *= 0.0000000000 * 0.1616605200 
3.3282915705 *= 4.3907266253 * 0.3337682200 
3.5252417898 *= 5.0492896598 * 0.0390055300 
3.5252417898 *= 0.0000000000 * -0.0276110200 
4.1763104188 *= 5.6864466524 * 0.1144948100 
4.1763104188 *= 0.0000000000 * -0.1471196600 
4.1763104188 *= 0.0000000000 * -0.0718148000 
tempVal = 4.1763104188 + 0.0736908700(biases), 
now the tempVal = 4.2500012888 

compute layer: 6, node : 19
-0.4525189615 *= 4.4343679937 * -0.1020481300 
-1.7483184562 *= 3.0432321013 * -0.4257971300 
-1.4798313914 *= 3.1679594342 * 0.0847507900 
-1.5651723301 *= 0.5027653479 * -0.1697430800 
-1.5651723301 *= 0.0000000000 * -0.0591039000 
-1.5435607245 *= 0.1809454382 * 0.1194371400 
-1.5435607245 *= 0.0000000000 * -0.0776738450 
-1.5435607245 *= 0.0000000000 * -0.2352047100 
-1.5435607245 *= 0.0000000000 * 0.0364957450 
-1.5435607245 *= 0.0000000000 * -0.0731876400 
-1.5435607245 *= 0.0000000000 * 0.0698399200 
-1.5173783882 *= 0.1517379236 * 0.1725497200 
-1.5173783882 *= 0.0000000000 * -0.1025779550 
-1.5173783882 *= 0.0000000000 * 0.0270709120 
-3.4398956175 *= 3.5997447551 * -0.5340704300 
-3.4858318151 *= 0.6412750829 * -0.0716325940 
-3.4858318151 *= 0.0000000000 * 0.0115997730 
-3.4858318151 *= 0.0000000000 * -0.4705503300 
-3.4858318151 *= 0.0000000000 * 0.1240304860 
-3.5734780463 *= 0.3410432707 * -0.2569944600 
-3.5734780463 *= 0.0000000000 * 0.1358060000 
-3.5733996621 *= 0.2545957501 * 0.0003078771 
-3.5436664036 *= 3.2269761843 * 0.0092139690 
-3.5436664036 *= 0.0000000000 * -0.1208525800 
-4.3126027660 *= 4.3907266253 * -0.1751273600 
-5.8579168108 *= 5.0492896598 * -0.3060458300 
-5.8579168108 *= 0.0000000000 * 0.2680716000 
-6.4859341774 *= 5.6864466524 * -0.1104410900 
-6.4859341774 *= 0.0000000000 * -0.0563997300 
-6.4859341774 *= 0.0000000000 * 0.1532148600 
tempVal = -6.4859341774 + -0.2880319400(biases), 
now the tempVal = -6.7739661174 
ReLU !!! in layer: 6, node : 19, its linear result is negative,so set it to 0

compute layer: 6, node : 20
0.8605043634 *= 4.4343679937 * 0.1940534400 
1.4672492810 *= 3.0432321013 * 0.1993751700 
0.7584797526 *= 3.1679594342 * -0.2237306200 
0.7769592876 *= 0.5027653479 * 0.0367557850 
0.7769592876 *= 0.0000000000 * 0.1154660000 
0.7956095384 *= 0.1809454382 * 0.1030711300 
0.7956095384 *= 0.0000000000 * 0.1609322100 
0.7956095384 *= 0.0000000000 * -0.2283327000 
0.7956095384 *= 0.0000000000 * -0.2304769500 
0.7956095384 *= 0.0000000000 * -0.2081348900 
0.7956095384 *= 0.0000000000 * 0.2186743900 
0.7494804054 *= 0.1517379236 * -0.3040053000 
0.7494804054 *= 0.0000000000 * -0.2347749200 
0.7494804054 *= 0.0000000000 * 0.0479274700 
0.6954872471 *= 3.5997447551 * -0.0149991630 
0.8881192921 *= 0.6412750829 * 0.3003891000 
0.8881192921 *= 0.0000000000 * -0.0423166270 
0.8881192921 *= 0.0000000000 * -0.1201295850 
0.8881192921 *= 0.0000000000 * -0.0758605500 
0.9095507889 *= 0.3410432707 * 0.0628409900 
0.9095507889 *= 0.0000000000 * -0.1704572400 
0.8340964577 *= 0.2545957501 * -0.2963691700 
1.8072750920 *= 3.2269761843 * 0.3015760200 
1.8072750920 *= 0.0000000000 * 0.1400356100 
0.5502131327 *= 4.3907266253 * -0.2862993000 
2.1939061235 *= 5.0492896598 * 0.3255295500 
2.1939061235 *= 0.0000000000 * 0.2921219800 
0.5631958559 *= 5.6864466524 * -0.2867714000 
0.5631958559 *= 0.0000000000 * 0.0901831500 
0.5631958559 *= 0.0000000000 * -0.2025967200 
tempVal = 0.5631958559 + 0.0391555060(biases), 
now the tempVal = 0.6023513619 

compute layer: 6, node : 21
-0.6475755019 *= 4.4343679937 * -0.1460355800 
-0.6436051300 *= 3.0432321013 * 0.0013046563 
-0.7428316702 *= 3.1679594342 * -0.0313219100 
-0.6395712394 *= 0.5027653479 * 0.2053849400 
-0.6395712394 *= 0.0000000000 * -0.2347669300 
-0.6683675822 *= 0.1809454382 * -0.1591437900 
-0.6683675822 *= 0.0000000000 * -0.2662300000 
-0.6683675822 *= 0.0000000000 * -0.2257150900 
-0.6683675822 *= 0.0000000000 * 0.2117074300 
-0.6683675822 *= 0.0000000000 * -0.2903015300 
-0.6683675822 *= 0.0000000000 * -0.0112929760 
-0.6608270628 *= 0.1517379236 * 0.0496943630 
-0.6608270628 *= 0.0000000000 * -0.1900504100 
-0.6608270628 *= 0.0000000000 * 0.1271887400 
-0.5652111826 *= 3.5997447551 * 0.0265618500 
-0.6577006333 *= 0.6412750829 * -0.1442274200 
-0.6577006333 *= 0.0000000000 * 0.1037909800 
-0.6577006333 *= 0.0000000000 * -0.2532937000 
-0.6577006333 *= 0.0000000000 * -0.1914379600 
-0.6645000941 *= 0.3410432707 * -0.0199372380 
-0.6645000941 *= 0.0000000000 * -0.2844372700 
-0.6238767250 *= 0.2545957501 * 0.1595602800 
0.5773732271 *= 3.2269761843 * 0.3722525000 
0.5773732271 *= 0.0000000000 * -0.0793927700 
1.0440947606 *= 4.3907266253 * 0.1062971060 
1.0075254620 *= 5.0492896598 * -0.0072424640 
1.0075254620 *= 0.0000000000 * 0.0137074120 
2.4390488859 *= 5.6864466524 * 0.2517430500 
2.4390488859 *= 0.0000000000 * -0.1235070400 
2.4390488859 *= 0.0000000000 * -0.0191012900 
tempVal = 2.4390488859 + 0.0212820540(biases), 
now the tempVal = 2.4603309399 

compute layer: 6, node : 22
1.2492698841 *= 4.4343679937 * 0.2817244500 
1.6611595717 *= 3.0432321013 * 0.1353461300 
2.2443488438 *= 3.1679594342 * 0.1840898800 
2.1473478516 *= 0.5027653479 * -0.1929349200 
2.1473478516 *= 0.0000000000 * 0.1168397700 
2.1413678988 *= 0.1809454382 * -0.0330483760 
2.1413678988 *= 0.0000000000 * 0.0190326740 
2.1413678988 *= 0.0000000000 * -0.0270267050 
2.1413678988 *= 0.0000000000 * -0.1747990000 
2.1413678988 *= 0.0000000000 * 0.1846077000 
2.1413678988 *= 0.0000000000 * -0.1735338400 
2.1691293382 *= 0.1517379236 * 0.1829565000 
2.1691293382 *= 0.0000000000 * 0.1205506500 
2.1691293382 *= 0.0000000000 * 0.1121677000 
2.4187603698 *= 3.5997447551 * 0.0693468700 
2.4498815521 *= 0.6412750829 * 0.0485301600 
2.4498815521 *= 0.0000000000 * 0.0493578950 
2.4498815521 *= 0.0000000000 * 0.1692799500 
2.4498815521 *= 0.0000000000 * -0.1866462800 
2.5266302026 *= 0.3410432707 * 0.2250408000 
2.5266302026 *= 0.0000000000 * -0.1927960800 
2.5843698353 *= 0.2545957501 * 0.2267894600 
3.5168470062 *= 3.2269761843 * 0.2889631400 
3.5168470062 *= 0.0000000000 * -0.1469611100 
3.7599362928 *= 4.3907266253 * 0.0553642500 
2.2151810023 *= 5.0492896598 * -0.3059351700 
2.2151810023 *= 0.0000000000 * -0.2591273200 
0.7148228574 *= 5.6864466524 * -0.2638481000 
0.7148228574 *= 0.0000000000 * 0.2297146200 
0.7148228574 *= 0.0000000000 * 0.0681226400 
tempVal = 0.7148228574 + -0.0385226940(biases), 
now the tempVal = 0.6763001634 

compute layer: 6, node : 23
-0.0257162241 *= 4.4343679937 * -0.0057992986 
0.3035923172 *= 3.0432321013 * 0.1082101300 
1.3474371050 *= 3.1679594342 * 0.3295006800 
1.3954410952 *= 0.5027653479 * 0.0954799100 
1.3954410952 *= 0.0000000000 * 0.0136966690 
1.4431110514 *= 0.1809454382 * 0.2634493400 
1.4431110514 *= 0.0000000000 * 0.2142422000 
1.4431110514 *= 0.0000000000 * 0.1974681600 
1.4431110514 *= 0.0000000000 * -0.1634978200 
1.4431110514 *= 0.0000000000 * -0.3063008800 
1.4431110514 *= 0.0000000000 * -0.2445496200 
1.4008425182 *= 0.1517379236 * -0.2785627500 
1.4008425182 *= 0.0000000000 * 0.1206106250 
1.4008425182 *= 0.0000000000 * -0.2187274400 
0.5914161876 *= 3.5997447551 * -0.2248565900 
0.5185293106 *= 0.6412750829 * -0.1136593000 
0.5185293106 *= 0.0000000000 * -0.0777860600 
0.5185293106 *= 0.0000000000 * 0.2610030800 
0.5185293106 *= 0.0000000000 * -0.2033504000 
0.4867086741 *= 0.3410432707 * -0.0933038100 
0.4867086741 *= 0.0000000000 * 0.1674045200 
0.4271827594 *= 0.2545957501 * -0.2338056100 
0.8647900955 *= 3.2269761843 * 0.1356091000 
0.8647900955 *= 0.0000000000 * -0.2564898700 
0.5451385452 *= 4.3907266253 * -0.0728015150 
-0.2272789641 *= 5.0492896598 * -0.1529754800 
-0.2272789641 *= 0.0000000000 * -0.0940546900 
-0.5122026954 *= 5.6864466524 * -0.0501057600 
-0.5122026954 *= 0.0000000000 * 0.1434263100 
-0.5122026954 *= 0.0000000000 * -0.0741857300 
tempVal = -0.5122026954 + 0.0270898800(biases), 
now the tempVal = -0.4851128154 
ReLU !!! in layer: 6, node : 23, its linear result is negative,so set it to 0

compute layer: 6, node : 24
-1.2385423941 *= 4.4343679937 * -0.2793052800 
-0.6984322084 *= 3.0432321013 * 0.1774791300 
0.0754045774 *= 3.1679594342 * 0.2442697900 
-0.0313319580 *= 0.5027653479 * -0.2122989100 
-0.0313319580 *= 0.0000000000 * 0.2369292500 
0.0063135776 *= 0.1809454382 * 0.2080491000 
0.0063135776 *= 0.0000000000 * 0.0748896100 
0.0063135776 *= 0.0000000000 * 0.1116633700 
0.0063135776 *= 0.0000000000 * 0.1561193600 
0.0063135776 *= 0.0000000000 * 0.3074477600 
0.0063135776 *= 0.0000000000 * 0.0615513030 
0.0503293655 *= 0.1517379236 * 0.2900777000 
0.0503293655 *= 0.0000000000 * -0.2526309200 
0.0503293655 *= 0.0000000000 * -0.2820507300 
-0.4826156173 *= 3.5997447551 * -0.1480507700 
-0.5929366195 *= 0.6412750829 * -0.1720338200 
-0.5929366195 *= 0.0000000000 * -0.1242061500 
-0.5929366195 *= 0.0000000000 * -0.0189970900 
-0.5929366195 *= 0.0000000000 * -0.0094906870 
-0.5648609382 *= 0.3410432707 * 0.0823229300 
-0.5648609382 *= 0.0000000000 * 0.2513348000 
-0.5876165969 *= 0.2545957501 * -0.0893795700 
-0.7411811522 *= 3.2269761843 * -0.0475877560 
-0.7411811522 *= 0.0000000000 * 0.0596907900 
0.3680208927 *= 4.3907266253 * 0.2526238000 
-0.3917517816 *= 5.0492896598 * -0.1504712000 
-0.3917517816 *= 0.0000000000 * 0.2452804900 
-0.5818683447 *= 5.6864466524 * -0.0334332800 
-0.5818683447 *= 0.0000000000 * 0.0440641050 
-0.5818683447 *= 0.0000000000 * -0.0100582540 
tempVal = -0.5818683447 + -0.1008950100(biases), 
now the tempVal = -0.6827633547 
ReLU !!! in layer: 6, node : 24, its linear result is negative,so set it to 0

compute layer: 6, node : 25
-0.9702903575 *= 4.4343679937 * -0.2188114200 
-0.2845153803 *= 3.0432321013 * 0.2253442900 
0.3258246980 *= 3.1679594342 * 0.1926603200 
0.2390216775 *= 0.5027653479 * -0.1726511600 
0.2390216775 *= 0.0000000000 * 0.3099562500 
0.2415540847 *= 0.1809454382 * 0.0139954190 
0.2415540847 *= 0.0000000000 * -0.1824551700 
0.2415540847 *= 0.0000000000 * -0.2467668700 
0.2415540847 *= 0.0000000000 * -0.0366244000 
0.2415540847 *= 0.0000000000 * 0.0622190350 
0.2415540847 *= 0.0000000000 * 0.1134683040 
0.1943205576 *= 0.1517379236 * -0.3112836000 
0.1943205576 *= 0.0000000000 * -0.0985826250 
0.1943205576 *= 0.0000000000 * -0.0272219270 
0.7935904775 *= 3.5997447551 * 0.1664756700 
0.8347077757 *= 0.6412750829 * 0.0641180350 
0.8347077757 *= 0.0000000000 * 0.0150876990 
0.8347077757 *= 0.0000000000 * -0.1898482900 
0.8347077757 *= 0.0000000000 * 0.1021166000 
0.7723527337 *= 0.3410432707 * -0.1828361600 
0.7723527337 *= 0.0000000000 * 0.3014044000 
0.7483296440 *= 0.2545957501 * -0.0943577800 
0.7264522408 *= 3.2269761843 * -0.0067795366 
0.7264522408 *= 0.0000000000 * 0.2159402800 
0.4559791470 *= 4.3907266253 * -0.0616009870 
-1.0849998302 *= 5.0492896598 * -0.3051872800 
-1.0849998302 *= 0.0000000000 * -0.2325893600 
-2.7058586132 *= 5.6864466524 * -0.2850389500 
-2.7058586132 *= 0.0000000000 * -0.2331842600 
-2.7058586132 *= 0.0000000000 * -0.2749114300 
tempVal = -2.7058586132 + 0.0000000000(biases), 
now the tempVal = -2.7058586132 
ReLU !!! in layer: 6, node : 25, its linear result is negative,so set it to 0

compute layer: 6, node : 26
-0.7328159388 *= 4.4343679937 * -0.1652582600 
-0.4353199156 *= 3.0432321013 * 0.0977566000 
-0.4493329460 *= 3.1679594342 * -0.0044233617 
-0.4182784286 *= 0.5027653479 * 0.0617674180 
-0.4182784286 *= 0.0000000000 * 0.2050960800 
-0.4546474665 *= 0.1809454382 * -0.2009945000 
-0.4546474665 *= 0.0000000000 * -0.1795687200 
-0.4546474665 *= 0.0000000000 * -0.2972350000 
-0.4546474665 *= 0.0000000000 * 0.3053697300 
-0.4546474665 *= 0.0000000000 * 0.0790715700 
-0.4546474665 *= 0.0000000000 * -0.1476392400 
-0.4078859536 *= 0.1517379236 * 0.3081728800 
-0.4078859536 *= 0.0000000000 * 0.0149305760 
-0.4078859536 *= 0.0000000000 * 0.0803086000 
0.4657826458 *= 3.5997447551 * 0.2427029300 
0.5483077462 *= 0.6412750829 * 0.1286890800 
0.5483077462 *= 0.0000000000 * -0.2874443000 
0.5483077462 *= 0.0000000000 * 0.2426931400 
0.5483077462 *= 0.0000000000 * -0.0132942125 
0.5456462710 *= 0.3410432707 * -0.0078039225 
0.5456462710 *= 0.0000000000 * -0.0290569180 
0.5487761438 *= 0.2545957501 * 0.0122935000 
-0.4495088815 *= 3.2269761843 * -0.3093561800 
-0.4495088815 *= 0.0000000000 * 0.0485867520 
-1.1752117785 *= 4.3907266253 * -0.1652808200 
-1.3587211271 *= 5.0492896598 * -0.0363435970 
-1.3587211271 *= 0.0000000000 * -0.2546624200 
-2.3308131547 *= 5.6864466524 * -0.1709489400 
-2.3308131547 *= 0.0000000000 * 0.3034158000 
-2.3308131547 *= 0.0000000000 * -0.1210308150 
tempVal = -2.3308131547 + 0.0000000000(biases), 
now the tempVal = -2.3308131547 
ReLU !!! in layer: 6, node : 26, its linear result is negative,so set it to 0

compute layer: 6, node : 27
-0.9660372665 *= 4.4343679937 * -0.2178523000 
-1.3387591266 *= 3.0432321013 * -0.1224756600 
-1.2577779006 *= 3.1679594342 * 0.0255625830 
-1.1408812167 *= 0.5027653479 * 0.2325074400 
-1.1408812167 *= 0.0000000000 * 0.0386926460 
-1.1262565314 *= 0.1809454382 * 0.0808237300 
-1.1262565314 *= 0.0000000000 * 0.2139805900 
-1.1262565314 *= 0.0000000000 * -0.0764697900 
-1.1262565314 *= 0.0000000000 * -0.2407467800 
-1.1262565314 *= 0.0000000000 * -0.3064512000 
-1.1262565314 *= 0.0000000000 * -0.2599132400 
-1.1551400667 *= 0.1517379236 * -0.1903514600 
-1.1551400667 *= 0.0000000000 * -0.1362247300 
-1.1551400667 *= 0.0000000000 * -0.1882580400 
-1.3278593982 *= 3.5997447551 * -0.0479809940 
-1.4515121310 *= 0.6412750829 * -0.1928232300 
-1.4515121310 *= 0.0000000000 * -0.0136159210 
-1.4515121310 *= 0.0000000000 * -0.1478186800 
-1.4515121310 *= 0.0000000000 * 0.2158713300 
-1.4236696960 *= 0.3410432707 * 0.0816390100 
-1.4236696960 *= 0.0000000000 * -0.2813975800 
-1.4692514753 *= 0.2545957501 * -0.1790359000 
-1.4762215964 *= 3.2269761843 * -0.0021599543 
-1.4762215964 *= 0.0000000000 * -0.0064086140 
-1.1167359911 *= 4.3907266253 * 0.0818738300 
0.0160760320 *= 5.0492896598 * 0.2243507700 
0.0160760320 *= 0.0000000000 * 0.0501707160 
0.2351442285 *= 5.6864466524 * 0.0385246200 
0.2351442285 *= 0.0000000000 * -0.0855683000 
0.2351442285 *= 0.0000000000 * 0.2523330200 
tempVal = 0.2351442285 + 0.0108597650(biases), 
now the tempVal = 0.2460039935 

compute layer: 6, node : 28
-0.3522310954 *= 4.4343679937 * -0.0794320850 
0.3251766673 *= 3.0432321013 * 0.2225948400 
0.3478172750 *= 3.1679594342 * 0.0071467480 
0.3307309817 *= 0.5027653479 * -0.0339846280 
0.3307309817 *= 0.0000000000 * 0.1835260700 
0.3462205934 *= 0.1809454382 * 0.0856037700 
0.3462205934 *= 0.0000000000 * -0.0727600300 
0.3462205934 *= 0.0000000000 * 0.3010426500 
0.3462205934 *= 0.0000000000 * 0.2646557000 
0.3462205934 *= 0.0000000000 * 0.0339032200 
0.3462205934 *= 0.0000000000 * -0.2661427000 
0.3625051665 *= 0.1517379236 * 0.1073203900 
0.3625051665 *= 0.0000000000 * -0.2724279500 
0.3625051665 *= 0.0000000000 * 0.2039688200 
0.4150050500 *= 3.5997447551 * 0.0145843350 
0.5666637855 *= 0.6412750829 * 0.2364956000 
0.5666637855 *= 0.0000000000 * 0.2761601200 
0.5666637855 *= 0.0000000000 * -0.1181358100 
0.5666637855 *= 0.0000000000 * -0.2253043700 
0.4996313418 *= 0.3410432707 * -0.1965511400 
0.4996313418 *= 0.0000000000 * 0.0857461000 
0.5820406000 *= 0.2545957501 * 0.3236867000 
1.2969566501 *= 3.2269761843 * 0.2215436400 
1.2969566501 *= 0.0000000000 * -0.1045670700 
1.2091742840 *= 4.3907266253 * -0.0199926740 
-0.7064387087 *= 5.0492896598 * -0.3793826700 
-0.7064387087 *= 0.0000000000 * -0.1880635900 
2.1251888154 *= 5.6864466524 * 0.4979608000 
2.1251888154 *= 0.0000000000 * 0.0491690900 
2.1251888154 *= 0.0000000000 * -0.3129717700 
tempVal = 2.1251888154 + 0.1849349400(biases), 
now the tempVal = 2.3101237554 

compute layer: 6, node : 29
1.0118641982 *= 4.4343679937 * 0.2281867900 
1.4750372767 *= 3.0432321013 * 0.1521977500 
0.5363809388 *= 3.1679594342 * -0.2962968300 
0.4193793780 *= 0.5027653479 * -0.2327160400 
0.4193793780 *= 0.0000000000 * 0.2846446000 
0.4179516339 *= 0.1809454382 * -0.0078904670 
0.4179516339 *= 0.0000000000 * -0.3135775000 
0.4179516339 *= 0.0000000000 * -0.0987352900 
0.4179516339 *= 0.0000000000 * 0.1455751700 
0.4179516339 *= 0.0000000000 * -0.0174116570 
0.4179516339 *= 0.0000000000 * -0.0679102300 
0.4357519955 *= 0.1517379236 * 0.1173099060 
0.4357519955 *= 0.0000000000 * 0.2878592300 
0.4357519955 *= 0.0000000000 * -0.2340267000 
-0.0190900093 *= 3.5997447551 * -0.1263539600 
-0.0966546225 *= 0.6412750829 * -0.1209537300 
-0.0966546225 *= 0.0000000000 * 0.0721872400 
-0.0966546225 *= 0.0000000000 * -0.2843596600 
-0.0966546225 *= 0.0000000000 * -0.1538596200 
0.0019702826 *= 0.3410432707 * 0.2891859000 
0.0019702826 *= 0.0000000000 * 0.0274615700 
0.0461919859 *= 0.2545957501 * 0.1736938000 
0.8685677305 *= 3.2269761843 * 0.2548440700 
0.8685677305 *= 0.0000000000 * -0.0433723480 
0.5094669461 *= 4.3907266253 * -0.0817861860 
-0.9659886110 *= 5.0492896598 * -0.2922105200 
-0.9659886110 *= 0.0000000000 * 0.1872324300 
-2.0065332873 *= 5.6864466524 * -0.1829868000 
-2.0065332873 *= 0.0000000000 * -0.1954251200 
-2.0065332873 *= 0.0000000000 * -0.0831575400 
tempVal = -2.0065332873 + -0.0083492560(biases), 
now the tempVal = -2.0148825433 
ReLU !!! in layer: 6, node : 29, its linear result is negative,so set it to 0

now we get all result in layer: 6
	node: 0, val: 0.0000000000
	node: 1, val: 2.1138708105
	node: 2, val: 3.3999542960
	node: 3, val: 0.0000000000
	node: 4, val: 0.0000000000
	node: 5, val: 0.0000000000
	node: 6, val: 0.0000000000
	node: 7, val: 3.2660223917
	node: 8, val: 0.0000000000
	node: 9, val: 6.5130531926
	node: 10, val: 4.2732101073
	node: 11, val: 0.0000000000
	node: 12, val: 0.0000000000
	node: 13, val: 2.3610960288
	node: 14, val: 0.0000000000
	node: 15, val: 2.4710257559
	node: 16, val: 0.0000000000
	node: 17, val: 0.9613779680
	node: 18, val: 4.2500012888
	node: 19, val: 0.0000000000
	node: 20, val: 0.6023513619
	node: 21, val: 2.4603309399
	node: 22, val: 0.6763001634
	node: 23, val: 0.0000000000
	node: 24, val: 0.0000000000
	node: 25, val: 0.0000000000
	node: 26, val: 0.0000000000
	node: 27, val: 0.2460039935
	node: 28, val: 2.3101237554
	node: 29, val: 0.0000000000

when compute layer[6] to layer[7]

compute layer: 7, node : 0
0.0000000000 *= 0.0000000000 * -0.0091413750 
0.2919685128 *= 2.1138708105 * 0.1381203200 
0.0172804593 *= 3.3999542960 * -0.0807916900 
0.0172804593 *= 0.0000000000 * 0.1659230900 
0.0172804593 *= 0.0000000000 * -0.2621302600 
0.0172804593 *= 0.0000000000 * 0.2090300200 
0.0172804593 *= 0.0000000000 * -0.2963322400 
0.9054435683 *= 3.2660223917 * 0.2719403000 
0.9054435683 *= 0.0000000000 * -0.1064163500 
2.6393388197 *= 6.5130531926 * 0.2662185000 
1.8090206366 *= 4.2732101073 * -0.1943078300 
1.8090206366 *= 0.0000000000 * 0.0701490340 
1.8090206366 *= 0.0000000000 * 0.1313406400 
1.6601559875 *= 2.3610960288 * -0.0630489600 
1.6601559875 *= 0.0000000000 * -0.1666183800 
1.0971793232 *= 2.4710257559 * -0.2278311600 
1.0971793232 *= 0.0000000000 * -0.1064365500 
0.9071016126 *= 0.9613779680 * -0.1977138200 
1.2125123153 *= 4.2500012888 * 0.0718613200 
1.2125123153 *= 0.0000000000 * -0.0507646950 
1.3564719898 *= 0.6023513619 * 0.2389961800 
1.6067623666 *= 2.4603309399 * 0.1017303700 
1.5149348715 *= 0.6763001634 * -0.1357792000 
1.5149348715 *= 0.0000000000 * 0.1138603100 
1.5149348715 *= 0.0000000000 * -0.2990846300 
1.5149348715 *= 0.0000000000 * -0.1390439700 
1.5149348715 *= 0.0000000000 * 0.1043313900 
1.5684626713 *= 0.2460039935 * 0.2175891500 
1.5323680619 *= 2.3101237554 * -0.0156245350 
1.5323680619 *= 0.0000000000 * 0.2327315500 
tempVal = 1.5323680619 + 0.0092586240(biases), 
now the tempVal = 1.5416266859 

compute layer: 7, node : 1
0.0000000000 *= 0.0000000000 * -0.1973827500 
-0.6708719920 *= 2.1138708105 * -0.3173666000 
-0.5373348295 *= 3.3999542960 * 0.0392761640 
-0.5373348295 *= 0.0000000000 * 0.1012201100 
-0.5373348295 *= 0.0000000000 * -0.0107651600 
-0.5373348295 *= 0.0000000000 * 0.1550976200 
-0.5373348295 *= 0.0000000000 * -0.2461768700 
-0.9029486610 *= 3.2660223917 * -0.1119446800 
-0.9029486610 *= 0.0000000000 * 0.2644546000 
-0.3277714505 *= 6.5130531926 * 0.0883114560 
0.1234198401 *= 4.2732101073 * 0.1055860300 
0.1234198401 *= 0.0000000000 * -0.2385585600 
0.1234198401 *= 0.0000000000 * -0.1541875600 
0.7840118675 *= 2.3610960288 * 0.2797819400 
0.7840118675 *= 0.0000000000 * 0.0200217590 
0.5298296055 *= 2.4710257559 * -0.1028650800 
0.5298296055 *= 0.0000000000 * -0.1897725800 
0.7465983025 *= 0.9613779680 * 0.2254770800 
-0.4400159549 *= 4.2500012888 * -0.2792032700 
-0.4400159549 *= 0.0000000000 * 0.1541065000 
-0.4491996700 *= 0.6023513619 * -0.0152464420 
-0.6747149325 *= 2.4603309399 * -0.0916605400 
-0.6327885459 *= 0.6763001634 * 0.0619937550 
-0.6327885459 *= 0.0000000000 * 0.2273843700 
-0.6327885459 *= 0.0000000000 * 0.1906813000 
-0.6327885459 *= 0.0000000000 * -0.2651001200 
-0.6327885459 *= 0.0000000000 * 0.3155219300 
-0.6591527471 *= 0.2460039935 * -0.1071698100 
-1.1659534719 *= 2.3101237554 * -0.2193825000 
-1.1659534719 *= 0.0000000000 * 0.2416321800 
tempVal = -1.1659534719 + -0.0217286050(biases), 
now the tempVal = -1.1876820769 
ReLU !!! in layer: 7, node : 1, its linear result is negative,so set it to 0

compute layer: 7, node : 2
0.0000000000 *= 0.0000000000 * 0.2118848000 
0.2228984732 *= 2.1138708105 * 0.1054456460 
0.9526092440 *= 3.3999542960 * 0.2146237000 
0.9526092440 *= 0.0000000000 * -0.1341152500 
0.9526092440 *= 0.0000000000 * -0.2155683600 
0.9526092440 *= 0.0000000000 * -0.2648172400 
0.9526092440 *= 0.0000000000 * -0.2339339300 
0.9160521263 *= 3.2660223917 * -0.0111931620 
0.9160521263 *= 0.0000000000 * -0.3117004600 
-1.2942005410 *= 6.5130531926 * -0.3393573800 
-0.9286831219 *= 4.2732101073 * 0.0855369640 
-0.9286831219 *= 0.0000000000 * -0.2627296700 
-0.9286831219 *= 0.0000000000 * -0.0515036770 
-0.8288406158 *= 2.3610960288 * 0.0422865080 
-0.8288406158 *= 0.0000000000 * -0.0253491830 
-0.9744750332 *= 2.4710257559 * -0.0589368270 
-0.9744750332 *= 0.0000000000 * 0.2610261700 
-0.8001612488 *= 0.9613779680 * 0.1813166000 
-0.6342421759 *= 4.2500012888 * 0.0390397700 
-0.6342421759 *= 0.0000000000 * -0.1973071800 
-0.4634026201 *= 0.6023513619 * 0.2836211000 
-1.0072176622 *= 2.4603309399 * -0.2210332900 
-1.1077976244 *= 0.6763001634 * -0.1487208900 
-1.1077976244 *= 0.0000000000 * 0.1274640400 
-1.1077976244 *= 0.0000000000 * 0.1888081000 
-1.1077976244 *= 0.0000000000 * 0.2939091600 
-1.1077976244 *= 0.0000000000 * -0.0615143400 
-1.0329287617 *= 0.2460039935 * 0.3043400300 
-0.6253186522 *= 2.3101237554 * 0.1764451400 
-0.6253186522 *= 0.0000000000 * -0.2010019100 
tempVal = -0.6253186522 + 0.0009658165(biases), 
now the tempVal = -0.6243528357 
ReLU !!! in layer: 7, node : 2, its linear result is negative,so set it to 0

compute layer: 7, node : 3
0.0000000000 *= 0.0000000000 * -0.0439490900 
-0.0251893221 *= 2.1138708105 * -0.0119162070 
0.7400609329 *= 3.3999542960 * 0.2250766300 
0.7400609329 *= 0.0000000000 * -0.0829502600 
0.7400609329 *= 0.0000000000 * 0.3126613800 
0.7400609329 *= 0.0000000000 * -0.0130078630 
0.7400609329 *= 0.0000000000 * -0.2298455000 
0.3089858227 *= 3.2660223917 * -0.1319878000 
0.3089858227 *= 0.0000000000 * 0.2873780700 
-0.8896852795 *= 6.5130531926 * -0.1840413500 
-0.3891742217 *= 4.2732101073 * 0.1171276500 
-0.3891742217 *= 0.0000000000 * -0.0129095670 
-0.3891742217 *= 0.0000000000 * -0.0173839160 
-0.2403755888 *= 2.3610960288 * 0.0630210000 
-0.2403755888 *= 0.0000000000 * 0.2392412000 
-0.7298422022 *= 2.4710257559 * -0.1980823600 
-0.7298422022 *= 0.0000000000 * 0.2276389900 
-0.4532415513 *= 0.9613779680 * 0.2877127000 
-0.8656550039 *= 4.2500012888 * -0.0970384300 
-0.8656550039 *= 0.0000000000 * 0.2806580700 
-0.8160179688 *= 0.6023513619 * 0.0824054500 
-1.5802269224 *= 2.4603309399 * -0.3106122600 
-1.6987431697 *= 0.6763001634 * -0.1752420800 
-1.6987431697 *= 0.0000000000 * 0.2276950300 
-1.6987431697 *= 0.0000000000 * -0.2722847000 
-1.6987431697 *= 0.0000000000 * -0.2827607700 
-1.6987431697 *= 0.0000000000 * -0.0827538740 
-1.6268490586 *= 0.2460039935 * 0.2922477400 
-1.2652648153 *= 2.3101237554 * 0.1565215900 
-1.2652648153 *= 0.0000000000 * -0.1849534000 
tempVal = -1.2652648153 + 0.0229314830(biases), 
now the tempVal = -1.2423333323 
ReLU !!! in layer: 7, node : 3, its linear result is negative,so set it to 0

compute layer: 7, node : 4
0.0000000000 *= 0.0000000000 * -0.1835615600 
-0.5306328982 *= 2.1138708105 * -0.2510242800 
-0.9792706034 *= 3.3999542960 * -0.1319540400 
-0.9792706034 *= 0.0000000000 * 0.1113369000 
-0.9792706034 *= 0.0000000000 * -0.1933734900 
-0.9792706034 *= 0.0000000000 * 0.1229325900 
-0.9792706034 *= 0.0000000000 * -0.2265243500 
-0.2750476546 *= 3.2660223917 * 0.2156209800 
-0.2750476546 *= 0.0000000000 * -0.2048653400 
-2.1884597813 *= 6.5130531926 * -0.2937811300 
-1.9368336971 *= 4.2732101073 * 0.0588845570 
-1.9368336971 *= 0.0000000000 * -0.2285035300 
-1.9368336971 *= 0.0000000000 * 0.0080652590 
-1.5820266025 *= 2.3610960288 * 0.1502722000 
-1.5820266025 *= 0.0000000000 * 0.2565857200 
-1.3657731896 *= 2.4710257559 * 0.0875156450 
-1.3657731896 *= 0.0000000000 * 0.1467461100 
-1.1291170050 *= 0.9613779680 * 0.2461635200 
-1.2416995264 *= 4.2500012888 * -0.0264899970 
-1.2416995264 *= 0.0000000000 * 0.0862590100 
-1.3768716113 *= 0.6023513619 * -0.2244073700 
-1.7650307165 *= 2.4603309399 * -0.1577670300 
-1.9077594430 *= 0.6763001634 * -0.2110434600 
-1.9077594430 *= 0.0000000000 * -0.3004229400 
-1.9077594430 *= 0.0000000000 * -0.1211518650 
-1.9077594430 *= 0.0000000000 * -0.0007953750 
-1.9077594430 *= 0.0000000000 * -0.2587403700 
-1.8400813262 *= 0.2460039935 * 0.2751098300 
-2.3875660793 *= 2.3101237554 * -0.2369936900 
-2.3875660793 *= 0.0000000000 * -0.1934910300 
tempVal = -2.3875660793 + 0.0000000000(biases), 
now the tempVal = -2.3875660793 
ReLU !!! in layer: 7, node : 4, its linear result is negative,so set it to 0

compute layer: 7, node : 5
0.0000000000 *= 0.0000000000 * -0.0570151950 
-0.7174813636 *= 2.1138708105 * -0.3394159000 
-0.2052551633 *= 3.3999542960 * 0.1506567900 
-0.2052551633 *= 0.0000000000 * -0.1450350900 
-0.2052551633 *= 0.0000000000 * -0.0103527310 
-0.2052551633 *= 0.0000000000 * 0.1264787300 
-0.2052551633 *= 0.0000000000 * -0.0708938500 
-0.2921857120 *= 3.2660223917 * -0.0266166420 
-0.2921857120 *= 0.0000000000 * -0.1215533540 
0.6027701917 *= 6.5130531926 * 0.1374095800 
2.0504356631 *= 4.2732101073 * 0.3387770400 
2.0504356631 *= 0.0000000000 * -0.1145639200 
2.0504356631 *= 0.0000000000 * -0.0145403350 
2.2537369489 *= 2.3610960288 * 0.0861046240 
2.2537369489 *= 0.0000000000 * -0.0661859200 
1.9879322419 *= 2.4710257559 * -0.1075685700 
1.9879322419 *= 0.0000000000 * 0.2321265000 
1.7896925094 *= 0.9613779680 * -0.2062037400 
1.3899209831 *= 4.2500012888 * -0.0940638600 
1.3899209831 *= 0.0000000000 * -0.2836901500 
1.5338271207 *= 0.6023513619 * 0.2389073000 
1.2235913710 *= 2.4603309399 * -0.1260951300 
1.1555330199 *= 0.6763001634 * -0.1006333500 
1.1555330199 *= 0.0000000000 * -0.2509294700 
1.1555330199 *= 0.0000000000 * -0.0981378300 
1.1555330199 *= 0.0000000000 * 0.2268931100 
1.1555330199 *= 0.0000000000 * 0.2166152400 
1.1803434747 *= 0.2460039935 * 0.1008538700 
1.2510895131 *= 2.3101237554 * 0.0306243500 
1.2510895131 *= 0.0000000000 * 0.2349227200 
tempVal = 1.2510895131 + 0.0289720540(biases), 
now the tempVal = 1.2800615671 

compute layer: 7, node : 6
0.0000000000 *= 0.0000000000 * 0.1653002600 
-0.5901780812 *= 2.1138708105 * -0.2791930700 
-0.6290676492 *= 3.3999542960 * -0.0114382620 
-0.6290676492 *= 0.0000000000 * 0.0688441200 
-0.6290676492 *= 0.0000000000 * -0.1590217600 
-0.6290676492 *= 0.0000000000 * 0.0754286100 
-0.6290676492 *= 0.0000000000 * -0.1654371500 
-0.1078167462 *= 3.2660223917 * 0.1595980800 
-0.1078167462 *= 0.0000000000 * 0.1971346100 
-0.3384774369 *= 6.5130531926 * -0.0354151400 
1.1153090235 *= 4.2732101073 * 0.3402094500 
1.1153090235 *= 0.0000000000 * 0.1312361200 
1.1153090235 *= 0.0000000000 * -0.2646781500 
0.5950145262 *= 2.3610960288 * -0.2203614300 
0.5950145262 *= 0.0000000000 * -0.2891712500 
0.4062689551 *= 2.4710257559 * -0.0763834900 
0.4062689551 *= 0.0000000000 * 0.1601254500 
0.5223110060 *= 0.9613779680 * 0.1207038800 
-0.6352174326 *= 4.2500012888 * -0.2723595500 
-0.6352174326 *= 0.0000000000 * -0.0820460900 
-0.4727927855 *= 0.6023513619 * 0.2696510000 
0.1437590623 *= 2.4603309399 * 0.2505971200 
0.3571217817 *= 0.6763001634 * 0.3154852400 
0.3571217817 *= 0.0000000000 * -0.0583074350 
0.3571217817 *= 0.0000000000 * 0.2709211700 
0.3571217817 *= 0.0000000000 * 0.0107139460 
0.3571217817 *= 0.0000000000 * 0.2756665600 
0.4053675732 *= 0.2460039935 * 0.1961179200 
0.2335560692 *= 2.3101237554 * -0.0743732900 
0.2335560692 *= 0.0000000000 * 0.0657730200 
tempVal = 0.2335560692 + 0.0674027300(biases), 
now the tempVal = 0.3009587992 

compute layer: 7, node : 7
0.0000000000 *= 0.0000000000 * -0.1022212360 
0.3229073796 *= 2.1138708105 * 0.1527564400 
-0.6568694517 *= 3.3999542960 * -0.2881735300 
-0.6568694517 *= 0.0000000000 * 0.2072160500 
-0.6568694517 *= 0.0000000000 * -0.1179553640 
-0.6568694517 *= 0.0000000000 * 0.1812644000 
-0.6568694517 *= 0.0000000000 * 0.2096508000 
-0.9839129631 *= 3.2660223917 * -0.1001351100 
-0.9839129631 *= 0.0000000000 * -0.2351980000 
-2.5054077803 *= 6.5130531926 * -0.2336070000 
-2.7716519180 *= 4.2732101073 * -0.0623054170 
-2.7716519180 *= 0.0000000000 * -0.1484310200 
-2.7716519180 *= 0.0000000000 * -0.3086334200 
-2.1208234004 *= 2.3610960288 * 0.2756467800 
-2.1208234004 *= 0.0000000000 * -0.1352197800 
-1.2697146063 *= 2.4710257559 * 0.3444354200 
-1.2697146063 *= 0.0000000000 * 0.1647452600 
-1.4870984795 *= 0.9613779680 * -0.2261169700 
-1.6350950078 *= 4.2500012888 * -0.0348227020 
-1.6350950078 *= 0.0000000000 * -0.1293896400 
-1.7624978625 *= 0.6023513619 * -0.2115092000 
-2.4487700272 *= 2.4603309399 * -0.2789349000 
-2.2610491880 *= 0.6763001634 * 0.2775703000 
-2.2610491880 *= 0.0000000000 * -0.2407029400 
-2.2610491880 *= 0.0000000000 * 0.0429636760 
-2.2610491880 *= 0.0000000000 * -0.2404993200 
-2.2610491880 *= 0.0000000000 * -0.0127572150 
-2.2441981408 *= 0.2460039935 * 0.0684990800 
-2.2680921966 *= 2.3101237554 * -0.0103431930 
-2.2680921966 *= 0.0000000000 * -0.2580951500 
tempVal = -2.2680921966 + 0.2267066100(biases), 
now the tempVal = -2.0413855866 
ReLU !!! in layer: 7, node : 7, its linear result is negative,so set it to 0

compute layer: 7, node : 8
0.0000000000 *= 0.0000000000 * 0.1538773800 
-0.5256951074 *= 2.1138708105 * -0.2486883800 
0.2485837603 *= 3.3999542960 * 0.2277321400 
0.2485837603 *= 0.0000000000 * 0.3248328600 
0.2485837603 *= 0.0000000000 * -0.2889716300 
0.2485837603 *= 0.0000000000 * 0.1470501400 
0.2485837603 *= 0.0000000000 * -0.2801393600 
1.2777047378 *= 3.2660223917 * 0.3150991800 
1.2777047378 *= 0.0000000000 * -0.0832945850 
-0.6133541995 *= 6.5130531926 * -0.2903490700 
-0.7370258570 *= 4.2732101073 * -0.0289411600 
-0.7370258570 *= 0.0000000000 * 0.1111816300 
-0.7370258570 *= 0.0000000000 * 0.2144657100 
-1.3719248860 *= 2.3610960288 * -0.2689001300 
-1.3719248860 *= 0.0000000000 * -0.1701286900 
-1.6452480843 *= 2.4710257559 * -0.1106112300 
-1.6452480843 *= 0.0000000000 * 0.0672158100 
-1.5447422522 *= 0.9613779680 * 0.1045435150 
-0.6473635751 *= 4.2500012888 * 0.2111478600 
-0.6473635751 *= 0.0000000000 * -0.2110213200 
-0.4499006312 *= 0.6023513619 * 0.3278202000 
-0.1691118444 *= 2.4603309399 * 0.1141264300 
-0.2506534734 *= 0.6763001634 * -0.1205701750 
-0.2506534734 *= 0.0000000000 * 0.0613281200 
-0.2506534734 *= 0.0000000000 * 0.1609059700 
-0.2506534734 *= 0.0000000000 * -0.2085085400 
-0.2506534734 *= 0.0000000000 * 0.0930473900 
-0.2879446407 *= 0.2460039935 * -0.1515876500 
-0.9962998514 *= 2.3101237554 * -0.3066308500 
-0.9962998514 *= 0.0000000000 * 0.0962679000 
tempVal = -0.9962998514 + 0.0325397200(biases), 
now the tempVal = -0.9637601314 
ReLU !!! in layer: 7, node : 8, its linear result is negative,so set it to 0

compute layer: 7, node : 9
0.0000000000 *= 0.0000000000 * 0.0958565850 
0.3836253804 *= 2.1138708105 * 0.1814800500 
0.3126725332 *= 3.3999542960 * -0.0208687650 
0.3126725332 *= 0.0000000000 * 0.0673932100 
0.3126725332 *= 0.0000000000 * 0.1634180400 
0.3126725332 *= 0.0000000000 * -0.0131768040 
0.3126725332 *= 0.0000000000 * 0.1615305700 
1.3405282536 *= 3.2660223917 * 0.3147117800 
1.3405282536 *= 0.0000000000 * -0.1164556700 
-0.6718488697 *= 6.5130531926 * -0.3089760000 
-1.1665293459 *= 4.2732101073 * -0.1157632000 
-1.1665293459 *= 0.0000000000 * 0.0053953864 
-1.1665293459 *= 0.0000000000 * -0.1824828100 
-1.8415404924 *= 2.3610960288 * -0.2858889000 
-1.8415404924 *= 0.0000000000 * -0.3006342600 
-2.2170821683 *= 2.4710257559 * -0.1519780500 
-2.2170821683 *= 0.0000000000 * -0.1895133000 
-2.2111837088 *= 0.9613779680 * 0.0061354220 
-1.9125615757 *= 4.2500012888 * 0.0702640100 
-1.9125615757 *= 0.0000000000 * 0.2786403300 
-1.9189579370 *= 0.6023513619 * -0.0106189870 
-2.5422180739 *= 2.4603309399 * -0.2533237000 
-2.7286861009 *= 0.6763001634 * -0.2757178500 
-2.7286861009 *= 0.0000000000 * -0.0902488160 
-2.7286861009 *= 0.0000000000 * -0.0702678000 
-2.7286861009 *= 0.0000000000 * -0.1595832700 
-2.7286861009 *= 0.0000000000 * 0.2670869000 
-2.7668811902 *= 0.2460039935 * -0.1552620700 
-2.4666429531 *= 2.3101237554 * 0.1299663000 
-2.4666429531 *= 0.0000000000 * 0.1240106500 
tempVal = -2.4666429531 + 0.0000000000(biases), 
now the tempVal = -2.4666429531 
ReLU !!! in layer: 7, node : 9, its linear result is negative,so set it to 0

compute layer: 7, node : 10
0.0000000000 *= 0.0000000000 * -0.0724540400 
0.0575000594 *= 2.1138708105 * 0.0272013120 
1.0875692527 *= 3.3999542960 * 0.3029656000 
1.0875692527 *= 0.0000000000 * -0.2100716200 
1.0875692527 *= 0.0000000000 * -0.1860023900 
1.0875692527 *= 0.0000000000 * -0.3150637000 
1.0875692527 *= 0.0000000000 * -0.0801373700 
2.2998982462 *= 3.2660223917 * 0.3711943300 
2.2998982462 *= 0.0000000000 * -0.1822310800 
5.1129731950 *= 6.5130531926 * 0.4319134000 
4.5209435227 *= 4.2732101073 * -0.1385444800 
4.5209435227 *= 0.0000000000 * -0.1754591600 
4.5209435227 *= 0.0000000000 * -0.1115059300 
4.7438982555 *= 2.3610960288 * 0.0944284900 
4.7438982555 *= 0.0000000000 * 0.0413148330 
4.3357411153 *= 2.4710257559 * -0.1651772100 
4.3357411153 *= 0.0000000000 * -0.2667730700 
4.3606111154 *= 0.9613779680 * 0.0258691180 
5.5799837877 *= 4.2500012888 * 0.2869111300 
5.5799837877 *= 0.0000000000 * 0.1022352300 
5.6706323187 *= 0.6023513619 * 0.1504911200 
5.3337168633 *= 2.4603309399 * -0.1369390800 
5.4470898682 *= 0.6763001634 * 0.1676371100 
5.4470898682 *= 0.0000000000 * 0.1304930900 
5.4470898682 *= 0.0000000000 * 0.1343862900 
5.4470898682 *= 0.0000000000 * 0.1522104400 
5.4470898682 *= 0.0000000000 * -0.2000773000 
5.4173101180 *= 0.2460039935 * -0.1210539300 
5.9896219098 *= 2.3101237554 * 0.2477407500 
5.9896219098 *= 0.0000000000 * -0.0820667400 
tempVal = 5.9896219098 + 0.0140584875(biases), 
now the tempVal = 6.0036803973 

compute layer: 7, node : 11
0.0000000000 *= 0.0000000000 * -0.1153257700 
0.2549865543 *= 2.1138708105 * 0.1206254200 
0.6536764999 *= 3.3999542960 * 0.1172633250 
0.6536764999 *= 0.0000000000 * 0.1805504000 
0.6536764999 *= 0.0000000000 * -0.1735308300 
0.6536764999 *= 0.0000000000 * -0.1205055600 
0.6536764999 *= 0.0000000000 * 0.2479380700 
0.8775672339 *= 3.2660223917 * 0.0685515000 
0.8775672339 *= 0.0000000000 * -0.0411156860 
-0.1494894107 *= 6.5130531926 * -0.1576920400 
-1.3579743387 *= 4.2732101073 * -0.2828049400 
-1.3579743387 *= 0.0000000000 * 0.3066921000 
-1.3579743387 *= 0.0000000000 * 0.0267902700 
-1.1475930231 *= 2.3610960288 * 0.0891032440 
-1.1475930231 *= 0.0000000000 * -0.1041120440 
-1.8738115546 *= 2.4710257559 * -0.2938935500 
-1.8738115546 *= 0.0000000000 * 0.2036839700 
-1.6823694950 *= 0.9613779680 * 0.1991329800 
-2.2505233948 *= 4.2500012888 * -0.1336832300 
-2.2505233948 *= 0.0000000000 * -0.1298533500 
-2.2814037053 *= 0.6023513619 * -0.0512662750 
-2.1995244870 *= 2.4603309399 * 0.0332797580 
-2.3203387347 *= 0.6763001634 * -0.1786399800 
-2.3203387347 *= 0.0000000000 * -0.2313992500 
-2.3203387347 *= 0.0000000000 * 0.1807786500 
-2.3203387347 *= 0.0000000000 * 0.2818929000 
-2.3203387347 *= 0.0000000000 * 0.1997129500 
-2.2494255104 *= 0.2460039935 * 0.2882604600 
-1.8549852779 *= 2.3101237554 * 0.1707442000 
-1.8549852779 *= 0.0000000000 * 0.2592631000 
tempVal = -1.8549852779 + -0.1365521600(biases), 
now the tempVal = -1.9915374379 
ReLU !!! in layer: 7, node : 11, its linear result is negative,so set it to 0

compute layer: 7, node : 12
0.0000000000 *= 0.0000000000 * -0.2819895700 
-0.4235030882 *= 2.1138708105 * -0.2003448300 
-0.3203673378 *= 3.3999542960 * 0.0303344520 
-0.3203673378 *= 0.0000000000 * 0.2781608400 
-0.3203673378 *= 0.0000000000 * 0.2590855700 
-0.3203673378 *= 0.0000000000 * -0.1554470500 
-0.3203673378 *= 0.0000000000 * -0.0791884000 
-0.1747933059 *= 3.2660223917 * 0.0445722700 
-0.1747933059 *= 0.0000000000 * -0.3177364200 
-1.9873722319 *= 6.5130531926 * -0.2782994200 
-2.2011131291 *= 4.2732101073 * -0.0500188130 
-2.2011131291 *= 0.0000000000 * 0.2370297900 
-2.2011131291 *= 0.0000000000 * -0.0731860400 
-1.7997338875 *= 2.3610960288 * 0.1699970000 
-1.7997338875 *= 0.0000000000 * -0.0471580960 
-1.1534647024 *= 2.4710257559 * 0.2615388300 
-1.1534647024 *= 0.0000000000 * 0.1479019500 
-1.1887726475 *= 0.9613779680 * -0.0367263930 
-2.3591599749 *= 4.2500012888 * -0.2753851700 
-2.3591599749 *= 0.0000000000 * 0.0489725550 
-2.4713807864 *= 0.6023513619 * -0.1863045700 
-2.2470030579 *= 2.4603309399 * 0.0911981900 
-2.2464732238 *= 0.6763001634 * 0.0007834304 
-2.2464732238 *= 0.0000000000 * 0.0239801220 
-2.2464732238 *= 0.0000000000 * 0.1658022300 
-2.2464732238 *= 0.0000000000 * -0.2254287700 
-2.2464732238 *= 0.0000000000 * 0.1005866500 
-2.2188961663 *= 0.2460039935 * 0.1121000400 
-2.2242668760 *= 2.3101237554 * -0.0023248580 
-2.2242668760 *= 0.0000000000 * 0.0285218790 
tempVal = -2.2242668760 + 0.0121945190(biases), 
now the tempVal = -2.2120723570 
ReLU !!! in layer: 7, node : 12, its linear result is negative,so set it to 0

compute layer: 7, node : 13
0.0000000000 *= 0.0000000000 * 0.3958031500 
-0.2276624489 *= 2.1138708105 * -0.1076993200 
-0.9695628038 *= 3.3999542960 * -0.2182089200 
-0.9695628038 *= 0.0000000000 * 0.2643923800 
-0.9695628038 *= 0.0000000000 * 0.1200786600 
-0.9695628038 *= 0.0000000000 * 0.0204524940 
-0.9695628038 *= 0.0000000000 * 0.5849024000 
-0.3674733722 *= 3.2660223917 * 0.1843494500 
-0.3674733722 *= 0.0000000000 * -0.1617082200 
-2.3362114108 *= 6.5130531926 * -0.3022757500 
-3.0445652121 *= 4.2732101073 * -0.1657662000 
-3.0445652121 *= 0.0000000000 * -0.2334996800 
-3.0445652121 *= 0.0000000000 * 0.2023020200 
-2.2020691050 *= 2.3610960288 * 0.3568241600 
-2.2020691050 *= 0.0000000000 * 0.1272817600 
-2.5964776308 *= 2.4710257559 * -0.1596132800 
-2.5964776308 *= 0.0000000000 * 0.2652017500 
-2.7114118186 *= 0.9613779680 * -0.1195515100 
-2.3764804625 *= 4.2500012888 * 0.0788073540 
-2.3764804625 *= 0.0000000000 * -0.0530705500 
-2.4313922222 *= 0.6023513619 * -0.0911623400 
-2.9047024217 *= 2.4603309399 * -0.1923766400 
-2.9656235945 *= 0.6763001634 * -0.0900800800 
-2.9656235945 *= 0.0000000000 * 0.2481473200 
-2.9656235945 *= 0.0000000000 * 0.2402319200 
-2.9656235945 *= 0.0000000000 * -0.2718784800 
-2.9656235945 *= 0.0000000000 * 0.0493972820 
-2.9460323334 *= 0.2460039935 * 0.0796379800 
-2.6685572011 *= 2.3101237554 * 0.1201126700 
-2.6685572011 *= 0.0000000000 * 0.0779000150 
tempVal = -2.6685572011 + 0.4555349600(biases), 
now the tempVal = -2.2130222411 
ReLU !!! in layer: 7, node : 13, its linear result is negative,so set it to 0

compute layer: 7, node : 14
0.0000000000 *= 0.0000000000 * 0.4331325600 
-0.4938447817 *= 2.1138708105 * -0.2336210800 
-1.3562183012 *= 3.3999542960 * -0.2536426800 
-1.3562183012 *= 0.0000000000 * -0.1979885000 
-1.3562183012 *= 0.0000000000 * 0.2709786000 
-1.3562183012 *= 0.0000000000 * 0.2586713400 
-1.3562183012 *= 0.0000000000 * 0.4758564000 
-1.1755223954 *= 3.2660223917 * 0.0553259850 
-1.1755223954 *= 0.0000000000 * 0.2415120000 
-1.6244030961 *= 6.5130531926 * -0.0689201650 
-1.2009803426 *= 4.2732101073 * 0.0990877450 
-1.2009803426 *= 0.0000000000 * -0.1578502400 
-1.2009803426 *= 0.0000000000 * -0.0733629300 
-1.7025252819 *= 2.3610960288 * -0.2124203900 
-1.7025252819 *= 0.0000000000 * -0.2235632500 
-1.3316583914 *= 2.4710257559 * 0.1500862100 
-1.3316583914 *= 0.0000000000 * -0.0505654500 
-1.3490841612 *= 0.9613779680 * -0.0181258260 
-0.6200050251 *= 4.2500012888 * 0.1715479800 
-0.6200050251 *= 0.0000000000 * 0.0045719900 
-0.6570267240 *= 0.6023513619 * -0.0614619660 
-1.2994605398 *= 2.4603309399 * -0.2611168300 
-1.0754704464 *= 0.6763001634 * 0.3311992300 
-1.0754704464 *= 0.0000000000 * 0.0935973900 
-1.0754704464 *= 0.0000000000 * 0.0893637760 
-1.0754704464 *= 0.0000000000 * 0.2632177200 
-1.0754704464 *= 0.0000000000 * -0.0604506000 
-1.0577750495 *= 0.2460039935 * 0.0719313400 
-0.9568845296 *= 2.3101237554 * 0.0436732100 
-0.9568845296 *= 0.0000000000 * -0.0021171880 
tempVal = -0.9568845296 + 0.2150583100(biases), 
now the tempVal = -0.7418262196 
ReLU !!! in layer: 7, node : 14, its linear result is negative,so set it to 0

compute layer: 7, node : 15
0.0000000000 *= 0.0000000000 * 0.0716494700 
0.3179346677 *= 2.1138708105 * 0.1504040200 
1.2293525959 *= 3.3999542960 * 0.2680677000 
1.2293525959 *= 0.0000000000 * 0.3466997700 
1.2293525959 *= 0.0000000000 * -0.1102405340 
1.2293525959 *= 0.0000000000 * -0.0673955600 
1.2293525959 *= 0.0000000000 * 0.3748954000 
2.0264461325 *= 3.2660223917 * 0.2440563600 
2.0264461325 *= 0.0000000000 * 0.1852354600 
3.3798473183 *= 6.5130531926 * 0.2077982700 
4.1881429576 *= 4.2732101073 * 0.1891542000 
4.1881429576 *= 0.0000000000 * -0.3064461600 
4.1881429576 *= 0.0000000000 * 0.0564823340 
3.5409811749 *= 2.3610960288 * -0.2740938000 
3.5409811749 *= 0.0000000000 * -0.0263395800 
2.9970209812 *= 2.4710257559 * -0.2201353800 
2.9970209812 *= 0.0000000000 * 0.2824654000 
3.2676823351 *= 0.9613779680 * 0.2815348000 
3.3233654822 *= 4.2500012888 * 0.0131019130 
3.3233654822 *= 0.0000000000 * 0.2434167000 
3.2997561459 *= 0.6023513619 * -0.0391952900 
2.9538312047 *= 2.4603309399 * -0.1406009800 
3.0956429087 *= 0.6763001634 * 0.2096875200 
3.0956429087 *= 0.0000000000 * 0.0112535610 
3.0956429087 *= 0.0000000000 * -0.0902191600 
3.0956429087 *= 0.0000000000 * -0.3098347200 
3.0956429087 *= 0.0000000000 * -0.1975537100 
3.0289226010 *= 0.2460039935 * -0.2712163600 
2.3864537369 *= 2.3101237554 * -0.2781101500 
2.3864537369 *= 0.0000000000 * -0.2454838500 
tempVal = 2.3864537369 + 0.1368603300(biases), 
now the tempVal = 2.5233140669 

compute layer: 7, node : 16
0.0000000000 *= 0.0000000000 * -0.0928001100 
-0.2517888597 *= 2.1138708105 * -0.1191127000 
0.1919689251 *= 3.3999542960 * 0.1305187500 
0.1919689251 *= 0.0000000000 * -0.2863167800 
0.1919689251 *= 0.0000000000 * -0.0661400600 
0.1919689251 *= 0.0000000000 * -0.1142885460 
0.1919689251 *= 0.0000000000 * -0.1000271300 
-0.0076585743 *= 3.2660223917 * -0.0611225140 
-0.0076585743 *= 0.0000000000 * 0.1778284300 
-0.5435477062 *= 6.5130531926 * -0.0822792500 
-0.3072913973 *= 4.2732101073 * 0.0552877820 
-0.3072913973 *= 0.0000000000 * 0.0603930900 
-0.3072913973 *= 0.0000000000 * 0.2164989600 
-0.7758736416 *= 2.3610960288 * -0.1984596300 
-0.7758736416 *= 0.0000000000 * -0.0285485140 
-1.4386857017 *= 2.4710257559 * -0.2682335700 
-1.4386857017 *= 0.0000000000 * 0.1594303800 
-1.3544681072 *= 0.9613779680 * 0.0876009200 
-1.4366864009 *= 4.2500012888 * -0.0193454750 
-1.4366864009 *= 0.0000000000 * 0.2768856300 
-1.5750074161 *= 0.6023513619 * -0.2296351000 
-1.6095472075 *= 2.4603309399 * -0.0140386770 
-1.6444456147 *= 0.6763001634 * -0.0516019500 
-1.6444456147 *= 0.0000000000 * 0.0061778314 
-1.6444456147 *= 0.0000000000 * 0.0399230100 
-1.6444456147 *= 0.0000000000 * 0.0676313040 
-1.6444456147 *= 0.0000000000 * -0.2960992500 
-1.6869322363 *= 0.2460039935 * -0.1727070400 
-1.6525526627 *= 2.3101237554 * 0.0148821350 
-1.6525526627 *= 0.0000000000 * 0.0795077200 
tempVal = -1.6525526627 + 0.0000000000(biases), 
now the tempVal = -1.6525526627 
ReLU !!! in layer: 7, node : 16, its linear result is negative,so set it to 0

compute layer: 7, node : 17
0.0000000000 *= 0.0000000000 * 0.1749580200 
0.2096538444 *= 2.1138708105 * 0.0991800650 
0.0850616488 *= 3.3999542960 * -0.0366452560 
0.0850616488 *= 0.0000000000 * -0.0255854300 
0.0850616488 *= 0.0000000000 * 0.0832367200 
0.0850616488 *= 0.0000000000 * 0.0888615600 
0.0850616488 *= 0.0000000000 * 0.2501666200 
0.5430302652 *= 3.2660223917 * 0.1402221300 
0.5430302652 *= 0.0000000000 * 0.2777630400 
-0.3015700980 *= 6.5130531926 * -0.1296781000 
-0.9856110431 *= 4.2732101073 * -0.1600766000 
-0.9856110431 *= 0.0000000000 * -0.2403120000 
-0.9856110431 *= 0.0000000000 * 0.2350816900 
-1.4019492683 *= 2.3610960288 * -0.1763326100 
-1.4019492683 *= 0.0000000000 * 0.2300181700 
-1.3755288558 *= 2.4710257559 * 0.0106920830 
-1.3755288558 *= 0.0000000000 * -0.2990117700 
-1.6295644564 *= 0.9613779680 * -0.2642411300 
-1.4940900128 *= 4.2500012888 * 0.0318763300 
-1.4940900128 *= 0.0000000000 * -0.1973035000 
-1.3253353396 *= 0.6023513619 * 0.2801598600 
-2.2121755524 *= 2.4603309399 * -0.3604556600 
-2.2034792115 *= 0.6763001634 * 0.0128587000 
-2.2034792115 *= 0.0000000000 * -0.2498956000 
-2.2034792115 *= 0.0000000000 * 0.1012938700 
-2.2034792115 *= 0.0000000000 * 0.2487000500 
-2.2034792115 *= 0.0000000000 * -0.1201075300 
-2.1543818845 *= 0.2460039935 * 0.1995793900 
-2.0795177502 *= 2.3101237554 * 0.0324069800 
-2.0795177502 *= 0.0000000000 * 0.1548098900 
tempVal = -2.0795177502 + -0.1777475800(biases), 
now the tempVal = -2.2572653302 
ReLU !!! in layer: 7, node : 17, its linear result is negative,so set it to 0

compute layer: 7, node : 18
0.0000000000 *= 0.0000000000 * 0.2904068200 
-0.2195361799 *= 2.1138708105 * -0.1038550600 
-0.3957085517 *= 3.3999542960 * -0.0518161000 
-0.3957085517 *= 0.0000000000 * 0.2803650200 
-0.3957085517 *= 0.0000000000 * 0.0476414560 
-0.3957085517 *= 0.0000000000 * -0.2653013800 
-0.3957085517 *= 0.0000000000 * -0.0257075110 
-0.5179408506 *= 3.2660223917 * -0.0374254320 
-0.5179408506 *= 0.0000000000 * -0.2350618200 
-0.2352357587 *= 6.5130531926 * 0.0434059240 
-1.0024628576 *= 4.2732101073 * -0.1795435000 
-1.0024628576 *= 0.0000000000 * 0.0257517550 
-1.0024628576 *= 0.0000000000 * 0.2902953600 
-0.9416049700 *= 2.3610960288 * 0.0257752700 
-0.9416049700 *= 0.0000000000 * -0.1377395200 
-0.8107434243 *= 2.4710257559 * 0.0529583900 
-0.8107434243 *= 0.0000000000 * 0.0736437400 
-0.9668033811 *= 0.9613779680 * -0.1623294500 
-1.7456777423 *= 4.2500012888 * -0.1832645000 
-1.7456777423 *= 0.0000000000 * 0.2964105000 
-1.6820953456 *= 0.6023513619 * 0.1055569900 
-2.3667194084 *= 2.4603309399 * -0.2782650300 
-2.3086356867 *= 0.6763001634 * 0.0858845300 
-2.3086356867 *= 0.0000000000 * 0.1548172100 
-2.3086356867 *= 0.0000000000 * 0.2223756800 
-2.3086356867 *= 0.0000000000 * -0.0371173500 
-2.3086356867 *= 0.0000000000 * 0.2413414600 
-2.2533467812 *= 0.2460039935 * 0.2247480000 
-2.0648676973 *= 2.3101237554 * 0.0815883060 
-2.0648676973 *= 0.0000000000 * -0.0568145070 
tempVal = -2.0648676973 + -0.0242954800(biases), 
now the tempVal = -2.0891631773 
ReLU !!! in layer: 7, node : 18, its linear result is negative,so set it to 0

compute layer: 7, node : 19
0.0000000000 *= 0.0000000000 * 0.2470991600 
0.3906501536 *= 2.1138708105 * 0.1848032300 
-0.4844336531 *= 3.3999542960 * -0.2573810500 
-0.4844336531 *= 0.0000000000 * -0.1258895100 
-0.4844336531 *= 0.0000000000 * -0.1367090000 
-0.4844336531 *= 0.0000000000 * -0.1310705700 
-0.4844336531 *= 0.0000000000 * 0.1985557200 
0.0866584173 *= 3.2660223917 * 0.1748585900 
0.0866584173 *= 0.0000000000 * -0.1816434700 
1.7165269876 *= 6.5130531926 * 0.2502464700 
0.2146297367 *= 4.2732101073 * -0.3514681500 
0.2146297367 *= 0.0000000000 * -0.1564633400 
0.2146297367 *= 0.0000000000 * 0.2012266500 
0.7798563872 *= 2.3610960288 * 0.2393916400 
0.7798563872 *= 0.0000000000 * 0.3079615000 
0.9563573091 *= 2.4710257559 * 0.0714282000 
0.9563573091 *= 0.0000000000 * 0.3002192700 
0.6965815033 *= 0.9613779680 * -0.2702119400 
-0.5874666261 *= 4.2500012888 * -0.3021288800 
-0.5874666261 *= 0.0000000000 * -0.1731366500 
-0.5844138242 *= 0.6023513619 * 0.0050681415 
-1.0881840771 *= 2.4603309399 * -0.2047571100 
-0.9303221335 *= 0.6763001634 * 0.2334199400 
-0.9303221335 *= 0.0000000000 * 0.2834359000 
-0.9303221335 *= 0.0000000000 * 0.2302378100 
-0.9303221335 *= 0.0000000000 * 0.3081832500 
-0.9303221335 *= 0.0000000000 * -0.2607311300 
-1.0102797291 *= 0.2460039935 * -0.3250256000 
-0.4183625870 *= 2.3101237554 * 0.2562274600 
-0.4183625870 *= 0.0000000000 * 0.2532542000 
tempVal = -0.4183625870 + 0.1921643800(biases), 
now the tempVal = -0.2261982070 
ReLU !!! in layer: 7, node : 19, its linear result is negative,so set it to 0

compute layer: 7, node : 20
0.0000000000 *= 0.0000000000 * -0.0508509540 
0.3843118599 *= 2.1138708105 * 0.1818048000 
0.9288637038 *= 3.3999542960 * 0.1601644600 
0.9288637038 *= 0.0000000000 * 0.0098971860 
0.9288637038 *= 0.0000000000 * -0.0365034800 
0.9288637038 *= 0.0000000000 * -0.1934790300 
0.9288637038 *= 0.0000000000 * -0.0909388660 
1.0474921626 *= 3.2660223917 * 0.0363219980 
1.0474921626 *= 0.0000000000 * 0.0767564900 
-0.8767876447 *= 6.5130531926 * -0.2954497300 
-2.1010957569 *= 4.2732101073 * -0.2865078200 
-2.1010957569 *= 0.0000000000 * 0.1173906800 
-2.1010957569 *= 0.0000000000 * 0.0698476400 
-2.6182377424 *= 2.3610960288 * -0.2190262400 
-2.6182377424 *= 0.0000000000 * -0.2827985000 
-3.3459262377 *= 2.4710257559 * -0.2944884300 
-3.3459262377 *= 0.0000000000 * 0.0479901170 
-3.4588633512 *= 0.9613779680 * -0.1174742060 
-3.5514105165 *= 4.2500012888 * -0.0217757970 
-3.5514105165 *= 0.0000000000 * 0.1148002300 
-3.5257193274 *= 0.6023513619 * 0.0426515000 
-4.0603282294 *= 2.4603309399 * -0.2172914600 
-4.0881863195 *= 0.6763001634 * -0.0411919020 
-4.0881863195 *= 0.0000000000 * 0.2797116300 
-4.0881863195 *= 0.0000000000 * -0.3515643800 
-4.0881863195 *= 0.0000000000 * 0.1965869800 
-4.0881863195 *= 0.0000000000 * -0.2358395900 
-4.0576805205 *= 0.2460039935 * 0.1240053000 
-4.7362759777 *= 2.3101237554 * -0.2937485300 
-4.7362759777 *= 0.0000000000 * 0.2057544700 
tempVal = -4.7362759777 + -0.2777791300(biases), 
now the tempVal = -5.0140551077 
ReLU !!! in layer: 7, node : 20, its linear result is negative,so set it to 0

compute layer: 7, node : 21
0.0000000000 *= 0.0000000000 * -0.0962529800 
0.5717204588 *= 2.1138708105 * 0.2704614000 
1.3946936080 *= 3.3999542960 * 0.2420541800 
1.3946936080 *= 0.0000000000 * -0.2271752700 
1.3946936080 *= 0.0000000000 * 0.3045696300 
1.3946936080 *= 0.0000000000 * -0.2284166700 
1.3946936080 *= 0.0000000000 * 0.3104269800 
1.9403679244 *= 3.2660223917 * 0.1670761100 
1.9403679244 *= 0.0000000000 * 0.1712464200 
2.9182232717 *= 6.5130531926 * 0.1501377800 
2.7291954296 *= 4.2732101073 * -0.0442355600 
2.7291954296 *= 0.0000000000 * -0.2831393800 
2.7291954296 *= 0.0000000000 * 0.1468941600 
2.9458808858 *= 2.3610960288 * 0.0917732500 
2.9458808858 *= 0.0000000000 * 0.0322621950 
2.6258511741 *= 2.4710257559 * -0.1295129000 
2.6258511741 *= 0.0000000000 * -0.1777177800 
2.4150973384 *= 0.9613779680 * -0.2192205800 
1.3144767996 *= 4.2500012888 * -0.2589694600 
1.3144767996 *= 0.0000000000 * -0.0515548500 
1.1854095036 *= 0.6023513619 * -0.2142724400 
0.6967355461 *= 2.4603309399 * -0.1986212300 
0.5622969138 *= 0.6763001634 * -0.1987854500 
0.5622969138 *= 0.0000000000 * 0.2172810400 
0.5622969138 *= 0.0000000000 * 0.2536472000 
0.5622969138 *= 0.0000000000 * -0.2029895200 
0.5622969138 *= 0.0000000000 * 0.0923165100 
0.6239691604 *= 0.2460039935 * 0.2506961200 
-0.1786137113 *= 2.3101237554 * -0.3474198600 
-0.1786137113 *= 0.0000000000 * 0.0414765330 
tempVal = -0.1786137113 + -0.0392367950(biases), 
now the tempVal = -0.2178505063 
ReLU !!! in layer: 7, node : 21, its linear result is negative,so set it to 0

compute layer: 7, node : 22
0.0000000000 *= 0.0000000000 * -0.3140754400 
-0.2243096595 *= 2.1138708105 * -0.1061132300 
-0.8176108640 *= 3.3999542960 * -0.1745027000 
-0.8176108640 *= 0.0000000000 * 0.1539098500 
-0.8176108640 *= 0.0000000000 * -0.0154690780 
-0.8176108640 *= 0.0000000000 * -0.1290404300 
-0.8176108640 *= 0.0000000000 * -0.2967046800 
-1.3381894889 *= 3.2660223917 * -0.1593922400 
-1.3381894889 *= 0.0000000000 * 0.0872335300 
-2.7926042871 *= 6.5130531926 * -0.2233076800 
-2.0972925367 *= 4.2732101073 * 0.1627141500 
-2.0972925367 *= 0.0000000000 * 0.1821920400 
-2.0972925367 *= 0.0000000000 * -0.1433609400 
-3.0829714334 *= 2.3610960288 * -0.4174666700 
-3.0829714334 *= 0.0000000000 * -0.0996343340 
-3.0418806374 *= 2.4710257559 * 0.0166290440 
-3.0418806374 *= 0.0000000000 * 0.2675331200 
-2.8714469552 *= 0.9613779680 * 0.1772806200 
-2.8973716162 *= 4.2500012888 * -0.0060999184 
-2.8973716162 *= 0.0000000000 * 0.0008182382 
-2.7975001160 *= 0.6023513619 * 0.1658027300 
-2.3927988773 *= 2.4603309399 * 0.1644905700 
-2.3881488385 *= 0.6763001634 * 0.0068757026 
-2.3881488385 *= 0.0000000000 * -0.0411989800 
-2.3881488385 *= 0.0000000000 * -0.1255567500 
-2.3881488385 *= 0.0000000000 * -0.2755305000 
-2.3881488385 *= 0.0000000000 * -0.2080171000 
-2.3681391984 *= 0.2460039935 * 0.0813386800 
-2.5365746413 *= 2.3101237554 * -0.0729118700 
-2.5365746413 *= 0.0000000000 * 0.1032961460 
tempVal = -2.5365746413 + -0.3424014400(biases), 
now the tempVal = -2.8789760813 
ReLU !!! in layer: 7, node : 22, its linear result is negative,so set it to 0

compute layer: 7, node : 23
0.0000000000 *= 0.0000000000 * 0.0454848800 
0.5549894673 *= 2.1138708105 * 0.2625465400 
0.6052975540 *= 3.3999542960 * 0.0147966950 
0.6052975540 *= 0.0000000000 * 0.0927435800 
0.6052975540 *= 0.0000000000 * 0.0139218000 
0.6052975540 *= 0.0000000000 * 0.2818828200 
0.6052975540 *= 0.0000000000 * -0.1365123800 
0.6309850161 *= 3.2660223917 * 0.0078650600 
0.6309850161 *= 0.0000000000 * 0.2463915600 
0.6516944587 *= 6.5130531926 * 0.0031796827 
-0.6868626691 *= 4.2732101073 * -0.3132439300 
-0.6868626691 *= 0.0000000000 * -0.2389062600 
-0.6868626691 *= 0.0000000000 * 0.2212869500 
-0.9206540629 *= 2.3610960288 * -0.0990181640 
-0.9206540629 *= 0.0000000000 * -0.3169727300 
-0.6152703927 *= 2.4710257559 * 0.1235857900 
-0.6152703927 *= 0.0000000000 * -0.2139778300 
-0.8664440961 *= 0.9613779680 * -0.2612642600 
0.0300748908 *= 4.2500012888 * 0.2109455800 
0.0300748908 *= 0.0000000000 * -0.2040052300 
0.0473799292 *= 0.6023513619 * 0.0287291430 
0.7735173774 *= 2.4603309399 * 0.2951381200 
0.7712293587 *= 0.6763001634 * -0.0033831408 
0.7712293587 *= 0.0000000000 * -0.2168628700 
0.7712293587 *= 0.0000000000 * 0.1948420000 
0.7712293587 *= 0.0000000000 * -0.3078920000 
0.7712293587 *= 0.0000000000 * -0.0704335000 
0.8048887887 *= 0.2460039935 * 0.1368247300 
0.4724294999 *= 2.3101237554 * -0.1439140600 
0.4724294999 *= 0.0000000000 * -0.2634719600 
tempVal = 0.4724294999 + 0.0163135530(biases), 
now the tempVal = 0.4887430529 

compute layer: 7, node : 24
0.0000000000 *= 0.0000000000 * 0.1012971700 
0.4910918455 *= 2.1138708105 * 0.2323187600 
1.2519021683 *= 3.3999542960 * 0.2237707500 
1.2519021683 *= 0.0000000000 * 0.1696236400 
1.2519021683 *= 0.0000000000 * 0.0229710300 
1.2519021683 *= 0.0000000000 * -0.2978168700 
1.2519021683 *= 0.0000000000 * 0.0566241960 
0.3624017211 *= 3.2660223917 * -0.2723497700 
0.3624017211 *= 0.0000000000 * 0.2729424500 
0.1742914126 *= 6.5130531926 * -0.0288820470 
1.1390557679 *= 4.2732101073 * 0.2257704000 
1.1390557679 *= 0.0000000000 * -0.0118812560 
1.1390557679 *= 0.0000000000 * -0.1267646700 
1.2211203282 *= 2.3610960288 * 0.0347569770 
1.2211203282 *= 0.0000000000 * 0.2694465200 
0.7300135962 *= 2.4710257559 * -0.1987461000 
0.7300135962 *= 0.0000000000 * -0.1671116500 
0.7347024955 *= 0.9613779680 * 0.0048772693 
0.6988266111 *= 4.2500012888 * -0.0084413820 
0.6988266111 *= 0.0000000000 * 0.1346302000 
0.7140922077 *= 0.6023513619 * 0.0253433420 
1.1273804688 *= 2.4603309399 * 0.1679807600 
0.9638577171 *= 0.6763001634 * -0.2417902000 
0.9638577171 *= 0.0000000000 * 0.1084754500 
0.9638577171 *= 0.0000000000 * 0.0226549770 
0.9638577171 *= 0.0000000000 * -0.2785427000 
0.9638577171 *= 0.0000000000 * 0.0934869700 
0.9341394187 *= 0.2460039935 * -0.1208041300 
0.5682382240 *= 2.3101237554 * -0.1583903000 
0.5682382240 *= 0.0000000000 * 0.3045167600 
tempVal = 0.5682382240 + -0.0286218880(biases), 
now the tempVal = 0.5396163360 

compute layer: 7, node : 25
0.0000000000 *= 0.0000000000 * -0.1043796600 
-0.1756000515 *= 2.1138708105 * -0.0830703800 
-0.9300065604 *= 3.3999542960 * -0.2218872500 
-0.9300065604 *= 0.0000000000 * 0.0711816850 
-0.9300065604 *= 0.0000000000 * 0.0169287580 
-0.9300065604 *= 0.0000000000 * -0.1654297700 
-0.9300065604 *= 0.0000000000 * -0.2043133200 
-1.7603442530 *= 3.2660223917 * -0.2542351500 
-1.7603442530 *= 0.0000000000 * 0.1013567750 
-0.7927769245 *= 6.5130531926 * 0.1485581800 
-0.1919010236 *= 4.2732101073 * 0.1406146400 
-0.1919010236 *= 0.0000000000 * 0.1017512800 
-0.1919010236 *= 0.0000000000 * 0.2020805300 
-0.3827903723 *= 2.3610960288 * -0.0808477700 
-0.3827903723 *= 0.0000000000 * 0.2972848000 
-1.0185008890 *= 2.4710257559 * -0.2572658400 
-1.0185008890 *= 0.0000000000 * -0.3066684000 
-1.2641119057 *= 0.9613779680 * -0.2554781000 
-2.5676629510 *= 4.2500012888 * -0.3067178000 
-2.5676629510 *= 0.0000000000 * 0.0938853550 
-2.6836960442 *= 0.6023513619 * -0.1926335700 
-2.9586837791 *= 2.4603309399 * -0.1117685960 
-2.9456793500 *= 0.6763001634 * 0.0192287830 
-2.9456793500 *= 0.0000000000 * -0.1270425300 
-2.9456793500 *= 0.0000000000 * 0.2076341700 
-2.9456793500 *= 0.0000000000 * -0.0660099100 
-2.9456793500 *= 0.0000000000 * 0.0381799640 
-2.8801193300 *= 0.2460039935 * 0.2664998200 
-2.8231659548 *= 2.3101237554 * 0.0246538200 
-2.8231659548 *= 0.0000000000 * -0.0803006300 
tempVal = -2.8231659548 + 0.0029391740(biases), 
now the tempVal = -2.8202267808 
ReLU !!! in layer: 7, node : 25, its linear result is negative,so set it to 0

compute layer: 7, node : 26
0.0000000000 *= 0.0000000000 * -0.1226153800 
-0.2270271461 *= 2.1138708105 * -0.1073987800 
0.7115312573 *= 3.3999542960 * 0.2760503000 
0.7115312573 *= 0.0000000000 * -0.0116784130 
0.7115312573 *= 0.0000000000 * -0.1797197500 
0.7115312573 *= 0.0000000000 * -0.2984775600 
0.7115312573 *= 0.0000000000 * -0.2630625400 
1.1122880645 *= 3.2660223917 * 0.1227048560 
1.1122880645 *= 0.0000000000 * -0.1223766400 
-0.5015976687 *= 6.5130531926 * -0.2477925000 
-0.7485620994 *= 4.2732101073 * -0.0577936550 
-0.7485620994 *= 0.0000000000 * 0.3081405000 
-0.7485620994 *= 0.0000000000 * -0.1342441300 
-0.9936952446 *= 2.3610960288 * -0.1038217600 
-0.9936952446 *= 0.0000000000 * -0.2221997100 
-1.4147935174 *= 2.4710257559 * -0.1704143600 
-1.4147935174 *= 0.0000000000 * -0.0047287475 
-1.1697667301 *= 0.9613779680 * 0.2548704000 
-0.3423406942 *= 4.2500012888 * 0.1946884200 
-0.3423406942 *= 0.0000000000 * -0.1082338100 
-0.2196048458 *= 0.6023513619 * 0.2037612200 
-0.1985994161 *= 2.4603309399 * 0.0085376440 
-0.3244075453 *= 0.6763001634 * -0.1860241000 
-0.3244075453 *= 0.0000000000 * -0.0731899100 
-0.3244075453 *= 0.0000000000 * 0.2973352000 
-0.3244075453 *= 0.0000000000 * -0.2949434500 
-0.3244075453 *= 0.0000000000 * -0.2609361000 
-0.3232917172 *= 0.2460039935 * 0.0045358130 
-0.2736284827 *= 2.3101237554 * 0.0214980840 
-0.2736284827 *= 0.0000000000 * -0.2527145400 
tempVal = -0.2736284827 + 0.0000000000(biases), 
now the tempVal = -0.2736284827 
ReLU !!! in layer: 7, node : 26, its linear result is negative,so set it to 0

compute layer: 7, node : 27
0.0000000000 *= 0.0000000000 * 0.2678112700 
0.2595555804 *= 2.1138708105 * 0.1227868700 
-0.1460266335 *= 3.3999542960 * -0.1192904900 
-0.1460266335 *= 0.0000000000 * -0.0841941900 
-0.1460266335 *= 0.0000000000 * 0.2926002700 
-0.1460266335 *= 0.0000000000 * 0.1453298600 
-0.1460266335 *= 0.0000000000 * -0.0217864830 
-0.4673268903 *= 3.2660223917 * -0.0983766240 
-0.4673268903 *= 0.0000000000 * 0.2912032600 
-2.0674190841 *= 6.5130531926 * -0.2456746700 
-0.7486332022 *= 4.2732101073 * 0.3086171400 
-0.7486332022 *= 0.0000000000 * -0.2378919700 
-0.7486332022 *= 0.0000000000 * -0.2515894200 
-0.6078387794 *= 2.3610960288 * 0.0596309600 
-0.6078387794 *= 0.0000000000 * -0.1124888700 
-0.8900746462 *= 2.4710257559 * -0.1142181000 
-0.8900746462 *= 0.0000000000 * 0.1241283640 
-0.6679508625 *= 0.9613779680 * 0.2310473000 
-0.1444793512 *= 4.2500012888 * 0.1231697300 
-0.1444793512 *= 0.0000000000 * 0.0470520970 
-0.1465657769 *= 0.6023513619 * -0.0034638017 
0.4578301170 *= 2.4603309399 * 0.2456563400 
0.3479656357 *= 0.6763001634 * -0.1624492900 
0.3479656357 *= 0.0000000000 * -0.0505473540 
0.3479656357 *= 0.0000000000 * -0.2983121000 
0.3479656357 *= 0.0000000000 * -0.0251194930 
0.3479656357 *= 0.0000000000 * -0.0951335100 
0.2987466351 *= 0.2460039935 * -0.2000739900 
0.4545911182 *= 2.3101237554 * 0.0674615300 
0.4545911182 *= 0.0000000000 * -0.1984132800 
tempVal = 0.4545911182 + 0.0197437180(biases), 
now the tempVal = 0.4743348362 

compute layer: 7, node : 28
0.0000000000 *= 0.0000000000 * -0.2501171800 
1.1949660959 *= 2.1138708105 * 0.5652976000 
2.0142252710 *= 3.3999542960 * 0.2409618200 
2.0142252710 *= 0.0000000000 * 0.3062613600 
2.0142252710 *= 0.0000000000 * -0.0217905700 
2.0142252710 *= 0.0000000000 * 0.1952654400 
2.0142252710 *= 0.0000000000 * 0.1776692000 
3.2717364182 *= 3.2660223917 * 0.3850283300 
3.2717364182 *= 0.0000000000 * -0.0881503900 
6.2592719638 *= 6.5130531926 * 0.4586997000 
6.0743706325 *= 4.2732101073 * -0.0432698900 
6.0743706325 *= 0.0000000000 * -0.0002053290 
6.0743706325 *= 0.0000000000 * -0.0262232760 
7.1848177058 *= 2.3610960288 * 0.4703100000 
7.1848177058 *= 0.0000000000 * -0.2608798400 
8.7457045310 *= 2.4710257559 * 0.6316756600 
8.7457045310 *= 0.0000000000 * 0.1800092200 
8.5613034882 *= 0.9613779680 * -0.1918091000 
9.8079623162 *= 4.2500012888 * 0.2933314000 
9.8079623162 *= 0.0000000000 * -0.1274732000 
9.5965295672 *= 0.6023513619 * -0.3510123200 
9.6566234531 *= 2.4603309399 * 0.0244251230 
9.7862441839 *= 0.6763001634 * 0.1916615400 
9.7862441839 *= 0.0000000000 * -0.3055322500 
9.7862441839 *= 0.0000000000 * -0.0305269160 
9.7862441839 *= 0.0000000000 * 0.0903924800 
9.7862441839 *= 0.0000000000 * -0.0523935200 
9.7518984273 *= 0.2460039935 * -0.1396146300 
10.6852838326 *= 2.3101237554 * 0.4040413000 
10.6852838326 *= 0.0000000000 * 0.2939970500 
tempVal = 10.6852838326 + 0.2886602600(biases), 
now the tempVal = 10.9739440926 

compute layer: 7, node : 29
0.0000000000 *= 0.0000000000 * -0.1716578600 
0.2836289331 *= 2.1138708105 * 0.1341751500 
1.1923715053 *= 3.3999542960 * 0.2672808200 
1.1923715053 *= 0.0000000000 * 0.1558218400 
1.1923715053 *= 0.0000000000 * 0.2307568200 
1.1923715053 *= 0.0000000000 * 0.0336193900 
1.1923715053 *= 0.0000000000 * 0.1345863600 
2.2731195438 *= 3.2660223917 * 0.3309065000 
2.2731195438 *= 0.0000000000 * -0.2401991500 
4.2038027896 *= 6.5130531926 * 0.2964329000 
2.9681637052 *= 4.2732101073 * -0.2891594500 
2.9681637052 *= 0.0000000000 * -0.2959745200 
2.9681637052 *= 0.0000000000 * -0.3076009000 
3.3187134604 *= 2.3610960288 * 0.1484690800 
3.3187134604 *= 0.0000000000 * 0.2024418600 
4.4318471075 *= 2.4710257559 * 0.4504743200 
4.4318471075 *= 0.0000000000 * -0.1663161700 
4.7043862922 *= 0.9613779680 * 0.2834880700 
4.2548831634 *= 4.2500012888 * -0.1057654100 
4.2548831634 *= 0.0000000000 * -0.0339703370 
4.4142427576 *= 0.6023513619 * 0.2645625200 
4.0849901259 *= 2.4603309399 * -0.1338245300 
4.2889030451 *= 0.6763001634 * 0.3015124500 
4.2889030451 *= 0.0000000000 * 0.2874552600 
4.2889030451 *= 0.0000000000 * 0.2477202600 
4.2889030451 *= 0.0000000000 * 0.2408667400 
4.2889030451 *= 0.0000000000 * 0.0491832700 
4.2685610167 *= 0.2460039935 * -0.0826898300 
4.1447767684 *= 2.3101237554 * -0.0535833840 
4.1447767684 *= 0.0000000000 * 0.2487159800 
tempVal = 4.1447767684 + 0.2336625500(biases), 
now the tempVal = 4.3784393184 

now we get all result in layer: 7
	node: 0, val: 1.5416266859
	node: 1, val: 0.0000000000
	node: 2, val: 0.0000000000
	node: 3, val: 0.0000000000
	node: 4, val: 0.0000000000
	node: 5, val: 1.2800615671
	node: 6, val: 0.3009587992
	node: 7, val: 0.0000000000
	node: 8, val: 0.0000000000
	node: 9, val: 0.0000000000
	node: 10, val: 6.0036803973
	node: 11, val: 0.0000000000
	node: 12, val: 0.0000000000
	node: 13, val: 0.0000000000
	node: 14, val: 0.0000000000
	node: 15, val: 2.5233140669
	node: 16, val: 0.0000000000
	node: 17, val: 0.0000000000
	node: 18, val: 0.0000000000
	node: 19, val: 0.0000000000
	node: 20, val: 0.0000000000
	node: 21, val: 0.0000000000
	node: 22, val: 0.0000000000
	node: 23, val: 0.4887430529
	node: 24, val: 0.5396163360
	node: 25, val: 0.0000000000
	node: 26, val: 0.0000000000
	node: 27, val: 0.4743348362
	node: 28, val: 10.9739440926
	node: 29, val: 4.3784393184

when compute layer[7] to layer[8]

compute layer: 8, node : 0
-0.1487501622 *= 1.5416266859 * -0.0964890940 
-0.1487501622 *= 0.0000000000 * 0.3275882300 
-0.1487501622 *= 0.0000000000 * 0.4852553300 
-0.1487501622 *= 0.0000000000 * 0.0973247100 
-0.1487501622 *= 0.0000000000 * -0.3682835000 
-0.2186302080 *= 1.2800615671 * -0.0545911600 
-0.2419630983 *= 0.3009587992 * -0.0775285200 
-0.2419630983 *= 0.0000000000 * 0.1270428700 
-0.2419630983 *= 0.0000000000 * -0.2202148400 
-0.2419630983 *= 0.0000000000 * -0.1931835000 
-3.5217190658 *= 6.0036803973 * -0.5462909000 
-3.5217190658 *= 0.0000000000 * 0.1753531200 
-3.5217190658 *= 0.0000000000 * 0.2302130500 
-3.5217190658 *= 0.0000000000 * 0.3987005700 
-3.5217190658 *= 0.0000000000 * 0.6705004600 
-3.2980623100 *= 2.5233140669 * 0.0886361150 
-3.2980623100 *= 0.0000000000 * -0.1364148300 
-3.2980623100 *= 0.0000000000 * 0.7058143600 
-3.2980623100 *= 0.0000000000 * 0.4910840400 
-3.2980623100 *= 0.0000000000 * -0.1080646500 
-3.2980623100 *= 0.0000000000 * -0.0636836100 
-3.2980623100 *= 0.0000000000 * 0.2787009000 
-3.2980623100 *= 0.0000000000 * -0.1664269400 
-3.3070011135 *= 0.4887430529 * -0.0182893720 
-3.4203539895 *= 0.5396163360 * -0.2100619800 
-3.4203539895 *= 0.0000000000 * -0.0077044475 
-3.4203539895 *= 0.0000000000 * -0.0248703940 
-3.3073191537 *= 0.4743348362 * 0.2383017800 
-14.0966283929 *= 10.9739440926 * -0.9831751600 
-15.5859388522 *= 4.3784393184 * -0.3401464200 
tempVal = -15.5859388522 + 1.0900713000(biases), 
now the tempVal = -14.4958675522 

compute layer: 8, node : 1
0.5921819756 *= 1.5416266859 * 0.3841280000 
0.5921819756 *= 0.0000000000 * 0.3344045000 
0.5921819756 *= 0.0000000000 * -0.1999096900 
0.5921819756 *= 0.0000000000 * -0.2264298200 
0.5921819756 *= 0.0000000000 * -0.1588977000 
0.0904932059 *= 1.2800615671 * -0.3919255000 
-0.0442382808 *= 0.3009587992 * -0.4476741900 
-0.0442382808 *= 0.0000000000 * -0.0916861200 
-0.0442382808 *= 0.0000000000 * -0.3749951400 
-0.0442382808 *= 0.0000000000 * 0.3778010300 
0.6814631673 *= 6.0036803973 * 0.1208760960 
0.6814631673 *= 0.0000000000 * 0.0619985650 
0.6814631673 *= 0.0000000000 * -0.0910130600 
0.6814631673 *= 0.0000000000 * 0.4268531800 
0.6814631673 *= 0.0000000000 * 0.0264180210 
0.0600345506 *= 2.5233140669 * -0.2462747800 
0.0600345506 *= 0.0000000000 * -0.2880283600 
0.0600345506 *= 0.0000000000 * 0.3810771400 
0.0600345506 *= 0.0000000000 * -0.1038547900 
0.0600345506 *= 0.0000000000 * 0.1045553100 
0.0600345506 *= 0.0000000000 * 0.2326604100 
0.0600345506 *= 0.0000000000 * -0.3606615700 
0.0600345506 *= 0.0000000000 * -0.0150560470 
0.2440238278 *= 0.4887430529 * 0.3764540000 
0.3693345047 *= 0.5396163360 * 0.2322218000 
0.3693345047 *= 0.0000000000 * 0.2753873000 
0.3693345047 *= 0.0000000000 * -0.4188677000 
0.4661286849 *= 0.4743348362 * 0.2040629800 
4.2606834902 *= 10.9739440926 * 0.3457785800 
6.8094172397 *= 4.3784393184 * 0.5821101000 
tempVal = 6.8094172397 + -0.1541001200(biases), 
now the tempVal = 6.6553171197 

compute layer: 8, node : 2
-0.3445645869 *= 1.5416266859 * -0.2235071500 
-0.3445645869 *= 0.0000000000 * 0.3570699400 
-0.3445645869 *= 0.0000000000 * 0.2252848000 
-0.3445645869 *= 0.0000000000 * -0.0292877370 
-0.3445645869 *= 0.0000000000 * -0.3056138800 
-0.3744152105 *= 1.2800615671 * -0.0233196780 
-0.5044447426 *= 0.3009587992 * -0.4320509400 
-0.5044447426 *= 0.0000000000 * 0.2834665800 
-0.5044447426 *= 0.0000000000 * -0.1925908500 
-0.5044447426 *= 0.0000000000 * 0.1756356800 
-1.2495341999 *= 6.0036803973 * -0.1241054500 
-1.2495341999 *= 0.0000000000 * 0.5528173000 
-1.2495341999 *= 0.0000000000 * -0.3074694000 
-1.2495341999 *= 0.0000000000 * -0.3392182600 
-1.2495341999 *= 0.0000000000 * 0.0845599100 
-2.1690082716 *= 2.5233140669 * -0.3643914500 
-2.1690082716 *= 0.0000000000 * -0.3580073000 
-2.1690082716 *= 0.0000000000 * 0.6373026000 
-2.1690082716 *= 0.0000000000 * -0.1063509700 
-2.1690082716 *= 0.0000000000 * 0.3667503000 
-2.1690082716 *= 0.0000000000 * -0.2414708400 
-2.1690082716 *= 0.0000000000 * 0.4619719000 
-2.1690082716 *= 0.0000000000 * 0.1328880300 
-2.1726843959 *= 0.4887430529 * -0.0075215890 
-2.3188052257 *= 0.5396163360 * -0.2707865200 
-2.3188052257 *= 0.0000000000 * -0.3565425600 
-2.3188052257 *= 0.0000000000 * -0.2889170300 
-2.4384054058 *= 0.4743348362 * -0.2521429400 
3.8419696297 *= 10.9739440926 * 0.5722988000 
5.3540650932 *= 4.3784393184 * 0.3453503300 
tempVal = 5.3540650932 + -0.1375057800(biases), 
now the tempVal = 5.2165593132 

now we get all result in layer: 8
	node: 0, val: -14.4958675522
	node: 1, val: 6.6553171197
	node: 2, val: 5.2165593132
	output[0] = -14.4958675522. Normalized: 0.000000
	output[1] = 6.6553171197. Normalized: 0.000000
	output[2] = 5.2165593132. Normalized: 0.000000
