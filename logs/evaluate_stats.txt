allLayerSize = 8
Input nodes = 5, relu nodes = 300, output nodes = 5

Inputs are: 
	input[0] = 0.000000
	input[1] = 0.000000
	input[2] = 0.000000
	input[3] = 0.000000
	input[4] = 0.000000

Output using nnet.cpp:
number of layers in nnet.cpp = 7

when compute layer[0] to layer[1]
compute layer: 1, node : 0
0.0000000000 * 0.0540062000 = 0.0000000000 
0.0000000000 * -2.6109200000 = 0.0000000000 
0.0000000000 * -0.1800270000 = 0.0000000000 
0.0000000000 * 0.2421940000 = 0.0000000000 
0.0000000000 * 0.1414070000 = 0.0000000000 
the biases is : 0.2276300000, now tempVal is : 0.2276300000
compute layer: 1, node : 1
0.0000000000 * -1.1237400000 = 0.0000000000 
0.0000000000 * 0.0263619000 = 0.0000000000 
0.0000000000 * -0.0091792900 = 0.0000000000 
0.0000000000 * 0.0556230000 = 0.0000000000 
0.0000000000 * -0.3276350000 = 0.0000000000 
the biases is : -0.1887620000, now tempVal is : -0.1887620000
ReLU !!! in layer: 1, node : 1, its linear result is negative,so set it to 0
compute layer: 1, node : 2
0.0000000000 * 0.1960190000 = 0.0000000000 
0.0000000000 * 0.2421590000 = 0.0000000000 
0.0000000000 * 0.6384520000 = 0.0000000000 
0.0000000000 * -0.4782650000 = 0.0000000000 
0.0000000000 * 0.1425770000 = 0.0000000000 
the biases is : 0.0534094000, now tempVal is : 0.0534094000
compute layer: 1, node : 3
0.0000000000 * -1.6301500000 = 0.0000000000 
0.0000000000 * -0.0344447000 = 0.0000000000 
0.0000000000 * -0.0060549200 = 0.0000000000 
0.0000000000 * 0.0112076000 = 0.0000000000 
0.0000000000 * -0.0104997000 = 0.0000000000 
the biases is : -0.3778610000, now tempVal is : -0.3778610000
ReLU !!! in layer: 1, node : 3, its linear result is negative,so set it to 0
compute layer: 1, node : 4
0.0000000000 * -0.3551330000 = 0.0000000000 
0.0000000000 * 0.5659690000 = 0.0000000000 
0.0000000000 * 0.2282670000 = 0.0000000000 
0.0000000000 * 0.1773420000 = 0.0000000000 
0.0000000000 * -0.2080780000 = 0.0000000000 
the biases is : -0.0812531000, now tempVal is : -0.0812531000
ReLU !!! in layer: 1, node : 4, its linear result is negative,so set it to 0
compute layer: 1, node : 5
0.0000000000 * -0.0341918000 = 0.0000000000 
0.0000000000 * 1.4957000000 = 0.0000000000 
0.0000000000 * -1.5337100000 = 0.0000000000 
0.0000000000 * 0.0405053000 = 0.0000000000 
0.0000000000 * 0.1643500000 = 0.0000000000 
the biases is : -0.5886510000, now tempVal is : -0.5886510000
ReLU !!! in layer: 1, node : 5, its linear result is negative,so set it to 0
compute layer: 1, node : 6
0.0000000000 * 0.4020020000 = 0.0000000000 
0.0000000000 * 0.2240220000 = 0.0000000000 
0.0000000000 * -0.0467160000 = 0.0000000000 
0.0000000000 * 0.1638900000 = 0.0000000000 
0.0000000000 * -0.1608260000 = 0.0000000000 
the biases is : 0.0746065000, now tempVal is : 0.0746065000
compute layer: 1, node : 7
0.0000000000 * -1.4157500000 = 0.0000000000 
0.0000000000 * -0.0747429000 = 0.0000000000 
0.0000000000 * 0.0604386000 = 0.0000000000 
0.0000000000 * 0.0482656000 = 0.0000000000 
0.0000000000 * -0.0560096000 = 0.0000000000 
the biases is : -0.3928870000, now tempVal is : -0.3928870000
ReLU !!! in layer: 1, node : 7, its linear result is negative,so set it to 0
compute layer: 1, node : 8
0.0000000000 * -1.4449800000 = 0.0000000000 
0.0000000000 * 0.0448403000 = 0.0000000000 
0.0000000000 * 0.0088891600 = 0.0000000000 
0.0000000000 * -0.2502300000 = 0.0000000000 
0.0000000000 * 0.0653312000 = 0.0000000000 
the biases is : -0.3563030000, now tempVal is : -0.3563030000
ReLU !!! in layer: 1, node : 8, its linear result is negative,so set it to 0
compute layer: 1, node : 9
0.0000000000 * -1.1274000000 = 0.0000000000 
0.0000000000 * 0.0239891000 = 0.0000000000 
0.0000000000 * -0.0095671100 = 0.0000000000 
0.0000000000 * 0.0089279600 = 0.0000000000 
0.0000000000 * -0.0045800700 = 0.0000000000 
the biases is : -0.1677120000, now tempVal is : -0.1677120000
ReLU !!! in layer: 1, node : 9, its linear result is negative,so set it to 0
compute layer: 1, node : 10
0.0000000000 * 0.6137170000 = 0.0000000000 
0.0000000000 * -0.5578200000 = 0.0000000000 
0.0000000000 * -0.0519507000 = 0.0000000000 
0.0000000000 * 0.1608520000 = 0.0000000000 
0.0000000000 * -0.0971775000 = 0.0000000000 
the biases is : 0.0587109000, now tempVal is : 0.0587109000
compute layer: 1, node : 11
0.0000000000 * 0.9336990000 = 0.0000000000 
0.0000000000 * 0.2036470000 = 0.0000000000 
0.0000000000 * 0.1661780000 = 0.0000000000 
0.0000000000 * -0.0015216300 = 0.0000000000 
0.0000000000 * -0.2094480000 = 0.0000000000 
the biases is : 0.1839170000, now tempVal is : 0.1839170000
compute layer: 1, node : 12
0.0000000000 * -0.0408026000 = 0.0000000000 
0.0000000000 * 0.5486660000 = 0.0000000000 
0.0000000000 * 0.0574868000 = 0.0000000000 
0.0000000000 * 0.1429850000 = 0.0000000000 
0.0000000000 * 0.0948681000 = 0.0000000000 
the biases is : 0.1319570000, now tempVal is : 0.1319570000
compute layer: 1, node : 13
0.0000000000 * -0.2122650000 = 0.0000000000 
0.0000000000 * -0.3280030000 = 0.0000000000 
0.0000000000 * 0.3575360000 = 0.0000000000 
0.0000000000 * -0.3897150000 = 0.0000000000 
0.0000000000 * -0.4593370000 = 0.0000000000 
the biases is : -0.3086810000, now tempVal is : -0.3086810000
ReLU !!! in layer: 1, node : 13, its linear result is negative,so set it to 0
compute layer: 1, node : 14
0.0000000000 * 0.0320180000 = 0.0000000000 
0.0000000000 * 0.4224550000 = 0.0000000000 
0.0000000000 * -0.5688330000 = 0.0000000000 
0.0000000000 * -0.2107820000 = 0.0000000000 
0.0000000000 * 0.0757506000 = 0.0000000000 
the biases is : 0.1969290000, now tempVal is : 0.1969290000
compute layer: 1, node : 15
0.0000000000 * -0.0124055000 = 0.0000000000 
0.0000000000 * 2.2845300000 = 0.0000000000 
0.0000000000 * 0.0534617000 = 0.0000000000 
0.0000000000 * 0.0580561000 = 0.0000000000 
0.0000000000 * 0.1186520000 = 0.0000000000 
the biases is : 0.2066640000, now tempVal is : 0.2066640000
compute layer: 1, node : 16
0.0000000000 * -0.1224300000 = 0.0000000000 
0.0000000000 * -0.7120420000 = 0.0000000000 
0.0000000000 * 0.0091590400 = 0.0000000000 
0.0000000000 * -0.3911230000 = 0.0000000000 
0.0000000000 * 0.0339849000 = 0.0000000000 
the biases is : -0.3116960000, now tempVal is : -0.3116960000
ReLU !!! in layer: 1, node : 16, its linear result is negative,so set it to 0
compute layer: 1, node : 17
0.0000000000 * 0.0601742000 = 0.0000000000 
0.0000000000 * -0.0639072000 = 0.0000000000 
0.0000000000 * -2.5028100000 = 0.0000000000 
0.0000000000 * 0.0499702000 = 0.0000000000 
0.0000000000 * -0.0377898000 = 0.0000000000 
the biases is : 0.0306576000, now tempVal is : 0.0306576000
compute layer: 1, node : 18
0.0000000000 * 0.0833034000 = 0.0000000000 
0.0000000000 * -0.0407486000 = 0.0000000000 
0.0000000000 * -0.7521010000 = 0.0000000000 
0.0000000000 * -0.1187980000 = 0.0000000000 
0.0000000000 * -0.2180440000 = 0.0000000000 
the biases is : -0.1388220000, now tempVal is : -0.1388220000
ReLU !!! in layer: 1, node : 18, its linear result is negative,so set it to 0
compute layer: 1, node : 19
0.0000000000 * -1.1880400000 = 0.0000000000 
0.0000000000 * 0.1446300000 = 0.0000000000 
0.0000000000 * -0.1492800000 = 0.0000000000 
0.0000000000 * -0.0360766000 = 0.0000000000 
0.0000000000 * -0.1189330000 = 0.0000000000 
the biases is : -0.3474340000, now tempVal is : -0.3474340000
ReLU !!! in layer: 1, node : 19, its linear result is negative,so set it to 0
compute layer: 1, node : 20
0.0000000000 * -0.1035370000 = 0.0000000000 
0.0000000000 * 0.0699915000 = 0.0000000000 
0.0000000000 * 2.4237300000 = 0.0000000000 
0.0000000000 * 0.0226499000 = 0.0000000000 
0.0000000000 * 0.0319605000 = 0.0000000000 
the biases is : -0.0045184000, now tempVal is : -0.0045184000
ReLU !!! in layer: 1, node : 20, its linear result is negative,so set it to 0
compute layer: 1, node : 21
0.0000000000 * -0.0853903000 = 0.0000000000 
0.0000000000 * 0.1752150000 = 0.0000000000 
0.0000000000 * -0.0874009000 = 0.0000000000 
0.0000000000 * -0.7318360000 = 0.0000000000 
0.0000000000 * -0.2208500000 = 0.0000000000 
the biases is : -0.3906160000, now tempVal is : -0.3906160000
ReLU !!! in layer: 1, node : 21, its linear result is negative,so set it to 0
compute layer: 1, node : 22
0.0000000000 * -0.0193838000 = 0.0000000000 
0.0000000000 * 3.9939000000 = 0.0000000000 
0.0000000000 * 0.1178070000 = 0.0000000000 
0.0000000000 * 0.0784146000 = 0.0000000000 
0.0000000000 * -0.0145183000 = 0.0000000000 
the biases is : 0.0969635000, now tempVal is : 0.0969635000
compute layer: 1, node : 23
0.0000000000 * 0.0166866000 = 0.0000000000 
0.0000000000 * -0.6544050000 = 0.0000000000 
0.0000000000 * 0.5600960000 = 0.0000000000 
0.0000000000 * 0.1965790000 = 0.0000000000 
0.0000000000 * -0.4498050000 = 0.0000000000 
the biases is : 0.0098326600, now tempVal is : 0.0098326600
compute layer: 1, node : 24
0.0000000000 * 0.0016763900 = 0.0000000000 
0.0000000000 * 0.0053843400 = 0.0000000000 
0.0000000000 * -0.0072663900 = 0.0000000000 
0.0000000000 * 0.0041808400 = 0.0000000000 
0.0000000000 * 0.0017810500 = 0.0000000000 
the biases is : -0.0188585000, now tempVal is : -0.0188585000
ReLU !!! in layer: 1, node : 24, its linear result is negative,so set it to 0
compute layer: 1, node : 25
0.0000000000 * -0.8975250000 = 0.0000000000 
0.0000000000 * -0.1276060000 = 0.0000000000 
0.0000000000 * 0.1628030000 = 0.0000000000 
0.0000000000 * -0.0481184000 = 0.0000000000 
0.0000000000 * 0.0785461000 = 0.0000000000 
the biases is : -0.2319190000, now tempVal is : -0.2319190000
ReLU !!! in layer: 1, node : 25, its linear result is negative,so set it to 0
compute layer: 1, node : 26
0.0000000000 * -0.9332200000 = 0.0000000000 
0.0000000000 * -0.0243277000 = 0.0000000000 
0.0000000000 * 0.2302730000 = 0.0000000000 
0.0000000000 * -0.2090330000 = 0.0000000000 
0.0000000000 * -0.0943662000 = 0.0000000000 
the biases is : -0.2381650000, now tempVal is : -0.2381650000
ReLU !!! in layer: 1, node : 26, its linear result is negative,so set it to 0
compute layer: 1, node : 27
0.0000000000 * 0.1603330000 = 0.0000000000 
0.0000000000 * 0.0036929100 = 0.0000000000 
0.0000000000 * 0.2621490000 = 0.0000000000 
0.0000000000 * 0.2819430000 = 0.0000000000 
0.0000000000 * -0.5514760000 = 0.0000000000 
the biases is : 0.0710148000, now tempVal is : 0.0710148000
compute layer: 1, node : 28
0.0000000000 * 0.0834021000 = 0.0000000000 
0.0000000000 * 2.0128100000 = 0.0000000000 
0.0000000000 * 0.3553100000 = 0.0000000000 
0.0000000000 * 0.0360065000 = 0.0000000000 
0.0000000000 * -0.0996482000 = 0.0000000000 
the biases is : -0.1419130000, now tempVal is : -0.1419130000
ReLU !!! in layer: 1, node : 28, its linear result is negative,so set it to 0
compute layer: 1, node : 29
0.0000000000 * 0.2840190000 = 0.0000000000 
0.0000000000 * -0.0465741000 = 0.0000000000 
0.0000000000 * 0.0074793000 = 0.0000000000 
0.0000000000 * -0.8405130000 = 0.0000000000 
0.0000000000 * -0.4817890000 = 0.0000000000 
the biases is : -0.4423070000, now tempVal is : -0.4423070000
ReLU !!! in layer: 1, node : 29, its linear result is negative,so set it to 0
compute layer: 1, node : 30
0.0000000000 * 1.3729500000 = 0.0000000000 
0.0000000000 * 0.0058815000 = 0.0000000000 
0.0000000000 * 0.0130908000 = 0.0000000000 
0.0000000000 * -0.0741005000 = 0.0000000000 
0.0000000000 * -0.1558490000 = 0.0000000000 
the biases is : 0.5590840000, now tempVal is : 0.5590840000
compute layer: 1, node : 31
0.0000000000 * -0.1444450000 = 0.0000000000 
0.0000000000 * 0.0006075910 = 0.0000000000 
0.0000000000 * -0.0211642000 = 0.0000000000 
0.0000000000 * -0.6477140000 = 0.0000000000 
0.0000000000 * -0.0182691000 = 0.0000000000 
the biases is : 0.1354830000, now tempVal is : 0.1354830000
compute layer: 1, node : 32
0.0000000000 * -1.3629000000 = 0.0000000000 
0.0000000000 * -0.0207197000 = 0.0000000000 
0.0000000000 * 0.0445642000 = 0.0000000000 
0.0000000000 * 0.0394107000 = 0.0000000000 
0.0000000000 * 0.0935691000 = 0.0000000000 
the biases is : -0.3732170000, now tempVal is : -0.3732170000
ReLU !!! in layer: 1, node : 32, its linear result is negative,so set it to 0
compute layer: 1, node : 33
0.0000000000 * -1.5517800000 = 0.0000000000 
0.0000000000 * 0.0838021000 = 0.0000000000 
0.0000000000 * -0.0352086000 = 0.0000000000 
0.0000000000 * 0.0060595300 = 0.0000000000 
0.0000000000 * 0.0082840400 = 0.0000000000 
the biases is : -0.4153900000, now tempVal is : -0.4153900000
ReLU !!! in layer: 1, node : 33, its linear result is negative,so set it to 0
compute layer: 1, node : 34
0.0000000000 * 1.2965900000 = 0.0000000000 
0.0000000000 * 0.0938274000 = 0.0000000000 
0.0000000000 * 0.1754740000 = 0.0000000000 
0.0000000000 * 0.1334400000 = 0.0000000000 
0.0000000000 * 0.2987770000 = 0.0000000000 
the biases is : 0.7596380000, now tempVal is : 0.7596380000
compute layer: 1, node : 35
0.0000000000 * 0.0158680000 = 0.0000000000 
0.0000000000 * 0.3297730000 = 0.0000000000 
0.0000000000 * -0.2653530000 = 0.0000000000 
0.0000000000 * -0.1035410000 = 0.0000000000 
0.0000000000 * 0.0765932000 = 0.0000000000 
the biases is : 0.1328250000, now tempVal is : 0.1328250000
compute layer: 1, node : 36
0.0000000000 * -0.0415857000 = 0.0000000000 
0.0000000000 * -1.4767400000 = 0.0000000000 
0.0000000000 * -0.0579324000 = 0.0000000000 
0.0000000000 * -0.2066670000 = 0.0000000000 
0.0000000000 * 0.2015470000 = 0.0000000000 
the biases is : 0.2355660000, now tempVal is : 0.2355660000
compute layer: 1, node : 37
0.0000000000 * -0.0826992000 = 0.0000000000 
0.0000000000 * 0.0025512000 = 0.0000000000 
0.0000000000 * 0.0098721500 = 0.0000000000 
0.0000000000 * 0.0689708000 = 0.0000000000 
0.0000000000 * -0.8789380000 = 0.0000000000 
the biases is : 0.2148580000, now tempVal is : 0.2148580000
compute layer: 1, node : 38
0.0000000000 * -1.5902500000 = 0.0000000000 
0.0000000000 * 0.0475710000 = 0.0000000000 
0.0000000000 * 0.0076307400 = 0.0000000000 
0.0000000000 * -0.0142601000 = 0.0000000000 
0.0000000000 * 0.0028504800 = 0.0000000000 
the biases is : -0.4408410000, now tempVal is : -0.4408410000
ReLU !!! in layer: 1, node : 38, its linear result is negative,so set it to 0
compute layer: 1, node : 39
0.0000000000 * 0.0283388000 = 0.0000000000 
0.0000000000 * -0.0230824000 = 0.0000000000 
0.0000000000 * -0.0763311000 = 0.0000000000 
0.0000000000 * -0.7716100000 = 0.0000000000 
0.0000000000 * 0.4990340000 = 0.0000000000 
the biases is : -0.0772968000, now tempVal is : -0.0772968000
ReLU !!! in layer: 1, node : 39, its linear result is negative,so set it to 0
compute layer: 1, node : 40
0.0000000000 * 0.1392120000 = 0.0000000000 
0.0000000000 * -0.5721820000 = 0.0000000000 
0.0000000000 * 0.4268050000 = 0.0000000000 
0.0000000000 * -0.3300290000 = 0.0000000000 
0.0000000000 * 0.2808640000 = 0.0000000000 
the biases is : 0.2216060000, now tempVal is : 0.2216060000
compute layer: 1, node : 41
0.0000000000 * 0.2578520000 = 0.0000000000 
0.0000000000 * -0.0626802000 = 0.0000000000 
0.0000000000 * -0.3311320000 = 0.0000000000 
0.0000000000 * 0.3299050000 = 0.0000000000 
0.0000000000 * -0.8563150000 = 0.0000000000 
the biases is : -0.0065087300, now tempVal is : -0.0065087300
ReLU !!! in layer: 1, node : 41, its linear result is negative,so set it to 0
compute layer: 1, node : 42
0.0000000000 * 0.0686480000 = 0.0000000000 
0.0000000000 * 0.0024586300 = 0.0000000000 
0.0000000000 * -0.0142610000 = 0.0000000000 
0.0000000000 * 0.0279897000 = 0.0000000000 
0.0000000000 * -1.8510300000 = 0.0000000000 
the biases is : -0.6348430000, now tempVal is : -0.6348430000
ReLU !!! in layer: 1, node : 42, its linear result is negative,so set it to 0
compute layer: 1, node : 43
0.0000000000 * -0.7445900000 = 0.0000000000 
0.0000000000 * 0.0031186300 = 0.0000000000 
0.0000000000 * -0.1878790000 = 0.0000000000 
0.0000000000 * 0.0136177000 = 0.0000000000 
0.0000000000 * -0.0159550000 = 0.0000000000 
the biases is : -0.1538330000, now tempVal is : -0.1538330000
ReLU !!! in layer: 1, node : 43, its linear result is negative,so set it to 0
compute layer: 1, node : 44
0.0000000000 * -0.4165690000 = 0.0000000000 
0.0000000000 * 0.0120669000 = 0.0000000000 
0.0000000000 * -0.0481611000 = 0.0000000000 
0.0000000000 * -0.3646030000 = 0.0000000000 
0.0000000000 * 0.2881940000 = 0.0000000000 
the biases is : -0.0573027000, now tempVal is : -0.0573027000
ReLU !!! in layer: 1, node : 44, its linear result is negative,so set it to 0
compute layer: 1, node : 45
0.0000000000 * -0.6325390000 = 0.0000000000 
0.0000000000 * -0.0358635000 = 0.0000000000 
0.0000000000 * 0.0283509000 = 0.0000000000 
0.0000000000 * 0.0737678000 = 0.0000000000 
0.0000000000 * 0.0649997000 = 0.0000000000 
the biases is : -0.1092290000, now tempVal is : -0.1092290000
ReLU !!! in layer: 1, node : 45, its linear result is negative,so set it to 0
compute layer: 1, node : 46
0.0000000000 * 0.0392007000 = 0.0000000000 
0.0000000000 * 0.5644690000 = 0.0000000000 
0.0000000000 * 0.2628180000 = 0.0000000000 
0.0000000000 * -0.0139606000 = 0.0000000000 
0.0000000000 * -0.3578830000 = 0.0000000000 
the biases is : 0.0370344000, now tempVal is : 0.0370344000
compute layer: 1, node : 47
0.0000000000 * -0.0385883000 = 0.0000000000 
0.0000000000 * -0.1238780000 = 0.0000000000 
0.0000000000 * -0.7626270000 = 0.0000000000 
0.0000000000 * 0.0423037000 = 0.0000000000 
0.0000000000 * 0.0498901000 = 0.0000000000 
the biases is : 0.0538087000, now tempVal is : 0.0538087000
compute layer: 1, node : 48
0.0000000000 * -1.5763100000 = 0.0000000000 
0.0000000000 * 0.0004400160 = 0.0000000000 
0.0000000000 * -0.0083217600 = 0.0000000000 
0.0000000000 * -0.0926607000 = 0.0000000000 
0.0000000000 * -0.0049370500 = 0.0000000000 
the biases is : -0.4475500000, now tempVal is : -0.4475500000
ReLU !!! in layer: 1, node : 48, its linear result is negative,so set it to 0
compute layer: 1, node : 49
0.0000000000 * 0.6203670000 = 0.0000000000 
0.0000000000 * 0.0750374000 = 0.0000000000 
0.0000000000 * -0.0146141000 = 0.0000000000 
0.0000000000 * 0.2625750000 = 0.0000000000 
0.0000000000 * -0.2579480000 = 0.0000000000 
the biases is : 0.1759170000, now tempVal is : 0.1759170000

now we get all result in layer: 1
	node: 0, val: 0.2276300000
	node: 1, val: 0.0000000000
	node: 2, val: 0.0534094000
	node: 3, val: 0.0000000000
	node: 4, val: 0.0000000000
	node: 5, val: 0.0000000000
	node: 6, val: 0.0746065000
	node: 7, val: 0.0000000000
	node: 8, val: 0.0000000000
	node: 9, val: 0.0000000000
	node: 10, val: 0.0587109000
	node: 11, val: 0.1839170000
	node: 12, val: 0.1319570000
	node: 13, val: 0.0000000000
	node: 14, val: 0.1969290000
	node: 15, val: 0.2066640000
	node: 16, val: 0.0000000000
	node: 17, val: 0.0306576000
	node: 18, val: 0.0000000000
	node: 19, val: 0.0000000000
	node: 20, val: 0.0000000000
	node: 21, val: 0.0000000000
	node: 22, val: 0.0969635000
	node: 23, val: 0.0098326600
	node: 24, val: 0.0000000000
	node: 25, val: 0.0000000000
	node: 26, val: 0.0000000000
	node: 27, val: 0.0710148000
	node: 28, val: 0.0000000000
	node: 29, val: 0.0000000000
	node: 30, val: 0.5590840000
	node: 31, val: 0.1354830000
	node: 32, val: 0.0000000000
	node: 33, val: 0.0000000000
	node: 34, val: 0.7596380000
	node: 35, val: 0.1328250000
	node: 36, val: 0.2355660000
	node: 37, val: 0.2148580000
	node: 38, val: 0.0000000000
	node: 39, val: 0.0000000000
	node: 40, val: 0.2216060000
	node: 41, val: 0.0000000000
	node: 42, val: 0.0000000000
	node: 43, val: 0.0000000000
	node: 44, val: 0.0000000000
	node: 45, val: 0.0000000000
	node: 46, val: 0.0370344000
	node: 47, val: 0.0538087000
	node: 48, val: 0.0000000000
	node: 49, val: 0.1759170000

when compute layer[1] to layer[2]
compute layer: 2, node : 0
0.2276300000 * -0.1842020000 = -0.0419299013 
0.0000000000 * 0.0343834000 = -0.0419299013 
0.0534094000 * -0.1151420000 = -0.0480795664 
0.0000000000 * 0.1847530000 = -0.0480795664 
0.0000000000 * -0.1371480000 = -0.0480795664 
0.0000000000 * -0.1893170000 = -0.0480795664 
0.0746065000 * -0.7486950000 = -0.1039370799 
0.0000000000 * 0.5758490000 = -0.1039370799 
0.0000000000 * -0.0133157000 = -0.1039370799 
0.0000000000 * 0.1436410000 = -0.1039370799 
0.0587109000 * 0.1330670000 = -0.0961245966 
0.1839170000 * -0.2244180000 = -0.1373988819 
0.1319570000 * 0.3021480000 = -0.0975283383 
0.0000000000 * 0.0408489000 = -0.0975283383 
0.1969290000 * -0.3395590000 = -0.1643973526 
0.2066640000 * 0.0649170000 = -0.1509813457 
0.0000000000 * 0.0731692000 = -0.1509813457 
0.0306576000 * -0.4592310000 = -0.1650602660 
0.0000000000 * 0.4747440000 = -0.1650602660 
0.0000000000 * 0.3772260000 = -0.1650602660 
0.0000000000 * -1.1140700000 = -0.1650602660 
0.0000000000 * -0.5718530000 = -0.1650602660 
0.0969635000 * 0.0499151000 = -0.1602203232 
0.0098326600 * -0.2542060000 = -0.1627198443 
0.0000000000 * -0.0252440000 = -0.1627198443 
0.0000000000 * 0.2257680000 = -0.1627198443 
0.0000000000 * 0.1499620000 = -0.1627198443 
0.0710148000 * -0.1552020000 = -0.1737414833 
0.0000000000 * -0.0172013000 = -0.1737414833 
0.0000000000 * 0.9906860000 = -0.1737414833 
0.5590840000 * 0.0783843000 = -0.1299180754 
0.1354830000 * -0.1441980000 = -0.1494544530 
0.0000000000 * -0.1790750000 = -0.1494544530 
0.0000000000 * -0.3400370000 = -0.1494544530 
0.7596380000 * 0.2123210000 = 0.0118326468 
0.1328250000 * 0.0082580600 = 0.0129295236 
0.2355660000 * 0.0684292000 = 0.0290491166 
0.2148580000 * 0.5879460000 = 0.1553740182 
0.0000000000 * -0.1707120000 = 0.1553740182 
0.0000000000 * -0.5436900000 = 0.1553740182 
0.2216060000 * 0.1189320000 = 0.1817300630 
0.0000000000 * -0.4958530000 = 0.1817300630 
0.0000000000 * -1.6665200000 = 0.1817300630 
0.0000000000 * -0.3240740000 = 0.1817300630 
0.0000000000 * -0.0154229000 = 0.1817300630 
0.0000000000 * 0.5101000000 = 0.1817300630 
0.0370344000 * 0.0940898000 = 0.1852146223 
0.0538087000 * 0.3373880000 = 0.2033690320 
0.0000000000 * 0.3956710000 = 0.2033690320 
0.1759170000 * -0.2234730000 = 0.1640563322 
the biases is : 0.0835500000, now tempVal is : 0.2476063322
compute layer: 2, node : 1
0.2276300000 * 0.0171639000 = 0.0039070186 
0.0000000000 * -0.0344739000 = 0.0039070186 
0.0534094000 * -0.0086931100 = 0.0034427248 
0.0000000000 * 0.0381665000 = 0.0034427248 
0.0000000000 * 0.0214070000 = 0.0034427248 
0.0000000000 * 0.0421881000 = 0.0034427248 
0.0746065000 * 0.0215526000 = 0.0050506888 
0.0000000000 * -0.0336170000 = 0.0050506888 
0.0000000000 * -0.0474388000 = 0.0050506888 
0.0000000000 * 0.0213502000 = 0.0050506888 
0.0587109000 * 0.0099430900 = 0.0056344566 
0.1839170000 * 0.0277698000 = 0.0107417949 
0.1319570000 * 0.0049270700 = 0.0113919563 
0.0000000000 * -0.0427201000 = 0.0113919563 
0.1969290000 * -0.0240032000 = 0.0066650301 
0.2066640000 * -0.0322351000 = 0.0000031954 
0.0000000000 * 0.0133943000 = 0.0000031954 
0.0306576000 * -0.0423694000 = -0.0012957487 
0.0000000000 * -0.0401146000 = -0.0012957487 
0.0000000000 * -0.0174541000 = -0.0012957487 
0.0000000000 * -0.0423118000 = -0.0012957487 
0.0000000000 * 0.0146571000 = -0.0012957487 
0.0969635000 * -0.0313675000 = -0.0043372513 
0.0098326600 * 0.0384782000 = -0.0039589083 
0.0000000000 * 0.0464228000 = -0.0039589083 
0.0000000000 * 0.0218262000 = -0.0039589083 
0.0000000000 * 0.0159546000 = -0.0039589083 
0.0710148000 * 0.0041746100 = -0.0036624492 
0.0000000000 * 0.0174008000 = -0.0036624492 
0.0000000000 * -0.0178484000 = -0.0036624492 
0.5590840000 * -0.0479125000 = -0.0304495613 
0.1354830000 * -0.0040848600 = -0.0310029904 
0.0000000000 * -0.0418420000 = -0.0310029904 
0.0000000000 * 0.0014546000 = -0.0310029904 
0.7596380000 * -0.0508771000 = -0.0696511689 
0.1328250000 * -0.0463350000 = -0.0758056153 
0.2355660000 * 0.0214261000 = -0.0707583546 
0.2148580000 * -0.0532753000 = -0.0822049790 
0.0000000000 * -0.0573137000 = -0.0822049790 
0.0000000000 * 0.0289767000 = -0.0822049790 
0.2216060000 * -0.0329390000 = -0.0895044590 
0.0000000000 * -0.0319730000 = -0.0895044590 
0.0000000000 * -0.0333988000 = -0.0895044590 
0.0000000000 * -0.0227086000 = -0.0895044590 
0.0000000000 * -0.0154722000 = -0.0895044590 
0.0000000000 * -0.0484061000 = -0.0895044590 
0.0370344000 * -0.0071155000 = -0.0897679773 
0.0538087000 * -0.0371157000 = -0.0917651249 
0.0000000000 * 0.0196442000 = -0.0917651249 
0.1759170000 * -0.0351744000 = -0.0979528998 
the biases is : -0.0213261000, now tempVal is : -0.1192789998
ReLU !!! in layer: 2, node : 1, its linear result is negative,so set it to 0
compute layer: 2, node : 2
0.2276300000 * 0.0698282000 = 0.0158949932 
0.0000000000 * -0.0040891100 = 0.0158949932 
0.0534094000 * -0.2779970000 = 0.0010473402 
0.0000000000 * 0.2587900000 = 0.0010473402 
0.0000000000 * 0.1558200000 = 0.0010473402 
0.0000000000 * -1.3315100000 = 0.0010473402 
0.0746065000 * -1.3118800000 = -0.0968274350 
0.0000000000 * -0.8931890000 = -0.0968274350 
0.0000000000 * 0.1954450000 = -0.0968274350 
0.0000000000 * 0.3840270000 = -0.0968274350 
0.0587109000 * 0.0427115000 = -0.0943198044 
0.1839170000 * -0.5393980000 = -0.1935242664 
0.1319570000 * 0.0812943000 = -0.1827969144 
0.0000000000 * 0.4012880000 = -0.1827969144 
0.1969290000 * -0.2745140000 = -0.2368566819 
0.2066640000 * 0.3679320000 = -0.1608183831 
0.0000000000 * -0.7606050000 = -0.1608183831 
0.0306576000 * -1.2934900000 = -0.2004736821 
0.0000000000 * 1.4711000000 = -0.2004736821 
0.0000000000 * 0.0977806000 = -0.2004736821 
0.0000000000 * -0.7900990000 = -0.2004736821 
0.0000000000 * -0.5346640000 = -0.2004736821 
0.0969635000 * 0.0072076800 = -0.1997748002 
0.0098326600 * -0.5536680000 = -0.2052188294 
0.0000000000 * -0.0219908000 = -0.2052188294 
0.0000000000 * 0.2653260000 = -0.2052188294 
0.0000000000 * 0.2039530000 = -0.2052188294 
0.0710148000 * 0.4091550000 = -0.1761627689 
0.0000000000 * -0.8595080000 = -0.1761627689 
0.0000000000 * 0.1875610000 = -0.1761627689 
0.5590840000 * 0.2424370000 = -0.0406201212 
0.1354830000 * -0.1128240000 = -0.0559058552 
0.0000000000 * 0.5265230000 = -0.0559058552 
0.0000000000 * -0.4639040000 = -0.0559058552 
0.7596380000 * -0.3643380000 = -0.3326708449 
0.1328250000 * 0.0536935000 = -0.3255390057 
0.2355660000 * 0.4436250000 = -0.2210360390 
0.2148580000 * 0.9196640000 = -0.0234388713 
0.0000000000 * 0.6399510000 = -0.0234388713 
0.0000000000 * -0.8787680000 = -0.0234388713 
0.2216060000 * -0.9785080000 = -0.2402821151 
0.0000000000 * -0.0391997000 = -0.2402821151 
0.0000000000 * 0.1421490000 = -0.2402821151 
0.0000000000 * -0.7985070000 = -0.2402821151 
0.0000000000 * -1.7670100000 = -0.2402821151 
0.0000000000 * 0.1529520000 = -0.2402821151 
0.0370344000 * 0.2610300000 = -0.2306150257 
0.0538087000 * -1.8765200000 = -0.3315881274 
0.0000000000 * -0.5922080000 = -0.3315881274 
0.1759170000 * 0.4406220000 = -0.2540752270 
the biases is : 0.7562910000, now tempVal is : 0.5022157730
compute layer: 2, node : 3
0.2276300000 * 0.7948370000 = 0.1809287463 
0.0000000000 * -0.3629800000 = 0.1809287463 
0.0534094000 * -0.1719110000 = 0.1717470829 
0.0000000000 * 0.0975946000 = 0.1717470829 
0.0000000000 * 0.0271402000 = 0.1717470829 
0.0000000000 * -0.4153270000 = 0.1717470829 
0.0746065000 * -0.0924507000 = 0.1648496598 
0.0000000000 * -0.6026030000 = 0.1648496598 
0.0000000000 * -0.3209250000 = 0.1648496598 
0.0000000000 * 0.4353300000 = 0.1648496598 
0.0587109000 * 0.5276300000 = 0.1958272920 
0.1839170000 * -0.4154120000 = 0.1194259632 
0.1319570000 * -0.1957730000 = 0.0935923454 
0.0000000000 * -0.0372765000 = 0.0935923454 
0.1969290000 * -1.0078300000 = -0.1048786087 
0.2066640000 * 0.1334260000 = -0.0773042578 
0.0000000000 * 0.2483560000 = -0.0773042578 
0.0306576000 * -1.6986500000 = -0.1293807900 
0.0000000000 * 2.0109900000 = -0.1293807900 
0.0000000000 * -0.7071260000 = -0.1293807900 
0.0000000000 * 1.1549700000 = -0.1293807900 
0.0000000000 * 0.5270520000 = -0.1293807900 
0.0969635000 * -0.1694220000 = -0.1458085401 
0.0098326600 * 0.3635580000 = -0.1422337979 
0.0000000000 * -0.0301804000 = -0.1422337979 
0.0000000000 * 0.7705380000 = -0.1422337979 
0.0000000000 * -0.3775480000 = -0.1422337979 
0.0710148000 * -0.0137244000 = -0.1432084335 
0.0000000000 * -0.4877390000 = -0.1432084335 
0.0000000000 * 0.2263300000 = -0.1432084335 
0.5590840000 * 0.3835430000 = 0.0712243212 
0.1354830000 * 0.2819000000 = 0.1094169789 
0.0000000000 * -0.4767640000 = 0.1094169789 
0.0000000000 * 0.0090300800 = 0.1094169789 
0.7596380000 * -0.1014260000 = 0.0323699351 
0.1328250000 * -0.6209820000 = -0.0501119991 
0.2355660000 * 0.0044563500 = -0.0490622345 
0.2148580000 * -0.1441750000 = -0.0800393867 
0.0000000000 * -0.1324670000 = -0.0800393867 
0.0000000000 * 0.3566080000 = -0.0800393867 
0.2216060000 * 0.0580446000 = -0.0671763551 
0.0000000000 * -0.4553110000 = -0.0671763551 
0.0000000000 * -0.7071040000 = -0.0671763551 
0.0000000000 * -0.4053810000 = -0.0671763551 
0.0000000000 * -0.0423059000 = -0.0671763551 
0.0000000000 * 0.5968770000 = -0.0671763551 
0.0370344000 * -0.2176350000 = -0.0752363367 
0.0538087000 * -0.1288990000 = -0.0821722243 
0.0000000000 * -0.1266110000 = -0.0821722243 
0.1759170000 * -0.1728460000 = -0.1125787741 
the biases is : -1.2508200000, now tempVal is : -1.3633987741
ReLU !!! in layer: 2, node : 3, its linear result is negative,so set it to 0
compute layer: 2, node : 4
0.2276300000 * -0.0585128000 = -0.0133192687 
0.0000000000 * 0.0070839400 = -0.0133192687 
0.0534094000 * 0.2681160000 = 0.0010006460 
0.0000000000 * -0.0065952100 = 0.0010006460 
0.0000000000 * 0.3158060000 = 0.0010006460 
0.0000000000 * -0.0537580000 = 0.0010006460 
0.0746065000 * 0.3656860000 = 0.0282831986 
0.0000000000 * 0.0360562000 = 0.0282831986 
0.0000000000 * -0.0474430000 = 0.0282831986 
0.0000000000 * -0.3712960000 = 0.0282831986 
0.0587109000 * 0.1539740000 = 0.0373231507 
0.1839170000 * -0.2157010000 = -0.0023479301 
0.1319570000 * 0.1462400000 = 0.0169494616 
0.0000000000 * 0.4145880000 = 0.0169494616 
0.1969290000 * -0.0522092000 = 0.0066679560 
0.2066640000 * -0.1221010000 = -0.0185659250 
0.0000000000 * -0.2384320000 = -0.0185659250 
0.0306576000 * -1.0995300000 = -0.0522748760 
0.0000000000 * -3.2050900000 = -0.0522748760 
0.0000000000 * -0.4389480000 = -0.0522748760 
0.0000000000 * -0.2605570000 = -0.0522748760 
0.0000000000 * -0.2692360000 = -0.0522748760 
0.0969635000 * -0.0409149000 = -0.0562421279 
0.0098326600 * 0.3691510000 = -0.0526123916 
0.0000000000 * -0.0435317000 = -0.0526123916 
0.0000000000 * -0.3444750000 = -0.0526123916 
0.0000000000 * -0.3709950000 = -0.0526123916 
0.0710148000 * -0.3688110000 = -0.0788034310 
0.0000000000 * -0.0348575000 = -0.0788034310 
0.0000000000 * 0.3837940000 = -0.0788034310 
0.5590840000 * -0.1040120000 = -0.1369548760 
0.1354830000 * -0.3459750000 = -0.1838286069 
0.0000000000 * 0.5255360000 = -0.1838286069 
0.0000000000 * 0.1402270000 = -0.1838286069 
0.7596380000 * 0.1560700000 = -0.0652719043 
0.1328250000 * 0.5730220000 = 0.0108397429 
0.2355660000 * -0.0164260000 = 0.0069703357 
0.2148580000 * -0.1342210000 = -0.0218681199 
0.0000000000 * -0.1335250000 = -0.0218681199 
0.0000000000 * 0.0098979100 = -0.0218681199 
0.2216060000 * -0.2180300000 = -0.0701848760 
0.0000000000 * -0.1565270000 = -0.0701848760 
0.0000000000 * -0.6396690000 = -0.0701848760 
0.0000000000 * 0.6675580000 = -0.0701848760 
0.0000000000 * 0.4149960000 = -0.0701848760 
0.0000000000 * 0.3240160000 = -0.0701848760 
0.0370344000 * -0.0659676000 = -0.0726279465 
0.0538087000 * 0.8590810000 = -0.0264019147 
0.0000000000 * -0.6195510000 = -0.0264019147 
0.1759170000 * -0.0111750000 = -0.0283677872 
the biases is : 0.1784690000, now tempVal is : 0.1501012128
compute layer: 2, node : 5
0.2276300000 * 0.0332535000 = 0.0075694942 
0.0000000000 * -0.0810360000 = 0.0075694942 
0.0534094000 * -0.5344100000 = -0.0209730232 
0.0000000000 * 0.6679560000 = -0.0209730232 
0.0000000000 * -0.8125300000 = -0.0209730232 
0.0000000000 * 1.2967700000 = -0.0209730232 
0.0746065000 * 1.2687000000 = 0.0736802433 
0.0000000000 * 0.7043890000 = 0.0736802433 
0.0000000000 * 0.1178200000 = 0.0736802433 
0.0000000000 * 0.0314183000 = 0.0736802433 
0.0587109000 * 0.3458930000 = 0.0939879326 
0.1839170000 * -1.2767600000 = -0.1408299363 
0.1319570000 * 0.2593260000 = -0.1066100553 
0.0000000000 * 0.7558130000 = -0.1066100553 
0.1969290000 * 0.5589890000 = 0.0034710895 
0.2066640000 * -0.1236100000 = -0.0220746476 
0.0000000000 * -0.3169660000 = -0.0220746476 
0.0306576000 * -1.3892900000 = -0.0646669447 
0.0000000000 * -2.3307300000 = -0.0646669447 
0.0000000000 * 0.6847390000 = -0.0646669447 
0.0000000000 * 0.0419089000 = -0.0646669447 
0.0000000000 * -0.6414080000 = -0.0646669447 
0.0969635000 * -0.0220248000 = -0.0668025464 
0.0098326600 * -0.8151360000 = -0.0748175015 
0.0000000000 * 0.0362659000 = -0.0748175015 
0.0000000000 * -0.3328060000 = -0.0748175015 
0.0000000000 * -0.1741750000 = -0.0748175015 
0.0710148000 * -0.6641140000 = -0.1219794244 
0.0000000000 * 0.2154660000 = -0.1219794244 
0.0000000000 * 0.4145450000 = -0.1219794244 
0.5590840000 * -0.3162140000 = -0.2987696124 
0.1354830000 * 0.4108800000 = -0.2431023573 
0.0000000000 * 0.6564230000 = -0.2431023573 
0.0000000000 * 1.7172100000 = -0.2431023573 
0.7596380000 * -0.3503900000 = -0.5092719161 
0.1328250000 * 0.0743160000 = -0.4994008934 
0.2355660000 * 0.3742490000 = -0.4112405535 
0.2148580000 * 0.2392120000 = -0.3598439416 
0.0000000000 * 1.4504200000 = -0.3598439416 
0.0000000000 * -0.3212680000 = -0.3598439416 
0.2216060000 * 0.2451780000 = -0.3055110257 
0.0000000000 * -0.7175880000 = -0.3055110257 
0.0000000000 * -1.7871000000 = -0.3055110257 
0.0000000000 * 1.1418800000 = -0.3055110257 
0.0000000000 * 0.2827640000 = -0.3055110257 
0.0000000000 * 0.7949520000 = -0.3055110257 
0.0370344000 * -0.2997620000 = -0.3166125316 
0.0538087000 * -0.7730110000 = -0.3582072486 
0.0000000000 * -0.0411885000 = -0.3582072486 
0.1759170000 * 0.8197620000 = -0.2139971768 
the biases is : -0.3391580000, now tempVal is : -0.5531551768
ReLU !!! in layer: 2, node : 5, its linear result is negative,so set it to 0
compute layer: 2, node : 6
0.2276300000 * -0.2083000000 = -0.0474153290 
0.0000000000 * 0.8351330000 = -0.0474153290 
0.0534094000 * -0.1512150000 = -0.0554916314 
0.0000000000 * 1.1516200000 = -0.0554916314 
0.0000000000 * 0.2215740000 = -0.0554916314 
0.0000000000 * 0.1082330000 = -0.0554916314 
0.0746065000 * 0.0651310000 = -0.0506324355 
0.0000000000 * 0.1454650000 = -0.0506324355 
0.0000000000 * 0.6319300000 = -0.0506324355 
0.0000000000 * 0.1088890000 = -0.0506324355 
0.0587109000 * 0.5082790000 = -0.0207909179 
0.1839170000 * -0.2691290000 = -0.0702883162 
0.1319570000 * -0.1981870000 = -0.0964404782 
0.0000000000 * 0.1723190000 = -0.0964404782 
0.1969290000 * 0.3258390000 = -0.0322733297 
0.2066640000 * 0.0612855000 = -0.0196078232 
0.0000000000 * -0.6353110000 = -0.0196078232 
0.0306576000 * -0.4355580000 = -0.0329609861 
0.0000000000 * 0.5906710000 = -0.0329609861 
0.0000000000 * 0.0923703000 = -0.0329609861 
0.0000000000 * -0.0099110000 = -0.0329609861 
0.0000000000 * -0.2275690000 = -0.0329609861 
0.0969635000 * -0.3912200000 = -0.0708950466 
0.0098326600 * 0.0431908000 = -0.0704703661 
0.0000000000 * -0.0457549000 = -0.0704703661 
0.0000000000 * 0.2002470000 = -0.0704703661 
0.0000000000 * 0.1274290000 = -0.0704703661 
0.0710148000 * -0.3269690000 = -0.0936900043 
0.0000000000 * 0.5948830000 = -0.0936900043 
0.0000000000 * -0.4127270000 = -0.0936900043 
0.5590840000 * 0.1784820000 = 0.0060964262 
0.1354830000 * 0.0057863600 = 0.0068803796 
0.0000000000 * -0.6611920000 = 0.0068803796 
0.0000000000 * 0.0103202000 = 0.0068803796 
0.7596380000 * -0.1103290000 = -0.0769297213 
0.1328250000 * 0.5420600000 = -0.0049306018 
0.2355660000 * 0.1588930000 = 0.0324991867 
0.2148580000 * 0.4666560000 = 0.1327639615 
0.0000000000 * -0.2702180000 = 0.1327639615 
0.0000000000 * -0.2238800000 = 0.1327639615 
0.2216060000 * -0.0313375000 = 0.1258193835 
0.0000000000 * -0.2381890000 = 0.1258193835 
0.0000000000 * -0.3998780000 = 0.1258193835 
0.0000000000 * 0.7289620000 = 0.1258193835 
0.0000000000 * 0.1098750000 = 0.1258193835 
0.0000000000 * -0.5188200000 = 0.1258193835 
0.0370344000 * 0.2804400000 = 0.1362053106 
0.0538087000 * 0.3656760000 = 0.1558818608 
0.0000000000 * 1.3629000000 = 0.1558818608 
0.1759170000 * -0.1381010000 = 0.1315875472 
the biases is : 0.1092260000, now tempVal is : 0.2408135472
compute layer: 2, node : 7
0.2276300000 * -1.1053300000 = -0.2516062679 
0.0000000000 * 0.2787980000 = -0.2516062679 
0.0534094000 * -1.3499500000 = -0.3237062874 
0.0000000000 * -0.0696007000 = -0.3237062874 
0.0000000000 * 0.7549570000 = -0.3237062874 
0.0000000000 * 2.5771600000 = -0.3237062874 
0.0746065000 * 0.0865201000 = -0.3172513256 
0.0000000000 * 0.5112880000 = -0.3172513256 
0.0000000000 * -0.0577744000 = -0.3172513256 
0.0000000000 * -0.1040500000 = -0.3172513256 
0.0587109000 * -0.4239330000 = -0.3421408136 
0.1839170000 * -0.2138070000 = -0.3814635556 
0.1319570000 * 0.0263156000 = -0.3779910279 
0.0000000000 * 3.1673000000 = -0.3779910279 
0.1969290000 * 0.7054540000 = -0.2390666772 
0.2066640000 * 0.1564420000 = -0.2067357477 
0.0000000000 * 0.1157420000 = -0.2067357477 
0.0306576000 * 0.8896920000 = -0.1794599262 
0.0000000000 * 0.0485605000 = -0.1794599262 
0.0000000000 * -0.3294140000 = -0.1794599262 
0.0000000000 * -7.3952400000 = -0.1794599262 
0.0000000000 * -0.5877560000 = -0.1794599262 
0.0969635000 * 0.6794890000 = -0.1135742946 
0.0098326600 * 0.4040110000 = -0.1096017918 
0.0000000000 * 0.0353466000 = -0.1096017918 
0.0000000000 * -1.8015900000 = -0.1096017918 
0.0000000000 * -0.3956590000 = -0.1096017918 
0.0710148000 * 0.1975220000 = -0.0955748065 
0.0000000000 * -0.2886670000 = -0.0955748065 
0.0000000000 * -0.8305360000 = -0.0955748065 
0.5590840000 * 0.3180750000 = 0.0822558368 
0.1354830000 * -0.8181030000 = -0.0285832119 
0.0000000000 * -0.7430750000 = -0.0285832119 
0.0000000000 * 0.3684270000 = -0.0285832119 
0.7596380000 * 0.0233990000 = -0.0108084423 
0.1328250000 * 0.4078310000 = 0.0433617102 
0.2355660000 * -1.0419900000 = -0.2020957061 
0.2148580000 * 0.4838190000 = -0.0981433234 
0.0000000000 * 0.0828921000 = -0.0981433234 
0.0000000000 * 0.3572200000 = -0.0981433234 
0.2216060000 * -1.5017400000 = -0.4309379178 
0.0000000000 * -0.1962540000 = -0.4309379178 
0.0000000000 * 0.7254350000 = -0.4309379178 
0.0000000000 * 0.2227410000 = -0.4309379178 
0.0000000000 * 0.0339974000 = -0.4309379178 
0.0000000000 * -0.5839280000 = -0.4309379178 
0.0370344000 * 0.0931427000 = -0.4274884338 
0.0538087000 * 0.3281580000 = -0.4098306785 
0.0000000000 * 0.8231240000 = -0.4098306785 
0.1759170000 * 0.0510477000 = -0.4008505202 
the biases is : -1.2621400000, now tempVal is : -1.6629905202
ReLU !!! in layer: 2, node : 7, its linear result is negative,so set it to 0
compute layer: 2, node : 8
0.2276300000 * 0.0180697000 = 0.0041132058 
0.0000000000 * -0.1209980000 = 0.0041132058 
0.0534094000 * -0.1933420000 = -0.0062130744 
0.0000000000 * 0.8577900000 = -0.0062130744 
0.0000000000 * -1.7599600000 = -0.0062130744 
0.0000000000 * -0.1456970000 = -0.0062130744 
0.0746065000 * 2.5676400000 = 0.1853495593 
0.0000000000 * 0.7827730000 = 0.1853495593 
0.0000000000 * 0.4503780000 = 0.1853495593 
0.0000000000 * -0.0982587000 = 0.1853495593 
0.0587109000 * -0.1247000000 = 0.1780283100 
0.1839170000 * -0.7263800000 = 0.0444346796 
0.1319570000 * -0.7323090000 = -0.0521986191 
0.0000000000 * 0.1535150000 = -0.0521986191 
0.1969290000 * -0.0326798000 = -0.0586342195 
0.2066640000 * 0.0859862000 = -0.0408639674 
0.0000000000 * -0.5698070000 = -0.0408639674 
0.0306576000 * 0.3940190000 = -0.0287842905 
0.0000000000 * 0.1174620000 = -0.0287842905 
0.0000000000 * 0.2512210000 = -0.0287842905 
0.0000000000 * 0.8458530000 = -0.0287842905 
0.0000000000 * 0.8477210000 = -0.0287842905 
0.0969635000 * 0.4211440000 = 0.0120513057 
0.0098326600 * 0.5733810000 = 0.0176891661 
0.0000000000 * 0.0250970000 = 0.0176891661 
0.0000000000 * -0.1707900000 = 0.0176891661 
0.0000000000 * -0.1277280000 = 0.0176891661 
0.0710148000 * 0.0083142500 = 0.0182796009 
0.0000000000 * 0.0787938000 = 0.0182796009 
0.0000000000 * 2.5770000000 = 0.0182796009 
0.5590840000 * -1.2993800000 = -0.7081829670 
0.1354830000 * 0.6911620000 = -0.6145422658 
0.0000000000 * -3.3245400000 = -0.6145422658 
0.0000000000 * -1.3571300000 = -0.6145422658 
0.7596380000 * -2.2021100000 = -2.2873487019 
0.1328250000 * 0.3927620000 = -2.2351800893 
0.2355660000 * 0.3731190000 = -2.1472859389 
0.2148580000 * 0.2802670000 = -2.0870683318 
0.0000000000 * -0.6100760000 = -2.0870683318 
0.0000000000 * 0.1030840000 = -2.0870683318 
0.2216060000 * -0.2776290000 = -2.1485925840 
0.0000000000 * 1.4285800000 = -2.1485925840 
0.0000000000 * 0.4732110000 = -2.1485925840 
0.0000000000 * -0.6736070000 = -2.1485925840 
0.0000000000 * 1.2108200000 = -2.1485925840 
0.0000000000 * -1.3545700000 = -2.1485925840 
0.0370344000 * 0.1019840000 = -2.1448156678 
0.0538087000 * -1.7022600000 = -2.2364120654 
0.0000000000 * 1.0881100000 = -2.2364120654 
0.1759170000 * -0.8126260000 = -2.3793667935 
the biases is : -0.3564880000, now tempVal is : -2.7358547935
ReLU !!! in layer: 2, node : 8, its linear result is negative,so set it to 0
compute layer: 2, node : 9
0.2276300000 * 0.2346120000 = 0.0534047296 
0.0000000000 * -0.0086511600 = 0.0534047296 
0.0534094000 * 0.0404159000 = 0.0555633185 
0.0000000000 * 0.2513500000 = 0.0555633185 
0.0000000000 * 0.6556180000 = 0.0555633185 
0.0000000000 * -0.1878350000 = 0.0555633185 
0.0746065000 * -0.6281190000 = 0.0087015584 
0.0000000000 * 0.5180790000 = 0.0087015584 
0.0000000000 * -0.3966700000 = 0.0087015584 
0.0000000000 * -0.7894200000 = 0.0087015584 
0.0587109000 * 0.1755550000 = 0.0190085504 
0.1839170000 * -0.3920380000 = -0.0530939024 
0.1319570000 * 0.2777560000 = -0.0164420539 
0.0000000000 * -1.0572700000 = -0.0164420539 
0.1969290000 * 0.5260560000 = 0.0871536281 
0.2066640000 * 0.5107970000 = 0.1927169793 
0.0000000000 * -0.1060470000 = 0.1927169793 
0.0306576000 * -1.6758300000 = 0.1413400535 
0.0000000000 * 1.8073600000 = 0.1413400535 
0.0000000000 * -0.2339500000 = 0.1413400535 
0.0000000000 * 0.7015260000 = 0.1413400535 
0.0000000000 * -0.5413580000 = 0.1413400535 
0.0969635000 * 0.1059990000 = 0.1516180875 
0.0098326600 * -0.1678280000 = 0.1499678918 
0.0000000000 * -0.0292290000 = 0.1499678918 
0.0000000000 * 1.1497500000 = 0.1499678918 
0.0000000000 * -0.1596500000 = 0.1499678918 
0.0710148000 * -0.2276140000 = 0.1338039292 
0.0000000000 * -0.1355540000 = 0.1338039292 
0.0000000000 * 1.5645400000 = 0.1338039292 
0.5590840000 * 0.7807790000 = 0.5703249756 
0.1354830000 * -0.7246060000 = 0.4721531809 
0.0000000000 * -0.5939930000 = 0.4721531809 
0.0000000000 * -0.9988910000 = 0.4721531809 
0.7596380000 * 0.0919827000 = 0.5420267352 
0.1328250000 * 0.4505940000 = 0.6018768832 
0.2355660000 * -0.5389010000 = 0.4749301302 
0.2148580000 * 0.5476490000 = 0.5925968991 
0.0000000000 * -0.3131180000 = 0.5925968991 
0.0000000000 * -0.1047410000 = 0.5925968991 
0.2216060000 * 0.4105570000 = 0.6835787936 
0.0000000000 * 0.7516590000 = 0.6835787936 
0.0000000000 * 0.4949660000 = 0.6835787936 
0.0000000000 * -0.8581620000 = 0.6835787936 
0.0000000000 * -0.2389850000 = 0.6835787936 
0.0000000000 * -0.2391990000 = 0.6835787936 
0.0370344000 * 0.4235370000 = 0.6992642323 
0.0538087000 * -0.2739490000 = 0.6845233927 
0.0000000000 * 0.2232150000 = 0.6845233927 
0.1759170000 * -0.1299850000 = 0.6616568215 
the biases is : -0.0082937900, now tempVal is : 0.6533630315
compute layer: 2, node : 10
0.2276300000 * -0.0058278800 = -0.0013266003 
0.0000000000 * 0.0164447000 = -0.0013266003 
0.0534094000 * -0.0498632000 = -0.0039897639 
0.0000000000 * -0.0581705000 = -0.0039897639 
0.0000000000 * 0.0244792000 = -0.0039897639 
0.0000000000 * 0.0157947000 = -0.0039897639 
0.0746065000 * -0.0355860000 = -0.0066447108 
0.0000000000 * 0.0039522200 = -0.0066447108 
0.0000000000 * -0.0216416000 = -0.0066447108 
0.0000000000 * 0.0112976000 = -0.0066447108 
0.0587109000 * 0.0100584000 = -0.0060541731 
0.1839170000 * -0.0641057000 = -0.0178443011 
0.1319570000 * 0.0240168000 = -0.0146751163 
0.0000000000 * 0.0058284200 = -0.0146751163 
0.1969290000 * -0.0351634000 = -0.0215998095 
0.2066640000 * 0.0137765000 = -0.0187527029 
0.0000000000 * -0.0420780000 = -0.0187527029 
0.0306576000 * -0.0348972000 = -0.0198225673 
0.0000000000 * -0.0375012000 = -0.0198225673 
0.0000000000 * -0.0257387000 = -0.0198225673 
0.0000000000 * -0.0546805000 = -0.0198225673 
0.0000000000 * -0.0358484000 = -0.0198225673 
0.0969635000 * 0.0020848900 = -0.0196204090 
0.0098326600 * -0.0363354000 = -0.0199776827 
0.0000000000 * 0.0247895000 = -0.0199776827 
0.0000000000 * 0.0334971000 = -0.0199776827 
0.0000000000 * 0.0216527000 = -0.0199776827 
0.0710148000 * 0.0198412000 = -0.0185686638 
0.0000000000 * -0.0471676000 = -0.0185686638 
0.0000000000 * -0.0070608000 = -0.0185686638 
0.5590840000 * -0.0093093700 = -0.0237733836 
0.1354830000 * -0.0494431000 = -0.0304720831 
0.0000000000 * -0.0618612000 = -0.0304720831 
0.0000000000 * 0.0300086000 = -0.0304720831 
0.7596380000 * -0.0300961000 = -0.0533342244 
0.1328250000 * 0.0139052000 = -0.0514872662 
0.2355660000 * -0.0482571000 = -0.0628549982 
0.2148580000 * -0.0045128400 = -0.0638246180 
0.0000000000 * -0.0189375000 = -0.0638246180 
0.0000000000 * 0.0402270000 = -0.0638246180 
0.2216060000 * 0.0181820000 = -0.0597953777 
0.0000000000 * 0.0375883000 = -0.0597953777 
0.0000000000 * -0.0270563000 = -0.0597953777 
0.0000000000 * 0.0337168000 = -0.0597953777 
0.0000000000 * -0.0198271000 = -0.0597953777 
0.0000000000 * -0.0165858000 = -0.0597953777 
0.0370344000 * 0.0209145000 = -0.0590208217 
0.0538087000 * -0.0422434000 = -0.0612938842 
0.0000000000 * -0.0260662000 = -0.0612938842 
0.1759170000 * -0.0249860000 = -0.0656893463 
the biases is : -0.0201183000, now tempVal is : -0.0858076463
ReLU !!! in layer: 2, node : 10, its linear result is negative,so set it to 0
compute layer: 2, node : 11
0.2276300000 * 0.2800570000 = 0.0637493749 
0.0000000000 * 0.3778010000 = 0.0637493749 
0.0534094000 * -0.4419520000 = 0.0401449838 
0.0000000000 * -1.2784500000 = 0.0401449838 
0.0000000000 * -0.2980680000 = 0.0401449838 
0.0000000000 * 1.2817100000 = 0.0401449838 
0.0746065000 * -0.5425600000 = -0.0003335189 
0.0000000000 * -0.3464680000 = -0.0003335189 
0.0000000000 * 0.2757640000 = -0.0003335189 
0.0000000000 * 0.5252150000 = -0.0003335189 
0.0587109000 * -0.2957720000 = -0.0176985592 
0.1839170000 * -0.5825970000 = -0.1248480516 
0.1319570000 * 0.1660790000 = -0.1029327650 
0.0000000000 * 0.1625960000 = -0.1029327650 
0.1969290000 * 0.3904770000 = -0.0260365199 
0.2066640000 * 0.1612760000 = 0.0072934234 
0.0000000000 * 0.0451447000 = 0.0072934234 
0.0306576000 * -0.1263150000 = 0.0034209086 
0.0000000000 * -1.2024100000 = 0.0034209086 
0.0000000000 * 0.5631220000 = 0.0034209086 
0.0000000000 * 0.4102490000 = 0.0034209086 
0.0000000000 * -1.7728400000 = 0.0034209086 
0.0969635000 * -0.2196240000 = -0.0178746031 
0.0098326600 * -0.1243390000 = -0.0190971862 
0.0000000000 * 0.0045475900 = -0.0190971862 
0.0000000000 * 0.1006020000 = -0.0190971862 
0.0000000000 * -0.5209500000 = -0.0190971862 
0.0710148000 * 0.0338173000 = -0.0166956574 
0.0000000000 * -0.2922700000 = -0.0166956574 
0.0000000000 * 0.1674080000 = -0.0166956574 
0.5590840000 * -0.3396290000 = -0.2065767973 
0.1354830000 * 0.4232170000 = -0.1492380885 
0.0000000000 * 1.0126900000 = -0.1492380885 
0.0000000000 * 0.7836480000 = -0.1492380885 
0.7596380000 * -0.3315970000 = -0.4011317703 
0.1328250000 * -0.6331300000 = -0.4852272626 
0.2355660000 * 0.0739286000 = -0.4678121980 
0.2148580000 * 0.9524320000 = -0.2631745633 
0.0000000000 * 0.2418800000 = -0.2631745633 
0.0000000000 * -0.2774570000 = -0.2631745633 
0.2216060000 * 0.4539790000 = -0.1625700931 
0.0000000000 * -0.0781443000 = -0.1625700931 
0.0000000000 * 0.4903600000 = -0.1625700931 
0.0000000000 * -0.1461280000 = -0.1625700931 
0.0000000000 * -0.8363120000 = -0.1625700931 
0.0000000000 * -0.7999470000 = -0.1625700931 
0.0370344000 * -0.0445305000 = -0.1642192534 
0.0538087000 * -0.0592702000 = -0.1674085058 
0.0000000000 * -0.5236760000 = -0.1674085058 
0.1759170000 * 0.5135790000 = -0.0770612289 
the biases is : -0.1920390000, now tempVal is : -0.2691002289
ReLU !!! in layer: 2, node : 11, its linear result is negative,so set it to 0
compute layer: 2, node : 12
0.2276300000 * 0.1087620000 = 0.0247574941 
0.0000000000 * -0.0242730000 = 0.0247574941 
0.0534094000 * 0.4392080000 = 0.0482153298 
0.0000000000 * 0.6505740000 = 0.0482153298 
0.0000000000 * 0.1965220000 = 0.0482153298 
0.0000000000 * -0.8384040000 = 0.0482153298 
0.0746065000 * 0.1214260000 = 0.0572744987 
0.0000000000 * 1.1703900000 = 0.0572744987 
0.0000000000 * 0.2328180000 = 0.0572744987 
0.0000000000 * 0.3046090000 = 0.0572744987 
0.0587109000 * -0.5359190000 = 0.0258102119 
0.1839170000 * -1.0651400000 = -0.1700871415 
0.1319570000 * 0.8696410000 = -0.0553319241 
0.0000000000 * 0.4960560000 = -0.0553319241 
0.1969290000 * 0.1541520000 = -0.0249749249 
0.2066640000 * 0.0577726000 = -0.0130354083 
0.0000000000 * 0.0889730000 = -0.0130354083 
0.0306576000 * 0.4882960000 = 0.0019345752 
0.0000000000 * -0.7073010000 = 0.0019345752 
0.0000000000 * -0.0893437000 = 0.0019345752 
0.0000000000 * -4.5639500000 = 0.0019345752 
0.0000000000 * 0.1740360000 = 0.0019345752 
0.0969635000 * -0.2110870000 = -0.0185331591 
0.0098326600 * -0.4795640000 = -0.0232485489 
0.0000000000 * -0.0084636000 = -0.0232485489 
0.0000000000 * 1.2371200000 = -0.0232485489 
0.0000000000 * 0.2909100000 = -0.0232485489 
0.0710148000 * 0.0513551000 = -0.0196015767 
0.0000000000 * 0.3974370000 = -0.0196015767 
0.0000000000 * 0.2630760000 = -0.0196015767 
0.5590840000 * -0.8622920000 = -0.5016952373 
0.1354830000 * -0.0608200000 = -0.5099353133 
0.0000000000 * 0.5804930000 = -0.5099353133 
0.0000000000 * 0.3206630000 = -0.5099353133 
0.7596380000 * -0.7836960000 = -1.1052605754 
0.1328250000 * 0.3661650000 = -1.0566247093 
0.2355660000 * -0.0244925000 = -1.0623943095 
0.2148580000 * -0.0981926000 = -1.0834917752 
0.0000000000 * 0.5745100000 = -1.0834917752 
0.0000000000 * -0.5968000000 = -1.0834917752 
0.2216060000 * 0.5892380000 = -0.9529130989 
0.0000000000 * -0.7044960000 = -0.9529130989 
0.0000000000 * -0.5608620000 = -0.9529130989 
0.0000000000 * -0.0839649000 = -0.9529130989 
0.0000000000 * 0.0147986000 = -0.9529130989 
0.0000000000 * 0.1431850000 = -0.9529130989 
0.0370344000 * -0.1125920000 = -0.9570828761 
0.0538087000 * 0.1156900000 = -0.9508577476 
0.0000000000 * 0.0241843000 = -0.9508577476 
0.1759170000 * 0.0078238100 = -0.9494814064 
the biases is : -0.0892578000, now tempVal is : -1.0387392064
ReLU !!! in layer: 2, node : 12, its linear result is negative,so set it to 0
compute layer: 2, node : 13
0.2276300000 * -0.0876624000 = -0.0199545921 
0.0000000000 * 0.6007030000 = -0.0199545921 
0.0534094000 * -0.3934110000 = -0.0409664376 
0.0000000000 * 1.0508800000 = -0.0409664376 
0.0000000000 * 0.2600390000 = -0.0409664376 
0.0000000000 * -0.1386410000 = -0.0409664376 
0.0746065000 * 0.3191350000 = -0.0171568922 
0.0000000000 * -0.5970470000 = -0.0171568922 
0.0000000000 * -0.7055880000 = -0.0171568922 
0.0000000000 * 0.6165100000 = -0.0171568922 
0.0587109000 * -4.6160000000 = -0.2881664066 
0.1839170000 * 0.2724110000 = -0.2380653927 
0.1319570000 * 0.4319700000 = -0.1810639274 
0.0000000000 * -0.1574180000 = -0.1810639274 
0.1969290000 * -0.3286960000 = -0.2457937020 
0.2066640000 * 0.5190950000 = -0.1385154529 
0.0000000000 * -0.8741610000 = -0.1385154529 
0.0306576000 * -0.0952020000 = -0.1414341178 
0.0000000000 * 1.0002000000 = -0.1414341178 
0.0000000000 * -0.2960850000 = -0.1414341178 
0.0000000000 * -0.1763760000 = -0.1414341178 
0.0000000000 * -0.2441040000 = -0.1414341178 
0.0969635000 * 0.4015310000 = -0.1025002666 
0.0098326600 * -0.9503050000 = -0.1118442926 
0.0000000000 * 0.0173988000 = -0.1118442926 
0.0000000000 * -1.4380200000 = -0.1118442926 
0.0000000000 * 1.3382400000 = -0.1118442926 
0.0710148000 * 0.1536400000 = -0.1009335787 
0.0000000000 * -0.4579630000 = -0.1009335787 
0.0000000000 * 0.9471990000 = -0.1009335787 
0.5590840000 * -1.3159200000 = -0.8366433960 
0.1354830000 * 0.2794870000 = -0.7987776588 
0.0000000000 * -0.7737420000 = -0.7987776588 
0.0000000000 * 0.8220720000 = -0.7987776588 
0.7596380000 * -1.3380300000 = -1.8151960919 
0.1328250000 * -0.5672440000 = -1.8905402762 
0.2355660000 * 0.4533840000 = -1.7837384209 
0.2148580000 * 0.2507740000 = -1.7298576208 
0.0000000000 * 0.4291380000 = -1.7298576208 
0.0000000000 * 0.2233680000 = -1.7298576208 
0.2216060000 * 1.0108500000 = -1.5058471957 
0.0000000000 * -0.9842220000 = -1.5058471957 
0.0000000000 * 0.2316510000 = -1.5058471957 
0.0000000000 * 0.1795500000 = -1.5058471957 
0.0000000000 * -0.3077550000 = -1.5058471957 
0.0000000000 * 0.4976360000 = -1.5058471957 
0.0370344000 * 0.3841380000 = -1.4916208753 
0.0538087000 * -0.1429330000 = -1.4993119143 
0.0000000000 * -0.4804060000 = -1.4993119143 
0.1759170000 * -1.6058000000 = -1.7817994329 
the biases is : -0.2063190000, now tempVal is : -1.9881184329
ReLU !!! in layer: 2, node : 13, its linear result is negative,so set it to 0
compute layer: 2, node : 14
0.2276300000 * -0.2620590000 = -0.0596524902 
0.0000000000 * 0.6612480000 = -0.0596524902 
0.0534094000 * -0.4254150000 = -0.0823736501 
0.0000000000 * 0.9885940000 = -0.0823736501 
0.0000000000 * -0.2633240000 = -0.0823736501 
0.0000000000 * -0.0854719000 = -0.0823736501 
0.0746065000 * 0.7272480000 = -0.0281162222 
0.0000000000 * 0.0519006000 = -0.0281162222 
0.0000000000 * -0.0411030000 = -0.0281162222 
0.0000000000 * 1.0341300000 = -0.0281162222 
0.0587109000 * 2.9472100000 = 0.1449171294 
0.1839170000 * -0.6028790000 = 0.0340374324 
0.1319570000 * 0.6644020000 = 0.1217099271 
0.0000000000 * 1.7868200000 = 0.1217099271 
0.1969290000 * -1.7807300000 = -0.2289674511 
0.2066640000 * 0.4425210000 = -0.1375142911 
0.0000000000 * -0.1941330000 = -0.1375142911 
0.0306576000 * 0.6217690000 = -0.1184523458 
0.0000000000 * 0.3884680000 = -0.1184523458 
0.0000000000 * -0.0222371000 = -0.1184523458 
0.0000000000 * 0.0464028000 = -0.1184523458 
0.0000000000 * 0.7264180000 = -0.1184523458 
0.0969635000 * 0.4311740000 = -0.0766442057 
0.0098326600 * -1.1257700000 = -0.0877135193 
0.0000000000 * -0.0164030000 = -0.0877135193 
0.0000000000 * -0.4316340000 = -0.0877135193 
0.0000000000 * -0.7137390000 = -0.0877135193 
0.0710148000 * 0.7689490000 = -0.0331067599 
0.0000000000 * -0.1800230000 = -0.0331067599 
0.0000000000 * 2.3755400000 = -0.0331067599 
0.5590840000 * -1.7070900000 = -0.9875134654 
0.1354830000 * 0.4666080000 = -0.9242960138 
0.0000000000 * 0.9572750000 = -0.9242960138 
0.0000000000 * 1.5436200000 = -0.9242960138 
0.7596380000 * -1.4532900000 = -2.0282703228 
0.1328250000 * -0.7214970000 = -2.1241031618 
0.2355660000 * 0.3165340000 = -2.0495385136 
0.2148580000 * -0.6042710000 = -2.1793709721 
0.0000000000 * 1.5306300000 = -2.1793709721 
0.0000000000 * -0.5032550000 = -2.1793709721 
0.2216060000 * -0.1042540000 = -2.2024742840 
0.0000000000 * 0.7150420000 = -2.2024742840 
0.0000000000 * 0.4911170000 = -2.2024742840 
0.0000000000 * 0.0150418000 = -2.2024742840 
0.0000000000 * 0.1527890000 = -2.2024742840 
0.0000000000 * 0.1638220000 = -2.2024742840 
0.0370344000 * 0.6659240000 = -2.1778121882 
0.0538087000 * -1.1909500000 = -2.2418956595 
0.0000000000 * -0.5363050000 = -2.2418956595 
0.1759170000 * -0.6528800000 = -2.3567483505 
the biases is : 0.1050530000, now tempVal is : -2.2516953505
ReLU !!! in layer: 2, node : 14, its linear result is negative,so set it to 0
compute layer: 2, node : 15
0.2276300000 * -0.6679950000 = -0.1520557019 
0.0000000000 * -0.0202133000 = -0.1520557019 
0.0534094000 * -0.4302600000 = -0.1750356303 
0.0000000000 * -0.5987960000 = -0.1750356303 
0.0000000000 * 0.3534950000 = -0.1750356303 
0.0000000000 * -0.4646020000 = -0.1750356303 
0.0746065000 * -0.1200800000 = -0.1839943788 
0.0000000000 * -0.0441756000 = -0.1839943788 
0.0000000000 * 0.1612970000 = -0.1839943788 
0.0000000000 * 1.1957800000 = -0.1839943788 
0.0587109000 * 0.1636750000 = -0.1743848723 
0.1839170000 * 0.2397330000 = -0.1302938981 
0.1319570000 * 0.4604810000 = -0.0695302068 
0.0000000000 * 1.5429200000 = -0.0695302068 
0.1969290000 * 0.5901850000 = 0.0466943351 
0.2066640000 * 0.5530500000 = 0.1609898603 
0.0000000000 * 0.0333647000 = 0.1609898603 
0.0306576000 * 1.0954900000 = 0.1945749545 
0.0000000000 * -0.1825150000 = 0.1945749545 
0.0000000000 * 0.1739150000 = 0.1945749545 
0.0000000000 * -2.1907700000 = 0.1945749545 
0.0000000000 * 0.2265210000 = 0.1945749545 
0.0969635000 * 0.2624190000 = 0.2200200192 
0.0098326600 * 0.9956120000 = 0.2298095335 
0.0000000000 * 0.0417400000 = 0.2298095335 
0.0000000000 * 0.5251670000 = 0.2298095335 
0.0000000000 * -0.4444400000 = 0.2298095335 
0.0710148000 * -0.2926280000 = 0.2090286146 
0.0000000000 * -0.1972060000 = 0.2090286146 
0.0000000000 * -0.4608710000 = 0.2090286146 
0.5590840000 * -0.4521320000 = -0.0437511525 
0.1354830000 * -0.2613020000 = -0.0791531313 
0.0000000000 * 0.2263080000 = -0.0791531313 
0.0000000000 * -0.2479080000 = -0.0791531313 
0.7596380000 * -0.1584710000 = -0.1995337248 
0.1328250000 * 0.3866750000 = -0.1481736180 
0.2355660000 * -1.0215500000 = -0.3888160653 
0.2148580000 * 0.2476390000 = -0.3356088450 
0.0000000000 * 0.2611880000 = -0.3356088450 
0.0000000000 * 0.2677500000 = -0.3356088450 
0.2216060000 * -0.3670030000 = -0.4169389118 
0.0000000000 * -0.3020240000 = -0.4169389118 
0.0000000000 * -1.0607300000 = -0.4169389118 
0.0000000000 * 0.2555330000 = -0.4169389118 
0.0000000000 * 0.1479950000 = -0.4169389118 
0.0000000000 * -0.0131401000 = -0.4169389118 
0.0370344000 * 0.2163710000 = -0.4089257417 
0.0538087000 * 0.6642700000 = -0.3731822365 
0.0000000000 * 0.6475650000 = -0.3731822365 
0.1759170000 * -0.0201000000 = -0.3767181682 
the biases is : -0.0932226000, now tempVal is : -0.4699407682
ReLU !!! in layer: 2, node : 15, its linear result is negative,so set it to 0
compute layer: 2, node : 16
0.2276300000 * -0.5220740000 = -0.1188397046 
0.0000000000 * -0.3927610000 = -0.1188397046 
0.0534094000 * 0.2906120000 = -0.1033182921 
0.0000000000 * -0.1027720000 = -0.1033182921 
0.0000000000 * 0.7129700000 = -0.1033182921 
0.0000000000 * -2.2841500000 = -0.1033182921 
0.0746065000 * 1.4242400000 = 0.0029392695 
0.0000000000 * 0.4410920000 = 0.0029392695 
0.0000000000 * 0.2971050000 = 0.0029392695 
0.0000000000 * -0.1197940000 = 0.0029392695 
0.0587109000 * -0.6752460000 = -0.0367050309 
0.1839170000 * 0.1329390000 = -0.0122552888 
0.1319570000 * 0.1436140000 = 0.0066955838 
0.0000000000 * -0.0059075700 = 0.0066955838 
0.1969290000 * 0.3197790000 = 0.0696693425 
0.2066640000 * 0.6287520000 = 0.1996097458 
0.0000000000 * 0.5042290000 = 0.1996097458 
0.0306576000 * 0.8070830000 = 0.2243529736 
0.0000000000 * -1.6953000000 = 0.2243529736 
0.0000000000 * -2.9057900000 = 0.2243529736 
0.0000000000 * 0.0504308000 = 0.2243529736 
0.0000000000 * 0.6625400000 = 0.2243529736 
0.0969635000 * -0.8227350000 = 0.1445777084 
0.0098326600 * 0.3096520000 = 0.1476224112 
0.0000000000 * 0.0441201000 = 0.1476224112 
0.0000000000 * 0.7031830000 = 0.1476224112 
0.0000000000 * 0.1733020000 = 0.1476224112 
0.0710148000 * -0.0732583000 = 0.1424199877 
0.0000000000 * 1.2796600000 = 0.1424199877 
0.0000000000 * 0.1576190000 = 0.1424199877 
0.5590840000 * 0.0039175600 = 0.1446102328 
0.1354830000 * 0.2429250000 = 0.1775224406 
0.0000000000 * -0.1641990000 = 0.1775224406 
0.0000000000 * -1.0204200000 = 0.1775224406 
0.7596380000 * -0.0541494000 = 0.1363884987 
0.1328250000 * -2.3978000000 = -0.1820992863 
0.2355660000 * 0.0937846000 = -0.1600068232 
0.2148580000 * -0.2755570000 = -0.2192124491 
0.0000000000 * -0.4885270000 = -0.2192124491 
0.0000000000 * 1.0171800000 = -0.2192124491 
0.2216060000 * -0.3225460000 = -0.2906905780 
0.0000000000 * -0.4318580000 = -0.2906905780 
0.0000000000 * -0.5447030000 = -0.2906905780 
0.0000000000 * -1.1859100000 = -0.2906905780 
0.0000000000 * -0.6462820000 = -0.2906905780 
0.0000000000 * -0.3529600000 = -0.2906905780 
0.0370344000 * 1.0000200000 = -0.2536554373 
0.0538087000 * 0.7024560000 = -0.2158571932 
0.0000000000 * 0.4104560000 = -0.2158571932 
0.1759170000 * 0.0614669000 = -0.2050441205 
the biases is : -0.2459240000, now tempVal is : -0.4509681205
ReLU !!! in layer: 2, node : 16, its linear result is negative,so set it to 0
compute layer: 2, node : 17
0.2276300000 * -0.2958390000 = -0.0673418316 
0.0000000000 * 0.4874900000 = -0.0673418316 
0.0534094000 * -0.2507670000 = -0.0807351466 
0.0000000000 * -0.7973910000 = -0.0807351466 
0.0000000000 * -0.2323840000 = -0.0807351466 
0.0000000000 * 0.4184620000 = -0.0807351466 
0.0746065000 * 0.3872350000 = -0.0518448986 
0.0000000000 * 0.9600610000 = -0.0518448986 
0.0000000000 * -0.1918970000 = -0.0518448986 
0.0000000000 * 1.0452500000 = -0.0518448986 
0.0587109000 * -0.6517560000 = -0.0901100799 
0.1839170000 * -0.2797840000 = -0.1415671138 
0.1319570000 * 0.7161940000 = -0.0470603022 
0.0000000000 * 0.3422360000 = -0.0470603022 
0.1969290000 * 0.8298230000 = 0.1163559114 
0.2066640000 * 0.1484680000 = 0.1470389022 
0.0000000000 * -0.1131370000 = 0.1470389022 
0.0306576000 * -0.4469950000 = 0.1333351082 
0.0000000000 * -0.3013310000 = 0.1333351082 
0.0000000000 * 0.1135710000 = 0.1333351082 
0.0000000000 * -0.0545101000 = 0.1333351082 
0.0000000000 * -0.2625500000 = 0.1333351082 
0.0969635000 * -1.2318400000 = 0.0138915904 
0.0098326600 * 0.1846420000 = 0.0157071124 
0.0000000000 * -0.0426401000 = 0.0157071124 
0.0000000000 * 1.1924500000 = 0.0157071124 
0.0000000000 * -0.4333360000 = 0.0157071124 
0.0710148000 * 0.0757407000 = 0.0210858231 
0.0000000000 * 0.6652450000 = 0.0210858231 
0.0000000000 * -0.3978530000 = 0.0210858231 
0.5590840000 * 0.2373940000 = 0.1538090102 
0.1354830000 * -0.4691610000 = 0.0902456704 
0.0000000000 * -0.6261060000 = 0.0902456704 
0.0000000000 * 0.1419710000 = 0.0902456704 
0.7596380000 * -0.1678290000 = -0.0372436155 
0.1328250000 * 0.2754240000 = -0.0006604227 
0.2355660000 * -0.7583470000 = -0.1793011921 
0.2148580000 * 0.5093590000 = -0.0698613361 
0.0000000000 * -0.2182160000 = -0.0698613361 
0.0000000000 * -0.6628730000 = -0.0698613361 
0.2216060000 * -0.0595916000 = -0.0830671922 
0.0000000000 * -0.0270402000 = -0.0830671922 
0.0000000000 * 0.5249640000 = -0.0830671922 
0.0000000000 * -0.2321000000 = -0.0830671922 
0.0000000000 * -0.0003896080 = -0.0830671922 
0.0000000000 * 0.1352450000 = -0.0830671922 
0.0370344000 * -0.4618960000 = -0.1001732334 
0.0538087000 * 0.9988130000 = -0.0464284043 
0.0000000000 * -0.3032570000 = -0.0464284043 
0.1759170000 * 0.0264833000 = -0.0417695416 
the biases is : 0.1594160000, now tempVal is : 0.1176464584
compute layer: 2, node : 18
0.2276300000 * -0.0597724000 = -0.0136059914 
0.0000000000 * -0.1815100000 = -0.0136059914 
0.0534094000 * 0.2343510000 = -0.0010894451 
0.0000000000 * 1.1646100000 = -0.0010894451 
0.0000000000 * 0.0971876000 = -0.0010894451 
0.0000000000 * 0.2140080000 = -0.0010894451 
0.0746065000 * 0.2099330000 = 0.0145729213 
0.0000000000 * 0.3295800000 = 0.0145729213 
0.0000000000 * -0.6684210000 = 0.0145729213 
0.0000000000 * 0.2938140000 = 0.0145729213 
0.0587109000 * -0.9885430000 = -0.0434653280 
0.1839170000 * -0.2891370000 = -0.0966425376 
0.1319570000 * 0.1522180000 = -0.0765563070 
0.0000000000 * -0.3278730000 = -0.0765563070 
0.1969290000 * -1.0000600000 = -0.2734971227 
0.2066640000 * 0.0065097200 = -0.2721517979 
0.0000000000 * 0.5410770000 = -0.2721517979 
0.0306576000 * 0.4093120000 = -0.2596032744 
0.0000000000 * -1.0031500000 = -0.2596032744 
0.0000000000 * -0.6689930000 = -0.2596032744 
0.0000000000 * -0.0659849000 = -0.2596032744 
0.0000000000 * 0.3143360000 = -0.2596032744 
0.0969635000 * -0.3556610000 = -0.2940894097 
0.0098326600 * -0.0508591000 = -0.2945894900 
0.0000000000 * 0.0379435000 = -0.2945894900 
0.0000000000 * 0.5009430000 = -0.2945894900 
0.0000000000 * -0.1107210000 = -0.2945894900 
0.0710148000 * 0.4740460000 = -0.2609252081 
0.0000000000 * 0.1442160000 = -0.2609252081 
0.0000000000 * -0.6873120000 = -0.2609252081 
0.5590840000 * -0.4770000000 = -0.5276082761 
0.1354830000 * 0.4353180000 = -0.4686300875 
0.0000000000 * 0.5718040000 = -0.4686300875 
0.0000000000 * 1.8263800000 = -0.4686300875 
0.7596380000 * -0.9299560000 = -1.1750600034 
0.1328250000 * -0.1183720000 = -1.1907827643 
0.2355660000 * -0.3497450000 = -1.2731707950 
0.2148580000 * 0.1941770000 = -1.2314503131 
0.0000000000 * 1.5493300000 = -1.2314503131 
0.0000000000 * 0.0245301000 = -1.2314503131 
0.2216060000 * -0.1841530000 = -1.2722597229 
0.0000000000 * 0.2932820000 = -1.2722597229 
0.0000000000 * -0.0971090000 = -1.2722597229 
0.0000000000 * -0.0632774000 = -1.2722597229 
0.0000000000 * 0.2274400000 = -1.2722597229 
0.0000000000 * 0.8726060000 = -1.2722597229 
0.0370344000 * -0.6011460000 = -1.2945228043 
0.0538087000 * -0.9850580000 = -1.3475274947 
0.0000000000 * -0.6164520000 = -1.3475274947 
0.1759170000 * -0.7303570000 = -1.4760097070 
the biases is : 0.4657940000, now tempVal is : -1.0102157070
ReLU !!! in layer: 2, node : 18, its linear result is negative,so set it to 0
compute layer: 2, node : 19
0.2276300000 * 0.2255810000 = 0.0513490030 
0.0000000000 * -0.1345500000 = 0.0513490030 
0.0534094000 * 2.6039500000 = 0.1904244102 
0.0000000000 * -0.2798200000 = 0.1904244102 
0.0000000000 * -0.0326815000 = 0.1904244102 
0.0000000000 * 2.9446500000 = 0.1904244102 
0.0746065000 * -0.3799550000 = 0.1620772975 
0.0000000000 * 1.0674300000 = 0.1620772975 
0.0000000000 * 0.2570160000 = 0.1620772975 
0.0000000000 * -0.2460810000 = 0.1620772975 
0.0587109000 * 0.0062605100 = 0.1624448576 
0.1839170000 * 1.0042900000 = 0.3471508616 
0.1319570000 * 0.4442240000 = 0.4057693279 
0.0000000000 * 1.9888200000 = 0.4057693279 
0.1969290000 * 0.4568730000 = 0.4957408709 
0.2066640000 * 0.1012070000 = 0.5166567144 
0.0000000000 * 0.2913070000 = 0.5166567144 
0.0306576000 * 0.4824860000 = 0.5314485772 
0.0000000000 * 0.0628707000 = 0.5314485772 
0.0000000000 * -0.6349020000 = 0.5314485772 
0.0000000000 * -0.8572190000 = 0.5314485772 
0.0000000000 * 0.0346260000 = 0.5314485772 
0.0969635000 * -0.6561980000 = 0.4678213224 
0.0098326600 * -0.1548940000 = 0.4662983024 
0.0000000000 * 0.0263009000 = 0.4662983024 
0.0000000000 * -0.0838850000 = 0.4662983024 
0.0000000000 * 0.3125760000 = 0.4662983024 
0.0710148000 * -0.4039160000 = 0.4376142884 
0.0000000000 * 0.1927520000 = 0.4376142884 
0.0000000000 * 1.1763700000 = 0.4376142884 
0.5590840000 * -0.4462980000 = 0.1880962174 
0.1354830000 * 1.1404600000 = 0.3426091596 
0.0000000000 * -0.4224770000 = 0.3426091596 
0.0000000000 * 0.4417570000 = 0.3426091596 
0.7596380000 * -0.1750560000 = 0.2096299698 
0.1328250000 * 0.2375130000 = 0.2411776341 
0.2355660000 * 0.3623710000 = 0.3265399210 
0.2148580000 * -1.0839000000 = 0.0936553348 
0.0000000000 * 0.7915690000 = 0.0936553348 
0.0000000000 * -0.2886360000 = 0.0936553348 
0.2216060000 * 0.1523200000 = 0.1274103608 
0.0000000000 * 0.1657100000 = 0.1274103608 
0.0000000000 * -5.5850300000 = 0.1274103608 
0.0000000000 * -0.2921780000 = 0.1274103608 
0.0000000000 * -0.6097990000 = 0.1274103608 
0.0000000000 * 0.0035977200 = 0.1274103608 
0.0370344000 * 0.0598140000 = 0.1296255364 
0.0538087000 * 0.3374970000 = 0.1477858112 
0.0000000000 * -0.0456116000 = 0.1477858112 
0.1759170000 * -0.0515602000 = 0.1387154955 
the biases is : -0.7600390000, now tempVal is : -0.6213235045
ReLU !!! in layer: 2, node : 19, its linear result is negative,so set it to 0
compute layer: 2, node : 20
0.2276300000 * -0.0766084000 = -0.0174383701 
0.0000000000 * 0.1209520000 = -0.0174383701 
0.0534094000 * 0.1593170000 = -0.0089293447 
0.0000000000 * -0.3764920000 = -0.0089293447 
0.0000000000 * -0.0740785000 = -0.0089293447 
0.0000000000 * -0.8273630000 = -0.0089293447 
0.0746065000 * -0.5775850000 = -0.0520209400 
0.0000000000 * -0.3411950000 = -0.0520209400 
0.0000000000 * 0.2025950000 = -0.0520209400 
0.0000000000 * 0.2093970000 = -0.0520209400 
0.0587109000 * 0.0713967000 = -0.0478291755 
0.1839170000 * 0.2212360000 = -0.0071401141 
0.1319570000 * 0.2676770000 = 0.0281817398 
0.0000000000 * -0.2770370000 = 0.0281817398 
0.1969290000 * -0.0728074000 = 0.0138438513 
0.2066640000 * -0.1219060000 = -0.0113497303 
0.0000000000 * 0.3801080000 = -0.0113497303 
0.0306576000 * 0.6874950000 = 0.0097272165 
0.0000000000 * -0.8515400000 = 0.0097272165 
0.0000000000 * 0.1485170000 = 0.0097272165 
0.0000000000 * 0.2430520000 = 0.0097272165 
0.0000000000 * -0.1863090000 = 0.0097272165 
0.0969635000 * -0.2686940000 = -0.0163262942 
0.0098326600 * 0.1377170000 = -0.0149721698 
0.0000000000 * -0.0112855000 = -0.0149721698 
0.0000000000 * -0.2914540000 = -0.0149721698 
0.0000000000 * -0.0438027000 = -0.0149721698 
0.0710148000 * -0.1384780000 = -0.0248061573 
0.0000000000 * 0.3477590000 = -0.0248061573 
0.0000000000 * 0.0071913600 = -0.0248061573 
0.5590840000 * -0.3422920000 = -0.2161761378 
0.1354830000 * -0.6780480000 = -0.3080401150 
0.0000000000 * -0.8106420000 = -0.3080401150 
0.0000000000 * 0.2246820000 = -0.3080401150 
0.7596380000 * 0.2837600000 = -0.0924852361 
0.1328250000 * 0.2408180000 = -0.0604985852 
0.2355660000 * 0.3685570000 = 0.0263209130 
0.2148580000 * 0.1667340000 = 0.0621450468 
0.0000000000 * -0.5844060000 = 0.0621450468 
0.0000000000 * -0.1185770000 = 0.0621450468 
0.2216060000 * -0.5500490000 = -0.0597491119 
0.0000000000 * 0.2137120000 = -0.0597491119 
0.0000000000 * 0.4060120000 = -0.0597491119 
0.0000000000 * 0.6339210000 = -0.0597491119 
0.0000000000 * 0.0375635000 = -0.0597491119 
0.0000000000 * -0.2147170000 = -0.0597491119 
0.0370344000 * -0.4487540000 = -0.0763684470 
0.0538087000 * 0.8530680000 = -0.0304659669 
0.0000000000 * 0.3680570000 = -0.0304659669 
0.1759170000 * -0.2349690000 = -0.0718010085 
the biases is : 0.1272130000, now tempVal is : 0.0554119915
compute layer: 2, node : 21
0.2276300000 * 0.0053438000 = 0.0012164092 
0.0000000000 * -0.0053754500 = 0.0012164092 
0.0534094000 * -0.1844080000 = -0.0086327114 
0.0000000000 * -0.1421570000 = -0.0086327114 
0.0000000000 * -0.4161680000 = -0.0086327114 
0.0000000000 * 0.3630140000 = -0.0086327114 
0.0746065000 * 0.3451050000 = 0.0171143647 
0.0000000000 * 0.2960370000 = 0.0171143647 
0.0000000000 * -0.1246540000 = 0.0171143647 
0.0000000000 * 0.3220520000 = 0.0171143647 
0.0587109000 * -0.2352920000 = 0.0033001597 
0.1839170000 * -0.0980614000 = -0.0147349988 
0.1319570000 * 0.4093970000 = 0.0392878011 
0.0000000000 * -0.0497859000 = 0.0392878011 
0.1969290000 * -0.3753880000 = -0.0346369824 
0.2066640000 * -0.2509690000 = -0.0865032398 
0.0000000000 * -0.0981585000 = -0.0865032398 
0.0306576000 * 0.0722905000 = -0.0842869866 
0.0000000000 * 0.5401310000 = -0.0842869866 
0.0000000000 * 0.2669870000 = -0.0842869866 
0.0000000000 * 0.3185700000 = -0.0842869866 
0.0000000000 * 0.3897360000 = -0.0842869866 
0.0969635000 * -0.0058765700 = -0.0848567993 
0.0098326600 * -0.5373690000 = -0.0901405660 
0.0000000000 * 0.0225036000 = -0.0901405660 
0.0000000000 * 0.1459290000 = -0.0901405660 
0.0000000000 * 0.4561020000 = -0.0901405660 
0.0710148000 * 0.4353840000 = -0.0592218583 
0.0000000000 * -0.4206180000 = -0.0592218583 
0.0000000000 * -0.9044360000 = -0.0592218583 
0.5590840000 * -0.1370070000 = -0.1358202799 
0.1354830000 * -0.5320210000 = -0.2079000811 
0.0000000000 * 0.0903367000 = -0.2079000811 
0.0000000000 * -0.1044810000 = -0.2079000811 
0.7596380000 * 0.0678861000 = -0.1563312198 
0.1328250000 * -0.0540483000 = -0.1635101853 
0.2355660000 * -0.5402820000 = -0.2907822549 
0.2148580000 * 0.5181670000 = -0.1794499296 
0.0000000000 * -0.0047956400 = -0.1794499296 
0.0000000000 * -0.0079926000 = -0.1794499296 
0.2216060000 * 0.4671290000 = -0.0759313404 
0.0000000000 * 0.0015673300 = -0.0759313404 
0.0000000000 * 0.3496940000 = -0.0759313404 
0.0000000000 * -0.1802260000 = -0.0759313404 
0.0000000000 * -0.2964380000 = -0.0759313404 
0.0000000000 * -0.4240880000 = -0.0759313404 
0.0370344000 * 0.6355080000 = -0.0523956830 
0.0538087000 * -0.6046760000 = -0.0849325124 
0.0000000000 * 0.2096620000 = -0.0849325124 
0.1759170000 * -0.3026300000 = -0.1381702741 
the biases is : 0.3931890000, now tempVal is : 0.2550187259
compute layer: 2, node : 22
0.2276300000 * 0.3165880000 = 0.0720649264 
0.0000000000 * 0.9415690000 = 0.0720649264 
0.0534094000 * 0.3421910000 = 0.0903411424 
0.0000000000 * -0.7283120000 = 0.0903411424 
0.0000000000 * 1.4476900000 = 0.0903411424 
0.0000000000 * 1.5975500000 = 0.0903411424 
0.0746065000 * 0.3782960000 = 0.1185644830 
0.0000000000 * -2.4875600000 = 0.1185644830 
0.0000000000 * 1.7536300000 = 0.1185644830 
0.0000000000 * 1.6410300000 = 0.1185644830 
0.0587109000 * 0.6516030000 = 0.1568206815 
0.1839170000 * 0.8959390000 = 0.3215990946 
0.1319570000 * 1.0602000000 = 0.4614999060 
0.0000000000 * 0.3328870000 = 0.4614999060 
0.1969290000 * -0.3898800000 = 0.3847212275 
0.2066640000 * -1.5175100000 = 0.0711065408 
0.0000000000 * 0.1954010000 = 0.0711065408 
0.0306576000 * 0.0682005000 = 0.0731974045 
0.0000000000 * 0.5721310000 = 0.0731974045 
0.0000000000 * 0.3571400000 = 0.0731974045 
0.0000000000 * -0.1767450000 = 0.0731974045 
0.0000000000 * -0.0618688000 = 0.0731974045 
0.0969635000 * -0.5126590000 = 0.0234881935 
0.0098326600 * -1.0056500000 = 0.0135999790 
0.0000000000 * -0.0173481000 = 0.0135999790 
0.0000000000 * 0.7939420000 = 0.0135999790 
0.0000000000 * 1.5776600000 = 0.0135999790 
0.0710148000 * 0.7058600000 = 0.0637264857 
0.0000000000 * -1.0544200000 = 0.0637264857 
0.0000000000 * 1.9655200000 = 0.0637264857 
0.5590840000 * 0.0225863000 = 0.0763541247 
0.1354830000 * 0.3064990000 = 0.1178795287 
0.0000000000 * -0.3899770000 = 0.1178795287 
0.0000000000 * 0.0613327000 = 0.1178795287 
0.7596380000 * -0.1232460000 = 0.0242571838 
0.1328250000 * 0.2015440000 = 0.0510272656 
0.2355660000 * -0.5141180000 = -0.0700814552 
0.2148580000 * 0.3577440000 = 0.0067827051 
0.0000000000 * -1.0397800000 = 0.0067827051 
0.0000000000 * -2.5285600000 = 0.0067827051 
0.2216060000 * -0.8262740000 = -0.1763245709 
0.0000000000 * -0.1961770000 = -0.1763245709 
0.0000000000 * 1.8553800000 = -0.1763245709 
0.0000000000 * 0.2437610000 = -0.1763245709 
0.0000000000 * -0.8368260000 = -0.1763245709 
0.0000000000 * -1.6309700000 = -0.1763245709 
0.0370344000 * 0.5268900000 = -0.1568115159 
0.0538087000 * -1.8827500000 = -0.2581198458 
0.0000000000 * 0.9661830000 = -0.2581198458 
0.1759170000 * -0.6304170000 = -0.3690209132 
the biases is : -0.0717872000, now tempVal is : -0.4408081132
ReLU !!! in layer: 2, node : 22, its linear result is negative,so set it to 0
compute layer: 2, node : 23
0.2276300000 * -0.3176470000 = -0.0723059866 
0.0000000000 * -0.3199180000 = -0.0723059866 
0.0534094000 * -0.7113230000 = -0.1102973212 
0.0000000000 * 1.5919100000 = -0.1102973212 
0.0000000000 * 0.0841627000 = -0.1102973212 
0.0000000000 * 1.8792300000 = -0.1102973212 
0.0746065000 * 1.0100700000 = -0.0349395338 
0.0000000000 * 0.7893840000 = -0.0349395338 
0.0000000000 * 0.5033490000 = -0.0349395338 
0.0000000000 * 0.5487070000 = -0.0349395338 
0.0587109000 * 0.6159190000 = 0.0012216250 
0.1839170000 * 0.3955580000 = 0.0739714657 
0.1319570000 * -0.6979820000 = -0.0181321451 
0.0000000000 * -0.2679810000 = -0.0181321451 
0.1969290000 * -2.1071500000 = -0.4330910874 
0.2066640000 * 0.0295865000 = -0.4269766230 
0.0000000000 * 0.1394860000 = -0.4269766230 
0.0306576000 * -0.5018450000 = -0.4423619862 
0.0000000000 * 5.9710600000 = -0.4423619862 
0.0000000000 * -0.0728299000 = -0.4423619862 
0.0000000000 * 0.3342780000 = -0.4423619862 
0.0000000000 * 0.2526990000 = -0.4423619862 
0.0969635000 * -0.2776810000 = -0.4692869079 
0.0098326600 * -0.2739760000 = -0.4719808207 
0.0000000000 * -0.0213905000 = -0.4719808207 
0.0000000000 * 0.5805960000 = -0.4719808207 
0.0000000000 * -0.8418130000 = -0.4719808207 
0.0710148000 * -0.0293286000 = -0.4740635854 
0.0000000000 * 0.0777785000 = -0.4740635854 
0.0000000000 * -1.3866100000 = -0.4740635854 
0.5590840000 * -2.2668300000 = -1.7414119691 
0.1354830000 * 0.8699260000 = -1.6235517849 
0.0000000000 * 0.9794550000 = -1.6235517849 
0.0000000000 * 0.8521650000 = -1.6235517849 
0.7596380000 * -0.7510460000 = -2.1940748662 
0.1328250000 * -1.0452300000 = -2.3329075410 
0.2355660000 * 0.1830310000 = -2.2897916604 
0.2148580000 * -0.0672466000 = -2.3042401304 
0.0000000000 * 1.7092500000 = -2.3042401304 
0.0000000000 * -0.0695859000 = -2.3042401304 
0.2216060000 * 0.6285630000 = -2.1649467982 
0.0000000000 * -0.6528280000 = -2.1649467982 
0.0000000000 * -1.7304300000 = -2.1649467982 
0.0000000000 * -0.9546730000 = -2.1649467982 
0.0000000000 * -0.0561551000 = -2.1649467982 
0.0000000000 * 0.8790250000 = -2.1649467982 
0.0370344000 * 0.6346870000 = -2.1414415460 
0.0538087000 * -1.5237600000 = -2.2234330907 
0.0000000000 * 0.6251990000 = -2.2234330907 
0.1759170000 * -0.0810672000 = -2.2376941893 
the biases is : 0.3198310000, now tempVal is : -1.9178631893
ReLU !!! in layer: 2, node : 23, its linear result is negative,so set it to 0
compute layer: 2, node : 24
0.2276300000 * -0.0386614000 = -0.0088004945 
0.0000000000 * 0.0300274000 = -0.0088004945 
0.0534094000 * -0.0406126000 = -0.0109695891 
0.0000000000 * 0.0106733000 = -0.0109695891 
0.0000000000 * -0.0154052000 = -0.0109695891 
0.0000000000 * 0.0442192000 = -0.0109695891 
0.0746065000 * 0.0197890000 = -0.0094932011 
0.0000000000 * -0.0104466000 = -0.0094932011 
0.0000000000 * -0.0295513000 = -0.0094932011 
0.0000000000 * -0.0004151950 = -0.0094932011 
0.0587109000 * -0.0114132000 = -0.0101632803 
0.1839170000 * -0.0339540000 = -0.0164079981 
0.1319570000 * 0.0096767800 = -0.0151310793 
0.0000000000 * 0.0219783000 = -0.0151310793 
0.1969290000 * -0.0582937000 = -0.0266107993 
0.2066640000 * 0.0227223000 = -0.0219149179 
0.0000000000 * 0.0164509000 = -0.0219149179 
0.0306576000 * -0.0288010000 = -0.0227978874 
0.0000000000 * -0.0246728000 = -0.0227978874 
0.0000000000 * 0.0300411000 = -0.0227978874 
0.0000000000 * 0.0194892000 = -0.0227978874 
0.0000000000 * -0.0024272300 = -0.0227978874 
0.0969635000 * -0.0388959000 = -0.0265693700 
0.0098326600 * -0.0476972000 = -0.0270383604 
0.0000000000 * 0.0300196000 = -0.0270383604 
0.0000000000 * -0.0141949000 = -0.0270383604 
0.0000000000 * -0.0017078600 = -0.0270383604 
0.0710148000 * 0.0337114000 = -0.0246443521 
0.0000000000 * -0.0053426100 = -0.0246443521 
0.0000000000 * -0.0399127000 = -0.0246443521 
0.5590840000 * -0.0209442000 = -0.0363539192 
0.1354830000 * -0.0418985000 = -0.0420304536 
0.0000000000 * 0.0235862000 = -0.0420304536 
0.0000000000 * -0.0160574000 = -0.0420304536 
0.7596380000 * -0.0107141000 = -0.0501692911 
0.1328250000 * 0.0011652300 = -0.0500145195 
0.2355660000 * -0.0192918000 = -0.0545590116 
0.2148580000 * -0.0132972000 = -0.0574160214 
0.0000000000 * 0.0290592000 = -0.0574160214 
0.0000000000 * 0.0237985000 = -0.0574160214 
0.2216060000 * 0.0251870000 = -0.0518344311 
0.0000000000 * -0.0084582100 = -0.0518344311 
0.0000000000 * -0.0390293000 = -0.0518344311 
0.0000000000 * -0.0494291000 = -0.0518344311 
0.0000000000 * -0.0308208000 = -0.0518344311 
0.0000000000 * -0.0264815000 = -0.0518344311 
0.0370344000 * -0.0119143000 = -0.0522756701 
0.0538087000 * -0.0404856000 = -0.0544541476 
0.0000000000 * 0.0034937500 = -0.0544541476 
0.1759170000 * -0.0002534650 = -0.0544987364 
the biases is : -0.0141183000, now tempVal is : -0.0686170364
ReLU !!! in layer: 2, node : 24, its linear result is negative,so set it to 0
compute layer: 2, node : 25
0.2276300000 * -0.0442498000 = -0.0100725820 
0.0000000000 * -0.0224060000 = -0.0100725820 
0.0534094000 * 0.0395571000 = -0.0079598610 
0.0000000000 * 0.0281488000 = -0.0079598610 
0.0000000000 * 0.0075683000 = -0.0079598610 
0.0000000000 * 0.0148697000 = -0.0079598610 
0.0746065000 * 0.0382801000 = -0.0051039167 
0.0000000000 * -0.0241124000 = -0.0051039167 
0.0000000000 * 0.0136336000 = -0.0051039167 
0.0000000000 * 0.0269792000 = -0.0051039167 
0.0587109000 * 0.0396601000 = -0.0027754366 
0.1839170000 * -0.0236657000 = -0.0071279611 
0.1319570000 * -0.0239268000 = -0.0102852698 
0.0000000000 * 0.0400947000 = -0.0102852698 
0.1969290000 * -0.0536841000 = -0.0208572260 
0.2066640000 * 0.0164122000 = -0.0174654151 
0.0000000000 * -0.0389649000 = -0.0174654151 
0.0306576000 * 0.0311577000 = -0.0165101948 
0.0000000000 * 0.0092381900 = -0.0165101948 
0.0000000000 * -0.0169541000 = -0.0165101948 
0.0000000000 * -0.0213906000 = -0.0165101948 
0.0000000000 * -0.0342286000 = -0.0165101948 
0.0969635000 * -0.0389736000 = -0.0202892114 
0.0098326600 * -0.0228373000 = -0.0205137628 
0.0000000000 * 0.0014902100 = -0.0205137628 
0.0000000000 * -0.0460210000 = -0.0205137628 
0.0000000000 * -0.0419726000 = -0.0205137628 
0.0710148000 * -0.0280963000 = -0.0225090160 
0.0000000000 * 0.0271984000 = -0.0225090160 
0.0000000000 * -0.0504214000 = -0.0225090160 
0.5590840000 * -0.0503820000 = -0.0506767861 
0.1354830000 * -0.0275260000 = -0.0544060911 
0.0000000000 * 0.0235949000 = -0.0544060911 
0.0000000000 * -0.0030510500 = -0.0544060911 
0.7596380000 * 0.0223165000 = -0.0374536297 
0.1328250000 * -0.0284985000 = -0.0412389429 
0.2355660000 * -0.0536751000 = -0.0538829716 
0.2148580000 * 0.0097900700 = -0.0517794967 
0.0000000000 * 0.0400998000 = -0.0517794967 
0.0000000000 * -0.0218434000 = -0.0517794967 
0.2216060000 * 0.0310683000 = -0.0448945750 
0.0000000000 * -0.0094176000 = -0.0448945750 
0.0000000000 * 0.0199976000 = -0.0448945750 
0.0000000000 * -0.0312057000 = -0.0448945750 
0.0000000000 * -0.0154904000 = -0.0448945750 
0.0000000000 * -0.0238395000 = -0.0448945750 
0.0370344000 * 0.0388896000 = -0.0434543220 
0.0538087000 * -0.0091461700 = -0.0439464655 
0.0000000000 * -0.0505772000 = -0.0439464655 
0.1759170000 * -0.0207484000 = -0.0475964618 
the biases is : -0.0066037700, now tempVal is : -0.0542002318
ReLU !!! in layer: 2, node : 25, its linear result is negative,so set it to 0
compute layer: 2, node : 26
0.2276300000 * -0.0617362000 = -0.0140530112 
0.0000000000 * 0.1968320000 = -0.0140530112 
0.0534094000 * 0.7758080000 = 0.0273824286 
0.0000000000 * -0.5482740000 = 0.0273824286 
0.0000000000 * 0.7132290000 = 0.0273824286 
0.0000000000 * -0.9436870000 = 0.0273824286 
0.0746065000 * -0.8263750000 = -0.0342705178 
0.0000000000 * 1.3531300000 = -0.0342705178 
0.0000000000 * -0.3923850000 = -0.0342705178 
0.0000000000 * -0.3737780000 = -0.0342705178 
0.0587109000 * 0.3911780000 = -0.0113041054 
0.1839170000 * 1.7113100000 = 0.3034348959 
0.1319570000 * 0.1772780000 = 0.3268279689 
0.0000000000 * 0.1112930000 = 0.3268279689 
0.1969290000 * -0.2967160000 = 0.2683959837 
0.2066640000 * 0.4084240000 = 0.3528025213 
0.0000000000 * -0.5500110000 = 0.3528025213 
0.0306576000 * -0.5062120000 = 0.3372832763 
0.0000000000 * -0.6981540000 = 0.3372832763 
0.0000000000 * -0.9205230000 = 0.3372832763 
0.0000000000 * -0.8040380000 = 0.3372832763 
0.0000000000 * 0.3472870000 = 0.3372832763 
0.0969635000 * 0.4926960000 = 0.3850568049 
0.0098326600 * -0.3905610000 = 0.3812165513 
0.0000000000 * 0.0203369000 = 0.3812165513 
0.0000000000 * 1.9185300000 = 0.3812165513 
0.0000000000 * 1.7049200000 = 0.3812165513 
0.0710148000 * -2.4419600000 = 0.2078012503 
0.0000000000 * 0.3264800000 = 0.2078012503 
0.0000000000 * 2.3785000000 = 0.2078012503 
0.5590840000 * -0.9265820000 = -0.3102359206 
0.1354830000 * 0.2740020000 = -0.2731133076 
0.0000000000 * -0.0613919000 = -0.2731133076 
0.0000000000 * -0.1750360000 = -0.2731133076 
0.7596380000 * -0.3877350000 = -0.5676515475 
0.1328250000 * 0.0123933000 = -0.5660054074 
0.2355660000 * 1.6901300000 = -0.1678682439 
0.2148580000 * -0.5505390000 = -0.2861559523 
0.0000000000 * 0.2526720000 = -0.2861559523 
0.0000000000 * 0.1942500000 = -0.2861559523 
0.2216060000 * -1.7122300000 = -0.6655963937 
0.0000000000 * -2.0759600000 = -0.6655963937 
0.0000000000 * -2.5106600000 = -0.6655963937 
0.0000000000 * -0.6373800000 = -0.6655963937 
0.0000000000 * 0.3841150000 = -0.6655963937 
0.0000000000 * -1.5687500000 = -0.6655963937 
0.0370344000 * -0.4314120000 = -0.6815734783 
0.0538087000 * 1.4898000000 = -0.6014092770 
0.0000000000 * 1.4597300000 = -0.6014092770 
0.1759170000 * 0.2882540000 = -0.5507004981 
the biases is : -0.7037140000, now tempVal is : -1.2544144981
ReLU !!! in layer: 2, node : 26, its linear result is negative,so set it to 0
compute layer: 2, node : 27
0.2276300000 * 0.0694637000 = 0.0158120220 
0.0000000000 * 0.2342930000 = 0.0158120220 
0.0534094000 * -0.0384624000 = 0.0137577683 
0.0000000000 * 1.8854400000 = 0.0137577683 
0.0000000000 * 0.0263936000 = 0.0137577683 
0.0000000000 * -0.1407580000 = 0.0137577683 
0.0746065000 * -0.2940750000 = -0.0081821382 
0.0000000000 * 0.6501190000 = -0.0081821382 
0.0000000000 * 0.1871380000 = -0.0081821382 
0.0000000000 * 1.0528600000 = -0.0081821382 
0.0587109000 * -0.3920440000 = -0.0311993942 
0.1839170000 * -0.0288931000 = -0.0365133265 
0.1319570000 * 0.2937390000 = 0.0022475907 
0.0000000000 * -0.0031515100 = 0.0022475907 
0.1969290000 * 0.0119241000 = 0.0045957918 
0.2066640000 * -0.0580794000 = -0.0074071293 
0.0000000000 * -0.1751090000 = -0.0074071293 
0.0306576000 * 0.1533880000 = -0.0027046214 
0.0000000000 * -0.2376270000 = -0.0027046214 
0.0000000000 * 0.2181680000 = -0.0027046214 
0.0000000000 * 0.1074950000 = -0.0027046214 
0.0000000000 * -0.0854477000 = -0.0027046214 
0.0969635000 * 0.0282669000 = 0.0000362362 
0.0098326600 * 0.0676320000 = 0.0007012386 
0.0000000000 * 0.0041908300 = 0.0007012386 
0.0000000000 * 0.1683740000 = 0.0007012386 
0.0000000000 * 0.0515999000 = 0.0007012386 
0.0710148000 * -0.2158410000 = -0.0146266668 
0.0000000000 * -0.1636930000 = -0.0146266668 
0.0000000000 * 0.3408740000 = -0.0146266668 
0.5590840000 * -3.0310600000 = -1.7092438158 
0.1354830000 * 0.0374973000 = -1.7041635691 
0.0000000000 * 0.2368920000 = -1.7041635691 
0.0000000000 * 2.0323800000 = -1.7041635691 
0.7596380000 * -1.2932000000 = -2.6865274307 
0.1328250000 * -0.1710700000 = -2.7092498035 
0.2355660000 * -0.0947622000 = -2.7315725559 
0.2148580000 * 0.1089340000 = -2.7081672145 
0.0000000000 * 2.7711900000 = -2.7081672145 
0.0000000000 * 0.0231219000 = -2.7081672145 
0.2216060000 * 0.1627330000 = -2.6721046053 
0.0000000000 * 0.0227226000 = -2.6721046053 
0.0000000000 * -0.0355209000 = -2.6721046053 
0.0000000000 * 0.1916820000 = -2.6721046053 
0.0000000000 * -0.0095909600 = -2.6721046053 
0.0000000000 * 0.8780610000 = -2.6721046053 
0.0370344000 * 0.1397560000 = -2.6669288257 
0.0538087000 * -0.3849200000 = -2.6876408705 
0.0000000000 * 0.9751600000 = -2.6876408705 
0.1759170000 * 0.0428244000 = -2.6801073306 
the biases is : 0.4408940000, now tempVal is : -2.2392133306
ReLU !!! in layer: 2, node : 27, its linear result is negative,so set it to 0
compute layer: 2, node : 28
0.2276300000 * 0.0956433000 = 0.0217712844 
0.0000000000 * 0.4340450000 = 0.0217712844 
0.0534094000 * -0.1124370000 = 0.0157660917 
0.0000000000 * 1.0157300000 = 0.0157660917 
0.0000000000 * 0.2107010000 = 0.0157660917 
0.0000000000 * -0.6626380000 = 0.0157660917 
0.0746065000 * -1.0367700000 = -0.0615836893 
0.0000000000 * 1.2155700000 = -0.0615836893 
0.0000000000 * 0.2153300000 = -0.0615836893 
0.0000000000 * 0.1999620000 = -0.0615836893 
0.0587109000 * 0.1572180000 = -0.0523532791 
0.1839170000 * -0.1754690000 = -0.0846250111 
0.1319570000 * 0.3077910000 = -0.0440098341 
0.0000000000 * 0.2954980000 = -0.0440098341 
0.1969290000 * 0.4240790000 = 0.0395036192 
0.2066640000 * -0.7012140000 = -0.1054120708 
0.0000000000 * 0.0062056700 = -0.1054120708 
0.0306576000 * -0.0681584000 = -0.1075016438 
0.0000000000 * 0.3591710000 = -0.1075016438 
0.0000000000 * 0.9567680000 = -0.1075016438 
0.0000000000 * 0.2396280000 = -0.1075016438 
0.0000000000 * 0.1805190000 = -0.1075016438 
0.0969635000 * 0.0732215000 = -0.1004018309 
0.0098326600 * 0.0870791000 = -0.0995456117 
0.0000000000 * -0.0214856000 = -0.0995456117 
0.0000000000 * -0.0086033700 = -0.0995456117 
0.0000000000 * 0.1758380000 = -0.0995456117 
0.0710148000 * -1.1067000000 = -0.1781376909 
0.0000000000 * 0.7134130000 = -0.1781376909 
0.0000000000 * 1.0537100000 = -0.1781376909 
0.5590840000 * -1.6134400000 = -1.0801861798 
0.1354830000 * 0.2533750000 = -1.0458581747 
0.0000000000 * 1.1062600000 = -1.0458581747 
0.0000000000 * 1.8271400000 = -1.0458581747 
0.7596380000 * -2.0918200000 = -2.6348841359 
0.1328250000 * 0.5247820000 = -2.5651799667 
0.2355660000 * 0.0983768000 = -2.5420057374 
0.2148580000 * 0.6009070000 = -2.4128960612 
0.0000000000 * 1.9032700000 = -2.4128960612 
0.0000000000 * -0.0871044000 = -2.4128960612 
0.2216060000 * -0.2469730000 = -2.4676267599 
0.0000000000 * -0.7061840000 = -2.4676267599 
0.0000000000 * 0.0576315000 = -2.4676267599 
0.0000000000 * 0.2914240000 = -2.4676267599 
0.0000000000 * -0.0198773000 = -2.4676267599 
0.0000000000 * 0.9404030000 = -2.4676267599 
0.0370344000 * 0.3229040000 = -2.4556682040 
0.0538087000 * -0.9025290000 = -2.5042321162 
0.0000000000 * 1.0415400000 = -2.5042321162 
0.1759170000 * 0.4796720000 = -2.4198496570 
the biases is : -0.4038740000, now tempVal is : -2.8237236570
ReLU !!! in layer: 2, node : 28, its linear result is negative,so set it to 0
compute layer: 2, node : 29
0.2276300000 * 0.1899240000 = 0.0432324001 
0.0000000000 * 0.0260059000 = 0.0432324001 
0.0534094000 * -0.2671030000 = 0.0289665892 
0.0000000000 * 0.7709390000 = 0.0289665892 
0.0000000000 * -0.9074560000 = 0.0289665892 
0.0000000000 * -1.0829800000 = 0.0289665892 
0.0746065000 * -0.1325640000 = 0.0190764531 
0.0000000000 * -0.0595572000 = 0.0190764531 
0.0000000000 * -0.3792260000 = 0.0190764531 
0.0000000000 * -0.1764190000 = 0.0190764531 
0.0587109000 * 0.1328850000 = 0.0268782510 
0.1839170000 * 0.0235959000 = 0.0312179382 
0.1319570000 * -0.4271540000 = -0.0251480222 
0.0000000000 * 0.0412024000 = -0.0251480222 
0.1969290000 * -1.2464200000 = -0.2706042664 
0.2066640000 * 0.6948700000 = -0.1269996527 
0.0000000000 * -0.1864570000 = -0.1269996527 
0.0306576000 * 0.7875670000 = -0.1028547386 
0.0000000000 * 0.3012050000 = -0.1028547386 
0.0000000000 * 0.4873380000 = -0.1028547386 
0.0000000000 * 0.1983970000 = -0.1028547386 
0.0000000000 * -1.1798600000 = -0.1028547386 
0.0969635000 * 0.4090790000 = -0.0631890070 
0.0098326600 * -0.1667690000 = -0.0648287899 
0.0000000000 * 0.0047250800 = -0.0648287899 
0.0000000000 * 0.4629920000 = -0.0648287899 
0.0000000000 * 0.0402926000 = -0.0648287899 
0.0710148000 * 0.1030180000 = -0.0575129872 
0.0000000000 * 0.2783310000 = -0.0575129872 
0.0000000000 * 0.0787222000 = -0.0575129872 
0.5590840000 * 0.7474310000 = 0.3603637260 
0.1354830000 * -1.4341000000 = 0.1660675557 
0.0000000000 * -0.0304184000 = 0.1660675557 
0.0000000000 * 0.0212685000 = 0.1660675557 
0.7596380000 * 0.1266100000 = 0.2622453228 
0.1328250000 * -0.5005460000 = 0.1957603004 
0.2355660000 * 0.0765586000 = 0.2137949036 
0.2148580000 * 1.7453700000 = 0.5888016110 
0.0000000000 * -0.1129250000 = 0.5888016110 
0.0000000000 * -0.0576047000 = 0.5888016110 
0.2216060000 * 0.2836350000 = 0.6516568288 
0.0000000000 * 0.0063628200 = 0.6516568288 
0.0000000000 * 1.3083400000 = 0.6516568288 
0.0000000000 * 0.6439670000 = 0.6516568288 
0.0000000000 * -0.2499900000 = 0.6516568288 
0.0000000000 * 0.5996400000 = 0.6516568288 
0.0370344000 * -0.2050210000 = 0.6440639991 
0.0538087000 * 0.1040040000 = 0.6496603191 
0.0000000000 * -0.6003840000 = 0.6496603191 
0.1759170000 * -0.0001557050 = 0.6496329280 
the biases is : -0.5502580000, now tempVal is : 0.0993749280
compute layer: 2, node : 30
0.2276300000 * -0.6959740000 = -0.1584245616 
0.0000000000 * -0.1296070000 = -0.1584245616 
0.0534094000 * 0.6003060000 = -0.1263625783 
0.0000000000 * 0.3040150000 = -0.1263625783 
0.0000000000 * 0.5644090000 = -0.1263625783 
0.0000000000 * 1.6221000000 = -0.1263625783 
0.0746065000 * -0.2866260000 = -0.1477467410 
0.0000000000 * 0.8965100000 = -0.1477467410 
0.0000000000 * -0.3704370000 = -0.1477467410 
0.0000000000 * 0.0783919000 = -0.1477467410 
0.0587109000 * -0.1567960000 = -0.1569523753 
0.1839170000 * 0.0115489000 = -0.1548283362 
0.1319570000 * -0.5460740000 = -0.2268866231 
0.0000000000 * -0.3138700000 = -0.2268866231 
0.1969290000 * 0.4230870000 = -0.1435685232 
0.2066640000 * 0.4406430000 = -0.0525034783 
0.0000000000 * 0.1960420000 = -0.0525034783 
0.0306576000 * 0.0763858000 = -0.0501616730 
0.0000000000 * 1.0421100000 = -0.0501616730 
0.0000000000 * 0.4344970000 = -0.0501616730 
0.0000000000 * 1.1086500000 = -0.0501616730 
0.0000000000 * 1.1441600000 = -0.0501616730 
0.0969635000 * -0.3384500000 = -0.0829789696 
0.0098326600 * 0.6976080000 = -0.0761196273 
0.0000000000 * -0.0430303000 = -0.0761196273 
0.0000000000 * -0.1606250000 = -0.0761196273 
0.0000000000 * 0.1752190000 = -0.0761196273 
0.0710148000 * -0.2192860000 = -0.0916921787 
0.0000000000 * 0.1384020000 = -0.0916921787 
0.0000000000 * -0.5323770000 = -0.0916921787 
0.5590840000 * 0.4919730000 = 0.1833620540 
0.1354830000 * 0.2802620000 = 0.2213327906 
0.0000000000 * -0.0919107000 = 0.2213327906 
0.0000000000 * -0.9776110000 = 0.2213327906 
0.7596380000 * -0.1443090000 = 0.1117101904 
0.1328250000 * 1.3297700000 = 0.2883368907 
0.2355660000 * 0.9289620000 = 0.5071687532 
0.2148580000 * -0.2645230000 = 0.4503338704 
0.0000000000 * -0.3256960000 = 0.4503338704 
0.0000000000 * 0.0506461000 = 0.4503338704 
0.2216060000 * -0.0671854000 = 0.4354451827 
0.0000000000 * 0.9204200000 = 0.4354451827 
0.0000000000 * 1.5252400000 = 0.4354451827 
0.0000000000 * -0.0115185000 = 0.4354451827 
0.0000000000 * 1.2364600000 = 0.4354451827 
0.0000000000 * 0.3835550000 = 0.4354451827 
0.0370344000 * 1.1147000000 = 0.4767274284 
0.0538087000 * -1.2132800000 = 0.4114424088 
0.0000000000 * -0.2334830000 = 0.4114424088 
0.1759170000 * 0.2608750000 = 0.4573347562 
the biases is : -1.3335500000, now tempVal is : -0.8762152438
ReLU !!! in layer: 2, node : 30, its linear result is negative,so set it to 0
compute layer: 2, node : 31
0.2276300000 * 0.8895810000 = 0.2024953230 
0.0000000000 * 0.4277300000 = 0.2024953230 
0.0534094000 * 0.1020210000 = 0.2079442034 
0.0000000000 * -0.0690815000 = 0.2079442034 
0.0000000000 * -0.5010900000 = 0.2079442034 
0.0000000000 * 0.0994008000 = 0.2079442034 
0.0746065000 * 0.0777038000 = 0.2137414120 
0.0000000000 * 0.3554470000 = 0.2137414120 
0.0000000000 * 0.1222230000 = 0.2137414120 
0.0000000000 * -0.3301190000 = 0.2137414120 
0.0587109000 * -0.4188540000 = 0.1891501167 
0.1839170000 * 0.1058620000 = 0.2086199381 
0.1319570000 * -0.3966140000 = 0.1562839445 
0.0000000000 * -0.3520800000 = 0.1562839445 
0.1969290000 * -1.0088300000 = -0.0423839385 
0.2066640000 * -0.6463760000 = -0.1759665882 
0.0000000000 * -0.1437500000 = -0.1759665882 
0.0306576000 * -5.9431700000 = -0.3581699168 
0.0000000000 * 6.3626000000 = -0.3581699168 
0.0000000000 * 0.7676760000 = -0.3581699168 
0.0000000000 * 1.0694400000 = -0.3581699168 
0.0000000000 * -0.0252855000 = -0.3581699168 
0.0969635000 * -0.5456310000 = -0.4110762083 
0.0098326600 * 0.3821340000 = -0.4073188146 
0.0000000000 * -0.0321749000 = -0.4073188146 
0.0000000000 * -0.3544300000 = -0.4073188146 
0.0000000000 * 0.0832172000 = -0.4073188146 
0.0710148000 * 0.2262290000 = -0.3912532074 
0.0000000000 * -3.4526400000 = -0.3912532074 
0.0000000000 * -0.8110950000 = -0.3912532074 
0.5590840000 * -0.0026689400 = -0.3927453690 
0.1354830000 * -0.4379920000 = -0.4520858392 
0.0000000000 * 0.2989220000 = -0.4520858392 
0.0000000000 * -0.2600960000 = -0.4520858392 
0.7596380000 * -0.0647190000 = -0.5012488509 
0.1328250000 * -0.4213870000 = -0.5572195792 
0.2355660000 * 0.2648860000 = -0.4948214437 
0.2148580000 * 0.1883940000 = -0.4543434856 
0.0000000000 * -0.5363350000 = -0.4543434856 
0.0000000000 * -0.0919568000 = -0.4543434856 
0.2216060000 * 0.3441940000 = -0.3780680301 
0.0000000000 * 0.2396290000 = -0.3780680301 
0.0000000000 * 0.1563150000 = -0.3780680301 
0.0000000000 * 0.2881740000 = -0.3780680301 
0.0000000000 * 0.0615565000 = -0.3780680301 
0.0000000000 * -0.3323550000 = -0.3780680301 
0.0370344000 * -0.2278380000 = -0.3865058737 
0.0538087000 * -0.9690600000 = -0.4386497325 
0.0000000000 * 0.3395350000 = -0.4386497325 
0.1759170000 * 0.0669412000 = -0.4268736374 
the biases is : -1.1195600000, now tempVal is : -1.5464336374
ReLU !!! in layer: 2, node : 31, its linear result is negative,so set it to 0
compute layer: 2, node : 32
0.2276300000 * -0.3127970000 = -0.0712019811 
0.0000000000 * 0.5202450000 = -0.0712019811 
0.0534094000 * -0.2478110000 = -0.0844374179 
0.0000000000 * 0.6060600000 = -0.0844374179 
0.0000000000 * -0.3088670000 = -0.0844374179 
0.0000000000 * 0.0390312000 = -0.0844374179 
0.0746065000 * 0.3855160000 = -0.0556754185 
0.0000000000 * 0.2283540000 = -0.0556754185 
0.0000000000 * 0.3336150000 = -0.0556754185 
0.0000000000 * -0.6076360000 = -0.0556754185 
0.0587109000 * -0.7258120000 = -0.0982884942 
0.1839170000 * -0.5111160000 = -0.1922914156 
0.1319570000 * -1.2652000000 = -0.3592434120 
0.0000000000 * 0.0569628000 = -0.3592434120 
0.1969290000 * 0.8476650000 = -0.1923135912 
0.2066640000 * -0.1953230000 = -0.2326798237 
0.0000000000 * -2.1794500000 = -0.2326798237 
0.0306576000 * 0.4450480000 = -0.2190357201 
0.0000000000 * 0.2724760000 = -0.2190357201 
0.0000000000 * -0.0023962700 = -0.2190357201 
0.0000000000 * 0.8787270000 = -0.2190357201 
0.0000000000 * -0.3022100000 = -0.2190357201 
0.0969635000 * 0.0928734000 = -0.2100303902 
0.0098326600 * -0.0238151000 = -0.2102645560 
0.0000000000 * 0.0143469000 = -0.2102645560 
0.0000000000 * -0.3658010000 = -0.2102645560 
0.0000000000 * -0.1229280000 = -0.2102645560 
0.0710148000 * 0.3541990000 = -0.1851111848 
0.0000000000 * 0.1068780000 = -0.1851111848 
0.0000000000 * 1.1502800000 = -0.1851111848 
0.5590840000 * 0.3480790000 = 0.0094942148 
0.1354830000 * 0.2745760000 = 0.0466945950 
0.0000000000 * -0.6153800000 = 0.0466945950 
0.0000000000 * 0.7477060000 = 0.0466945950 
0.7596380000 * -0.1102950000 = -0.0370896782 
0.1328250000 * 0.4049830000 = 0.0167021888 
0.2355660000 * -0.4726550000 = -0.0946392590 
0.2148580000 * -0.0062685800 = -0.0959861135 
0.0000000000 * -1.0562900000 = -0.0959861135 
0.0000000000 * -0.3329010000 = -0.0959861135 
0.2216060000 * -0.3369360000 = -0.1706531527 
0.0000000000 * 0.3026570000 = -0.1706531527 
0.0000000000 * 1.4528900000 = -0.1706531527 
0.0000000000 * 0.8612870000 = -0.1706531527 
0.0000000000 * 0.2415940000 = -0.1706531527 
0.0000000000 * -1.3979500000 = -0.1706531527 
0.0370344000 * -0.6893640000 = -0.1961833349 
0.0538087000 * 0.1718020000 = -0.1869388926 
0.0000000000 * -0.6123820000 = -0.1869388926 
0.1759170000 * 0.2708540000 = -0.1392910695 
the biases is : -0.7316730000, now tempVal is : -0.8709640695
ReLU !!! in layer: 2, node : 32, its linear result is negative,so set it to 0
compute layer: 2, node : 33
0.2276300000 * 0.1935640000 = 0.0440609733 
0.0000000000 * 1.4452300000 = 0.0440609733 
0.0534094000 * 0.6599220000 = 0.0793070114 
0.0000000000 * 1.5942200000 = 0.0793070114 
0.0000000000 * 1.1214300000 = 0.0793070114 
0.0000000000 * 0.1544260000 = 0.0793070114 
0.0746065000 * -0.3206500000 = 0.0553844372 
0.0000000000 * 1.9537400000 = 0.0553844372 
0.0000000000 * 1.1312600000 = 0.0553844372 
0.0000000000 * 0.7487860000 = 0.0553844372 
0.0587109000 * 0.1112940000 = 0.0619186081 
0.1839170000 * 1.0583400000 = 0.2565653258 
0.1319570000 * 0.1778600000 = 0.2800351979 
0.0000000000 * 0.1739920000 = 0.2800351979 
0.1969290000 * 0.5910470000 = 0.3964294925 
0.2066640000 * -0.1564000000 = 0.3641072429 
0.0000000000 * 1.0019400000 = 0.3641072429 
0.0306576000 * -0.5509800000 = 0.3472155185 
0.0000000000 * 0.4217430000 = 0.3472155185 
0.0000000000 * 0.4749030000 = 0.3472155185 
0.0000000000 * 0.2326180000 = 0.3472155185 
0.0000000000 * 0.7670890000 = 0.3472155185 
0.0969635000 * -0.0872520000 = 0.3387552592 
0.0098326600 * -0.0644955000 = 0.3381210969 
0.0000000000 * 0.0031754700 = 0.3381210969 
0.0000000000 * 0.5045450000 = 0.3381210969 
0.0000000000 * 0.8661050000 = 0.3381210969 
0.0710148000 * -0.1290730000 = 0.3289550036 
0.0000000000 * -0.6673220000 = 0.3289550036 
0.0000000000 * 2.2109000000 = 0.3289550036 
0.5590840000 * -0.9284050000 = -0.1901013774 
0.1354830000 * -0.7750130000 = -0.2951024637 
0.0000000000 * 0.6484020000 = -0.2951024637 
0.0000000000 * 1.9962900000 = -0.2951024637 
0.7596380000 * -2.2268800000 = -1.9867251332 
0.1328250000 * 0.2002290000 = -1.9601297162 
0.2355660000 * -0.4516360000 = -2.0665198022 
0.2148580000 * -1.1549900000 = -2.3146786436 
0.0000000000 * 2.4939500000 = -2.3146786436 
0.0000000000 * -0.2150810000 = -2.3146786436 
0.2216060000 * -0.3550660000 = -2.3933633996 
0.0000000000 * 0.7242670000 = -2.3933633996 
0.0000000000 * 1.1544800000 = -2.3933633996 
0.0000000000 * 0.5984340000 = -2.3933633996 
0.0000000000 * -0.7220570000 = -2.3933633996 
0.0000000000 * 0.3554730000 = -2.3933633996 
0.0370344000 * -0.1574400000 = -2.3991940956 
0.0538087000 * 0.4821680000 = -2.3732492623 
0.0000000000 * 1.8524600000 = -2.3732492623 
0.1759170000 * -0.1330230000 = -2.3966502694 
the biases is : 0.2374150000, now tempVal is : -2.1592352694
ReLU !!! in layer: 2, node : 33, its linear result is negative,so set it to 0
compute layer: 2, node : 34
0.2276300000 * -0.1530710000 = -0.0348435517 
0.0000000000 * 0.0185324000 = -0.0348435517 
0.0534094000 * 0.4966090000 = -0.0083199630 
0.0000000000 * -0.1762420000 = -0.0083199630 
0.0000000000 * 0.1325200000 = -0.0083199630 
0.0000000000 * -0.3687070000 = -0.0083199630 
0.0746065000 * -0.3741780000 = -0.0362360740 
0.0000000000 * -0.6662810000 = -0.0362360740 
0.0000000000 * 0.7841580000 = -0.0362360740 
0.0000000000 * 0.0972886000 = -0.0362360740 
0.0587109000 * -0.0192852000 = -0.0373683254 
0.1839170000 * 0.3061200000 = 0.0189323466 
0.1319570000 * -0.8326630000 = -0.0909433649 
0.0000000000 * -0.3185170000 = -0.0909433649 
0.1969290000 * 0.1594660000 = -0.0595398849 
0.2066640000 * 0.1783600000 = -0.0226792939 
0.0000000000 * 0.3339910000 = -0.0226792939 
0.0306576000 * 0.4368960000 = -0.0092851111 
0.0000000000 * -1.0754600000 = -0.0092851111 
0.0000000000 * 0.2880740000 = -0.0092851111 
0.0000000000 * -0.1496330000 = -0.0092851111 
0.0000000000 * 0.5786930000 = -0.0092851111 
0.0969635000 * -0.0163636000 = -0.0108717830 
0.0098326600 * -0.0300377000 = -0.0111671335 
0.0000000000 * -0.0052357700 = -0.0111671335 
0.0000000000 * 0.1716760000 = -0.0111671335 
0.0000000000 * 0.2706490000 = -0.0111671335 
0.0710148000 * 1.1906200000 = 0.0733845077 
0.0000000000 * -0.1462850000 = 0.0733845077 
0.0000000000 * 1.7746500000 = 0.0733845077 
0.5590840000 * 0.3339480000 = 0.2600894913 
0.1354830000 * 0.7019420000 = 0.3551906993 
0.0000000000 * -0.3407340000 = 0.3551906993 
0.0000000000 * -0.1829130000 = 0.3551906993 
0.7596380000 * -0.4232620000 = 0.0336648001 
0.1328250000 * 0.4068860000 = 0.0877094331 
0.2355660000 * 0.3461950000 = 0.1692612044 
0.2148580000 * 0.2788650000 = 0.2291775806 
0.0000000000 * -0.0925859000 = 0.2291775806 
0.0000000000 * -1.1977900000 = 0.2291775806 
0.2216060000 * 0.1253430000 = 0.2569543415 
0.0000000000 * -0.1099690000 = 0.2569543415 
0.0000000000 * -0.1272160000 = 0.2569543415 
0.0000000000 * 0.1507080000 = 0.2569543415 
0.0000000000 * 0.5373670000 = 0.2569543415 
0.0000000000 * 0.2016250000 = 0.2569543415 
0.0370344000 * 0.3342420000 = 0.2693327934 
0.0538087000 * 0.0266590000 = 0.2707672795 
0.0000000000 * -0.1166100000 = 0.2707672795 
0.1759170000 * 0.7143120000 = 0.3964269036 
the biases is : -0.8274880000, now tempVal is : -0.4310610964
ReLU !!! in layer: 2, node : 34, its linear result is negative,so set it to 0
compute layer: 2, node : 35
0.2276300000 * 0.1470910000 = 0.0334823243 
0.0000000000 * -0.9208170000 = 0.0334823243 
0.0534094000 * -0.6704970000 = -0.0023285181 
0.0000000000 * 0.2762990000 = -0.0023285181 
0.0000000000 * -0.0595598000 = -0.0023285181 
0.0000000000 * -1.8004300000 = -0.0023285181 
0.0746065000 * 0.4822100000 = 0.0336474822 
0.0000000000 * 1.1820700000 = 0.0336474822 
0.0000000000 * 0.1636450000 = 0.0336474822 
0.0000000000 * 1.1555400000 = 0.0336474822 
0.0587109000 * 0.2085650000 = 0.0458925211 
0.1839170000 * 0.1230330000 = 0.0685203813 
0.1319570000 * 0.0145719000 = 0.0704432456 
0.0000000000 * 0.4832990000 = 0.0704432456 
0.1969290000 * -0.3706960000 = -0.0025575470 
0.2066640000 * 0.1166190000 = 0.0215434020 
0.0000000000 * -0.2024450000 = 0.0215434020 
0.0306576000 * -3.1970700000 = -0.0764710912 
0.0000000000 * 4.6203000000 = -0.0764710912 
0.0000000000 * -0.3800480000 = -0.0764710912 
0.0000000000 * 0.0601541000 = -0.0764710912 
0.0000000000 * 0.1744400000 = -0.0764710912 
0.0969635000 * 0.5369120000 = -0.0244102245 
0.0098326600 * -1.0438700000 = -0.0346742433 
0.0000000000 * 0.0414812000 = -0.0346742433 
0.0000000000 * 0.1187980000 = -0.0346742433 
0.0000000000 * 0.2002870000 = -0.0346742433 
0.0710148000 * 0.3210810000 = -0.0118727403 
0.0000000000 * -0.8688470000 = -0.0118727403 
0.0000000000 * 0.4206650000 = -0.0118727403 
0.5590840000 * -0.0039635600 = -0.0140887033 
0.1354830000 * 0.4965250000 = 0.0531819933 
0.0000000000 * 0.2653150000 = 0.0531819933 
0.0000000000 * 0.5516300000 = 0.0531819933 
0.7596380000 * 0.1375330000 = 0.1576572863 
0.1328250000 * -0.0918724000 = 0.1454543348 
0.2355660000 * -0.6422990000 = -0.0058494714 
0.2148580000 * 0.1441510000 = 0.0251225241 
0.0000000000 * 0.3352510000 = 0.0251225241 
0.0000000000 * 0.0266440000 = 0.0251225241 
0.2216060000 * -0.3916100000 = -0.0616606015 
0.0000000000 * -0.3068940000 = -0.0616606015 
0.0000000000 * -2.1848200000 = -0.0616606015 
0.0000000000 * -0.4693820000 = -0.0616606015 
0.0000000000 * 0.1554840000 = -0.0616606015 
0.0000000000 * 0.3296420000 = -0.0616606015 
0.0370344000 * 0.0499698000 = -0.0598100000 
0.0538087000 * -2.6732200000 = -0.2036524930 
0.0000000000 * 1.0975800000 = -0.2036524930 
0.1759170000 * -0.7590990000 = -0.3371909118 
the biases is : 0.3175290000, now tempVal is : -0.0196619118
ReLU !!! in layer: 2, node : 35, its linear result is negative,so set it to 0
compute layer: 2, node : 36
0.2276300000 * 0.5202400000 = 0.1184222312 
0.0000000000 * -0.2522080000 = 0.1184222312 
0.0534094000 * 0.6103680000 = 0.1510216199 
0.0000000000 * 0.8699770000 = 0.1510216199 
0.0000000000 * -0.1053830000 = 0.1510216199 
0.0000000000 * -0.5885150000 = 0.1510216199 
0.0746065000 * -0.3662130000 = 0.1236997497 
0.0000000000 * 0.3022300000 = 0.1236997497 
0.0000000000 * 0.1010590000 = 0.1236997497 
0.0000000000 * -0.2789910000 = 0.1236997497 
0.0587109000 * -0.3076020000 = 0.1056401594 
0.1839170000 * 0.0397712000 = 0.1129547592 
0.1319570000 * 0.1498320000 = 0.1327261404 
0.0000000000 * 0.5434510000 = 0.1327261404 
0.1969290000 * -0.0666054000 = 0.1196096056 
0.2066640000 * 0.4535210000 = 0.2133360696 
0.0000000000 * 0.0148984000 = 0.2133360696 
0.0306576000 * -0.4554940000 = 0.1993717167 
0.0000000000 * 1.2776100000 = 0.1993717167 
0.0000000000 * 0.0723849000 = 0.1993717167 
0.0000000000 * -2.0132700000 = 0.1993717167 
0.0000000000 * 0.2539640000 = 0.1993717167 
0.0969635000 * 0.5305490000 = 0.2508156047 
0.0098326600 * 0.2629470000 = 0.2534010731 
0.0000000000 * -0.0040259900 = 0.2534010731 
0.0000000000 * 0.8449940000 = 0.2534010731 
0.0000000000 * 0.4873160000 = 0.2534010731 
0.0710148000 * -1.2987200000 = 0.1611727321 
0.0000000000 * 0.3786000000 = 0.1611727321 
0.0000000000 * 1.7897000000 = 0.1611727321 
0.5590840000 * -0.1628880000 = 0.0701046575 
0.1354830000 * 1.2224900000 = 0.2357312701 
0.0000000000 * 1.7351600000 = 0.2357312701 
0.0000000000 * -0.4183350000 = 0.2357312701 
0.7596380000 * 0.0013910700 = 0.2367879798 
0.1328250000 * -0.2073000000 = 0.2092533573 
0.2355660000 * 0.2148100000 = 0.2598552897 
0.2148580000 * -0.5800940000 = 0.1352174531 
0.0000000000 * -0.4443390000 = 0.1352174531 
0.0000000000 * -0.5241510000 = 0.1352174531 
0.2216060000 * -0.0877953000 = 0.1157614878 
0.0000000000 * -1.3584100000 = 0.1157614878 
0.0000000000 * -2.0812500000 = 0.1157614878 
0.0000000000 * -0.2879980000 = 0.1157614878 
0.0000000000 * 0.2655650000 = 0.1157614878 
0.0000000000 * -0.0688904000 = 0.1157614878 
0.0370344000 * -0.6141910000 = 0.0930152927 
0.0538087000 * -0.4749380000 = 0.0674594963 
0.0000000000 * 0.6496890000 = 0.0674594963 
0.1759170000 * 0.0298627000 = 0.0727128529 
the biases is : -0.7418010000, now tempVal is : -0.6690881471
ReLU !!! in layer: 2, node : 36, its linear result is negative,so set it to 0
compute layer: 2, node : 37
0.2276300000 * 0.0033795700 = 0.0007692915 
0.0000000000 * 0.0035812300 = 0.0007692915 
0.0534094000 * -0.0523126000 = -0.0020246931 
0.0000000000 * -0.0435683000 = -0.0020246931 
0.0000000000 * -0.0121571000 = -0.0020246931 
0.0000000000 * 0.0389191000 = -0.0020246931 
0.0746065000 * -0.0244973000 = -0.0038523509 
0.0000000000 * 0.0083311400 = -0.0038523509 
0.0000000000 * -0.0030972600 = -0.0038523509 
0.0000000000 * -0.0167869000 = -0.0038523509 
0.0587109000 * -0.0075369900 = -0.0042948543 
0.1839170000 * -0.0139463000 = -0.0068598160 
0.1319570000 * -0.0515684000 = -0.0136646274 
0.0000000000 * -0.0134991000 = -0.0136646274 
0.1969290000 * -0.0500966000 = -0.0235301007 
0.2066640000 * 0.0318874000 = -0.0169401231 
0.0000000000 * 0.0118100000 = -0.0169401231 
0.0306576000 * -0.0374396000 = -0.0180879313 
0.0000000000 * -0.0066159800 = -0.0180879313 
0.0000000000 * -0.0471460000 = -0.0180879313 
0.0000000000 * 0.0211228000 = -0.0180879313 
0.0000000000 * 0.0419343000 = -0.0180879313 
0.0969635000 * -0.0287218000 = -0.0208728976 
0.0098326600 * -0.0241813000 = -0.0211106641 
0.0000000000 * -0.0021630600 = -0.0211106641 
0.0000000000 * -0.0163612000 = -0.0211106641 
0.0000000000 * -0.0027264000 = -0.0211106641 
0.0710148000 * -0.0023311900 = -0.0212762131 
0.0000000000 * -0.0456672000 = -0.0212762131 
0.0000000000 * 0.0397102000 = -0.0212762131 
0.5590840000 * 0.0369856000 = -0.0005981559 
0.1354830000 * -0.0438300000 = -0.0065363758 
0.0000000000 * -0.0307999000 = -0.0065363758 
0.0000000000 * -0.0311257000 = -0.0065363758 
0.7596380000 * 0.0045958200 = -0.0030452163 
0.1328250000 * -0.0222941000 = -0.0060064301 
0.2355660000 * -0.0466089000 = -0.0169859022 
0.2148580000 * -0.0410443000 = -0.0258045985 
0.0000000000 * 0.0011491900 = -0.0258045985 
0.0000000000 * -0.0275192000 = -0.0258045985 
0.2216060000 * 0.0201718000 = -0.0213344065 
0.0000000000 * 0.0173984000 = -0.0213344065 
0.0000000000 * -0.0135623000 = -0.0213344065 
0.0000000000 * -0.0421613000 = -0.0213344065 
0.0000000000 * 0.0354616000 = -0.0213344065 
0.0000000000 * -0.0466780000 = -0.0213344065 
0.0370344000 * -0.0230274000 = -0.0221872125 
0.0538087000 * 0.0185662000 = -0.0211881894 
0.0000000000 * -0.0059387400 = -0.0211881894 
0.1759170000 * -0.0432285000 = -0.0287928174 
the biases is : -0.0174412000, now tempVal is : -0.0462340174
ReLU !!! in layer: 2, node : 37, its linear result is negative,so set it to 0
compute layer: 2, node : 38
0.2276300000 * 0.0394096000 = 0.0089708072 
0.0000000000 * 0.5512100000 = 0.0089708072 
0.0534094000 * -0.0374195000 = 0.0069722542 
0.0000000000 * 2.1275500000 = 0.0069722542 
0.0000000000 * 0.0327126000 = 0.0069722542 
0.0000000000 * -0.0055392000 = 0.0069722542 
0.0746065000 * 0.1319430000 = 0.0168160596 
0.0000000000 * 1.4483200000 = 0.0168160596 
0.0000000000 * 0.3980950000 = 0.0168160596 
0.0000000000 * 1.1594100000 = 0.0168160596 
0.0587109000 * -0.0985198000 = 0.0110318735 
0.1839170000 * -0.2103240000 = -0.0276502856 
0.1319570000 * 0.0354951000 = -0.0229664587 
0.0000000000 * 0.0111342000 = -0.0229664587 
0.1969290000 * 0.0401923000 = -0.0150514292 
0.2066640000 * 0.0671328000 = -0.0011774963 
0.0000000000 * -0.0669259000 = -0.0011774963 
0.0306576000 * -0.1970690000 = -0.0072191588 
0.0000000000 * -0.1079300000 = -0.0072191588 
0.0000000000 * 0.1158930000 = -0.0072191588 
0.0000000000 * 0.1934120000 = -0.0072191588 
0.0000000000 * -0.1864140000 = -0.0072191588 
0.0969635000 * -0.0141833000 = -0.0085944212 
0.0098326600 * -0.1092710000 = -0.0096688458 
0.0000000000 * -0.0004625050 = -0.0096688458 
0.0000000000 * 0.4080580000 = -0.0096688458 
0.0000000000 * 0.2071890000 = -0.0096688458 
0.0710148000 * 0.0120423000 = -0.0088136643 
0.0000000000 * -0.0833266000 = -0.0088136643 
0.0000000000 * 0.0256778000 = -0.0088136643 
0.5590840000 * -3.8290500000 = -2.1495742545 
0.1354830000 * -0.0571050000 = -2.1573110112 
0.0000000000 * 1.0042200000 = -2.1573110112 
0.0000000000 * 2.0887700000 = -2.1573110112 
0.7596380000 * -1.6909600000 = -3.4418284837 
0.1328250000 * 0.0373892000 = -3.4368622632 
0.2355660000 * 0.0479907000 = -3.4255572860 
0.2148580000 * 0.0536657000 = -3.4140267810 
0.0000000000 * 2.5822700000 = -3.4140267810 
0.0000000000 * -0.0178714000 = -3.4140267810 
0.2216060000 * -0.1261880000 = -3.4419907989 
0.0000000000 * -0.0469560000 = -3.4419907989 
0.0000000000 * -0.0208863000 = -3.4419907989 
0.0000000000 * 0.6457680000 = -3.4419907989 
0.0000000000 * 0.0434935000 = -3.4419907989 
0.0000000000 * 0.6521710000 = -3.4419907989 
0.0370344000 * 0.0188168000 = -3.4412939300 
0.0538087000 * 0.1347780000 = -3.4340417011 
0.0000000000 * 1.7204300000 = -3.4340417011 
0.1759170000 * -0.0939978000 = -3.4505775121 
the biases is : -0.3022060000, now tempVal is : -3.7527835121
ReLU !!! in layer: 2, node : 38, its linear result is negative,so set it to 0
compute layer: 2, node : 39
0.2276300000 * 0.5445240000 = 0.1239499981 
0.0000000000 * 0.0611729000 = 0.1239499981 
0.0534094000 * -0.1002780000 = 0.1185942103 
0.0000000000 * -0.4166780000 = 0.1185942103 
0.0000000000 * 0.0386408000 = 0.1185942103 
0.0000000000 * -0.1430120000 = 0.1185942103 
0.0746065000 * 0.2051940000 = 0.1339030165 
0.0000000000 * -0.2028110000 = 0.1339030165 
0.0000000000 * -0.1436230000 = 0.1339030165 
0.0000000000 * 0.7224680000 = 0.1339030165 
0.0587109000 * -0.2726630000 = 0.1178947263 
0.1839170000 * 0.0566484000 = 0.1283133301 
0.1319570000 * -0.4649740000 = 0.0669567560 
0.0000000000 * -0.0557419000 = 0.0669567560 
0.1969290000 * -0.9351830000 = -0.1172078970 
0.2066640000 * -0.4872670000 = -0.2179084443 
0.0000000000 * 0.0660513000 = -0.2179084443 
0.0306576000 * -1.1468200000 = -0.2530671931 
0.0000000000 * 0.7519960000 = -0.2530671931 
0.0000000000 * 0.7762970000 = -0.2530671931 
0.0000000000 * 0.9993780000 = -0.2530671931 
0.0000000000 * 0.4153070000 = -0.2530671931 
0.0969635000 * -0.0259069000 = -0.2555792168 
0.0098326600 * 0.1743510000 = -0.2538648827 
0.0000000000 * 0.0108560000 = -0.2538648827 
0.0000000000 * -0.0581010000 = -0.2538648827 
0.0000000000 * -0.0898991000 = -0.2538648827 
0.0710148000 * -0.2102200000 = -0.2687936140 
0.0000000000 * -0.6493790000 = -0.2687936140 
0.0000000000 * -0.4430880000 = -0.2687936140 
0.5590840000 * 0.0840818000 = -0.2217848249 
0.1354830000 * 0.0259013000 = -0.2182756391 
0.0000000000 * 0.2617920000 = -0.2182756391 
0.0000000000 * 0.4335810000 = -0.2182756391 
0.7596380000 * -0.3185840000 = -0.4602841517 
0.1328250000 * -0.6491730000 = -0.5465105554 
0.2355660000 * 0.6928690000 = -0.3832941765 
0.2148580000 * -0.1593440000 = -0.4175305097 
0.0000000000 * 0.8411410000 = -0.4175305097 
0.0000000000 * 0.0955951000 = -0.4175305097 
0.2216060000 * -0.2898210000 = -0.4817565822 
0.0000000000 * -0.2508920000 = -0.4817565822 
0.0000000000 * -1.6858800000 = -0.4817565822 
0.0000000000 * 0.1527920000 = -0.4817565822 
0.0000000000 * 0.3148450000 = -0.4817565822 
0.0000000000 * 0.5034010000 = -0.4817565822 
0.0370344000 * -0.0960577000 = -0.4853140215 
0.0538087000 * -0.5622900000 = -0.5155701154 
0.0000000000 * 0.6015550000 = -0.5155701154 
0.1759170000 * -0.0050908200 = -0.5164656772 
the biases is : -0.0996994000, now tempVal is : -0.6161650772
ReLU !!! in layer: 2, node : 39, its linear result is negative,so set it to 0
compute layer: 2, node : 40
0.2276300000 * 0.0672764000 = 0.0153141269 
0.0000000000 * -0.4788930000 = 0.0153141269 
0.0534094000 * 0.8342310000 = 0.0598699041 
0.0000000000 * -0.2726910000 = 0.0598699041 
0.0000000000 * 0.1207820000 = 0.0598699041 
0.0000000000 * -2.3506000000 = 0.0598699041 
0.0746065000 * 0.4059750000 = 0.0901582779 
0.0000000000 * -0.9265390000 = 0.0901582779 
0.0000000000 * 0.4696390000 = 0.0901582779 
0.0000000000 * 0.1745900000 = 0.0901582779 
0.0587109000 * 0.0400554000 = 0.0925099665 
0.1839170000 * 0.2964080000 = 0.1470244367 
0.1319570000 * -0.2393500000 = 0.1154405287 
0.0000000000 * 1.1969800000 = 0.1154405287 
0.1969290000 * 0.1144790000 = 0.1379847637 
0.2066640000 * 0.1188280000 = 0.1625422335 
0.0000000000 * -0.7268330000 = 0.1625422335 
0.0306576000 * -0.3844860000 = 0.1507548155 
0.0000000000 * -0.6306760000 = 0.1507548155 
0.0000000000 * -0.8023550000 = 0.1507548155 
0.0000000000 * -1.8825200000 = 0.1507548155 
0.0000000000 * 1.5098900000 = 0.1507548155 
0.0969635000 * -0.6277030000 = 0.0898905357 
0.0098326600 * 0.3120840000 = 0.0929591515 
0.0000000000 * 0.0084205900 = 0.0929591515 
0.0000000000 * -0.7472980000 = 0.0929591515 
0.0000000000 * 0.2429160000 = 0.0929591515 
0.0710148000 * -0.4174420000 = 0.0633145914 
0.0000000000 * -0.0627678000 = 0.0633145914 
0.0000000000 * 0.4350470000 = 0.0633145914 
0.5590840000 * -0.4356110000 = -0.1802285489 
0.1354830000 * 1.0110900000 = -0.0432430425 
0.0000000000 * 1.1652100000 = -0.0432430425 
0.0000000000 * -0.4815820000 = -0.0432430425 
0.7596380000 * 0.0393550000 = -0.0133474890 
0.1328250000 * -0.4360700000 = -0.0712684867 
0.2355660000 * 0.0440735000 = -0.0608862686 
0.2148580000 * -0.8462130000 = -0.2427019014 
0.0000000000 * 0.4953750000 = -0.2427019014 
0.0000000000 * 0.2151440000 = -0.2427019014 
0.2216060000 * 0.0238547000 = -0.2374155567 
0.0000000000 * -0.2015470000 = -0.2374155567 
0.0000000000 * -2.2149800000 = -0.2374155567 
0.0000000000 * -0.3036790000 = -0.2374155567 
0.0000000000 * 0.6354500000 = -0.2374155567 
0.0000000000 * -0.2303950000 = -0.2374155567 
0.0370344000 * 0.7044470000 = -0.2113267848 
0.0538087000 * 0.8170420000 = -0.1673628169 
0.0000000000 * 1.3692600000 = -0.1673628169 
0.1759170000 * 0.0497661000 = -0.1586081139 
the biases is : 0.6550790000, now tempVal is : 0.4964708861
compute layer: 2, node : 41
0.2276300000 * -0.9286400000 = -0.2113863232 
0.0000000000 * -0.0805053000 = -0.2113863232 
0.0534094000 * 0.0640302000 = -0.2079665086 
0.0000000000 * -0.2630190000 = -0.2079665086 
0.0000000000 * 0.1660900000 = -0.2079665086 
0.0000000000 * -1.6621100000 = -0.2079665086 
0.0746065000 * -0.1320930000 = -0.2178215050 
0.0000000000 * -1.3270500000 = -0.2178215050 
0.0000000000 * 0.1660860000 = -0.2178215050 
0.0000000000 * -0.1298650000 = -0.2178215050 
0.0587109000 * -0.3345940000 = -0.2374658199 
0.1839170000 * 0.0661127000 = -0.2253065705 
0.1319570000 * 0.6330070000 = -0.1417768658 
0.0000000000 * 0.0379516000 = -0.1417768658 
0.1969290000 * -0.3870320000 = -0.2179946905 
0.2066640000 * -0.0128015000 = -0.2206402997 
0.0000000000 * 1.0130700000 = -0.2206402997 
0.0306576000 * -0.3846650000 = -0.2324332054 
0.0000000000 * 0.0075020800 = -0.2324332054 
0.0000000000 * 0.4838270000 = -0.2324332054 
0.0000000000 * -0.0300168000 = -0.2324332054 
0.0000000000 * 0.9709700000 = -0.2324332054 
0.0969635000 * -0.5164220000 = -0.2825072900 
0.0098326600 * -0.0000118488 = -0.2825074065 
0.0000000000 * -0.0239806000 = -0.2825074065 
0.0000000000 * -0.0991065000 = -0.2825074065 
0.0000000000 * -0.4516640000 = -0.2825074065 
0.0710148000 * -0.5089150000 = -0.3186479034 
0.0000000000 * 0.0869450000 = -0.3186479034 
0.0000000000 * -1.3724400000 = -0.3186479034 
0.5590840000 * -0.0566116000 = -0.3502985432 
0.1354830000 * 0.8455390000 = -0.2357423829 
0.0000000000 * -0.0248938000 = -0.2357423829 
0.0000000000 * 0.0752465000 = -0.2357423829 
0.7596380000 * 0.2832550000 = -0.0205711212 
0.1328250000 * 0.0503731000 = -0.0138803142 
0.2355660000 * -0.6359550000 = -0.1636896897 
0.2148580000 * -0.6338550000 = -0.2998785073 
0.0000000000 * -0.4630810000 = -0.2998785073 
0.0000000000 * 0.3661670000 = -0.2998785073 
0.2216060000 * -0.4435740000 = -0.3981771671 
0.0000000000 * -0.3033060000 = -0.3981771671 
0.0000000000 * -0.4552090000 = -0.3981771671 
0.0000000000 * -0.4375950000 = -0.3981771671 
0.0000000000 * 0.4779660000 = -0.3981771671 
0.0000000000 * 0.4345850000 = -0.3981771671 
0.0370344000 * -0.1278420000 = -0.4029117189 
0.0538087000 * -1.3090200000 = -0.4733483834 
0.0000000000 * 0.1761070000 = -0.4733483834 
0.1759170000 * 0.1035210000 = -0.4551372796 
the biases is : 1.2524100000, now tempVal is : 0.7972727204
compute layer: 2, node : 42
0.2276300000 * -0.0876844000 = -0.0199596000 
0.0000000000 * -0.0394447000 = -0.0199596000 
0.0534094000 * 0.0651309000 = -0.0164809977 
0.0000000000 * 1.9742400000 = -0.0164809977 
0.0000000000 * -0.2475380000 = -0.0164809977 
0.0000000000 * -0.1782400000 = -0.0164809977 
0.0746065000 * 0.3707580000 = 0.0111799590 
0.0000000000 * 0.4385170000 = 0.0111799590 
0.0000000000 * -0.0527650000 = 0.0111799590 
0.0000000000 * 0.0938755000 = 0.0111799590 
0.0587109000 * -1.6223400000 = -0.0840690825 
0.1839170000 * 0.3723720000 = -0.0155835413 
0.1319570000 * 0.6527170000 = 0.0705470358 
0.0000000000 * -0.3388960000 = 0.0705470358 
0.1969290000 * 0.6852370000 = 0.2054900730 
0.2066640000 * -0.0467079000 = 0.1958372316 
0.0000000000 * 0.0935516000 = 0.1958372316 
0.0306576000 * -0.5017770000 = 0.1804539530 
0.0000000000 * -0.0820838000 = 0.1804539530 
0.0000000000 * 0.1796160000 = 0.1804539530 
0.0000000000 * 0.1030240000 = 0.1804539530 
0.0000000000 * 0.0365015000 = 0.1804539530 
0.0969635000 * -0.1940730000 = 0.1616359557 
0.0098326600 * 0.5340990000 = 0.1668875695 
0.0000000000 * -0.0251719000 = 0.1668875695 
0.0000000000 * -0.7634320000 = 0.1668875695 
0.0000000000 * 0.1165820000 = 0.1668875695 
0.0710148000 * -0.6435830000 = 0.1211836515 
0.0000000000 * -0.0173197000 = 0.1211836515 
0.0000000000 * 0.6904730000 = 0.1211836515 
0.5590840000 * -0.6850650000 = -0.2618252289 
0.1354830000 * -0.2405480000 = -0.2944153936 
0.0000000000 * 0.4168650000 = -0.2944153936 
0.0000000000 * 2.4520800000 = -0.2944153936 
0.7596380000 * -1.0554000000 = -1.0961373388 
0.1328250000 * 0.3061080000 = -1.0554785437 
0.2355660000 * 0.1250490000 = -1.0260212510 
0.2148580000 * 0.2165600000 = -0.9794916025 
0.0000000000 * 2.4573300000 = -0.9794916025 
0.0000000000 * -0.0456824000 = -0.9794916025 
0.2216060000 * -1.4182400000 = -1.2937820960 
0.0000000000 * 0.3894720000 = -1.2937820960 
0.0000000000 * -0.4670010000 = -1.2937820960 
0.0000000000 * 0.3017310000 = -1.2937820960 
0.0000000000 * 0.8583880000 = -1.2937820960 
0.0000000000 * 0.9018230000 = -1.2937820960 
0.0370344000 * -0.4275940000 = -1.3096177832 
0.0538087000 * 0.6842890000 = -1.2727970817 
0.0000000000 * 0.0118938000 = -1.2727970817 
0.1759170000 * -0.2034760000 = -1.3085919692 
the biases is : 0.0390987000, now tempVal is : -1.2694932692
ReLU !!! in layer: 2, node : 42, its linear result is negative,so set it to 0
compute layer: 2, node : 43
0.2276300000 * -0.1369480000 = -0.0311734732 
0.0000000000 * 0.0094959900 = -0.0311734732 
0.0534094000 * -0.1388630000 = -0.0385900628 
0.0000000000 * 0.0145009000 = -0.0385900628 
0.0000000000 * 0.0200551000 = -0.0385900628 
0.0000000000 * -0.2408080000 = -0.0385900628 
0.0746065000 * -0.1230840000 = -0.0477729292 
0.0000000000 * 0.0325245000 = -0.0477729292 
0.0000000000 * 0.0788718000 = -0.0477729292 
0.0000000000 * 0.0204245000 = -0.0477729292 
0.0587109000 * -0.1368030000 = -0.0558047565 
0.1839170000 * -0.0574912000 = -0.0663783655 
0.1319570000 * 0.0101873000 = -0.0650340799 
0.0000000000 * 0.0759982000 = -0.0650340799 
0.1969290000 * -0.1461380000 = -0.0938128901 
0.2066640000 * -0.0910074000 = -0.1126208435 
0.0000000000 * 0.0573273000 = -0.1126208435 
0.0306576000 * -0.0659210000 = -0.1146418231 
0.0000000000 * 0.1479550000 = -0.1146418231 
0.0000000000 * 0.0703083000 = -0.1146418231 
0.0000000000 * -0.0661596000 = -0.1146418231 
0.0000000000 * 0.1055620000 = -0.1146418231 
0.0969635000 * -0.0755332000 = -0.1219657865 
0.0098326600 * -0.0848411000 = -0.1228000002 
0.0000000000 * -0.0047537300 = -0.1228000002 
0.0000000000 * 0.0660235000 = -0.1228000002 
0.0000000000 * 0.0783520000 = -0.1228000002 
0.0710148000 * -0.0748353000 = -0.1281144141 
0.0000000000 * -0.1363680000 = -0.1281144141 
0.0000000000 * 0.0435885000 = -0.1281144141 
0.5590840000 * -0.1473880000 = -0.2105166867 
0.1354830000 * 0.0636972000 = -0.2018867989 
0.0000000000 * 0.0917308000 = -0.2018867989 
0.0000000000 * 0.0016157400 = -0.2018867989 
0.7596380000 * -0.1128730000 = -0.2876294189 
0.1328250000 * -0.1444280000 = -0.3068130680 
0.2355660000 * -0.0574710000 = -0.3203512816 
0.2148580000 * 0.0699405000 = -0.3053240056 
0.0000000000 * 0.0593641000 = -0.3053240056 
0.0000000000 * -0.1690080000 = -0.3053240056 
0.2216060000 * -0.0948852000 = -0.3263511353 
0.0000000000 * -0.0303798000 = -0.3263511353 
0.0000000000 * -0.0645098000 = -0.3263511353 
0.0000000000 * 0.0536553000 = -0.3263511353 
0.0000000000 * 0.0368449000 = -0.3263511353 
0.0000000000 * 0.0618894000 = -0.3263511353 
0.0370344000 * 0.0667266000 = -0.3238799557 
0.0538087000 * 0.0957317000 = -0.3187287574 
0.0000000000 * 0.0667804000 = -0.3187287574 
0.1759170000 * -0.1160740000 = -0.3391481472 
the biases is : -0.0242382000, now tempVal is : -0.3633863472
ReLU !!! in layer: 2, node : 43, its linear result is negative,so set it to 0
compute layer: 2, node : 44
0.2276300000 * 0.4699260000 = 0.1069692554 
0.0000000000 * 0.4088840000 = 0.1069692554 
0.0534094000 * 0.1854630000 = 0.1168747229 
0.0000000000 * 0.8688830000 = 0.1168747229 
0.0000000000 * -0.9476570000 = 0.1168747229 
0.0000000000 * -8.5792000000 = 0.1168747229 
0.0746065000 * -3.5073100000 = -0.1447934006 
0.0000000000 * 1.1403000000 = -0.1447934006 
0.0000000000 * 0.0518583000 = -0.1447934006 
0.0000000000 * 0.3139760000 = -0.1447934006 
0.0587109000 * 0.4311510000 = -0.1194801373 
0.1839170000 * 1.8457900000 = 0.2199920221 
0.1319570000 * 0.2447690000 = 0.2522910050 
0.0000000000 * -0.0179830000 = 0.2522910050 
0.1969290000 * -0.1121370000 = 0.2302079778 
0.2066640000 * 1.0983400000 = 0.4571953155 
0.0000000000 * 0.4793140000 = 0.4571953155 
0.0306576000 * -0.4324280000 = 0.4439381109 
0.0000000000 * 1.7045700000 = 0.4439381109 
0.0000000000 * -0.6867100000 = 0.4439381109 
0.0000000000 * -0.2695060000 = 0.4439381109 
0.0000000000 * -0.3307780000 = 0.4439381109 
0.0969635000 * -0.6586050000 = 0.3800774649 
0.0098326600 * -0.2246330000 = 0.3778687250 
0.0000000000 * 0.0204342000 = 0.3778687250 
0.0000000000 * 0.5214410000 = 0.3778687250 
0.0000000000 * 0.9139280000 = 0.3778687250 
0.0710148000 * 0.7911340000 = 0.4340509478 
0.0000000000 * -0.7329730000 = 0.4340509478 
0.0000000000 * 0.1017040000 = 0.4340509478 
0.5590840000 * -0.6235390000 = 0.0854402695 
0.1354830000 * -0.7170650000 = -0.0117098479 
0.0000000000 * 0.7277610000 = -0.0117098479 
0.0000000000 * -0.7287950000 = -0.0117098479 
0.7596380000 * -1.7978000000 = -1.3773870443 
0.1328250000 * 1.0837400000 = -1.2334392788 
0.2355660000 * 0.6663710000 = -1.0764649278 
0.2148580000 * 0.0765811000 = -1.0600108658 
0.0000000000 * 0.1866470000 = -1.0600108658 
0.0000000000 * -0.1713600000 = -1.0600108658 
0.2216060000 * 0.6213380000 = -0.9223186370 
0.0000000000 * -0.3588660000 = -0.9223186370 
0.0000000000 * 0.2821170000 = -0.9223186370 
0.0000000000 * -0.1371080000 = -0.9223186370 
0.0000000000 * -0.2101270000 = -0.9223186370 
0.0000000000 * 0.3609470000 = -0.9223186370 
0.0370344000 * 0.4004600000 = -0.9074878411 
0.0538087000 * 0.4376480000 = -0.8839385712 
0.0000000000 * 0.8844440000 = -0.8839385712 
0.1759170000 * -1.5219900000 = -1.1516824860 
the biases is : -0.3856960000, now tempVal is : -1.5373784860
ReLU !!! in layer: 2, node : 44, its linear result is negative,so set it to 0
compute layer: 2, node : 45
0.2276300000 * 0.5176930000 = 0.1178424576 
0.0000000000 * -0.1888610000 = 0.1178424576 
0.0534094000 * -0.1106530000 = 0.1119325473 
0.0000000000 * 0.6101810000 = 0.1119325473 
0.0000000000 * 0.3576510000 = 0.1119325473 
0.0000000000 * 1.1095900000 = 0.1119325473 
0.0746065000 * 0.2130890000 = 0.1278303717 
0.0000000000 * 0.1383390000 = 0.1278303717 
0.0000000000 * -0.5981330000 = 0.1278303717 
0.0000000000 * 0.0333181000 = 0.1278303717 
0.0587109000 * -0.2864770000 = 0.1110110492 
0.1839170000 * 0.0409145000 = 0.1185359213 
0.1319570000 * -0.8965200000 = 0.0002338317 
0.0000000000 * 0.5634810000 = 0.0002338317 
0.1969290000 * 0.1054930000 = 0.0210084627 
0.2066640000 * -1.1844200000 = -0.2237685122 
0.0000000000 * -1.1641300000 = -0.2237685122 
0.0306576000 * 0.4424350000 = -0.2102045169 
0.0000000000 * -1.3584600000 = -0.2102045169 
0.0000000000 * 0.5990780000 = -0.2102045169 
0.0000000000 * -0.0404175000 = -0.2102045169 
0.0000000000 * 1.9820100000 = -0.2102045169 
0.0969635000 * -2.9036200000 = -0.4917496748 
0.0098326600 * 0.6235240000 = -0.4856187753 
0.0000000000 * 0.0098696400 = -0.4856187753 
0.0000000000 * 0.4911890000 = -0.4856187753 
0.0000000000 * -0.3930000000 = -0.4856187753 
0.0710148000 * 0.3945160000 = -0.4576023005 
0.0000000000 * -0.5092880000 = -0.4576023005 
0.0000000000 * -1.0722000000 = -0.4576023005 
0.5590840000 * 0.0456513000 = -0.4320793891 
0.1354830000 * -0.4905000000 = -0.4985338006 
0.0000000000 * -0.3572250000 = -0.4985338006 
0.0000000000 * -0.4293780000 = -0.4985338006 
0.7596380000 * 0.1699150000 = -0.3694599098 
0.1328250000 * 0.1533390000 = -0.3490926571 
0.2355660000 * 0.3533800000 = -0.2658483440 
0.2148580000 * 0.9764870000 = -0.0560423002 
0.0000000000 * -0.6933230000 = -0.0560423002 
0.0000000000 * -0.7233890000 = -0.0560423002 
0.2216060000 * -0.2328650000 = -0.1076465814 
0.0000000000 * 0.0909224000 = -0.1076465814 
0.0000000000 * 0.5225030000 = -0.1076465814 
0.0000000000 * -0.4991660000 = -0.1076465814 
0.0000000000 * -0.4393030000 = -0.1076465814 
0.0000000000 * -0.1795120000 = -0.1076465814 
0.0370344000 * 0.5070230000 = -0.0888692888 
0.0538087000 * 0.4466330000 = -0.0648365477 
0.0000000000 * 0.0971412000 = -0.0648365477 
0.1759170000 * -0.4231090000 = -0.1392686136 
the biases is : -0.3590710000, now tempVal is : -0.4983396136
ReLU !!! in layer: 2, node : 45, its linear result is negative,so set it to 0
compute layer: 2, node : 46
0.2276300000 * -0.1649870000 = -0.0375559908 
0.0000000000 * -0.0833527000 = -0.0375559908 
0.0534094000 * 0.2424730000 = -0.0246056534 
0.0000000000 * 0.8503680000 = -0.0246056534 
0.0000000000 * -0.4794600000 = -0.0246056534 
0.0000000000 * 0.5825130000 = -0.0246056534 
0.0746065000 * 0.9829520000 = 0.0487289550 
0.0000000000 * 1.0787900000 = 0.0487289550 
0.0000000000 * 0.7268920000 = 0.0487289550 
0.0000000000 * 0.5292690000 = 0.0487289550 
0.0587109000 * -0.4185370000 = 0.0241562711 
0.1839170000 * -0.7809710000 = -0.1194775723 
0.1319570000 * 0.3651210000 = -0.0712973005 
0.0000000000 * 0.7174310000 = -0.0712973005 
0.1969290000 * 0.2656420000 = -0.0189846871 
0.2066640000 * -0.0855164000 = -0.0366578484 
0.0000000000 * -0.0624654000 = -0.0366578484 
0.0306576000 * -0.0433837000 = -0.0379878885 
0.0000000000 * -0.4745970000 = -0.0379878885 
0.0000000000 * 0.2636880000 = -0.0379878885 
0.0000000000 * 0.0366676000 = -0.0379878885 
0.0000000000 * 1.0547600000 = -0.0379878885 
0.0969635000 * -0.1846340000 = -0.0558906474 
0.0098326600 * 0.3424880000 = -0.0525230793 
0.0000000000 * -0.0071398700 = -0.0525230793 
0.0000000000 * 0.7951760000 = -0.0525230793 
0.0000000000 * 1.1953300000 = -0.0525230793 
0.0710148000 * 0.5417260000 = -0.0140525158 
0.0000000000 * 0.6097280000 = -0.0140525158 
0.0000000000 * 0.1735060000 = -0.0140525158 
0.5590840000 * -2.5762500000 = -1.4543926708 
0.1354830000 * -1.2116100000 = -1.6185452284 
0.0000000000 * 1.0144000000 = -1.6185452284 
0.0000000000 * 1.1573500000 = -1.6185452284 
0.7596380000 * -1.4084600000 = -2.6884649659 
0.1328250000 * 0.8103310000 = -2.5808327508 
0.2355660000 * 0.1299690000 = -2.5502164734 
0.2148580000 * 0.5324790000 = -2.4358091004 
0.0000000000 * 2.0418600000 = -2.4358091004 
0.0000000000 * 0.1375690000 = -2.4358091004 
0.2216060000 * -0.1647290000 = -2.4723140352 
0.0000000000 * -0.5304150000 = -2.4723140352 
0.0000000000 * 0.2259230000 = -2.4723140352 
0.0000000000 * 0.6529570000 = -2.4723140352 
0.0000000000 * -0.1655510000 = -2.4723140352 
0.0000000000 * 0.6864380000 = -2.4723140352 
0.0370344000 * 0.1997110000 = -2.4649178581 
0.0538087000 * 0.8208530000 = -2.4207488253 
0.0000000000 * 1.6985000000 = -2.4207488253 
0.1759170000 * -0.9240890000 = -2.5833117899 
the biases is : -0.1558560000, now tempVal is : -2.7391677899
ReLU !!! in layer: 2, node : 46, its linear result is negative,so set it to 0
compute layer: 2, node : 47
0.2276300000 * 0.3966910000 = 0.0902987723 
0.0000000000 * -0.0966309000 = 0.0902987723 
0.0534094000 * 0.5247380000 = 0.1183247141 
0.0000000000 * 0.2903950000 = 0.1183247141 
0.0000000000 * -0.1411330000 = 0.1183247141 
0.0000000000 * -1.8913300000 = 0.1183247141 
0.0746065000 * -1.6107200000 = -0.0018454676 
0.0000000000 * 0.1250040000 = -0.0018454676 
0.0000000000 * -0.4605840000 = -0.0018454676 
0.0000000000 * 0.9903980000 = -0.0018454676 
0.0587109000 * 0.1499350000 = 0.0069573512 
0.1839170000 * -0.4036420000 = -0.0672792745 
0.1319570000 * -0.2087450000 = -0.0948246385 
0.0000000000 * -0.3960320000 = -0.0948246385 
0.1969290000 * -1.3251600000 = -0.3557870721 
0.2066640000 * -0.2297430000 = -0.4032666795 
0.0000000000 * -0.7859020000 = -0.4032666795 
0.0306576000 * 0.1202390000 = -0.3995804403 
0.0000000000 * -0.4749800000 = -0.3995804403 
0.0000000000 * 0.5983140000 = -0.3995804403 
0.0000000000 * -2.3821800000 = -0.3995804403 
0.0000000000 * 1.4270700000 = -0.3995804403 
0.0969635000 * 0.2474730000 = -0.3755845921 
0.0098326600 * -0.1412310000 = -0.3769732685 
0.0000000000 * -0.0268979000 = -0.3769732685 
0.0000000000 * 0.2710520000 = -0.3769732685 
0.0000000000 * -0.9507640000 = -0.3769732685 
0.0710148000 * -0.4880940000 = -0.4116351663 
0.0000000000 * 0.7893930000 = -0.4116351663 
0.0000000000 * -0.0062522800 = -0.4116351663 
0.5590840000 * -0.1231650000 = -0.4804947471 
0.1354830000 * 0.1101310000 = -0.4655738689 
0.0000000000 * -0.1703460000 = -0.4655738689 
0.0000000000 * 0.4735050000 = -0.4655738689 
0.7596380000 * -0.0567374000 = -0.5086737539 
0.1328250000 * -0.1988190000 = -0.5350818876 
0.2355660000 * -0.0413459000 = -0.5448215759 
0.2148580000 * 0.3357430000 = -0.4726845064 
0.0000000000 * 0.2296500000 = -0.4726845064 
0.0000000000 * -0.1055830000 = -0.4726845064 
0.2216060000 * -0.3424920000 = -0.5485827885 
0.0000000000 * 0.0980278000 = -0.5485827885 
0.0000000000 * -0.7323160000 = -0.5485827885 
0.0000000000 * 0.0609348000 = -0.5485827885 
0.0000000000 * 0.6048830000 = -0.5485827885 
0.0000000000 * 0.5810110000 = -0.5485827885 
0.0370344000 * -1.7630800000 = -0.6138773985 
0.0538087000 * -0.7420390000 = -0.6538055524 
0.0000000000 * -0.1696200000 = -0.6538055524 
0.1759170000 * -0.5814660000 = -0.7560953068 
the biases is : 0.0285971000, now tempVal is : -0.7274982068
ReLU !!! in layer: 2, node : 47, its linear result is negative,so set it to 0
compute layer: 2, node : 48
0.2276300000 * -1.2450800000 = -0.2834175604 
0.0000000000 * 0.5626990000 = -0.2834175604 
0.0534094000 * 0.2601050000 = -0.2695255084 
0.0000000000 * -0.2362350000 = -0.2695255084 
0.0000000000 * -0.3679310000 = -0.2695255084 
0.0000000000 * -0.2267990000 = -0.2695255084 
0.0746065000 * 0.2391460000 = -0.2516836624 
0.0000000000 * 0.6635390000 = -0.2516836624 
0.0000000000 * -0.8591040000 = -0.2516836624 
0.0000000000 * -0.8280270000 = -0.2516836624 
0.0587109000 * -0.1149670000 = -0.2584334784 
0.1839170000 * 0.4529360000 = -0.1751308481 
0.1319570000 * -0.0238205000 = -0.1782741298 
0.0000000000 * 0.4821790000 = -0.1782741298 
0.1969290000 * 0.8252680000 = -0.0157549278 
0.2066640000 * 0.1613580000 = 0.0175919619 
0.0000000000 * -0.0338258000 = 0.0175919619 
0.0306576000 * 0.5683600000 = 0.0350165154 
0.0000000000 * -1.8827500000 = 0.0350165154 
0.0000000000 * 0.7450160000 = 0.0350165154 
0.0000000000 * -0.0119559000 = 0.0350165154 
0.0000000000 * -1.0478300000 = 0.0350165154 
0.0969635000 * 1.1007500000 = 0.1417490880 
0.0098326600 * 0.3318470000 = 0.1450120268 
0.0000000000 * -0.0344808000 = 0.1450120268 
0.0000000000 * 0.2386940000 = 0.1450120268 
0.0000000000 * 0.0153113000 = 0.1450120268 
0.0710148000 * 0.1144930000 = 0.1531427243 
0.0000000000 * 0.3546610000 = 0.1531427243 
0.0000000000 * 0.4533070000 = 0.1531427243 
0.5590840000 * -0.1660630000 = 0.0602995580 
0.1354830000 * -0.7102240000 = -0.0359237202 
0.0000000000 * -0.6565240000 = -0.0359237202 
0.0000000000 * -0.2077680000 = -0.0359237202 
0.7596380000 * -0.2619550000 = -0.2349146925 
0.1328250000 * 0.3243390000 = -0.1918343648 
0.2355660000 * -0.0728687000 = -0.2089997530 
0.2148580000 * 0.7261050000 = -0.0529902849 
0.0000000000 * -0.0455242000 = -0.0529902849 
0.0000000000 * -1.2691300000 = -0.0529902849 
0.2216060000 * -0.6329060000 = -0.1932460520 
0.0000000000 * 0.4174520000 = -0.1932460520 
0.0000000000 * 1.4387800000 = -0.1932460520 
0.0000000000 * -0.3903300000 = -0.1932460520 
0.0000000000 * -0.0065411700 = -0.1932460520 
0.0000000000 * -1.0086300000 = -0.1932460520 
0.0370344000 * 0.0509374000 = -0.1913596159 
0.0538087000 * 0.6466980000 = -0.1565616373 
0.0000000000 * -0.1598380000 = -0.1565616373 
0.1759170000 * -0.2311390000 = -0.1972229167 
the biases is : -0.4266230000, now tempVal is : -0.6238459167
ReLU !!! in layer: 2, node : 48, its linear result is negative,so set it to 0
compute layer: 2, node : 49
0.2276300000 * -0.3487130000 = -0.0793775402 
0.0000000000 * 0.0989373000 = -0.0793775402 
0.0534094000 * 0.1763640000 = -0.0699580448 
0.0000000000 * 1.0037100000 = -0.0699580448 
0.0000000000 * 0.2170030000 = -0.0699580448 
0.0000000000 * 0.2446860000 = -0.0699580448 
0.0746065000 * 0.0574970000 = -0.0656683948 
0.0000000000 * 0.5668700000 = -0.0656683948 
0.0000000000 * -0.3482770000 = -0.0656683948 
0.0000000000 * 2.1293100000 = -0.0656683948 
0.0587109000 * 0.2621620000 = -0.0502766279 
0.1839170000 * -0.5176900000 = -0.1454886196 
0.1319570000 * -0.1124070000 = -0.1603215101 
0.0000000000 * -0.3091140000 = -0.1603215101 
0.1969290000 * 0.1196330000 = -0.1367623030 
0.2066640000 * 0.2838630000 = -0.0780980400 
0.0000000000 * 0.3792860000 = -0.0780980400 
0.0306576000 * 0.0909194000 = -0.0753106694 
0.0000000000 * -0.0207329000 = -0.0753106694 
0.0000000000 * 0.6669180000 = -0.0753106694 
0.0000000000 * 0.2885510000 = -0.0753106694 
0.0000000000 * -0.0461617000 = -0.0753106694 
0.0969635000 * -0.1568720000 = -0.0905215276 
0.0098326600 * 0.0430320000 = -0.0900984086 
0.0000000000 * -0.0235660000 = -0.0900984086 
0.0000000000 * 0.3680110000 = -0.0900984086 
0.0000000000 * 0.0401163000 = -0.0900984086 
0.0710148000 * 0.2133420000 = -0.0749479691 
0.0000000000 * 0.0291498000 = -0.0749479691 
0.0000000000 * 0.1919330000 = -0.0749479691 
0.5590840000 * -0.3804000000 = -0.2876235227 
0.1354830000 * 0.0649060000 = -0.2788298631 
0.0000000000 * 0.1402890000 = -0.2788298631 
0.0000000000 * 1.3862100000 = -0.2788298631 
0.7596380000 * -0.3875080000 = -0.5731956652 
0.1328250000 * -0.4344610000 = -0.6309029475 
0.2355660000 * -0.0981892000 = -0.6540329846 
0.2148580000 * -0.6130560000 = -0.7857529707 
0.0000000000 * 0.6172260000 = -0.7857529707 
0.0000000000 * 0.1719850000 = -0.7857529707 
0.2216060000 * -0.2661640000 = -0.8447365101 
0.0000000000 * 0.0484587000 = -0.8447365101 
0.0000000000 * 0.3310190000 = -0.8447365101 
0.0000000000 * 0.3217730000 = -0.8447365101 
0.0000000000 * 0.5070490000 = -0.8447365101 
0.0000000000 * 0.8953110000 = -0.8447365101 
0.0370344000 * -0.1507590000 = -0.8503197792 
0.0538087000 * -0.6023800000 = -0.8827330639 
0.0000000000 * -0.1421550000 = -0.8827330639 
0.1759170000 * 0.1609510000 = -0.8544190468 
the biases is : 0.7809250000, now tempVal is : -0.0734940468
ReLU !!! in layer: 2, node : 49, its linear result is negative,so set it to 0

now we get all result in layer: 2
	node: 0, val: 0.2476063322
	node: 1, val: 0.0000000000
	node: 2, val: 0.5022157730
	node: 3, val: 0.0000000000
	node: 4, val: 0.1501012128
	node: 5, val: 0.0000000000
	node: 6, val: 0.2408135472
	node: 7, val: 0.0000000000
	node: 8, val: 0.0000000000
	node: 9, val: 0.6533630315
	node: 10, val: 0.0000000000
	node: 11, val: 0.0000000000
	node: 12, val: 0.0000000000
	node: 13, val: 0.0000000000
	node: 14, val: 0.0000000000
	node: 15, val: 0.0000000000
	node: 16, val: 0.0000000000
	node: 17, val: 0.1176464584
	node: 18, val: 0.0000000000
	node: 19, val: 0.0000000000
	node: 20, val: 0.0554119915
	node: 21, val: 0.2550187259
	node: 22, val: 0.0000000000
	node: 23, val: 0.0000000000
	node: 24, val: 0.0000000000
	node: 25, val: 0.0000000000
	node: 26, val: 0.0000000000
	node: 27, val: 0.0000000000
	node: 28, val: 0.0000000000
	node: 29, val: 0.0993749280
	node: 30, val: 0.0000000000
	node: 31, val: 0.0000000000
	node: 32, val: 0.0000000000
	node: 33, val: 0.0000000000
	node: 34, val: 0.0000000000
	node: 35, val: 0.0000000000
	node: 36, val: 0.0000000000
	node: 37, val: 0.0000000000
	node: 38, val: 0.0000000000
	node: 39, val: 0.0000000000
	node: 40, val: 0.4964708861
	node: 41, val: 0.7972727204
	node: 42, val: 0.0000000000
	node: 43, val: 0.0000000000
	node: 44, val: 0.0000000000
	node: 45, val: 0.0000000000
	node: 46, val: 0.0000000000
	node: 47, val: 0.0000000000
	node: 48, val: 0.0000000000
	node: 49, val: 0.0000000000

when compute layer[2] to layer[3]
compute layer: 3, node : 0
0.2476063322 * 0.1460620000 = 0.0361658761 
0.0000000000 * -0.0054906900 = 0.0361658761 
0.5022157730 * 0.7939070000 = 0.4348784938 
0.0000000000 * 1.3088800000 = 0.4348784938 
0.1501012128 * 0.2240810000 = 0.4685133236 
0.0000000000 * -1.3641000000 = 0.4685133236 
0.2408135472 * -0.1096350000 = 0.4421117304 
0.0000000000 * 0.8985390000 = 0.4421117304 
0.0000000000 * 0.3100220000 = 0.4421117304 
0.6533630315 * 0.0068247500 = 0.4465707697 
0.0000000000 * -0.0036206200 = 0.4465707697 
0.0000000000 * 0.1498340000 = 0.4465707697 
0.0000000000 * -0.2350710000 = 0.4465707697 
0.0000000000 * 0.1578900000 = 0.4465707697 
0.0000000000 * -0.0017813500 = 0.4465707697 
0.0000000000 * 0.4847200000 = 0.4465707697 
0.0000000000 * 0.3238070000 = 0.4465707697 
0.1176464584 * -0.5980650000 = 0.3762105406 
0.0000000000 * -0.4915310000 = 0.3762105406 
0.0000000000 * 0.3244350000 = 0.3762105406 
0.0554119915 * -0.6684010000 = 0.3391731101 
0.2550187259 * 0.3049150000 = 0.4169321449 
0.0000000000 * 0.4190030000 = 0.4169321449 
0.0000000000 * 0.2987460000 = 0.4169321449 
0.0000000000 * 0.0234912000 = 0.4169321449 
0.0000000000 * 0.0054965300 = 0.4169321449 
0.0000000000 * -0.1794870000 = 0.4169321449 
0.0000000000 * -1.5038600000 = 0.4169321449 
0.0000000000 * 0.0308066000 = 0.4169321449 
0.0993749280 * 0.3376360000 = 0.4504846981 
0.0000000000 * 0.3407960000 = 0.4504846981 
0.0000000000 * 1.6473900000 = 0.4504846981 
0.0000000000 * 0.0150481000 = 0.4504846981 
0.0000000000 * 0.3390500000 = 0.4504846981 
0.0000000000 * 0.3954860000 = 0.4504846981 
0.0000000000 * -0.7853590000 = 0.4504846981 
0.0000000000 * -0.6335380000 = 0.4504846981 
0.0000000000 * -0.0384620000 = 0.4504846981 
0.0000000000 * -3.2246100000 = 0.4504846981 
0.0000000000 * 0.6247050000 = 0.4504846981 
0.4964708861 * -0.8801330000 = 0.0135242877 
0.7972727204 * -1.0050300000 = -0.7877587145 
0.0000000000 * -0.5206760000 = -0.7877587145 
0.0000000000 * 0.0333464000 = -0.7877587145 
0.0000000000 * 0.4965590000 = -0.7877587145 
0.0000000000 * 0.1137490000 = -0.7877587145 
0.0000000000 * -1.1159000000 = -0.7877587145 
0.0000000000 * -1.1565700000 = -0.7877587145 
0.0000000000 * 0.5152790000 = -0.7877587145 
0.0000000000 * -0.1326220000 = -0.7877587145 
the biases is : -0.4084860000, now tempVal is : -1.1962447145
ReLU !!! in layer: 3, node : 0, its linear result is negative,so set it to 0
compute layer: 3, node : 1
0.2476063322 * -1.1590000000 = -0.2869757391 
0.0000000000 * -0.0082778900 = -0.2869757391 
0.5022157730 * -0.4786480000 = -0.5273603144 
0.0000000000 * -0.4851650000 = -0.5273603144 
0.1501012128 * 1.4353300000 = -0.3119155406 
0.0000000000 * 1.0891200000 = -0.3119155406 
0.2408135472 * 0.3483080000 = -0.2280382556 
0.0000000000 * -4.8434600000 = -0.2280382556 
0.0000000000 * 0.0427388000 = -0.2280382556 
0.6533630315 * 0.3704650000 = 0.0140098799 
0.0000000000 * -0.0192723000 = 0.0140098799 
0.0000000000 * -0.6737090000 = 0.0140098799 
0.0000000000 * 0.1607450000 = 0.0140098799 
0.0000000000 * 0.6504050000 = 0.0140098799 
0.0000000000 * 0.8563480000 = 0.0140098799 
0.0000000000 * 0.0371640000 = 0.0140098799 
0.0000000000 * 0.0255892000 = 0.0140098799 
0.1176464584 * -0.2628800000 = -0.0169170211 
0.0000000000 * -1.0854400000 = -0.0169170211 
0.0000000000 * -0.3631100000 = -0.0169170211 
0.0554119915 * -1.6206100000 = -0.1067182486 
0.2550187259 * -0.7892670000 = -0.3079961133 
0.0000000000 * 0.3739780000 = -0.3079961133 
0.0000000000 * -0.9789650000 = -0.3079961133 
0.0000000000 * 0.0276093000 = -0.3079961133 
0.0000000000 * 0.0313649000 = -0.3079961133 
0.0000000000 * 0.5368090000 = -0.3079961133 
0.0000000000 * -1.1492000000 = -0.3079961133 
0.0000000000 * -0.0940774000 = -0.3079961133 
0.0993749280 * -0.0333346000 = -0.3113087368 
0.0000000000 * -0.2577510000 = -0.3113087368 
0.0000000000 * 1.9695000000 = -0.3113087368 
0.0000000000 * 0.0501485000 = -0.3113087368 
0.0000000000 * 0.0733369000 = -0.3113087368 
0.0000000000 * -0.8663540000 = -0.3113087368 
0.0000000000 * 0.7799350000 = -0.3113087368 
0.0000000000 * 0.7603520000 = -0.3113087368 
0.0000000000 * -0.0217517000 = -0.3113087368 
0.0000000000 * -2.0037400000 = -0.3113087368 
0.0000000000 * -0.8010140000 = -0.3113087368 
0.4964708861 * 0.2143370000 = -0.2048966565 
0.7972727204 * 1.1548000000 = 0.7157938810 
0.0000000000 * -0.9678420000 = 0.7157938810 
0.0000000000 * 0.0254242000 = 0.7157938810 
0.0000000000 * 0.1580380000 = 0.7157938810 
0.0000000000 * -0.1842180000 = 0.7157938810 
0.0000000000 * -0.0593141000 = 0.7157938810 
0.0000000000 * -2.3321100000 = 0.7157938810 
0.0000000000 * -0.5178980000 = 0.7157938810 
0.0000000000 * -0.3175560000 = 0.7157938810 
the biases is : 1.0687500000, now tempVal is : 1.7845438810
compute layer: 3, node : 2
0.2476063322 * 1.0158300000 = 0.2515259405 
0.0000000000 * 0.0282395000 = 0.2515259405 
0.5022157730 * 0.1118660000 = 0.3077068101 
0.0000000000 * -0.5241300000 = 0.3077068101 
0.1501012128 * 0.3731360000 = 0.3637149763 
0.0000000000 * -0.0115599000 = 0.3637149763 
0.2408135472 * -0.1169230000 = 0.3355583339 
0.0000000000 * -0.7870780000 = 0.3355583339 
0.0000000000 * -0.1544540000 = 0.3355583339 
0.6533630315 * 0.0678869000 = 0.3799131247 
0.0000000000 * -0.0035303400 = 0.3799131247 
0.0000000000 * 0.2639660000 = 0.3799131247 
0.0000000000 * -0.0961603000 = 0.3799131247 
0.0000000000 * 0.5446800000 = 0.3799131247 
0.0000000000 * 0.1486240000 = 0.3799131247 
0.0000000000 * 0.1158760000 = 0.3799131247 
0.0000000000 * -0.0490365000 = 0.3799131247 
0.1176464584 * -0.6469440000 = 0.3038024543 
0.0000000000 * 0.8010840000 = 0.3038024543 
0.0000000000 * -0.1029750000 = 0.3038024543 
0.0554119915 * 0.6478240000 = 0.3396996723 
0.2550187259 * 0.2105180000 = 0.3933857044 
0.0000000000 * 0.0134414000 = 0.3933857044 
0.0000000000 * 0.0718505000 = 0.3933857044 
0.0000000000 * 0.0419941000 = 0.3933857044 
0.0000000000 * -0.0028635600 = 0.3933857044 
0.0000000000 * -1.8878600000 = 0.3933857044 
0.0000000000 * -0.5091270000 = 0.3933857044 
0.0000000000 * 0.3960810000 = 0.3933857044 
0.0993749280 * 0.2351390000 = 0.4167526256 
0.0000000000 * -0.2342690000 = 0.4167526256 
0.0000000000 * -0.5945990000 = 0.4167526256 
0.0000000000 * -0.0888495000 = 0.4167526256 
0.0000000000 * 0.6631040000 = 0.4167526256 
0.0000000000 * -0.1104670000 = 0.4167526256 
0.0000000000 * -0.6335790000 = 0.4167526256 
0.0000000000 * -0.7408030000 = 0.4167526256 
0.0000000000 * 0.0317191000 = 0.4167526256 
0.0000000000 * 0.1295430000 = 0.4167526256 
0.0000000000 * 0.3613220000 = 0.4167526256 
0.4964708861 * -0.1007590000 = 0.3667287156 
0.7972727204 * -0.5030370000 = -0.0343289618 
0.0000000000 * -0.1974470000 = -0.0343289618 
0.0000000000 * 0.0010141900 = -0.0343289618 
0.0000000000 * 0.2362940000 = -0.0343289618 
0.0000000000 * 0.3129050000 = -0.0343289618 
0.0000000000 * -0.3518230000 = -0.0343289618 
0.0000000000 * 0.0769389000 = -0.0343289618 
0.0000000000 * -0.4900590000 = -0.0343289618 
0.0000000000 * -0.3050790000 = -0.0343289618 
the biases is : -0.1013510000, now tempVal is : -0.1356799618
ReLU !!! in layer: 3, node : 2, its linear result is negative,so set it to 0
compute layer: 3, node : 3
0.2476063322 * 0.1715500000 = 0.0424768663 
0.0000000000 * 0.0282890000 = 0.0424768663 
0.5022157730 * 0.0047712400 = 0.0448730583 
0.0000000000 * 0.0251563000 = 0.0448730583 
0.1501012128 * 0.5625350000 = 0.1293102440 
0.0000000000 * -0.0817147000 = 0.1293102440 
0.2408135472 * 1.0752400000 = 0.3882426025 
0.0000000000 * -0.1493150000 = 0.3882426025 
0.0000000000 * 0.3332890000 = 0.3882426025 
0.6533630315 * -0.2676870000 = 0.2133458127 
0.0000000000 * 0.0251055000 = 0.2133458127 
0.0000000000 * 0.0681931000 = 0.2133458127 
0.0000000000 * -0.0694010000 = 0.2133458127 
0.0000000000 * 0.3543270000 = 0.2133458127 
0.0000000000 * -0.1327190000 = 0.2133458127 
0.0000000000 * 0.1935320000 = 0.2133458127 
0.0000000000 * 0.0164038000 = 0.2133458127 
0.1176464584 * -0.2626180000 = 0.1824497351 
0.0000000000 * 0.4276650000 = 0.1824497351 
0.0000000000 * -0.2746040000 = 0.1824497351 
0.0554119915 * -0.5262760000 = 0.1532877338 
0.2550187259 * 0.3692840000 = 0.2474620690 
0.0000000000 * 0.2878870000 = 0.2474620690 
0.0000000000 * -0.1812970000 = 0.2474620690 
0.0000000000 * -0.0281393000 = 0.2474620690 
0.0000000000 * -0.0030989600 = 0.2474620690 
0.0000000000 * 0.0811781000 = 0.2474620690 
0.0000000000 * 0.7711880000 = 0.2474620690 
0.0000000000 * 0.2673600000 = 0.2474620690 
0.0993749280 * -0.1777610000 = 0.2297970824 
0.0000000000 * 0.1510550000 = 0.2297970824 
0.0000000000 * -0.6834150000 = 0.2297970824 
0.0000000000 * 0.3477940000 = 0.2297970824 
0.0000000000 * 0.6745800000 = 0.2297970824 
0.0000000000 * 1.0430300000 = 0.2297970824 
0.0000000000 * -0.0356357000 = 0.2297970824 
0.0000000000 * 0.2541700000 = 0.2297970824 
0.0000000000 * -0.0400246000 = 0.2297970824 
0.0000000000 * 1.7695900000 = 0.2297970824 
0.0000000000 * 0.2317120000 = 0.2297970824 
0.4964708861 * -0.0273251000 = 0.2162309658 
0.7972727204 * 0.1166410000 = 0.3092256532 
0.0000000000 * 0.3762220000 = 0.3092256532 
0.0000000000 * 0.0395626000 = 0.3092256532 
0.0000000000 * 0.3620950000 = 0.3092256532 
0.0000000000 * -0.1355760000 = 0.3092256532 
0.0000000000 * 0.1868650000 = 0.3092256532 
0.0000000000 * -0.3636630000 = 0.3092256532 
0.0000000000 * -0.1928500000 = 0.3092256532 
0.0000000000 * -0.3041860000 = 0.3092256532 
the biases is : 0.2917390000, now tempVal is : 0.6009646532
compute layer: 3, node : 4
0.2476063322 * 0.9554850000 = 0.2365841364 
0.0000000000 * 0.0254362000 = 0.2365841364 
0.5022157730 * 1.0283000000 = 0.7530126157 
0.0000000000 * -0.3712880000 = 0.7530126157 
0.1501012128 * 0.3741850000 = 0.8091782380 
0.0000000000 * -0.4672780000 = 0.8091782380 
0.2408135472 * -0.3567280000 = 0.7232733029 
0.0000000000 * -0.0264583000 = 0.7232733029 
0.0000000000 * -0.1617470000 = 0.7232733029 
0.6533630315 * 0.5011910000 = 1.0507329741 
0.0000000000 * 0.0511949000 = 1.0507329741 
0.0000000000 * -0.1328080000 = 1.0507329741 
0.0000000000 * -0.7263300000 = 1.0507329741 
0.0000000000 * -0.6938490000 = 1.0507329741 
0.0000000000 * 0.7694990000 = 1.0507329741 
0.0000000000 * -0.0407224000 = 1.0507329741 
0.0000000000 * 0.0251933000 = 1.0507329741 
0.1176464584 * 0.0097927800 = 1.0518850599 
0.0000000000 * -0.5321920000 = 1.0518850599 
0.0000000000 * -0.2579750000 = 1.0518850599 
0.0554119915 * -1.6632600000 = 0.9597205110 
0.2550187259 * -1.1538600000 = 0.6654646040 
0.0000000000 * 0.1957590000 = 0.6654646040 
0.0000000000 * -0.4425270000 = 0.6654646040 
0.0000000000 * 0.0414540000 = 0.6654646040 
0.0000000000 * 0.0496907000 = 0.6654646040 
0.0000000000 * 0.9682330000 = 0.6654646040 
0.0000000000 * -0.8195940000 = 0.6654646040 
0.0000000000 * -0.5157860000 = 0.6654646040 
0.0993749280 * 0.5033780000 = 0.7154877565 
0.0000000000 * 0.5341200000 = 0.7154877565 
0.0000000000 * -1.9317600000 = 0.7154877565 
0.0000000000 * 0.5468520000 = 0.7154877565 
0.0000000000 * 0.2175260000 = 0.7154877565 
0.0000000000 * 0.0159655000 = 0.7154877565 
0.0000000000 * 0.6954260000 = 0.7154877565 
0.0000000000 * -0.4294300000 = 0.7154877565 
0.0000000000 * 0.0447726000 = 0.7154877565 
0.0000000000 * -0.0976005000 = 0.7154877565 
0.0000000000 * 0.3801330000 = 0.7154877565 
0.4964708861 * 0.0274513000 = 0.7291165277 
0.7972727204 * -0.8086100000 = 0.0844338333 
0.0000000000 * 1.0480400000 = 0.0844338333 
0.0000000000 * -0.0053091000 = 0.0844338333 
0.0000000000 * 0.2722280000 = 0.0844338333 
0.0000000000 * 0.8179470000 = 0.0844338333 
0.0000000000 * 0.9771070000 = 0.0844338333 
0.0000000000 * 0.1377150000 = 0.0844338333 
0.0000000000 * -0.6361240000 = 0.0844338333 
0.0000000000 * -0.5018040000 = 0.0844338333 
the biases is : 0.3619060000, now tempVal is : 0.4463398333
compute layer: 3, node : 5
0.2476063322 * -1.2082800000 = -0.2991777791 
0.0000000000 * -0.0303847000 = -0.2991777791 
0.5022157730 * 0.4367920000 = -0.0798139472 
0.0000000000 * 0.3350910000 = -0.0798139472 
0.1501012128 * -0.1734460000 = -0.1058484022 
0.0000000000 * 0.4107840000 = -0.1058484022 
0.2408135472 * 0.3697840000 = -0.0167994054 
0.0000000000 * -0.3090070000 = -0.0167994054 
0.0000000000 * -0.3605490000 = -0.0167994054 
0.6533630315 * -0.0524694000 = -0.0510809717 
0.0000000000 * 0.0112505000 = -0.0510809717 
0.0000000000 * -0.7915860000 = -0.0510809717 
0.0000000000 * 0.6356830000 = -0.0510809717 
0.0000000000 * -0.7332200000 = -0.0510809717 
0.0000000000 * 1.0655900000 = -0.0510809717 
0.0000000000 * 1.0683100000 = -0.0510809717 
0.0000000000 * -0.2830250000 = -0.0510809717 
0.1176464584 * 1.8709000000 = 0.1690237873 
0.0000000000 * -1.0488600000 = 0.1690237873 
0.0000000000 * 0.5040830000 = 0.1690237873 
0.0554119915 * -0.2939270000 = 0.1527367068 
0.2550187259 * 0.1903970000 = 0.2012915072 
0.0000000000 * 0.7130500000 = 0.2012915072 
0.0000000000 * 0.0126695000 = 0.2012915072 
0.0000000000 * 0.0116692000 = 0.2012915072 
0.0000000000 * -0.0070279700 = 0.2012915072 
0.0000000000 * 0.2248720000 = 0.2012915072 
0.0000000000 * -0.9042210000 = 0.2012915072 
0.0000000000 * -0.6257750000 = 0.2012915072 
0.0993749280 * -0.1436180000 = 0.1870194788 
0.0000000000 * -0.1473740000 = 0.1870194788 
0.0000000000 * 1.0681300000 = 0.1870194788 
0.0000000000 * 0.5569230000 = 0.1870194788 
0.0000000000 * -0.2145500000 = 0.1870194788 
0.0000000000 * 0.1356980000 = 0.1870194788 
0.0000000000 * -2.6186000000 = 0.1870194788 
0.0000000000 * 0.1184050000 = 0.1870194788 
0.0000000000 * 0.0145899000 = 0.1870194788 
0.0000000000 * 1.4799500000 = 0.1870194788 
0.0000000000 * 0.5652170000 = 0.1870194788 
0.4964708861 * 0.4502130000 = 0.4105371258 
0.7972727204 * -0.9721230000 = -0.3645100229 
0.0000000000 * 0.7017660000 = -0.3645100229 
0.0000000000 * -0.0015690500 = -0.3645100229 
0.0000000000 * 0.5466970000 = -0.3645100229 
0.0000000000 * 0.4847280000 = -0.3645100229 
0.0000000000 * -0.6901850000 = -0.3645100229 
0.0000000000 * -0.5925180000 = -0.3645100229 
0.0000000000 * 0.1404180000 = -0.3645100229 
0.0000000000 * -0.6362790000 = -0.3645100229 
the biases is : -1.1759800000, now tempVal is : -1.5404900229
ReLU !!! in layer: 3, node : 5, its linear result is negative,so set it to 0
compute layer: 3, node : 6
0.2476063322 * -0.4229530000 = -0.1047258410 
0.0000000000 * 0.0222066000 = -0.1047258410 
0.5022157730 * 0.3388280000 = 0.0654389249 
0.0000000000 * 1.2763500000 = 0.0654389249 
0.1501012128 * -0.9927000000 = -0.0835665491 
0.0000000000 * 1.8613600000 = -0.0835665491 
0.2408135472 * -0.2553660000 = -0.1450621414 
0.0000000000 * 0.2352680000 = -0.1450621414 
0.0000000000 * -0.6446580000 = -0.1450621414 
0.6533630315 * -0.2288690000 = -0.2945966850 
0.0000000000 * -0.0086017800 = -0.2945966850 
0.0000000000 * 0.4949660000 = -0.2945966850 
0.0000000000 * 0.7121840000 = -0.2945966850 
0.0000000000 * -0.0216503000 = -0.2945966850 
0.0000000000 * 0.1732940000 = -0.2945966850 
0.0000000000 * 0.4412200000 = -0.2945966850 
0.0000000000 * -0.4126070000 = -0.2945966850 
0.1176464584 * 1.1162500000 = -0.1632738259 
0.0000000000 * -0.8424930000 = -0.1632738259 
0.0000000000 * 0.4964950000 = -0.1632738259 
0.0554119915 * -0.6573960000 = -0.1997014474 
0.2550187259 * 0.2177460000 = -0.1441721399 
0.0000000000 * -5.2563500000 = -0.1441721399 
0.0000000000 * 0.0585211000 = -0.1441721399 
0.0000000000 * 0.0364919000 = -0.1441721399 
0.0000000000 * -0.0127628000 = -0.1441721399 
0.0000000000 * -0.5188830000 = -0.1441721399 
0.0000000000 * -0.1132220000 = -0.1441721399 
0.0000000000 * 0.2039690000 = -0.1441721399 
0.0993749280 * -0.5071750000 = -0.1945726191 
0.0000000000 * 0.9997720000 = -0.1945726191 
0.0000000000 * 0.4590760000 = -0.1945726191 
0.0000000000 * -0.3515770000 = -0.1945726191 
0.0000000000 * -0.2374410000 = -0.1945726191 
0.0000000000 * -0.2159000000 = -0.1945726191 
0.0000000000 * -0.4566830000 = -0.1945726191 
0.0000000000 * 0.2795740000 = -0.1945726191 
0.0000000000 * -0.0187747000 = -0.1945726191 
0.0000000000 * -0.0689664000 = -0.1945726191 
0.0000000000 * -0.4718740000 = -0.1945726191 
0.4964708861 * -0.4099320000 = -0.3980919223 
0.7972727204 * 0.4499810000 = -0.0393343464 
0.0000000000 * -0.3026010000 = -0.0393343464 
0.0000000000 * -0.0475218000 = -0.0393343464 
0.0000000000 * -0.7125860000 = -0.0393343464 
0.0000000000 * 0.1102930000 = -0.0393343464 
0.0000000000 * -1.6318600000 = -0.0393343464 
0.0000000000 * 0.1511750000 = -0.0393343464 
0.0000000000 * 0.7411530000 = -0.0393343464 
0.0000000000 * -0.1305180000 = -0.0393343464 
the biases is : -1.0849400000, now tempVal is : -1.1242743464
ReLU !!! in layer: 3, node : 6, its linear result is negative,so set it to 0
compute layer: 3, node : 7
0.2476063322 * -0.7991420000 = -0.1978726196 
0.0000000000 * 0.0081698800 = -0.1978726196 
0.5022157730 * 0.0553741000 = -0.1700628731 
0.0000000000 * -0.5593720000 = -0.1700628731 
0.1501012128 * 0.4002470000 = -0.1099853130 
0.0000000000 * 0.3172410000 = -0.1099853130 
0.2408135472 * 0.1199100000 = -0.0811093606 
0.0000000000 * -0.0809255000 = -0.0811093606 
0.0000000000 * -0.4168700000 = -0.0811093606 
0.6533630315 * 0.3199470000 = 0.1279321813 
0.0000000000 * 0.0216162000 = 0.1279321813 
0.0000000000 * 0.0765637000 = 0.1279321813 
0.0000000000 * 0.4783670000 = 0.1279321813 
0.0000000000 * 0.1183770000 = 0.1279321813 
0.0000000000 * -0.0137534000 = 0.1279321813 
0.0000000000 * 0.0871742000 = 0.1279321813 
0.0000000000 * -0.2229590000 = 0.1279321813 
0.1176464584 * 0.1212100000 = 0.1421921085 
0.0000000000 * 0.5169310000 = 0.1421921085 
0.0000000000 * -0.1463080000 = 0.1421921085 
0.0554119915 * 0.4914060000 = 0.1694218936 
0.2550187259 * 0.5125970000 = 0.3001437274 
0.0000000000 * 0.0623626000 = 0.3001437274 
0.0000000000 * 0.1625390000 = 0.3001437274 
0.0000000000 * 0.0129173000 = 0.3001437274 
0.0000000000 * 0.0106943000 = 0.3001437274 
0.0000000000 * 1.1734900000 = 0.3001437274 
0.0000000000 * -0.9460970000 = 0.3001437274 
0.0000000000 * -0.5177430000 = 0.3001437274 
0.0993749280 * -0.2280960000 = 0.2774767038 
0.0000000000 * -0.2041020000 = 0.2774767038 
0.0000000000 * -2.0131900000 = 0.2774767038 
0.0000000000 * 0.2315220000 = 0.2774767038 
0.0000000000 * 0.3373100000 = 0.2774767038 
0.0000000000 * 0.5137400000 = 0.2774767038 
0.0000000000 * -0.2902170000 = 0.2774767038 
0.0000000000 * 0.0242341000 = 0.2774767038 
0.0000000000 * 0.0342037000 = 0.2774767038 
0.0000000000 * -2.1485000000 = 0.2774767038 
0.0000000000 * 0.6281770000 = 0.2774767038 
0.4964708861 * 0.0631272000 = 0.3088175207 
0.7972727204 * 0.7075560000 = 0.8729326177 
0.0000000000 * -0.2659110000 = 0.8729326177 
0.0000000000 * 0.0099005500 = 0.8729326177 
0.0000000000 * 0.0868733000 = 0.8729326177 
0.0000000000 * -0.1297350000 = 0.8729326177 
0.0000000000 * 0.3949000000 = 0.8729326177 
0.0000000000 * -0.2079670000 = 0.8729326177 
0.0000000000 * 0.0195495000 = 0.8729326177 
0.0000000000 * 0.4278050000 = 0.8729326177 
the biases is : -0.5253960000, now tempVal is : 0.3475366177
compute layer: 3, node : 8
0.2476063322 * 2.0073300000 = 0.4970276189 
0.0000000000 * -0.0127730000 = 0.4970276189 
0.5022157730 * -0.2325780000 = 0.3802232788 
0.0000000000 * 0.1593150000 = 0.3802232788 
0.1501012128 * 0.0390867000 = 0.3860902399 
0.0000000000 * 0.6199460000 = 0.3860902399 
0.2408135472 * 0.5095410000 = 0.5087946156 
0.0000000000 * 0.3070730000 = 0.5087946156 
0.0000000000 * 0.1608230000 = 0.5087946156 
0.6533630315 * -0.1465490000 = 0.4130449167 
0.0000000000 * 0.0248556000 = 0.4130449167 
0.0000000000 * 0.0796208000 = 0.4130449167 
0.0000000000 * 0.6146870000 = 0.4130449167 
0.0000000000 * 0.3534650000 = 0.4130449167 
0.0000000000 * 0.0074694800 = 0.4130449167 
0.0000000000 * -0.5932430000 = 0.4130449167 
0.0000000000 * -0.5285300000 = 0.4130449167 
0.1176464584 * -0.2008850000 = 0.3894115079 
0.0000000000 * -0.4411880000 = 0.3894115079 
0.0000000000 * 0.0406136000 = 0.3894115079 
0.0554119915 * -0.3826360000 = 0.3682088851 
0.2550187259 * -0.4073890000 = 0.2643170614 
0.0000000000 * 0.0213565000 = 0.2643170614 
0.0000000000 * 0.5000720000 = 0.2643170614 
0.0000000000 * 0.0136711000 = 0.2643170614 
0.0000000000 * 0.0051225200 = 0.2643170614 
0.0000000000 * 0.3890100000 = 0.2643170614 
0.0000000000 * -0.1713960000 = 0.2643170614 
0.0000000000 * -0.1798470000 = 0.2643170614 
0.0993749280 * -0.2604510000 = 0.2384347620 
0.0000000000 * 0.1692230000 = 0.2384347620 
0.0000000000 * -0.0089947800 = 0.2384347620 
0.0000000000 * 0.4399300000 = 0.2384347620 
0.0000000000 * 0.5095780000 = 0.2384347620 
0.0000000000 * 0.3927610000 = 0.2384347620 
0.0000000000 * 0.1066030000 = 0.2384347620 
0.0000000000 * -0.3941780000 = 0.2384347620 
0.0000000000 * 0.0081518700 = 0.2384347620 
0.0000000000 * -0.1882120000 = 0.2384347620 
0.0000000000 * -0.2664590000 = 0.2384347620 
0.4964708861 * 0.4985820000 = 0.4859662094 
0.7972727204 * 0.2732410000 = 0.7038138048 
0.0000000000 * 0.3959520000 = 0.7038138048 
0.0000000000 * 0.0477267000 = 0.7038138048 
0.0000000000 * 0.4049170000 = 0.7038138048 
0.0000000000 * 0.0280034000 = 0.7038138048 
0.0000000000 * 0.3544420000 = 0.7038138048 
0.0000000000 * 1.0436400000 = 0.7038138048 
0.0000000000 * 0.2017040000 = 0.7038138048 
0.0000000000 * 0.0153662000 = 0.7038138048 
the biases is : -0.4851210000, now tempVal is : 0.2186928048
compute layer: 3, node : 9
0.2476063322 * 0.7366840000 = 0.1824076233 
0.0000000000 * -0.0349476000 = 0.1824076233 
0.5022157730 * -0.5931360000 = -0.1154746315 
0.0000000000 * -0.6602300000 = -0.1154746315 
0.1501012128 * -0.0605671000 = -0.1245658266 
0.0000000000 * 0.1790660000 = -0.1245658266 
0.2408135472 * 0.0228669000 = -0.1190591673 
0.0000000000 * -0.7248730000 = -0.1190591673 
0.0000000000 * -0.9950800000 = -0.1190591673 
0.6533630315 * 0.1966200000 = 0.0094050719 
0.0000000000 * -0.0382987000 = 0.0094050719 
0.0000000000 * -0.5353980000 = 0.0094050719 
0.0000000000 * -1.7007800000 = 0.0094050719 
0.0000000000 * -0.3171440000 = 0.0094050719 
0.0000000000 * -0.6503130000 = 0.0094050719 
0.0000000000 * 0.6944230000 = 0.0094050719 
0.0000000000 * 0.2324350000 = 0.0094050719 
0.1176464584 * -0.3999750000 = -0.0376505702 
0.0000000000 * -0.0130644000 = -0.0376505702 
0.0000000000 * -0.1823400000 = -0.0376505702 
0.0554119915 * -0.1427960000 = -0.0455631810 
0.2550187259 * 0.6921940000 = 0.1309592509 
0.0000000000 * -0.2435100000 = 0.1309592509 
0.0000000000 * -0.2860190000 = 0.1309592509 
0.0000000000 * 0.0267213000 = 0.1309592509 
0.0000000000 * -0.0311121000 = 0.1309592509 
0.0000000000 * -0.2684370000 = 0.1309592509 
0.0000000000 * -0.8220440000 = 0.1309592509 
0.0000000000 * 0.3730820000 = 0.1309592509 
0.0993749280 * -0.7518170000 = 0.0562474907 
0.0000000000 * -0.1176260000 = 0.0562474907 
0.0000000000 * -0.2794960000 = 0.0562474907 
0.0000000000 * -0.1987160000 = 0.0562474907 
0.0000000000 * 0.7790350000 = 0.0562474907 
0.0000000000 * -0.3518060000 = 0.0562474907 
0.0000000000 * 0.4721950000 = 0.0562474907 
0.0000000000 * -1.0053000000 = 0.0562474907 
0.0000000000 * 0.0489097000 = 0.0562474907 
0.0000000000 * -0.2113480000 = 0.0562474907 
0.0000000000 * 0.7655230000 = 0.0562474907 
0.4964708861 * 0.1530600000 = 0.1322373245 
0.7972727204 * -0.0026115000 = 0.1301552468 
0.0000000000 * -0.0146425000 = 0.1301552468 
0.0000000000 * -0.0432454000 = 0.1301552468 
0.0000000000 * 0.1993870000 = 0.1301552468 
0.0000000000 * -0.0137113000 = 0.1301552468 
0.0000000000 * 0.9707940000 = 0.1301552468 
0.0000000000 * -12.3406000000 = 0.1301552468 
0.0000000000 * 0.0075413700 = 0.1301552468 
0.0000000000 * 0.0891815000 = 0.1301552468 
the biases is : -0.5634510000, now tempVal is : -0.4332957532
ReLU !!! in layer: 3, node : 9, its linear result is negative,so set it to 0
compute layer: 3, node : 10
0.2476063322 * 0.1452890000 = 0.0359744764 
0.0000000000 * 0.0185443000 = 0.0359744764 
0.5022157730 * 0.3924310000 = 0.2330595144 
0.0000000000 * 0.6835240000 = 0.2330595144 
0.1501012128 * -0.1678750000 = 0.2078612733 
0.0000000000 * 0.6176110000 = 0.2078612733 
0.2408135472 * -0.2617050000 = 0.1448391639 
0.0000000000 * 0.1656970000 = 0.1448391639 
0.0000000000 * 0.1224780000 = 0.1448391639 
0.6533630315 * -0.4084040000 = -0.1219969116 
0.0000000000 * 0.0265899000 = -0.1219969116 
0.0000000000 * 0.2514810000 = -0.1219969116 
0.0000000000 * 1.0081100000 = -0.1219969116 
0.0000000000 * -0.1624850000 = -0.1219969116 
0.0000000000 * -0.0393967000 = -0.1219969116 
0.0000000000 * 0.5485620000 = -0.1219969116 
0.0000000000 * -0.1019270000 = -0.1219969116 
0.1176464584 * -0.4216650000 = -0.1716043054 
0.0000000000 * 0.0293742000 = -0.1716043054 
0.0000000000 * 0.1151740000 = -0.1716043054 
0.0554119915 * 0.1932130000 = -0.1608979883 
0.2550187259 * 0.2853370000 = -0.0881317102 
0.0000000000 * 0.2232360000 = -0.0881317102 
0.0000000000 * 0.1534700000 = -0.0881317102 
0.0000000000 * 0.0537730000 = -0.0881317102 
0.0000000000 * -0.0383626000 = -0.0881317102 
0.0000000000 * -0.3019580000 = -0.0881317102 
0.0000000000 * -0.1740120000 = -0.0881317102 
0.0000000000 * 0.2988700000 = -0.0881317102 
0.0993749280 * 0.1582200000 = -0.0724086090 
0.0000000000 * 0.3877160000 = -0.0724086090 
0.0000000000 * -8.8421400000 = -0.0724086090 
0.0000000000 * -0.4974440000 = -0.0724086090 
0.0000000000 * 0.1340550000 = -0.0724086090 
0.0000000000 * 0.0349669000 = -0.0724086090 
0.0000000000 * 0.0324018000 = -0.0724086090 
0.0000000000 * -0.3122630000 = -0.0724086090 
0.0000000000 * 0.0045383200 = -0.0724086090 
0.0000000000 * -0.3805910000 = -0.0724086090 
0.0000000000 * 0.0948510000 = -0.0724086090 
0.4964708861 * -0.3358610000 = -0.2391538173 
0.7972727204 * -0.7065750000 = -0.8024867897 
0.0000000000 * 0.0620854000 = -0.8024867897 
0.0000000000 * 0.0250020000 = -0.8024867897 
0.0000000000 * -0.1005990000 = -0.8024867897 
0.0000000000 * -0.4456250000 = -0.8024867897 
0.0000000000 * 0.0191583000 = -0.8024867897 
0.0000000000 * 1.2161300000 = -0.8024867897 
0.0000000000 * 0.2601890000 = -0.8024867897 
0.0000000000 * -0.1233280000 = -0.8024867897 
the biases is : -0.4309580000, now tempVal is : -1.2334447897
ReLU !!! in layer: 3, node : 10, its linear result is negative,so set it to 0
compute layer: 3, node : 11
0.2476063322 * -0.0586311000 = -0.0145174316 
0.0000000000 * -0.0325541000 = -0.0145174316 
0.5022157730 * 0.0212813000 = -0.0038296271 
0.0000000000 * -0.1270020000 = -0.0038296271 
0.1501012128 * 0.2487700000 = 0.0335110516 
0.0000000000 * 0.2592320000 = 0.0335110516 
0.2408135472 * 0.2065350000 = 0.0832474776 
0.0000000000 * 0.2536480000 = 0.0832474776 
0.0000000000 * 0.0273293000 = 0.0832474776 
0.6533630315 * -0.0389660000 = 0.0577885337 
0.0000000000 * 0.0327889000 = 0.0577885337 
0.0000000000 * -0.0373718000 = 0.0577885337 
0.0000000000 * 0.4594180000 = 0.0577885337 
0.0000000000 * 0.3109780000 = 0.0577885337 
0.0000000000 * 0.1215220000 = 0.0577885337 
0.0000000000 * -0.2192440000 = 0.0577885337 
0.0000000000 * -0.1039010000 = 0.0577885337 
0.1176464584 * -0.4172500000 = 0.0087005489 
0.0000000000 * 0.2845480000 = 0.0087005489 
0.0000000000 * 0.0570689000 = 0.0087005489 
0.0554119915 * 0.0509280000 = 0.0115225708 
0.2550187259 * -0.1199080000 = -0.0190562145 
0.0000000000 * -0.1232510000 = -0.0190562145 
0.0000000000 * 0.0970952000 = -0.0190562145 
0.0000000000 * 0.0140834000 = -0.0190562145 
0.0000000000 * -0.0015338800 = -0.0190562145 
0.0000000000 * -0.0095528400 = -0.0190562145 
0.0000000000 * 1.7455900000 = -0.0190562145 
0.0000000000 * 0.0305404000 = -0.0190562145 
0.0993749280 * 0.0925489000 = -0.0098591743 
0.0000000000 * -0.1100950000 = -0.0098591743 
0.0000000000 * 0.4407220000 = -0.0098591743 
0.0000000000 * -0.1703890000 = -0.0098591743 
0.0000000000 * 0.1158450000 = -0.0098591743 
0.0000000000 * -0.1301840000 = -0.0098591743 
0.0000000000 * 0.2226110000 = -0.0098591743 
0.0000000000 * -0.2516200000 = -0.0098591743 
0.0000000000 * -0.0369903000 = -0.0098591743 
0.0000000000 * 5.8717400000 = -0.0098591743 
0.0000000000 * -0.2536370000 = -0.0098591743 
0.4964708861 * 0.1072820000 = 0.0434032153 
0.7972727204 * 0.0209906000 = 0.0601384481 
0.0000000000 * 0.3101170000 = 0.0601384481 
0.0000000000 * 0.0142127000 = 0.0601384481 
0.0000000000 * 0.2990720000 = 0.0601384481 
0.0000000000 * 0.2131500000 = 0.0601384481 
0.0000000000 * 0.3856740000 = 0.0601384481 
0.0000000000 * 0.3114700000 = 0.0601384481 
0.0000000000 * 0.0025038100 = 0.0601384481 
0.0000000000 * 0.4909020000 = 0.0601384481 
the biases is : -0.3751020000, now tempVal is : -0.3149635519
ReLU !!! in layer: 3, node : 11, its linear result is negative,so set it to 0
compute layer: 3, node : 12
0.2476063322 * 0.8981320000 = 0.2223831704 
0.0000000000 * 0.0030921400 = 0.2223831704 
0.5022157730 * 0.1925080000 = 0.3190637244 
0.0000000000 * 0.8553170000 = 0.3190637244 
0.1501012128 * -0.7627400000 = 0.2045755254 
0.0000000000 * -0.1080650000 = 0.2045755254 
0.2408135472 * 0.1088490000 = 0.2307878392 
0.0000000000 * 0.7317080000 = 0.2307878392 
0.0000000000 * -0.9990040000 = 0.2307878392 
0.6533630315 * 0.2912650000 = 0.4210896225 
0.0000000000 * 0.0035866800 = 0.4210896225 
0.0000000000 * -0.0048943700 = 0.4210896225 
0.0000000000 * 1.0298400000 = 0.4210896225 
0.0000000000 * -0.1899730000 = 0.4210896225 
0.0000000000 * 1.1037900000 = 0.4210896225 
0.0000000000 * 0.2987590000 = 0.4210896225 
0.0000000000 * 0.3641150000 = 0.4210896225 
0.1176464584 * -0.1598530000 = 0.4022834832 
0.0000000000 * -0.3904240000 = 0.4022834832 
0.0000000000 * 0.3573790000 = 0.4022834832 
0.0554119915 * -0.7711810000 = 0.3595508082 
0.2550187259 * 0.4280500000 = 0.4687115738 
0.0000000000 * -0.0966753000 = 0.4687115738 
0.0000000000 * 0.3341530000 = 0.4687115738 
0.0000000000 * -0.0503492000 = 0.4687115738 
0.0000000000 * 0.0302441000 = 0.4687115738 
0.0000000000 * -0.1222400000 = 0.4687115738 
0.0000000000 * -0.0026345700 = 0.4687115738 
0.0000000000 * 0.4158530000 = 0.4687115738 
0.0993749280 * -0.0637170000 = 0.4623797015 
0.0000000000 * 0.1616210000 = 0.4623797015 
0.0000000000 * -0.3945650000 = 0.4623797015 
0.0000000000 * -0.4582260000 = 0.4623797015 
0.0000000000 * 0.0149316000 = 0.4623797015 
0.0000000000 * 0.7664410000 = 0.4623797015 
0.0000000000 * -0.8834420000 = 0.4623797015 
0.0000000000 * 0.9720340000 = 0.4623797015 
0.0000000000 * 0.0116764000 = 0.4623797015 
0.0000000000 * -0.0778877000 = 0.4623797015 
0.0000000000 * 1.2405900000 = 0.4623797015 
0.4964708861 * -1.1754400000 = -0.1211920369 
0.7972727204 * -0.0264858000 = -0.1423084427 
0.0000000000 * -0.2694900000 = -0.1423084427 
0.0000000000 * -0.0126421000 = -0.1423084427 
0.0000000000 * -0.2638980000 = -0.1423084427 
0.0000000000 * -0.9548280000 = -0.1423084427 
0.0000000000 * 0.7901320000 = -0.1423084427 
0.0000000000 * -6.4985900000 = -0.1423084427 
0.0000000000 * 0.3564170000 = -0.1423084427 
0.0000000000 * -0.9022850000 = -0.1423084427 
the biases is : -0.2993690000, now tempVal is : -0.4416774427
ReLU !!! in layer: 3, node : 12, its linear result is negative,so set it to 0
compute layer: 3, node : 13
0.2476063322 * -0.2031910000 = -0.0503113783 
0.0000000000 * 0.0354445000 = -0.0503113783 
0.5022157730 * -0.1357430000 = -0.1184836539 
0.0000000000 * 1.7259700000 = -0.1184836539 
0.1501012128 * -0.5606610000 = -0.2026395500 
0.0000000000 * 1.4455900000 = -0.2026395500 
0.2408135472 * -0.3149390000 = -0.2784811277 
0.0000000000 * -0.8182130000 = -0.2784811277 
0.0000000000 * -0.5699820000 = -0.2784811277 
0.6533630315 * -0.3136030000 = -0.4833777345 
0.0000000000 * -0.0005822170 = -0.4833777345 
0.0000000000 * -0.0649615000 = -0.4833777345 
0.0000000000 * 0.2668500000 = -0.4833777345 
0.0000000000 * 0.4687040000 = -0.4833777345 
0.0000000000 * 0.0015489100 = -0.4833777345 
0.0000000000 * 0.2676960000 = -0.4833777345 
0.0000000000 * -0.3948400000 = -0.4833777345 
0.1176464584 * -0.1380250000 = -0.4996158869 
0.0000000000 * -0.6130580000 = -0.4996158869 
0.0000000000 * 0.2334370000 = -0.4996158869 
0.0554119915 * 0.2453560000 = -0.4860202223 
0.2550187259 * -0.0398625000 = -0.4961859063 
0.0000000000 * -0.5885350000 = -0.4961859063 
0.0000000000 * -0.3850300000 = -0.4961859063 
0.0000000000 * -0.0287808000 = -0.4961859063 
0.0000000000 * 0.0347579000 = -0.4961859063 
0.0000000000 * 1.3458000000 = -0.4961859063 
0.0000000000 * 0.1393660000 = -0.4961859063 
0.0000000000 * 0.2717170000 = -0.4961859063 
0.0993749280 * -0.1188680000 = -0.5079984052 
0.0000000000 * 0.4623110000 = -0.5079984052 
0.0000000000 * -1.0763500000 = -0.5079984052 
0.0000000000 * 0.6273030000 = -0.5079984052 
0.0000000000 * 0.8754280000 = -0.5079984052 
0.0000000000 * 0.1892520000 = -0.5079984052 
0.0000000000 * -0.0640010000 = -0.5079984052 
0.0000000000 * 0.6187530000 = -0.5079984052 
0.0000000000 * 0.0444535000 = -0.5079984052 
0.0000000000 * -0.8934620000 = -0.5079984052 
0.0000000000 * -0.3772050000 = -0.5079984052 
0.4964708861 * 0.4999650000 = -0.2597803386 
0.7972727204 * 0.2535360000 = -0.0576430022 
0.0000000000 * -1.0739700000 = -0.0576430022 
0.0000000000 * 0.0369999000 = -0.0576430022 
0.0000000000 * -0.3082840000 = -0.0576430022 
0.0000000000 * 0.0194815000 = -0.0576430022 
0.0000000000 * -0.4974180000 = -0.0576430022 
0.0000000000 * -0.7944750000 = -0.0576430022 
0.0000000000 * -0.4993620000 = -0.0576430022 
0.0000000000 * -0.0333678000 = -0.0576430022 
the biases is : -0.3002630000, now tempVal is : -0.3579060022
ReLU !!! in layer: 3, node : 13, its linear result is negative,so set it to 0
compute layer: 3, node : 14
0.2476063322 * 0.6323050000 = 0.1565627219 
0.0000000000 * 0.0412482000 = 0.1565627219 
0.5022157730 * -0.5406810000 = -0.1149758044 
0.0000000000 * -0.1659970000 = -0.1149758044 
0.1501012128 * 0.2208730000 = -0.0818224993 
0.0000000000 * -0.1290480000 = -0.0818224993 
0.2408135472 * 0.1688870000 = -0.0411522217 
0.0000000000 * -0.9944120000 = -0.0411522217 
0.0000000000 * 0.1418140000 = -0.0411522217 
0.6533630315 * -0.2195440000 = -0.1845941551 
0.0000000000 * -0.0124984000 = -0.1845941551 
0.0000000000 * 0.1385160000 = -0.1845941551 
0.0000000000 * 0.1629820000 = -0.1845941551 
0.0000000000 * 0.2689590000 = -0.1845941551 
0.0000000000 * -0.5576150000 = -0.1845941551 
0.0000000000 * 0.2745730000 = -0.1845941551 
0.0000000000 * -0.9932380000 = -0.1845941551 
0.1176464584 * -0.0918738000 = -0.1954027823 
0.0000000000 * 0.6158590000 = -0.1954027823 
0.0000000000 * -0.1791010000 = -0.1954027823 
0.0554119915 * 0.0966425000 = -0.1900476289 
0.2550187259 * 0.2198190000 = -0.1339896676 
0.0000000000 * -0.1456080000 = -0.1339896676 
0.0000000000 * -0.5440130000 = -0.1339896676 
0.0000000000 * -0.0290327000 = -0.1339896676 
0.0000000000 * -0.0114326000 = -0.1339896676 
0.0000000000 * -0.2131310000 = -0.1339896676 
0.0000000000 * 0.1667010000 = -0.1339896676 
0.0000000000 * 0.0333745000 = -0.1339896676 
0.0993749280 * 0.1720500000 = -0.1168922112 
0.0000000000 * -2.8335000000 = -0.1168922112 
0.0000000000 * 0.3108480000 = -0.1168922112 
0.0000000000 * 0.0019126500 = -0.1168922112 
0.0000000000 * -0.4487360000 = -0.1168922112 
0.0000000000 * -0.4292620000 = -0.1168922112 
0.0000000000 * 0.0119225000 = -0.1168922112 
0.0000000000 * 0.2229330000 = -0.1168922112 
0.0000000000 * 0.0202681000 = -0.1168922112 
0.0000000000 * 0.1764660000 = -0.1168922112 
0.0000000000 * 0.2277150000 = -0.1168922112 
0.4964708861 * 0.4052800000 = 0.0843175095 
0.7972727204 * 0.0194034000 = 0.0997873110 
0.0000000000 * 0.3701970000 = 0.0997873110 
0.0000000000 * -0.0536075000 = 0.0997873110 
0.0000000000 * -0.0216867000 = 0.0997873110 
0.0000000000 * -0.6050300000 = 0.0997873110 
0.0000000000 * -0.1816510000 = 0.0997873110 
0.0000000000 * 0.1627050000 = 0.0997873110 
0.0000000000 * -0.1959630000 = 0.0997873110 
0.0000000000 * -0.0041119700 = 0.0997873110 
the biases is : -0.5280580000, now tempVal is : -0.4282706890
ReLU !!! in layer: 3, node : 14, its linear result is negative,so set it to 0
compute layer: 3, node : 15
0.2476063322 * 0.2955400000 = 0.0731775754 
0.0000000000 * 0.0134774000 = 0.0731775754 
0.5022157730 * -0.0766397000 = 0.0346879093 
0.0000000000 * 1.5544400000 = 0.0346879093 
0.1501012128 * -0.0015692400 = 0.0344523644 
0.0000000000 * -0.6909610000 = 0.0344523644 
0.2408135472 * 0.3435430000 = 0.1171821729 
0.0000000000 * 0.7836980000 = 0.1171821729 
0.0000000000 * 0.1507080000 = 0.1171821729 
0.6533630315 * -0.2655350000 = -0.0563085797 
0.0000000000 * 0.0480418000 = -0.0563085797 
0.0000000000 * 0.4466130000 = -0.0563085797 
0.0000000000 * -0.6237180000 = -0.0563085797 
0.0000000000 * -0.9683480000 = -0.0563085797 
0.0000000000 * -0.3916310000 = -0.0563085797 
0.0000000000 * -0.1775340000 = -0.0563085797 
0.0000000000 * 1.5979700000 = -0.0563085797 
0.1176464584 * -0.7453470000 = -0.1439960145 
0.0000000000 * 1.0222800000 = -0.1439960145 
0.0000000000 * -0.1310520000 = -0.1439960145 
0.0554119915 * 0.4844170000 = -0.1171535038 
0.2550187259 * -0.5026830000 = -0.2453470820 
0.0000000000 * -0.4938210000 = -0.2453470820 
0.0000000000 * 0.7053580000 = -0.2453470820 
0.0000000000 * -0.0019781900 = -0.2453470820 
0.0000000000 * -0.0333751000 = -0.2453470820 
0.0000000000 * 1.2048800000 = -0.2453470820 
0.0000000000 * -0.7887680000 = -0.2453470820 
0.0000000000 * 1.4575100000 = -0.2453470820 
0.0993749280 * -0.2158780000 = -0.2667999427 
0.0000000000 * 0.2637810000 = -0.2667999427 
0.0000000000 * -0.4799280000 = -0.2667999427 
0.0000000000 * -0.3433490000 = -0.2667999427 
0.0000000000 * -0.9735860000 = -0.2667999427 
0.0000000000 * 0.7266540000 = -0.2667999427 
0.0000000000 * 0.7191190000 = -0.2667999427 
0.0000000000 * 0.4503420000 = -0.2667999427 
0.0000000000 * 0.0380341000 = -0.2667999427 
0.0000000000 * -0.4123170000 = -0.2667999427 
0.0000000000 * -0.7136300000 = -0.2667999427 
0.4964708861 * 0.3500720000 = -0.0929993866 
0.7972727204 * -0.6761840000 = -0.6321024438 
0.0000000000 * 0.7059490000 = -0.6321024438 
0.0000000000 * -0.0028837300 = -0.6321024438 
0.0000000000 * 0.2388110000 = -0.6321024438 
0.0000000000 * -0.0433828000 = -0.6321024438 
0.0000000000 * 0.8756980000 = -0.6321024438 
0.0000000000 * 0.3556300000 = -0.6321024438 
0.0000000000 * -0.6469880000 = -0.6321024438 
0.0000000000 * -0.2692840000 = -0.6321024438 
the biases is : -0.0620032000, now tempVal is : -0.6941056438
ReLU !!! in layer: 3, node : 15, its linear result is negative,so set it to 0
compute layer: 3, node : 16
0.2476063322 * 0.9251190000 = 0.2290653225 
0.0000000000 * 0.0347794000 = 0.2290653225 
0.5022157730 * 0.5839570000 = 0.5223377386 
0.0000000000 * 2.6275400000 = 0.5223377386 
0.1501012128 * 1.2478000000 = 0.7096340319 
0.0000000000 * -0.2350010000 = 0.7096340319 
0.2408135472 * 0.3166530000 = 0.7858883641 
0.0000000000 * 0.7275200000 = 0.7858883641 
0.0000000000 * 0.1993350000 = 0.7858883641 
0.6533630315 * -0.2164970000 = 0.6444372279 
0.0000000000 * 0.0101935000 = 0.6444372279 
0.0000000000 * 0.1486900000 = 0.6444372279 
0.0000000000 * -0.1103960000 = 0.6444372279 
0.0000000000 * -0.0240330000 = 0.6444372279 
0.0000000000 * 0.4561260000 = 0.6444372279 
0.0000000000 * -0.4904870000 = 0.6444372279 
0.0000000000 * 0.1961070000 = 0.6444372279 
0.1176464584 * 0.5465060000 = 0.7087317232 
0.0000000000 * -0.3526320000 = 0.7087317232 
0.0000000000 * 0.0783501000 = 0.7087317232 
0.0554119915 * 0.6720630000 = 0.7459720725 
0.2550187259 * 0.6935020000 = 0.9228280689 
0.0000000000 * -0.0081917700 = 0.9228280689 
0.0000000000 * 0.1519100000 = 0.9228280689 
0.0000000000 * -0.0157389000 = 0.9228280689 
0.0000000000 * -0.0373847000 = 0.9228280689 
0.0000000000 * -1.6311800000 = 0.9228280689 
0.0000000000 * 0.4173570000 = 0.9228280689 
0.0000000000 * 0.7155410000 = 0.9228280689 
0.0993749280 * -0.0381919000 = 0.9190327516 
0.0000000000 * 0.5540910000 = 0.9190327516 
0.0000000000 * -1.7952900000 = 0.9190327516 
0.0000000000 * -0.1078390000 = 0.9190327516 
0.0000000000 * -0.2687050000 = 0.9190327516 
0.0000000000 * -0.0496835000 = 0.9190327516 
0.0000000000 * 0.1462790000 = 0.9190327516 
0.0000000000 * -0.1361020000 = 0.9190327516 
0.0000000000 * 0.0072954800 = 0.9190327516 
0.0000000000 * 1.3094900000 = 0.9190327516 
0.0000000000 * -0.8740770000 = 0.9190327516 
0.4964708861 * 0.0343603000 = 0.9360916401 
0.7972727204 * 0.1335660000 = 1.0425801683 
0.0000000000 * -0.3555620000 = 1.0425801683 
0.0000000000 * 0.0273204000 = 1.0425801683 
0.0000000000 * -0.0083848100 = 1.0425801683 
0.0000000000 * -0.6045180000 = 1.0425801683 
0.0000000000 * -1.0275500000 = 1.0425801683 
0.0000000000 * 0.0375703000 = 1.0425801683 
0.0000000000 * -0.0240937000 = 1.0425801683 
0.0000000000 * -0.2229680000 = 1.0425801683 
the biases is : -0.6537900000, now tempVal is : 0.3887901683
compute layer: 3, node : 17
0.2476063322 * 0.5277950000 = 0.1306853841 
0.0000000000 * 0.0383142000 = 0.1306853841 
0.5022157730 * -0.0262704000 = 0.1174919749 
0.0000000000 * -0.0558835000 = 0.1174919749 
0.1501012128 * 1.0395300000 = 0.2735266886 
0.0000000000 * -0.0452990000 = 0.2735266886 
0.2408135472 * 0.6194270000 = 0.4226931017 
0.0000000000 * 0.3880130000 = 0.4226931017 
0.0000000000 * 0.1963090000 = 0.4226931017 
0.6533630315 * 0.0995666000 = 0.4877462373 
0.0000000000 * 0.0250881000 = 0.4877462373 
0.0000000000 * -0.4756380000 = 0.4877462373 
0.0000000000 * 0.4943890000 = 0.4877462373 
0.0000000000 * 0.3666060000 = 0.4877462373 
0.0000000000 * -0.0601781000 = 0.4877462373 
0.0000000000 * -0.3262810000 = 0.4877462373 
0.0000000000 * 0.3207770000 = 0.4877462373 
0.1176464584 * -0.9145590000 = 0.3801516100 
0.0000000000 * -0.2375880000 = 0.3801516100 
0.0000000000 * -0.0936699000 = 0.3801516100 
0.0554119915 * -0.2119660000 = 0.3684061518 
0.2550187259 * -0.0690574000 = 0.3507952217 
0.0000000000 * -0.2710390000 = 0.3507952217 
0.0000000000 * -0.2109160000 = 0.3507952217 
0.0000000000 * 0.0038806000 = 0.3507952217 
0.0000000000 * 0.0158154000 = 0.3507952217 
0.0000000000 * -0.3726750000 = 0.3507952217 
0.0000000000 * -0.5709930000 = 0.3507952217 
0.0000000000 * -0.3049660000 = 0.3507952217 
0.0993749280 * 0.4421600000 = 0.3947348398 
0.0000000000 * -0.0889994000 = 0.3947348398 
0.0000000000 * 0.4240150000 = 0.3947348398 
0.0000000000 * 0.1493650000 = 0.3947348398 
0.0000000000 * -0.1307860000 = 0.3947348398 
0.0000000000 * 0.6937330000 = 0.3947348398 
0.0000000000 * 0.2182130000 = 0.3947348398 
0.0000000000 * -0.2808420000 = 0.3947348398 
0.0000000000 * 0.0195526000 = 0.3947348398 
0.0000000000 * -3.5402000000 = 0.3947348398 
0.0000000000 * -1.0593300000 = 0.3947348398 
0.4964708861 * 0.3031390000 = 0.5452345278 
0.7972727204 * 0.2030080000 = 0.7070872682 
0.0000000000 * -0.7899940000 = 0.7070872682 
0.0000000000 * -0.0378943000 = 0.7070872682 
0.0000000000 * 0.3887550000 = 0.7070872682 
0.0000000000 * 0.3339510000 = 0.7070872682 
0.0000000000 * -0.5586410000 = 0.7070872682 
0.0000000000 * 0.9231710000 = 0.7070872682 
0.0000000000 * 0.0037354800 = 0.7070872682 
0.0000000000 * -0.0270135000 = 0.7070872682 
the biases is : 0.7301810000, now tempVal is : 1.4372682682
compute layer: 3, node : 18
0.2476063322 * -0.6094290000 = -0.1508984794 
0.0000000000 * -0.0267744000 = -0.1508984794 
0.5022157730 * -0.5802390000 = -0.4423036573 
0.0000000000 * 0.7090730000 = -0.4423036573 
0.1501012128 * 1.5405900000 = -0.2110592299 
0.0000000000 * 1.2783100000 = -0.2110592299 
0.2408135472 * 1.1936400000 = 0.0763854525 
0.0000000000 * -0.0852780000 = 0.0763854525 
0.0000000000 * -0.2140360000 = 0.0763854525 
0.6533630315 * 0.1359610000 = 0.1652173437 
0.0000000000 * 0.0180170000 = 0.1652173437 
0.0000000000 * -0.9294850000 = 0.1652173437 
0.0000000000 * 0.2453210000 = 0.1652173437 
0.0000000000 * 0.3509630000 = 0.1652173437 
0.0000000000 * -0.5276700000 = 0.1652173437 
0.0000000000 * 0.3123890000 = 0.1652173437 
0.0000000000 * -0.6948400000 = 0.1652173437 
0.1176464584 * -0.8888290000 = 0.0606497597 
0.0000000000 * 0.9895150000 = 0.0606497597 
0.0000000000 * 0.0686288000 = 0.0606497597 
0.0554119915 * 0.5117840000 = 0.0890087304 
0.2550187259 * 0.7775720000 = 0.2873041511 
0.0000000000 * 0.4837110000 = 0.2873041511 
0.0000000000 * 0.5939320000 = 0.2873041511 
0.0000000000 * -0.0176397000 = 0.2873041511 
0.0000000000 * -0.0080772400 = 0.2873041511 
0.0000000000 * 0.4787050000 = 0.2873041511 
0.0000000000 * -0.2726880000 = 0.2873041511 
0.0000000000 * 0.9317930000 = 0.2873041511 
0.0993749280 * -1.0883600000 = 0.1791484545 
0.0000000000 * -0.2288220000 = 0.1791484545 
0.0000000000 * 0.1790020000 = 0.1791484545 
0.0000000000 * -0.2089950000 = 0.1791484545 
0.0000000000 * -0.0970445000 = 0.1791484545 
0.0000000000 * -0.2221300000 = 0.1791484545 
0.0000000000 * -0.3501610000 = 0.1791484545 
0.0000000000 * 0.3355240000 = 0.1791484545 
0.0000000000 * -0.0359516000 = 0.1791484545 
0.0000000000 * -1.1245600000 = 0.1791484545 
0.0000000000 * 0.0349130000 = 0.1791484545 
0.4964708861 * -0.0466457000 = 0.1559902224 
0.7972727204 * 0.5109570000 = 0.5633622998 
0.0000000000 * 0.0574043000 = 0.5633622998 
0.0000000000 * -0.0493969000 = 0.5633622998 
0.0000000000 * 0.4622430000 = 0.5633622998 
0.0000000000 * -0.5680020000 = 0.5633622998 
0.0000000000 * 0.1455910000 = 0.5633622998 
0.0000000000 * -0.4481480000 = 0.5633622998 
0.0000000000 * -0.3901420000 = 0.5633622998 
0.0000000000 * -0.4350300000 = 0.5633622998 
the biases is : -0.8499610000, now tempVal is : -0.2865987002
ReLU !!! in layer: 3, node : 18, its linear result is negative,so set it to 0
compute layer: 3, node : 19
0.2476063322 * 0.0281987000 = 0.0069821767 
0.0000000000 * 0.0005665820 = 0.0069821767 
0.5022157730 * -0.0331900000 = -0.0096863648 
0.0000000000 * 0.0221532000 = -0.0096863648 
0.1501012128 * -0.0084935400 = -0.0109612555 
0.0000000000 * -0.0180649000 = -0.0109612555 
0.2408135472 * -0.0565698000 = -0.0245840297 
0.0000000000 * -0.0119536000 = -0.0245840297 
0.0000000000 * 0.0327668000 = -0.0245840297 
0.6533630315 * 0.0118744000 = -0.0168257357 
0.0000000000 * -0.0385735000 = -0.0168257357 
0.0000000000 * -0.0314957000 = -0.0168257357 
0.0000000000 * -0.0186819000 = -0.0168257357 
0.0000000000 * -0.0245256000 = -0.0168257357 
0.0000000000 * -0.0309155000 = -0.0168257357 
0.0000000000 * -0.0117556000 = -0.0168257357 
0.0000000000 * -0.0076011500 = -0.0168257357 
0.1176464584 * 0.0056835500 = -0.0161570862 
0.0000000000 * -0.0477713000 = -0.0161570862 
0.0000000000 * -0.0185308000 = -0.0161570862 
0.0554119915 * -0.0168257000 = -0.0170894317 
0.2550187259 * -0.0325391000 = -0.0253875115 
0.0000000000 * -0.0412281000 = -0.0253875115 
0.0000000000 * 0.0357343000 = -0.0253875115 
0.0000000000 * 0.0029233600 = -0.0253875115 
0.0000000000 * -0.0178145000 = -0.0253875115 
0.0000000000 * 0.0438456000 = -0.0253875115 
0.0000000000 * 0.0184717000 = -0.0253875115 
0.0000000000 * -0.0219421000 = -0.0253875115 
0.0993749280 * -0.0254984000 = -0.0279214132 
0.0000000000 * -0.0324205000 = -0.0279214132 
0.0000000000 * -0.0493456000 = -0.0279214132 
0.0000000000 * 0.0099054500 = -0.0279214132 
0.0000000000 * -0.0401097000 = -0.0279214132 
0.0000000000 * -0.0324605000 = -0.0279214132 
0.0000000000 * -0.0212912000 = -0.0279214132 
0.0000000000 * -0.0194038000 = -0.0279214132 
0.0000000000 * -0.0400194000 = -0.0279214132 
0.0000000000 * 0.0053588000 = -0.0279214132 
0.0000000000 * -0.0263758000 = -0.0279214132 
0.4964708861 * -0.0080125000 = -0.0318993862 
0.7972727204 * -0.0210690000 = -0.0486971251 
0.0000000000 * 0.0099170000 = -0.0486971251 
0.0000000000 * 0.0446544000 = -0.0486971251 
0.0000000000 * 0.0345754000 = -0.0486971251 
0.0000000000 * -0.0117978000 = -0.0486971251 
0.0000000000 * 0.0309422000 = -0.0486971251 
0.0000000000 * -0.0197059000 = -0.0486971251 
0.0000000000 * -0.0286900000 = -0.0486971251 
0.0000000000 * 0.0284456000 = -0.0486971251 
the biases is : -0.0157298000, now tempVal is : -0.0644269251
ReLU !!! in layer: 3, node : 19, its linear result is negative,so set it to 0
compute layer: 3, node : 20
0.2476063322 * 0.4982260000 = 0.1233639125 
0.0000000000 * -0.0021275400 = 0.1233639125 
0.5022157730 * -0.3006080000 = -0.0276061666 
0.0000000000 * -1.3081400000 = -0.0276061666 
0.1501012128 * -1.9419400000 = -0.3190937158 
0.0000000000 * 0.2543320000 = -0.3190937158 
0.2408135472 * -0.1450140000 = -0.3540150515 
0.0000000000 * -0.7695560000 = -0.3540150515 
0.0000000000 * -0.0293914000 = -0.3540150515 
0.6533630315 * 0.2058620000 = -0.2195124311 
0.0000000000 * -0.0193495000 = -0.2195124311 
0.0000000000 * 0.9120170000 = -0.2195124311 
0.0000000000 * 0.3959640000 = -0.2195124311 
0.0000000000 * -0.1093700000 = -0.2195124311 
0.0000000000 * -0.1659530000 = -0.2195124311 
0.0000000000 * 0.2197080000 = -0.2195124311 
0.0000000000 * -0.9990700000 = -0.2195124311 
0.1176464584 * 1.0018300000 = -0.1016506797 
0.0000000000 * 0.1532230000 = -0.1016506797 
0.0000000000 * 0.7102010000 = -0.1016506797 
0.0554119915 * -0.3560560000 = -0.1213804518 
0.2550187259 * 0.4728340000 = -0.0007989276 
0.0000000000 * -0.1503690000 = -0.0007989276 
0.0000000000 * 0.9072500000 = -0.0007989276 
0.0000000000 * -0.0108754000 = -0.0007989276 
0.0000000000 * -0.0156438000 = -0.0007989276 
0.0000000000 * -0.6442230000 = -0.0007989276 
0.0000000000 * 0.0745345000 = -0.0007989276 
0.0000000000 * 1.9238100000 = -0.0007989276 
0.0993749280 * 0.4980270000 = 0.0486924697 
0.0000000000 * -0.0260848000 = 0.0486924697 
0.0000000000 * -0.8329250000 = 0.0486924697 
0.0000000000 * 0.1395490000 = 0.0486924697 
0.0000000000 * -0.9295770000 = 0.0486924697 
0.0000000000 * -0.7098520000 = 0.0486924697 
0.0000000000 * -0.9005590000 = 0.0486924697 
0.0000000000 * 0.3208680000 = 0.0486924697 
0.0000000000 * -0.0016284400 = 0.0486924697 
0.0000000000 * -0.1098560000 = 0.0486924697 
0.0000000000 * 0.4655360000 = 0.0486924697 
0.4964708861 * -0.4231070000 = -0.1613678375 
0.7972727204 * 0.5314790000 = 0.2623658706 
0.0000000000 * 0.3834890000 = 0.2623658706 
0.0000000000 * 0.0733732000 = 0.2623658706 
0.0000000000 * 0.3278930000 = 0.2623658706 
0.0000000000 * -0.4989300000 = 0.2623658706 
0.0000000000 * 0.2393180000 = 0.2623658706 
0.0000000000 * -0.8813060000 = 0.2623658706 
0.0000000000 * 0.1593690000 = 0.2623658706 
0.0000000000 * -0.3603080000 = 0.2623658706 
the biases is : -0.2898080000, now tempVal is : -0.0274421294
ReLU !!! in layer: 3, node : 20, its linear result is negative,so set it to 0
compute layer: 3, node : 21
0.2476063322 * 0.2653520000 = 0.0657028355 
0.0000000000 * -0.0307186000 = 0.0657028355 
0.5022157730 * 0.0462529000 = 0.0889317714 
0.0000000000 * -0.1817810000 = 0.0889317714 
0.1501012128 * 0.7330430000 = 0.1989624147 
0.0000000000 * -0.1938160000 = 0.1989624147 
0.2408135472 * 0.2819040000 = 0.2668487169 
0.0000000000 * -0.6996890000 = 0.2668487169 
0.0000000000 * 0.1860550000 = 0.2668487169 
0.6533630315 * -0.0936909000 = 0.2056345465 
0.0000000000 * 0.0238121000 = 0.2056345465 
0.0000000000 * -0.0934531000 = 0.2056345465 
0.0000000000 * 0.2648310000 = 0.2056345465 
0.0000000000 * -0.1776570000 = 0.2056345465 
0.0000000000 * 0.0420084000 = 0.2056345465 
0.0000000000 * 0.3741260000 = 0.2056345465 
0.0000000000 * -0.1729450000 = 0.2056345465 
0.1176464584 * 0.0928257000 = 0.2165551613 
0.0000000000 * 0.4395110000 = 0.2165551613 
0.0000000000 * -0.0465424000 = 0.2165551613 
0.0554119915 * -0.8800430000 = 0.1677902261 
0.2550187259 * -0.4767580000 = 0.0462080084 
0.0000000000 * -0.0776608000 = 0.0462080084 
0.0000000000 * 0.1666940000 = 0.0462080084 
0.0000000000 * -0.0312025000 = 0.0462080084 
0.0000000000 * -0.0423739000 = 0.0462080084 
0.0000000000 * -0.4139750000 = 0.0462080084 
0.0000000000 * -0.0678724000 = 0.0462080084 
0.0000000000 * 0.1307690000 = 0.0462080084 
0.0993749280 * -0.7483840000 = -0.0281625977 
0.0000000000 * 0.2878190000 = -0.0281625977 
0.0000000000 * -1.1199300000 = -0.0281625977 
0.0000000000 * 0.3315070000 = -0.0281625977 
0.0000000000 * -0.2691910000 = -0.0281625977 
0.0000000000 * -0.0071234100 = -0.0281625977 
0.0000000000 * 0.2624850000 = -0.0281625977 
0.0000000000 * -0.2085050000 = -0.0281625977 
0.0000000000 * 0.0427367000 = -0.0281625977 
0.0000000000 * -0.9313980000 = -0.0281625977 
0.0000000000 * 0.5793820000 = -0.0281625977 
0.4964708861 * -0.3016030000 = -0.1778997064 
0.7972727204 * -0.1571700000 = -0.3032070598 
0.0000000000 * 0.3653640000 = -0.3032070598 
0.0000000000 * -0.0236449000 = -0.3032070598 
0.0000000000 * 0.1336630000 = -0.3032070598 
0.0000000000 * 0.4017160000 = -0.3032070598 
0.0000000000 * -0.0758450000 = -0.3032070598 
0.0000000000 * -0.0966528000 = -0.3032070598 
0.0000000000 * 0.1550620000 = -0.3032070598 
0.0000000000 * -0.2646580000 = -0.3032070598 
the biases is : 0.2789400000, now tempVal is : -0.0242670598
ReLU !!! in layer: 3, node : 21, its linear result is negative,so set it to 0
compute layer: 3, node : 22
0.2476063322 * -2.5210800000 = -0.6242353721 
0.0000000000 * 0.0290909000 = -0.6242353721 
0.5022157730 * -2.0170000000 = -1.6372045861 
0.0000000000 * -3.7354300000 = -1.6372045861 
0.1501012128 * -4.0476100000 = -2.2447557561 
0.0000000000 * -0.5625090000 = -2.2447557561 
0.2408135472 * -0.1999050000 = -2.2928955882 
0.0000000000 * 1.4029800000 = -2.2928955882 
0.0000000000 * -0.2512440000 = -2.2928955882 
0.6533630315 * 0.6555910000 = -1.8645566650 
0.0000000000 * -0.0043156900 = -1.8645566650 
0.0000000000 * -0.7044310000 = -1.8645566650 
0.0000000000 * 0.8460590000 = -1.8645566650 
0.0000000000 * -0.7932530000 = -1.8645566650 
0.0000000000 * 1.1970100000 = -1.8645566650 
0.0000000000 * -1.7002100000 = -1.8645566650 
0.0000000000 * 0.6267170000 = -1.8645566650 
0.1176464584 * -0.7171110000 = -1.9489222344 
0.0000000000 * 0.1410320000 = -1.9489222344 
0.0000000000 * 0.5586860000 = -1.9489222344 
0.0554119915 * 0.2987650000 = -1.9323670708 
0.2550187259 * -0.7906340000 = -2.1339935461 
0.0000000000 * -0.5929910000 = -2.1339935461 
0.0000000000 * -1.0909400000 = -2.1339935461 
0.0000000000 * 0.0377733000 = -2.1339935461 
0.0000000000 * 0.0284864000 = -2.1339935461 
0.0000000000 * -0.1431410000 = -2.1339935461 
0.0000000000 * 0.4824170000 = -2.1339935461 
0.0000000000 * 0.5855170000 = -2.1339935461 
0.0993749280 * 1.0931500000 = -2.0253618435 
0.0000000000 * -0.4697090000 = -2.0253618435 
0.0000000000 * -5.9711100000 = -2.0253618435 
0.0000000000 * -0.1721660000 = -2.0253618435 
0.0000000000 * -0.5776100000 = -2.0253618435 
0.0000000000 * 0.6118730000 = -2.0253618435 
0.0000000000 * 1.2243000000 = -2.0253618435 
0.0000000000 * 0.0391898000 = -2.0253618435 
0.0000000000 * -0.0215232000 = -2.0253618435 
0.0000000000 * -0.3363160000 = -2.0253618435 
0.0000000000 * -1.7009800000 = -2.0253618435 
0.4964708861 * 1.5757800000 = -1.2430329506 
0.7972727204 * 1.6973100000 = 0.1101860104 
0.0000000000 * -1.1117800000 = 0.1101860104 
0.0000000000 * -0.0397061000 = 0.1101860104 
0.0000000000 * 0.5569670000 = 0.1101860104 
0.0000000000 * -0.5363280000 = 0.1101860104 
0.0000000000 * 0.0221273000 = 0.1101860104 
0.0000000000 * 1.6325000000 = 0.1101860104 
0.0000000000 * -0.6564370000 = 0.1101860104 
0.0000000000 * 1.0397200000 = 0.1101860104 
the biases is : 1.4707800000, now tempVal is : 1.5809660104
compute layer: 3, node : 23
0.2476063322 * 0.0395581000 = 0.0097948361 
0.0000000000 * -0.0326162000 = 0.0097948361 
0.5022157730 * -0.0040585700 = 0.0077565582 
0.0000000000 * -1.0265100000 = 0.0077565582 
0.1501012128 * -0.1077610000 = -0.0084184986 
0.0000000000 * 0.1386990000 = -0.0084184986 
0.2408135472 * -0.0094659800 = -0.0106980348 
0.0000000000 * -2.8040000000 = -0.0106980348 
0.0000000000 * -0.2040170000 = -0.0106980348 
0.6533630315 * -0.7758590000 = -0.5176156231 
0.0000000000 * 0.0094790700 = -0.5176156231 
0.0000000000 * -0.3278770000 = -0.5176156231 
0.0000000000 * 0.6785730000 = -0.5176156231 
0.0000000000 * 0.5763700000 = -0.5176156231 
0.0000000000 * -0.5588280000 = -0.5176156231 
0.0000000000 * -0.4260740000 = -0.5176156231 
0.0000000000 * -1.6205000000 = -0.5176156231 
0.1176464584 * 0.7911280000 = -0.4245422158 
0.0000000000 * -0.1342790000 = -0.4245422158 
0.0000000000 * -0.9161400000 = -0.4245422158 
0.0554119915 * 0.8014320000 = -0.3801332726 
0.2550187259 * -0.8603910000 = -0.5995490892 
0.0000000000 * 0.0842009000 = -0.5995490892 
0.0000000000 * -0.3240980000 = -0.5995490892 
0.0000000000 * 0.0348720000 = -0.5995490892 
0.0000000000 * -0.0022483100 = -0.5995490892 
0.0000000000 * -0.6240060000 = -0.5995490892 
0.0000000000 * -0.9087930000 = -0.5995490892 
0.0000000000 * -0.3634670000 = -0.5995490892 
0.0993749280 * -0.3691290000 = -0.6362312570 
0.0000000000 * 0.6744710000 = -0.6362312570 
0.0000000000 * -2.9880800000 = -0.6362312570 
0.0000000000 * -0.2145130000 = -0.6362312570 
0.0000000000 * 0.1515820000 = -0.6362312570 
0.0000000000 * -0.5375650000 = -0.6362312570 
0.0000000000 * -0.8994730000 = -0.6362312570 
0.0000000000 * 0.5030650000 = -0.6362312570 
0.0000000000 * -0.0347963000 = -0.6362312570 
0.0000000000 * 0.4425890000 = -0.6362312570 
0.0000000000 * -1.1746500000 = -0.6362312570 
0.4964708861 * 1.0438100000 = -0.1180099813 
0.7972727204 * 0.0212021000 = -0.1011061254 
0.0000000000 * 0.7742940000 = -0.1011061254 
0.0000000000 * 0.0275866000 = -0.1011061254 
0.0000000000 * 0.6302690000 = -0.1011061254 
0.0000000000 * -0.4350670000 = -0.1011061254 
0.0000000000 * 0.2728390000 = -0.1011061254 
0.0000000000 * 1.0373900000 = -0.1011061254 
0.0000000000 * -0.6774810000 = -0.1011061254 
0.0000000000 * -0.5704490000 = -0.1011061254 
the biases is : 2.1079300000, now tempVal is : 2.0068238746
compute layer: 3, node : 24
0.2476063322 * -0.7505420000 = -0.1858389518 
0.0000000000 * -0.0218864000 = -0.1858389518 
0.5022157730 * 0.0847197000 = -0.1432913822 
0.0000000000 * -0.7040430000 = -0.1432913822 
0.1501012128 * -0.0048571300 = -0.1440204433 
0.0000000000 * 0.3054850000 = -0.1440204433 
0.2408135472 * -0.0585694000 = -0.1581247483 
0.0000000000 * -0.4907190000 = -0.1581247483 
0.0000000000 * 0.4746230000 = -0.1581247483 
0.6533630315 * 0.0964657000 = -0.0950976261 
0.0000000000 * 0.0115016000 = -0.0950976261 
0.0000000000 * 0.2412200000 = -0.0950976261 
0.0000000000 * -0.3826140000 = -0.0950976261 
0.0000000000 * 0.2231100000 = -0.0950976261 
0.0000000000 * -0.2311760000 = -0.0950976261 
0.0000000000 * 0.6871900000 = -0.0950976261 
0.0000000000 * 0.3293340000 = -0.0950976261 
0.1176464584 * -0.0391206000 = -0.0997000261 
0.0000000000 * -0.3475050000 = -0.0997000261 
0.0000000000 * 0.3409760000 = -0.0997000261 
0.0554119915 * -0.2679640000 = -0.1145484450 
0.2550187259 * -0.5339780000 = -0.2507228342 
0.0000000000 * 0.1739830000 = -0.2507228342 
0.0000000000 * -0.3224950000 = -0.2507228342 
0.0000000000 * -0.0485967000 = -0.2507228342 
0.0000000000 * 0.0271819000 = -0.2507228342 
0.0000000000 * -0.5119460000 = -0.2507228342 
0.0000000000 * -0.1520640000 = -0.2507228342 
0.0000000000 * 0.0743975000 = -0.2507228342 
0.0993749280 * -0.0727767000 = -0.2579550135 
0.0000000000 * -0.0481172000 = -0.2579550135 
0.0000000000 * -0.9702820000 = -0.2579550135 
0.0000000000 * 0.0936253000 = -0.2579550135 
0.0000000000 * -0.0681210000 = -0.2579550135 
0.0000000000 * -0.2768420000 = -0.2579550135 
0.0000000000 * 0.0881781000 = -0.2579550135 
0.0000000000 * -0.1907900000 = -0.2579550135 
0.0000000000 * -0.0059446200 = -0.2579550135 
0.0000000000 * 0.6789530000 = -0.2579550135 
0.0000000000 * 1.2771200000 = -0.2579550135 
0.4964708861 * -0.2066370000 = -0.3605442680 
0.7972727204 * 0.2412720000 = -0.1681846842 
0.0000000000 * -0.0020342000 = -0.1681846842 
0.0000000000 * 0.0153705000 = -0.1681846842 
0.0000000000 * 0.3190870000 = -0.1681846842 
0.0000000000 * -0.3881810000 = -0.1681846842 
0.0000000000 * -0.2458890000 = -0.1681846842 
0.0000000000 * 0.1568000000 = -0.1681846842 
0.0000000000 * 0.1406980000 = -0.1681846842 
0.0000000000 * -0.4092180000 = -0.1681846842 
the biases is : -0.3101700000, now tempVal is : -0.4783546842
ReLU !!! in layer: 3, node : 24, its linear result is negative,so set it to 0
compute layer: 3, node : 25
0.2476063322 * 0.7970690000 = 0.1973593316 
0.0000000000 * -0.0194802000 = 0.1973593316 
0.5022157730 * 0.3160950000 = 0.3561072264 
0.0000000000 * 0.2853290000 = 0.3561072264 
0.1501012128 * -0.1173650000 = 0.3384905975 
0.0000000000 * -0.0632377000 = 0.3384905975 
0.2408135472 * -0.2325920000 = 0.2824792930 
0.0000000000 * -0.4754680000 = 0.2824792930 
0.0000000000 * -0.1709410000 = 0.2824792930 
0.6533630315 * -0.3106990000 = 0.0794800525 
0.0000000000 * -0.0232985000 = 0.0794800525 
0.0000000000 * 0.1606420000 = 0.0794800525 
0.0000000000 * 0.0627335000 = 0.0794800525 
0.0000000000 * 0.2144350000 = 0.0794800525 
0.0000000000 * 0.4180080000 = 0.0794800525 
0.0000000000 * 0.2323140000 = 0.0794800525 
0.0000000000 * 0.1974940000 = 0.0794800525 
0.1176464584 * 0.6456410000 = 0.1554374295 
0.0000000000 * 0.0546500000 = 0.1554374295 
0.0000000000 * 0.2297250000 = 0.1554374295 
0.0554119915 * -0.3050950000 = 0.1385315079 
0.2550187259 * -0.0045071100 = 0.1373821105 
0.0000000000 * 0.0072977000 = 0.1373821105 
0.0000000000 * 0.7285620000 = 0.1373821105 
0.0000000000 * -0.0140871000 = 0.1373821105 
0.0000000000 * 0.0311146000 = 0.1373821105 
0.0000000000 * -0.5210480000 = 0.1373821105 
0.0000000000 * 0.3783780000 = 0.1373821105 
0.0000000000 * 0.3691330000 = 0.1373821105 
0.0993749280 * 0.0929027000 = 0.1466143096 
0.0000000000 * 0.2215040000 = 0.1466143096 
0.0000000000 * 0.5715800000 = 0.1466143096 
0.0000000000 * 0.3027090000 = 0.1466143096 
0.0000000000 * 0.1767940000 = 0.1466143096 
0.0000000000 * 0.4547050000 = 0.1466143096 
0.0000000000 * -0.5256330000 = 0.1466143096 
0.0000000000 * 0.0873920000 = 0.1466143096 
0.0000000000 * 0.0229355000 = 0.1466143096 
0.0000000000 * 1.7270100000 = 0.1466143096 
0.0000000000 * -0.2587430000 = 0.1466143096 
0.4964708861 * -0.6496150000 = -0.1759006251 
0.7972727204 * -0.4749600000 = -0.5545732764 
0.0000000000 * 0.2069500000 = -0.5545732764 
0.0000000000 * 0.0477512000 = -0.5545732764 
0.0000000000 * 0.3706920000 = -0.5545732764 
0.0000000000 * 0.0448857000 = -0.5545732764 
0.0000000000 * 0.1150910000 = -0.5545732764 
0.0000000000 * 1.0108500000 = -0.5545732764 
0.0000000000 * 0.1676520000 = -0.5545732764 
0.0000000000 * 0.2677230000 = -0.5545732764 
the biases is : -0.5384440000, now tempVal is : -1.0930172764
ReLU !!! in layer: 3, node : 25, its linear result is negative,so set it to 0
compute layer: 3, node : 26
0.2476063322 * 0.7526500000 = 0.1863609060 
0.0000000000 * -0.0376294000 = 0.1863609060 
0.5022157730 * 0.6691180000 = 0.5224025195 
0.0000000000 * 0.6526610000 = 0.5224025195 
0.1501012128 * 0.5926360000 = 0.6113579019 
0.0000000000 * -0.5609770000 = 0.6113579019 
0.2408135472 * 0.1303080000 = 0.6427378336 
0.0000000000 * 0.0851664000 = 0.6427378336 
0.0000000000 * 0.1631210000 = 0.6427378336 
0.6533630315 * -0.2241850000 = 0.4962636424 
0.0000000000 * -0.0182982000 = 0.4962636424 
0.0000000000 * 0.1319560000 = 0.4962636424 
0.0000000000 * 0.2811810000 = 0.4962636424 
0.0000000000 * 0.1540900000 = 0.4962636424 
0.0000000000 * 0.6605910000 = 0.4962636424 
0.0000000000 * 0.6465050000 = 0.4962636424 
0.0000000000 * 0.4212920000 = 0.4962636424 
0.1176464584 * -0.2829500000 = 0.4629755770 
0.0000000000 * -0.1247090000 = 0.4629755770 
0.0000000000 * 0.1914520000 = 0.4629755770 
0.0554119915 * -0.6436290000 = 0.4273108123 
0.2550187259 * -0.7414810000 = 0.2382192724 
0.0000000000 * -0.1144390000 = 0.2382192724 
0.0000000000 * 0.1258420000 = 0.2382192724 
0.0000000000 * 0.0262423000 = 0.2382192724 
0.0000000000 * -0.0312195000 = 0.2382192724 
0.0000000000 * -0.5376180000 = 0.2382192724 
0.0000000000 * 0.1439490000 = 0.2382192724 
0.0000000000 * -0.2570220000 = 0.2382192724 
0.0993749280 * 0.6584370000 = 0.3036514019 
0.0000000000 * 0.5658790000 = 0.3036514019 
0.0000000000 * 0.6667860000 = 0.3036514019 
0.0000000000 * -0.0388398000 = 0.3036514019 
0.0000000000 * 0.1615690000 = 0.3036514019 
0.0000000000 * -0.4519110000 = 0.3036514019 
0.0000000000 * -0.0419057000 = 0.3036514019 
0.0000000000 * -0.2234000000 = 0.3036514019 
0.0000000000 * -0.0445499000 = 0.3036514019 
0.0000000000 * 0.4284390000 = 0.3036514019 
0.0000000000 * 0.4480010000 = 0.3036514019 
0.4964708861 * -0.1026520000 = 0.2526876725 
0.7972727204 * -1.0227100000 = -0.5626911114 
0.0000000000 * -0.2487740000 = -0.5626911114 
0.0000000000 * 0.0379576000 = -0.5626911114 
0.0000000000 * 0.2475300000 = -0.5626911114 
0.0000000000 * -0.0889271000 = -0.5626911114 
0.0000000000 * -0.4742760000 = -0.5626911114 
0.0000000000 * -0.1445190000 = -0.5626911114 
0.0000000000 * 0.4956240000 = -0.5626911114 
0.0000000000 * -0.0968043000 = -0.5626911114 
the biases is : -0.1459190000, now tempVal is : -0.7086101114
ReLU !!! in layer: 3, node : 26, its linear result is negative,so set it to 0
compute layer: 3, node : 27
0.2476063322 * 0.0951803000 = 0.0235672450 
0.0000000000 * -0.0018725700 = 0.0235672450 
0.5022157730 * -0.7651310000 = -0.3606936116 
0.0000000000 * 0.1779840000 = -0.3606936116 
0.1501012128 * -0.0028489500 = -0.3611212424 
0.0000000000 * -0.2583640000 = -0.3611212424 
0.2408135472 * 0.4200460000 = -0.2599684752 
0.0000000000 * 0.5307610000 = -0.2599684752 
0.0000000000 * -0.2900800000 = -0.2599684752 
0.6533630315 * -0.3045800000 = -0.4589697873 
0.0000000000 * -0.0321534000 = -0.4589697873 
0.0000000000 * -0.2695940000 = -0.4589697873 
0.0000000000 * 0.2454710000 = -0.4589697873 
0.0000000000 * 0.1412960000 = -0.4589697873 
0.0000000000 * -1.3413000000 = -0.4589697873 
0.0000000000 * -0.6478620000 = -0.4589697873 
0.0000000000 * -1.1480600000 = -0.4589697873 
0.1176464584 * -0.2211850000 = -0.4849914192 
0.0000000000 * -0.4225110000 = -0.4849914192 
0.0000000000 * -0.0581615000 = -0.4849914192 
0.0554119915 * -0.0934520000 = -0.4901697807 
0.2550187259 * 0.5294830000 = -0.3551417006 
0.0000000000 * -0.0785954000 = -0.3551417006 
0.0000000000 * 0.3679730000 = -0.3551417006 
0.0000000000 * -0.0237267000 = -0.3551417006 
0.0000000000 * -0.0344987000 = -0.3551417006 
0.0000000000 * 0.3812970000 = -0.3551417006 
0.0000000000 * -0.1097120000 = -0.3551417006 
0.0000000000 * 0.7518400000 = -0.3551417006 
0.0993749280 * -1.3296800000 = -0.4872785549 
0.0000000000 * -0.0576448000 = -0.4872785549 
0.0000000000 * -1.1039900000 = -0.4872785549 
0.0000000000 * 0.1295840000 = -0.4872785549 
0.0000000000 * 0.0876565000 = -0.4872785549 
0.0000000000 * 0.2703920000 = -0.4872785549 
0.0000000000 * -0.6027510000 = -0.4872785549 
0.0000000000 * 0.3607430000 = -0.4872785549 
0.0000000000 * -0.0202855000 = -0.4872785549 
0.0000000000 * -0.0015778900 = -0.4872785549 
0.0000000000 * -0.7774200000 = -0.4872785549 
0.4964708861 * -0.1073730000 = -0.5405861233 
0.7972727204 * 0.3750240000 = -0.2415897187 
0.0000000000 * -0.6691790000 = -0.2415897187 
0.0000000000 * -0.0412196000 = -0.2415897187 
0.0000000000 * -0.0495119000 = -0.2415897187 
0.0000000000 * 0.0244512000 = -0.2415897187 
0.0000000000 * 0.1723650000 = -0.2415897187 
0.0000000000 * 0.7854150000 = -0.2415897187 
0.0000000000 * -0.1411020000 = -0.2415897187 
0.0000000000 * -0.3519600000 = -0.2415897187 
the biases is : 1.0104900000, now tempVal is : 0.7689002813
compute layer: 3, node : 28
0.2476063322 * -1.2535200000 = -0.3103794896 
0.0000000000 * 0.0242106000 = -0.3103794896 
0.5022157730 * -0.2010390000 = -0.4113444464 
0.0000000000 * 0.1205240000 = -0.4113444464 
0.1501012128 * -0.6179820000 = -0.5041042941 
0.0000000000 * -0.5974990000 = -0.5041042941 
0.2408135472 * 0.5450330000 = -0.3728529640 
0.0000000000 * 0.2644990000 = -0.3728529640 
0.0000000000 * -0.1584100000 = -0.3728529640 
0.6533630315 * 0.2203500000 = -0.2288844200 
0.0000000000 * 0.0107195000 = -0.2288844200 
0.0000000000 * -0.8742330000 = -0.2288844200 
0.0000000000 * -0.1231660000 = -0.2288844200 
0.0000000000 * -0.8820700000 = -0.2288844200 
0.0000000000 * 0.1789220000 = -0.2288844200 
0.0000000000 * -0.2802960000 = -0.2288844200 
0.0000000000 * -0.2860000000 = -0.2288844200 
0.1176464584 * -0.2965180000 = -0.2637687125 
0.0000000000 * -1.2504800000 = -0.2637687125 
0.0000000000 * -0.2168880000 = -0.2637687125 
0.0554119915 * -0.0809658000 = -0.2682551888 
0.2550187259 * -0.3451230000 = -0.3562680165 
0.0000000000 * 0.0340223000 = -0.3562680165 
0.0000000000 * -0.3179270000 = -0.3562680165 
0.0000000000 * 0.0286623000 = -0.3562680165 
0.0000000000 * 0.0476056000 = -0.3562680165 
0.0000000000 * -0.2516010000 = -0.3562680165 
0.0000000000 * 0.3812930000 = -0.3562680165 
0.0000000000 * -0.3173580000 = -0.3562680165 
0.0993749280 * 0.2260150000 = -0.3338077921 
0.0000000000 * -0.1371310000 = -0.3338077921 
0.0000000000 * 0.0653059000 = -0.3338077921 
0.0000000000 * -0.0646779000 = -0.3338077921 
0.0000000000 * 0.4419590000 = -0.3338077921 
0.0000000000 * -0.8385870000 = -0.3338077921 
0.0000000000 * 0.0562255000 = -0.3338077921 
0.0000000000 * 0.3524520000 = -0.3338077921 
0.0000000000 * -0.0072979200 = -0.3338077921 
0.0000000000 * 6.0661900000 = -0.3338077921 
0.0000000000 * 0.0546006000 = -0.3338077921 
0.4964708861 * 0.0240395000 = -0.3218728803 
0.7972727204 * -0.1750760000 = -0.4614561991 
0.0000000000 * -0.5525870000 = -0.4614561991 
0.0000000000 * -0.0185979000 = -0.4614561991 
0.0000000000 * 0.1888260000 = -0.4614561991 
0.0000000000 * 0.1512100000 = -0.4614561991 
0.0000000000 * 0.3870680000 = -0.4614561991 
0.0000000000 * 0.1083740000 = -0.4614561991 
0.0000000000 * -0.1454250000 = -0.4614561991 
0.0000000000 * 1.0210600000 = -0.4614561991 
the biases is : -0.3741560000, now tempVal is : -0.8356121991
ReLU !!! in layer: 3, node : 28, its linear result is negative,so set it to 0
compute layer: 3, node : 29
0.2476063322 * -0.4642700000 = -0.1149561919 
0.0000000000 * -0.0209486000 = -0.1149561919 
0.5022157730 * -0.1615420000 = -0.1960851323 
0.0000000000 * 0.7640340000 = -0.1960851323 
0.1501012128 * -0.4848220000 = -0.2688575025 
0.0000000000 * -0.3316980000 = -0.2688575025 
0.2408135472 * 0.1366310000 = -0.2359549067 
0.0000000000 * -0.6022920000 = -0.2359549067 
0.0000000000 * 0.3317180000 = -0.2359549067 
0.6533630315 * 0.5725790000 = 0.1381470445 
0.0000000000 * -0.0233067000 = 0.1381470445 
0.0000000000 * 0.5724740000 = 0.1381470445 
0.0000000000 * 0.9878700000 = 0.1381470445 
0.0000000000 * 1.0706800000 = 0.1381470445 
0.0000000000 * 0.1797630000 = 0.1381470445 
0.0000000000 * -0.4719470000 = 0.1381470445 
0.0000000000 * -0.6692450000 = 0.1381470445 
0.1176464584 * 0.2266300000 = 0.1648092614 
0.0000000000 * -0.0050268500 = 0.1648092614 
0.0000000000 * -0.4058760000 = 0.1648092614 
0.0554119915 * 0.7766540000 = 0.2078452062 
0.2550187259 * 0.3763960000 = 0.3038332346 
0.0000000000 * 0.3434380000 = 0.3038332346 
0.0000000000 * 0.2086820000 = 0.3038332346 
0.0000000000 * 0.0233998000 = 0.3038332346 
0.0000000000 * 0.0006731030 = 0.3038332346 
0.0000000000 * 0.6047540000 = 0.3038332346 
0.0000000000 * 0.0778545000 = 0.3038332346 
0.0000000000 * -0.2847440000 = 0.3038332346 
0.0993749280 * 0.2822320000 = 0.3318800192 
0.0000000000 * -0.3241210000 = 0.3318800192 
0.0000000000 * 0.3061660000 = 0.3318800192 
0.0000000000 * -0.3197130000 = 0.3318800192 
0.0000000000 * -0.3545890000 = 0.3318800192 
0.0000000000 * -0.9054420000 = 0.3318800192 
0.0000000000 * 0.1457540000 = 0.3318800192 
0.0000000000 * 0.3289990000 = 0.3318800192 
0.0000000000 * 0.0185485000 = 0.3318800192 
0.0000000000 * 1.0441800000 = 0.3318800192 
0.0000000000 * -0.2907140000 = 0.3318800192 
0.4964708861 * -0.0861877000 = 0.2890903354 
0.7972727204 * -0.1014180000 = 0.2082325307 
0.0000000000 * 0.4771020000 = 0.2082325307 
0.0000000000 * -0.0292807000 = 0.2082325307 
0.0000000000 * -0.3193950000 = 0.2082325307 
0.0000000000 * 0.5374650000 = 0.2082325307 
0.0000000000 * -0.0509263000 = 0.2082325307 
0.0000000000 * -0.4492790000 = 0.2082325307 
0.0000000000 * -0.4297290000 = 0.2082325307 
0.0000000000 * -0.4710500000 = 0.2082325307 
the biases is : -0.0527222000, now tempVal is : 0.1555103307
compute layer: 3, node : 30
0.2476063322 * 0.1075840000 = 0.0266384796 
0.0000000000 * -0.0149620000 = 0.0266384796 
0.5022157730 * -0.0359278000 = 0.0085949718 
0.0000000000 * -0.3724820000 = 0.0085949718 
0.1501012128 * 0.7029550000 = 0.1141093698 
0.0000000000 * 0.7626290000 = 0.1141093698 
0.2408135472 * 0.3580100000 = 0.2003230279 
0.0000000000 * 0.0503258000 = 0.2003230279 
0.0000000000 * -0.3823090000 = 0.2003230279 
0.6533630315 * -0.2602860000 = 0.0302617778 
0.0000000000 * -0.0263229000 = 0.0302617778 
0.0000000000 * 0.2812570000 = 0.0302617778 
0.0000000000 * 0.1217500000 = 0.0302617778 
0.0000000000 * 0.0935972000 = 0.0302617778 
0.0000000000 * -0.1971870000 = 0.0302617778 
0.0000000000 * 0.1252120000 = 0.0302617778 
0.0000000000 * 0.4003830000 = 0.0302617778 
0.1176464584 * -0.3950410000 = -0.0162133967 
0.0000000000 * 0.5658610000 = -0.0162133967 
0.0000000000 * 0.0360610000 = -0.0162133967 
0.0554119915 * -0.1779370000 = -0.0260732402 
0.2550187259 * 0.1379430000 = 0.0091048079 
0.0000000000 * -0.1933470000 = 0.0091048079 
0.0000000000 * 0.0602310000 = 0.0091048079 
0.0000000000 * 0.0083256800 = 0.0091048079 
0.0000000000 * 0.0319692000 = 0.0091048079 
0.0000000000 * -0.0170368000 = 0.0091048079 
0.0000000000 * -0.2770480000 = 0.0091048079 
0.0000000000 * 0.4097350000 = 0.0091048079 
0.0993749280 * -0.0627620000 = 0.0028678386 
0.0000000000 * 0.0261019000 = 0.0028678386 
0.0000000000 * -0.0868398000 = 0.0028678386 
0.0000000000 * -0.1042580000 = 0.0028678386 
0.0000000000 * 0.1133260000 = 0.0028678386 
0.0000000000 * 0.1185360000 = 0.0028678386 
0.0000000000 * -0.4157330000 = 0.0028678386 
0.0000000000 * -0.1287230000 = 0.0028678386 
0.0000000000 * -0.0050591900 = 0.0028678386 
0.0000000000 * 4.1728300000 = 0.0028678386 
0.0000000000 * -0.3252910000 = 0.0028678386 
0.4964708861 * -0.1927670000 = -0.0928353647 
0.7972727204 * 0.0232578000 = -0.0742925552 
0.0000000000 * -0.8733120000 = -0.0742925552 
0.0000000000 * 0.0125965000 = -0.0742925552 
0.0000000000 * 0.2029840000 = -0.0742925552 
0.0000000000 * 0.0939274000 = -0.0742925552 
0.0000000000 * -0.2339930000 = -0.0742925552 
0.0000000000 * -0.1027400000 = -0.0742925552 
0.0000000000 * 0.1587070000 = -0.0742925552 
0.0000000000 * 0.5374790000 = -0.0742925552 
the biases is : -0.1487900000, now tempVal is : -0.2230825552
ReLU !!! in layer: 3, node : 30, its linear result is negative,so set it to 0
compute layer: 3, node : 31
0.2476063322 * 0.7797680000 = 0.1930754945 
0.0000000000 * 0.0046052100 = 0.1930754945 
0.5022157730 * -0.1077880000 = 0.1389426607 
0.0000000000 * 0.4134160000 = 0.1389426607 
0.1501012128 * 0.0950057000 = 0.1532031315 
0.0000000000 * -0.5667900000 = 0.1532031315 
0.2408135472 * -0.0087927700 = 0.1510857134 
0.0000000000 * -0.0498294000 = 0.1510857134 
0.0000000000 * -0.1503670000 = 0.1510857134 
0.6533630315 * -0.3202930000 = -0.0581818921 
0.0000000000 * -0.0391555000 = -0.0581818921 
0.0000000000 * -0.2711650000 = -0.0581818921 
0.0000000000 * -0.3212040000 = -0.0581818921 
0.0000000000 * 0.3528980000 = -0.0581818921 
0.0000000000 * 0.2564460000 = -0.0581818921 
0.0000000000 * -0.0161893000 = -0.0581818921 
0.0000000000 * -0.3611390000 = -0.0581818921 
0.1176464584 * 0.3378970000 = -0.0184295067 
0.0000000000 * -0.2647900000 = -0.0184295067 
0.0000000000 * -0.2998720000 = -0.0184295067 
0.0554119915 * -0.0254086000 = -0.0198374478 
0.2550187259 * -0.2543150000 = -0.0846925351 
0.0000000000 * 0.1552350000 = -0.0846925351 
0.0000000000 * -0.0992112000 = -0.0846925351 
0.0000000000 * -0.0136903000 = -0.0846925351 
0.0000000000 * -0.0006559710 = -0.0846925351 
0.0000000000 * 0.0762300000 = -0.0846925351 
0.0000000000 * -0.0703230000 = -0.0846925351 
0.0000000000 * -0.2853940000 = -0.0846925351 
0.0993749280 * -0.0773502000 = -0.0923792057 
0.0000000000 * 0.2871470000 = -0.0923792057 
0.0000000000 * 0.2240830000 = -0.0923792057 
0.0000000000 * -0.1367030000 = -0.0923792057 
0.0000000000 * 0.0887629000 = -0.0923792057 
0.0000000000 * -0.4754070000 = -0.0923792057 
0.0000000000 * -0.3981680000 = -0.0923792057 
0.0000000000 * 0.1082110000 = -0.0923792057 
0.0000000000 * -0.0093956100 = -0.0923792057 
0.0000000000 * 0.6360190000 = -0.0923792057 
0.0000000000 * -0.4674880000 = -0.0923792057 
0.4964708861 * 0.0203305000 = -0.0822857043 
0.7972727204 * -0.1013260000 = -0.1630701600 
0.0000000000 * 0.4971730000 = -0.1630701600 
0.0000000000 * 0.0003057030 = -0.1630701600 
0.0000000000 * 0.2532830000 = -0.1630701600 
0.0000000000 * 0.3526090000 = -0.1630701600 
0.0000000000 * 0.1912000000 = -0.1630701600 
0.0000000000 * -0.0233907000 = -0.1630701600 
0.0000000000 * -0.0936437000 = -0.1630701600 
0.0000000000 * 0.0037674800 = -0.1630701600 
the biases is : 0.2554640000, now tempVal is : 0.0923938400
compute layer: 3, node : 32
0.2476063322 * 0.9070450000 = 0.2245900856 
0.0000000000 * -0.0200609000 = 0.2245900856 
0.5022157730 * -0.0542313000 = 0.1973542714 
0.0000000000 * 0.2566820000 = 0.1973542714 
0.1501012128 * -0.2736090000 = 0.1562852286 
0.0000000000 * -0.0816323000 = 0.1562852286 
0.2408135472 * -0.0819423000 = 0.1365524127 
0.0000000000 * -0.6674300000 = 0.1365524127 
0.0000000000 * 0.0648148000 = 0.1365524127 
0.6533630315 * -0.3711690000 = -0.1059556903 
0.0000000000 * -0.0207716000 = -0.1059556903 
0.0000000000 * 0.5448160000 = -0.1059556903 
0.0000000000 * -0.0402844000 = -0.1059556903 
0.0000000000 * 0.0818872000 = -0.1059556903 
0.0000000000 * 0.2442910000 = -0.1059556903 
0.0000000000 * 0.9263700000 = -0.1059556903 
0.0000000000 * 0.0006807570 = -0.1059556903 
0.1176464584 * -0.0576869000 = -0.1127423498 
0.0000000000 * 0.0118569000 = -0.1127423498 
0.0000000000 * -0.0363323000 = -0.1127423498 
0.0554119915 * 0.2672320000 = -0.0979344925 
0.2550187259 * 0.4379040000 = 0.0137392276 
0.0000000000 * -0.3646640000 = 0.0137392276 
0.0000000000 * -0.8082040000 = 0.0137392276 
0.0000000000 * 0.0059398500 = 0.0137392276 
0.0000000000 * -0.0288534000 = 0.0137392276 
0.0000000000 * 0.4502730000 = 0.0137392276 
0.0000000000 * 0.4519010000 = 0.0137392276 
0.0000000000 * 0.6041250000 = 0.0137392276 
0.0993749280 * -0.3232620000 = -0.0183849103 
0.0000000000 * 0.0928226000 = -0.0183849103 
0.0000000000 * -0.7424430000 = -0.0183849103 
0.0000000000 * -0.2459760000 = -0.0183849103 
0.0000000000 * -0.2983090000 = -0.0183849103 
0.0000000000 * 0.2289930000 = -0.0183849103 
0.0000000000 * -0.0734490000 = -0.0183849103 
0.0000000000 * 0.1049420000 = -0.0183849103 
0.0000000000 * -0.0241614000 = -0.0183849103 
0.0000000000 * 0.7782160000 = -0.0183849103 
0.0000000000 * 0.5686080000 = -0.0183849103 
0.4964708861 * 0.0823384000 = 0.0224937081 
0.7972727204 * 0.2620530000 = 0.2314214163 
0.0000000000 * 0.0433182000 = 0.2314214163 
0.0000000000 * 0.0543064000 = 0.2314214163 
0.0000000000 * 0.0359142000 = 0.2314214163 
0.0000000000 * 0.2492330000 = 0.2314214163 
0.0000000000 * -0.6581380000 = 0.2314214163 
0.0000000000 * -1.1932400000 = 0.2314214163 
0.0000000000 * 0.0658258000 = 0.2314214163 
0.0000000000 * -0.1734050000 = 0.2314214163 
the biases is : -0.7721980000, now tempVal is : -0.5407765837
ReLU !!! in layer: 3, node : 32, its linear result is negative,so set it to 0
compute layer: 3, node : 33
0.2476063322 * 0.0553672000 = 0.0137092693 
0.0000000000 * 0.0097690500 = 0.0137092693 
0.5022157730 * -0.9715020000 = -0.4741943585 
0.0000000000 * -0.3584020000 = -0.4741943585 
0.1501012128 * -1.0427200000 = -0.6307078951 
0.0000000000 * 0.6100960000 = -0.6307078951 
0.2408135472 * -0.2568090000 = -0.6925509814 
0.0000000000 * 0.0651194000 = -0.6925509814 
0.0000000000 * -0.6624670000 = -0.6925509814 
0.6533630315 * -0.1468770000 = -0.7885149834 
0.0000000000 * 0.0258337000 = -0.7885149834 
0.0000000000 * -0.3346750000 = -0.7885149834 
0.0000000000 * -2.2083400000 = -0.7885149834 
0.0000000000 * -0.2592620000 = -0.7885149834 
0.0000000000 * 0.9316600000 = -0.7885149834 
0.0000000000 * 0.4533300000 = -0.7885149834 
0.0000000000 * -0.7042700000 = -0.7885149834 
0.1176464584 * 0.7860250000 = -0.6960419259 
0.0000000000 * -0.5356430000 = -0.6960419259 
0.0000000000 * -0.2155620000 = -0.6960419259 
0.0554119915 * 0.8474850000 = -0.6490810943 
0.2550187259 * 0.4454420000 = -0.5354850431 
0.0000000000 * 0.4550080000 = -0.5354850431 
0.0000000000 * 0.4355400000 = -0.5354850431 
0.0000000000 * -0.0180971000 = -0.5354850431 
0.0000000000 * -0.0226917000 = -0.5354850431 
0.0000000000 * -0.4412850000 = -0.5354850431 
0.0000000000 * 0.2093120000 = -0.5354850431 
0.0000000000 * -0.1837920000 = -0.5354850431 
0.0993749280 * -0.3324970000 = -0.5685269085 
0.0000000000 * 1.4979000000 = -0.5685269085 
0.0000000000 * -0.4236520000 = -0.5685269085 
0.0000000000 * -14.6970000000 = -0.5685269085 
0.0000000000 * -0.3442240000 = -0.5685269085 
0.0000000000 * 0.5022040000 = -0.5685269085 
0.0000000000 * 1.0678600000 = -0.5685269085 
0.0000000000 * 1.1077000000 = -0.5685269085 
0.0000000000 * -0.0281584000 = -0.5685269085 
0.0000000000 * 0.1921950000 = -0.5685269085 
0.0000000000 * 1.0001700000 = -0.5685269085 
0.4964708861 * -0.2552780000 = -0.6952650034 
0.7972727204 * 0.7590570000 = -0.0900895640 
0.0000000000 * 0.9227680000 = -0.0900895640 
0.0000000000 * -0.0367276000 = -0.0900895640 
0.0000000000 * 1.1220700000 = -0.0900895640 
0.0000000000 * -1.3116800000 = -0.0900895640 
0.0000000000 * -0.4715070000 = -0.0900895640 
0.0000000000 * -4.6521500000 = -0.0900895640 
0.0000000000 * 0.0272306000 = -0.0900895640 
0.0000000000 * -0.6856820000 = -0.0900895640 
the biases is : -1.7604700000, now tempVal is : -1.8505595640
ReLU !!! in layer: 3, node : 33, its linear result is negative,so set it to 0
compute layer: 3, node : 34
0.2476063322 * 0.2340000000 = 0.0579398817 
0.0000000000 * 0.0293159000 = 0.0579398817 
0.5022157730 * 0.3328820000 = 0.2251184727 
0.0000000000 * 1.2470600000 = 0.2251184727 
0.1501012128 * -0.7735630000 = 0.1090057282 
0.0000000000 * 0.1165770000 = 0.1090057282 
0.2408135472 * -0.5728680000 = -0.0289486469 
0.0000000000 * 0.2591730000 = -0.0289486469 
0.0000000000 * -0.3375440000 = -0.0289486469 
0.6533630315 * 0.1594130000 = 0.0752059140 
0.0000000000 * 0.0023609700 = 0.0752059140 
0.0000000000 * 0.0541645000 = 0.0752059140 
0.0000000000 * -0.9399950000 = 0.0752059140 
0.0000000000 * 0.0436153000 = 0.0752059140 
0.0000000000 * 0.4549260000 = 0.0752059140 
0.0000000000 * 0.3358520000 = 0.0752059140 
0.0000000000 * 1.4211500000 = 0.0752059140 
0.1176464584 * -0.3606400000 = 0.0327778953 
0.0000000000 * 0.1461850000 = 0.0327778953 
0.0000000000 * -0.0522267000 = 0.0327778953 
0.0554119915 * -0.0931296000 = 0.0276173987 
0.2550187259 * 0.5946530000 = 0.1792650490 
0.0000000000 * 0.2746270000 = 0.1792650490 
0.0000000000 * 0.0927465000 = 0.1792650490 
0.0000000000 * 0.0161132000 = 0.1792650490 
0.0000000000 * 0.0332546000 = 0.1792650490 
0.0000000000 * -0.4029240000 = 0.1792650490 
0.0000000000 * 0.0338912000 = 0.1792650490 
0.0000000000 * 0.1878770000 = 0.1792650490 
0.0993749280 * -0.4046150000 = 0.1390564625 
0.0000000000 * 0.0159843000 = 0.1390564625 
0.0000000000 * 0.5417490000 = 0.1390564625 
0.0000000000 * 0.4923090000 = 0.1390564625 
0.0000000000 * 0.4046740000 = 0.1390564625 
0.0000000000 * -0.5691830000 = 0.1390564625 
0.0000000000 * -0.4422600000 = 0.1390564625 
0.0000000000 * 0.1781130000 = 0.1390564625 
0.0000000000 * -0.0111348000 = 0.1390564625 
0.0000000000 * -0.2239760000 = 0.1390564625 
0.0000000000 * -0.1080610000 = 0.1390564625 
0.4964708861 * 0.3676420000 = 0.3215800121 
0.7972727204 * -1.3161500000 = -0.7277504789 
0.0000000000 * 0.4060110000 = -0.7277504789 
0.0000000000 * 0.0156123000 = -0.7277504789 
0.0000000000 * 0.2270710000 = -0.7277504789 
0.0000000000 * -0.5197890000 = -0.7277504789 
0.0000000000 * -0.5137060000 = -0.7277504789 
0.0000000000 * 0.4621350000 = -0.7277504789 
0.0000000000 * 0.0778425000 = -0.7277504789 
0.0000000000 * 0.0773384000 = -0.7277504789 
the biases is : 0.0622966000, now tempVal is : -0.6654538789
ReLU !!! in layer: 3, node : 34, its linear result is negative,so set it to 0
compute layer: 3, node : 35
0.2476063322 * 0.8629830000 = 0.2136800554 
0.0000000000 * -0.0467611000 = 0.2136800554 
0.5022157730 * 0.2069600000 = 0.3176186318 
0.0000000000 * 0.4342220000 = 0.3176186318 
0.1501012128 * 0.5760170000 = 0.4040794821 
0.0000000000 * 1.1425500000 = 0.4040794821 
0.2408135472 * 0.0566379000 = 0.4177186557 
0.0000000000 * -0.6365940000 = 0.4177186557 
0.0000000000 * 0.0501918000 = 0.4177186557 
0.6533630315 * -0.3284820000 = 0.2031006604 
0.0000000000 * 0.0068994400 = 0.2031006604 
0.0000000000 * -0.3402730000 = 0.2031006604 
0.0000000000 * 0.2064830000 = 0.2031006604 
0.0000000000 * -0.1124460000 = 0.2031006604 
0.0000000000 * 0.4313020000 = 0.2031006604 
0.0000000000 * -0.0805058000 = 0.2031006604 
0.0000000000 * 0.0644224000 = 0.2031006604 
0.1176464584 * 0.8038580000 = 0.2976717071 
0.0000000000 * -0.1457120000 = 0.2976717071 
0.0000000000 * -0.5864310000 = 0.2976717071 
0.0554119915 * -0.0061222500 = 0.2973324610 
0.2550187259 * 0.8761990000 = 0.5207796136 
0.0000000000 * 0.3551410000 = 0.5207796136 
0.0000000000 * -0.0433557000 = 0.5207796136 
0.0000000000 * -0.0426076000 = 0.5207796136 
0.0000000000 * -0.0298103000 = 0.5207796136 
0.0000000000 * 0.8047720000 = 0.5207796136 
0.0000000000 * -0.4296250000 = 0.5207796136 
0.0000000000 * 0.1448280000 = 0.5207796136 
0.0993749280 * -0.5509550000 = 0.4660285001 
0.0000000000 * -0.2466740000 = 0.4660285001 
0.0000000000 * -0.3443670000 = 0.4660285001 
0.0000000000 * 0.0142266000 = 0.4660285001 
0.0000000000 * 0.0930318000 = 0.4660285001 
0.0000000000 * -0.2479990000 = 0.4660285001 
0.0000000000 * 0.0288773000 = 0.4660285001 
0.0000000000 * 0.7053610000 = 0.4660285001 
0.0000000000 * -0.0042829300 = 0.4660285001 
0.0000000000 * 1.8792900000 = 0.4660285001 
0.0000000000 * -0.1308600000 = 0.4660285001 
0.4964708861 * -0.0342430000 = 0.4490278476 
0.7972727204 * 0.0676066000 = 0.5029287455 
0.0000000000 * 0.3350970000 = 0.5029287455 
0.0000000000 * 0.0653250000 = 0.5029287455 
0.0000000000 * 0.2237280000 = 0.5029287455 
0.0000000000 * 0.2370860000 = 0.5029287455 
0.0000000000 * -0.1324410000 = 0.5029287455 
0.0000000000 * 0.1472740000 = 0.5029287455 
0.0000000000 * 0.0666699000 = 0.5029287455 
0.0000000000 * -0.0768807000 = 0.5029287455 
the biases is : 0.2544390000, now tempVal is : 0.7573677455
compute layer: 3, node : 36
0.2476063322 * -0.1364540000 = -0.0337868745 
0.0000000000 * -0.0301639000 = -0.0337868745 
0.5022157730 * 0.2115480000 = 0.0724558679 
0.0000000000 * 0.4007020000 = 0.0724558679 
0.1501012128 * -0.1634570000 = 0.0479207739 
0.0000000000 * -0.1029360000 = 0.0479207739 
0.2408135472 * -0.0172071000 = 0.0437770712 
0.0000000000 * -0.1438470000 = 0.0437770712 
0.0000000000 * -0.1547090000 = 0.0437770712 
0.6533630315 * -0.2056570000 = -0.0905916098 
0.0000000000 * 0.0056280100 = -0.0905916098 
0.0000000000 * -0.1100260000 = -0.0905916098 
0.0000000000 * -0.6706490000 = -0.0905916098 
0.0000000000 * -0.2701030000 = -0.0905916098 
0.0000000000 * 0.2207890000 = -0.0905916098 
0.0000000000 * 0.0869835000 = -0.0905916098 
0.0000000000 * -0.3895930000 = -0.0905916098 
0.1176464584 * -0.1347860000 = -0.1064487054 
0.0000000000 * 0.0678404000 = -0.1064487054 
0.0000000000 * -0.4386530000 = -0.1064487054 
0.0554119915 * 0.4168100000 = -0.0833524332 
0.2550187259 * -0.1939010000 = -0.1328008191 
0.0000000000 * 0.0465170000 = -0.1328008191 
0.0000000000 * 0.4162420000 = -0.1328008191 
0.0000000000 * -0.0324072000 = -0.1328008191 
0.0000000000 * 0.0417997000 = -0.1328008191 
0.0000000000 * 0.7257920000 = -0.1328008191 
0.0000000000 * 0.0616304000 = -0.1328008191 
0.0000000000 * -0.2890060000 = -0.1328008191 
0.0993749280 * -0.1333090000 = -0.1460483914 
0.0000000000 * 0.0023211800 = -0.1460483914 
0.0000000000 * 1.0018800000 = -0.1460483914 
0.0000000000 * -0.1747720000 = -0.1460483914 
0.0000000000 * 0.3336390000 = -0.1460483914 
0.0000000000 * -0.6190600000 = -0.1460483914 
0.0000000000 * -0.2569120000 = -0.1460483914 
0.0000000000 * 0.1789770000 = -0.1460483914 
0.0000000000 * -0.0036210300 = -0.1460483914 
0.0000000000 * 3.4871300000 = -0.1460483914 
0.0000000000 * 0.1719890000 = -0.1460483914 
0.4964708861 * 0.0043933900 = -0.1438672012 
0.7972727204 * -0.2177810000 = -0.3174980515 
0.0000000000 * 0.0994489000 = -0.3174980515 
0.0000000000 * 0.0242226000 = -0.3174980515 
0.0000000000 * 0.1726930000 = -0.3174980515 
0.0000000000 * 0.5645080000 = -0.3174980515 
0.0000000000 * 0.5912170000 = -0.3174980515 
0.0000000000 * -0.8213460000 = -0.3174980515 
0.0000000000 * -0.2199710000 = -0.3174980515 
0.0000000000 * 0.1439070000 = -0.3174980515 
the biases is : -0.1507440000, now tempVal is : -0.4682420515
ReLU !!! in layer: 3, node : 36, its linear result is negative,so set it to 0
compute layer: 3, node : 37
0.2476063322 * 0.3672190000 = 0.0909257497 
0.0000000000 * -0.0147802000 = 0.0909257497 
0.5022157730 * 0.2481190000 = 0.2155350251 
0.0000000000 * -1.6088400000 = 0.2155350251 
0.1501012128 * 0.3811060000 = 0.2727394979 
0.0000000000 * 1.1023700000 = 0.2727394979 
0.2408135472 * -0.3123250000 = 0.1975274068 
0.0000000000 * 0.5094280000 = 0.1975274068 
0.0000000000 * 0.2148460000 = 0.1975274068 
0.6533630315 * -1.4154700000 = -0.7272883634 
0.0000000000 * -0.0317061000 = -0.7272883634 
0.0000000000 * -1.0808600000 = -0.7272883634 
0.0000000000 * 0.6577400000 = -0.7272883634 
0.0000000000 * 0.2435250000 = -0.7272883634 
0.0000000000 * 0.0280457000 = -0.7272883634 
0.0000000000 * 0.0785658000 = -0.7272883634 
0.0000000000 * 1.2539000000 = -0.7272883634 
0.1176464584 * -0.2059880000 = -0.7515221221 
0.0000000000 * 0.0093420800 = -0.7515221221 
0.0000000000 * 0.1347400000 = -0.7515221221 
0.0554119915 * -0.6994910000 = -0.7902823114 
0.2550187259 * -0.3294490000 = -0.8742979756 
0.0000000000 * -0.6109310000 = -0.8742979756 
0.0000000000 * -0.3751920000 = -0.8742979756 
0.0000000000 * 0.0242696000 = -0.8742979756 
0.0000000000 * 0.0322354000 = -0.8742979756 
0.0000000000 * 1.1484800000 = -0.8742979756 
0.0000000000 * -0.4394310000 = -0.8742979756 
0.0000000000 * -0.2664750000 = -0.8742979756 
0.0993749280 * 0.4110690000 = -0.8334480234 
0.0000000000 * 0.1225000000 = -0.8334480234 
0.0000000000 * 1.7407600000 = -0.8334480234 
0.0000000000 * -0.3841560000 = -0.8334480234 
0.0000000000 * 0.0558477000 = -0.8334480234 
0.0000000000 * 0.8269830000 = -0.8334480234 
0.0000000000 * -0.2787780000 = -0.8334480234 
0.0000000000 * 0.4268100000 = -0.8334480234 
0.0000000000 * 0.0166626000 = -0.8334480234 
0.0000000000 * 1.5755800000 = -0.8334480234 
0.0000000000 * 0.4384770000 = -0.8334480234 
0.4964708861 * -0.0420085000 = -0.8543040206 
0.7972727204 * 1.0625900000 = -0.0071300007 
0.0000000000 * 0.5655760000 = -0.0071300007 
0.0000000000 * 0.0156828000 = -0.0071300007 
0.0000000000 * -0.7251620000 = -0.0071300007 
0.0000000000 * 0.4680680000 = -0.0071300007 
0.0000000000 * 0.4556210000 = -0.0071300007 
0.0000000000 * 0.7181440000 = -0.0071300007 
0.0000000000 * -0.0053078400 = -0.0071300007 
0.0000000000 * -0.0925064000 = -0.0071300007 
the biases is : -0.7572640000, now tempVal is : -0.7643940007
ReLU !!! in layer: 3, node : 37, its linear result is negative,so set it to 0
compute layer: 3, node : 38
0.2476063322 * -0.2577060000 = -0.0638096375 
0.0000000000 * -0.0331422000 = -0.0638096375 
0.5022157730 * 0.2762240000 = 0.0749144122 
0.0000000000 * 1.3779900000 = 0.0749144122 
0.1501012128 * -0.8250000000 = -0.0489190883 
0.0000000000 * -0.5988080000 = -0.0489190883 
0.2408135472 * 0.6684420000 = 0.1120508008 
0.0000000000 * -0.2055900000 = 0.1120508008 
0.0000000000 * 0.0580261000 = 0.1120508008 
0.6533630315 * 0.3058800000 = 0.3119014848 
0.0000000000 * -0.0150193000 = 0.3119014848 
0.0000000000 * 0.2328050000 = 0.3119014848 
0.0000000000 * 0.9030980000 = 0.3119014848 
0.0000000000 * 0.8311360000 = 0.3119014848 
0.0000000000 * 1.0035300000 = 0.3119014848 
0.0000000000 * 0.7857500000 = 0.3119014848 
0.0000000000 * 0.1890790000 = 0.3119014848 
0.1176464584 * 0.3155000000 = 0.3490189424 
0.0000000000 * 1.5256700000 = 0.3490189424 
0.0000000000 * 0.8526900000 = 0.3490189424 
0.0554119915 * 0.7409440000 = 0.3900761251 
0.2550187259 * 1.6090400000 = 0.8004114557 
0.0000000000 * 0.5239760000 = 0.8004114557 
0.0000000000 * -0.0523105000 = 0.8004114557 
0.0000000000 * 0.0052972200 = 0.8004114557 
0.0000000000 * -0.0198361000 = 0.8004114557 
0.0000000000 * -0.9224460000 = 0.8004114557 
0.0000000000 * -0.5323100000 = 0.8004114557 
0.0000000000 * 0.3827640000 = 0.8004114557 
0.0993749280 * 0.0887215000 = 0.8092281484 
0.0000000000 * 0.3282770000 = 0.8092281484 
0.0000000000 * 0.9259580000 = 0.8092281484 
0.0000000000 * 0.3450250000 = 0.8092281484 
0.0000000000 * -0.0630245000 = 0.8092281484 
0.0000000000 * 0.2578920000 = 0.8092281484 
0.0000000000 * -0.3630160000 = 0.8092281484 
0.0000000000 * 0.7498740000 = 0.8092281484 
0.0000000000 * -0.0406652000 = 0.8092281484 
0.0000000000 * 0.1355250000 = 0.8092281484 
0.0000000000 * -0.1407090000 = 0.8092281484 
0.4964708861 * 0.9793960000 = 1.2954697484 
0.7972727204 * -0.0623986000 = 1.2457210468 
0.0000000000 * 0.0922492000 = 1.2457210468 
0.0000000000 * -0.0133643000 = 1.2457210468 
0.0000000000 * -0.1281910000 = 1.2457210468 
0.0000000000 * -0.1803860000 = 1.2457210468 
0.0000000000 * 0.1290150000 = 1.2457210468 
0.0000000000 * 2.6050000000 = 1.2457210468 
0.0000000000 * -0.2992330000 = 1.2457210468 
0.0000000000 * -0.8005690000 = 1.2457210468 
the biases is : -2.4642500000, now tempVal is : -1.2185289532
ReLU !!! in layer: 3, node : 38, its linear result is negative,so set it to 0
compute layer: 3, node : 39
0.2476063322 * -0.5778850000 = -0.1430879853 
0.0000000000 * 0.0215591000 = -0.1430879853 
0.5022157730 * 0.1489330000 = -0.0682914836 
0.0000000000 * -0.1702770000 = -0.0682914836 
0.1501012128 * -0.3861510000 = -0.1262532170 
0.0000000000 * 0.0342367000 = -0.1262532170 
0.2408135472 * -0.2084520000 = -0.1764512825 
0.0000000000 * -1.4679400000 = -0.1764512825 
0.0000000000 * 0.3985080000 = -0.1764512825 
0.6533630315 * 0.1656860000 = -0.0681981753 
0.0000000000 * -0.0308293000 = -0.0681981753 
0.0000000000 * 0.1843040000 = -0.0681981753 
0.0000000000 * 0.0772126000 = -0.0681981753 
0.0000000000 * 0.1582580000 = -0.0681981753 
0.0000000000 * -0.3962620000 = -0.0681981753 
0.0000000000 * 1.2467200000 = -0.0681981753 
0.0000000000 * -0.0669484000 = -0.0681981753 
0.1176464584 * 0.1626230000 = -0.0490661553 
0.0000000000 * 0.3211190000 = -0.0490661553 
0.0000000000 * -0.1277420000 = -0.0490661553 
0.0554119915 * 0.3159590000 = -0.0315582379 
0.2550187259 * 0.3988160000 = 0.0701473103 
0.0000000000 * 0.3577580000 = 0.0701473103 
0.0000000000 * -0.5638360000 = 0.0701473103 
0.0000000000 * 0.0403536000 = 0.0701473103 
0.0000000000 * 0.0251802000 = 0.0701473103 
0.0000000000 * 0.0577722000 = 0.0701473103 
0.0000000000 * 0.1119920000 = 0.0701473103 
0.0000000000 * 0.1713460000 = 0.0701473103 
0.0993749280 * -0.0805749000 = 0.0621401854 
0.0000000000 * 0.2623440000 = 0.0621401854 
0.0000000000 * -1.8104900000 = 0.0621401854 
0.0000000000 * -0.1110440000 = 0.0621401854 
0.0000000000 * -0.3410430000 = 0.0621401854 
0.0000000000 * -0.4794810000 = 0.0621401854 
0.0000000000 * 0.1215630000 = 0.0621401854 
0.0000000000 * 0.0885163000 = 0.0621401854 
0.0000000000 * -0.0233549000 = 0.0621401854 
0.0000000000 * 0.2812660000 = 0.0621401854 
0.0000000000 * 1.5326900000 = 0.0621401854 
0.4964708861 * 0.2342760000 = 0.1784513987 
0.7972727204 * -0.2800600000 = -0.0448327994 
0.0000000000 * 0.1613150000 = -0.0448327994 
0.0000000000 * 0.0354072000 = -0.0448327994 
0.0000000000 * 0.5738790000 = -0.0448327994 
0.0000000000 * -0.4212200000 = -0.0448327994 
0.0000000000 * -0.3258460000 = -0.0448327994 
0.0000000000 * 0.2569800000 = -0.0448327994 
0.0000000000 * -0.0852825000 = -0.0448327994 
0.0000000000 * -0.2104700000 = -0.0448327994 
the biases is : -0.9131940000, now tempVal is : -0.9580267994
ReLU !!! in layer: 3, node : 39, its linear result is negative,so set it to 0
compute layer: 3, node : 40
0.2476063322 * -0.3527790000 = -0.0873503143 
0.0000000000 * 0.0373517000 = -0.0873503143 
0.5022157730 * 0.4499180000 = 0.1386056019 
0.0000000000 * 0.2755720000 = 0.1386056019 
0.1501012128 * -0.0897830000 = 0.1251290647 
0.0000000000 * -0.1868090000 = 0.1251290647 
0.2408135472 * -0.1190940000 = 0.0964496161 
0.0000000000 * -0.8991510000 = 0.0964496161 
0.0000000000 * -0.2420460000 = 0.0964496161 
0.6533630315 * -0.2296470000 = -0.0535932440 
0.0000000000 * 0.0432978000 = -0.0535932440 
0.0000000000 * -0.2609130000 = -0.0535932440 
0.0000000000 * 0.6102680000 = -0.0535932440 
0.0000000000 * 1.3819800000 = -0.0535932440 
0.0000000000 * 0.2177360000 = -0.0535932440 
0.0000000000 * -0.2819950000 = -0.0535932440 
0.0000000000 * 0.5495240000 = -0.0535932440 
0.1176464584 * 0.6111030000 = 0.0183008596 
0.0000000000 * 0.1105840000 = 0.0183008596 
0.0000000000 * 0.1675330000 = 0.0183008596 
0.0554119915 * 1.2572100000 = 0.0879653694 
0.2550187259 * 0.3846960000 = 0.1860700532 
0.0000000000 * -0.6632570000 = 0.1860700532 
0.0000000000 * 0.9643440000 = 0.1860700532 
0.0000000000 * 0.0421780000 = 0.1860700532 
0.0000000000 * 0.0371448000 = 0.1860700532 
0.0000000000 * -1.0881500000 = 0.1860700532 
0.0000000000 * -0.4351930000 = 0.1860700532 
0.0000000000 * 0.9690100000 = 0.1860700532 
0.0993749280 * -0.1524420000 = 0.1709211404 
0.0000000000 * -0.3446560000 = 0.1709211404 
0.0000000000 * 1.0673600000 = 0.1709211404 
0.0000000000 * 0.4221550000 = 0.1709211404 
0.0000000000 * 0.6209290000 = 0.1709211404 
0.0000000000 * -0.3076270000 = 0.1709211404 
0.0000000000 * 0.7814260000 = 0.1709211404 
0.0000000000 * -0.5100160000 = 0.1709211404 
0.0000000000 * 0.0378419000 = 0.1709211404 
0.0000000000 * 0.1196820000 = 0.1709211404 
0.0000000000 * -0.1606290000 = 0.1709211404 
0.4964708861 * 0.3204610000 = 0.3300206971 
0.7972727204 * -0.1110420000 = 0.2414899396 
0.0000000000 * 0.1650710000 = 0.2414899396 
0.0000000000 * -0.0413847000 = 0.2414899396 
0.0000000000 * -0.4892000000 = 0.2414899396 
0.0000000000 * -0.0025590500 = 0.2414899396 
0.0000000000 * -0.1260750000 = 0.2414899396 
0.0000000000 * -0.3200520000 = 0.2414899396 
0.0000000000 * -0.2720040000 = 0.2414899396 
0.0000000000 * -0.3392640000 = 0.2414899396 
the biases is : -0.5630580000, now tempVal is : -0.3215680604
ReLU !!! in layer: 3, node : 40, its linear result is negative,so set it to 0
compute layer: 3, node : 41
0.2476063322 * 0.7517430000 = 0.1861363270 
0.0000000000 * 0.0080277600 = 0.1861363270 
0.5022157730 * 0.1271710000 = 0.2500036091 
0.0000000000 * 0.7644130000 = 0.2500036091 
0.1501012128 * -0.6498430000 = 0.1524613867 
0.0000000000 * 0.4277170000 = 0.1524613867 
0.2408135472 * -0.2820830000 = 0.0845319788 
0.0000000000 * 0.2427260000 = 0.0845319788 
0.0000000000 * 0.0509590000 = 0.0845319788 
0.6533630315 * -0.3740610000 = -0.1598656501 
0.0000000000 * 0.0030859700 = -0.1598656501 
0.0000000000 * 0.3271120000 = -0.1598656501 
0.0000000000 * 0.5069600000 = -0.1598656501 
0.0000000000 * -0.1239950000 = -0.1598656501 
0.0000000000 * -0.7810090000 = -0.1598656501 
0.0000000000 * 0.6043330000 = -0.1598656501 
0.0000000000 * -0.1482930000 = -0.1598656501 
0.1176464584 * -0.4233640000 = -0.2096729253 
0.0000000000 * 0.2187640000 = -0.2096729253 
0.0000000000 * -0.2095300000 = -0.2096729253 
0.0554119915 * 0.2194640000 = -0.1975119880 
0.2550187259 * 0.4370410000 = -0.0860583490 
0.0000000000 * 0.3902180000 = -0.0860583490 
0.0000000000 * 0.3648120000 = -0.0860583490 
0.0000000000 * 0.0378370000 = -0.0860583490 
0.0000000000 * 0.0406732000 = -0.0860583490 
0.0000000000 * 0.3254070000 = -0.0860583490 
0.0000000000 * 0.1972350000 = -0.0860583490 
0.0000000000 * 0.1229190000 = -0.0860583490 
0.0993749280 * 0.2288570000 = -0.0633157011 
0.0000000000 * 0.3863050000 = -0.0633157011 
0.0000000000 * 0.3459480000 = -0.0633157011 
0.0000000000 * -0.4606320000 = -0.0633157011 
0.0000000000 * 0.2094410000 = -0.0633157011 
0.0000000000 * -0.4546880000 = -0.0633157011 
0.0000000000 * -0.7676260000 = -0.0633157011 
0.0000000000 * -0.4330380000 = -0.0633157011 
0.0000000000 * 0.0285780000 = -0.0633157011 
0.0000000000 * -1.8701000000 = -0.0633157011 
0.0000000000 * -0.0743135000 = -0.0633157011 
0.4964708861 * -0.6411730000 = -0.3816394286 
0.7972727204 * -0.2441490000 = -0.5762927660 
0.0000000000 * 0.5498230000 = -0.5762927660 
0.0000000000 * 0.0387929000 = -0.5762927660 
0.0000000000 * 0.0478138000 = -0.5762927660 
0.0000000000 * 0.7775700000 = -0.5762927660 
0.0000000000 * -0.5113420000 = -0.5762927660 
0.0000000000 * -0.1639860000 = -0.5762927660 
0.0000000000 * 0.2318960000 = -0.5762927660 
0.0000000000 * 0.0773283000 = -0.5762927660 
the biases is : -0.2171010000, now tempVal is : -0.7933937660
ReLU !!! in layer: 3, node : 41, its linear result is negative,so set it to 0
compute layer: 3, node : 42
0.2476063322 * -0.4059810000 = -0.1005234664 
0.0000000000 * -0.0171778000 = -0.1005234664 
0.5022157730 * -0.3486400000 = -0.2756159735 
0.0000000000 * -2.7488100000 = -0.2756159735 
0.1501012128 * -1.2488500000 = -0.4630698731 
0.0000000000 * 0.9143880000 = -0.4630698731 
0.2408135472 * -0.1340130000 = -0.4953420190 
0.0000000000 * -0.0336847000 = -0.4953420190 
0.0000000000 * -0.0268316000 = -0.4953420190 
0.6533630315 * 0.5626830000 = -0.1277057483 
0.0000000000 * 0.0061949800 = -0.1277057483 
0.0000000000 * -0.2445150000 = -0.1277057483 
0.0000000000 * -0.7845750000 = -0.1277057483 
0.0000000000 * 0.1475440000 = -0.1277057483 
0.0000000000 * -0.0553004000 = -0.1277057483 
0.0000000000 * -0.5575270000 = -0.1277057483 
0.0000000000 * -1.1706300000 = -0.1277057483 
0.1176464584 * -0.3084960000 = -0.1639992101 
0.0000000000 * -0.3158100000 = -0.1639992101 
0.0000000000 * 0.1545220000 = -0.1639992101 
0.0554119915 * 0.2287610000 = -0.1513231075 
0.2550187259 * 0.6118720000 = 0.0047157103 
0.0000000000 * -0.0536644000 = 0.0047157103 
0.0000000000 * 0.0151532000 = 0.0047157103 
0.0000000000 * -0.0205841000 = 0.0047157103 
0.0000000000 * 0.0141396000 = 0.0047157103 
0.0000000000 * 0.2236930000 = 0.0047157103 
0.0000000000 * -0.6217420000 = 0.0047157103 
0.0000000000 * 0.6127580000 = 0.0047157103 
0.0993749280 * 0.0115760000 = 0.0058660745 
0.0000000000 * -0.2046150000 = 0.0058660745 
0.0000000000 * -4.6173700000 = 0.0058660745 
0.0000000000 * 0.3887980000 = 0.0058660745 
0.0000000000 * 0.2053910000 = 0.0058660745 
0.0000000000 * -0.3357030000 = 0.0058660745 
0.0000000000 * -0.1467880000 = 0.0058660745 
0.0000000000 * -0.3562300000 = 0.0058660745 
0.0000000000 * -0.0164430000 = 0.0058660745 
0.0000000000 * 0.4559010000 = 0.0058660745 
0.0000000000 * -0.0345588000 = 0.0058660745 
0.4964708861 * 0.2919430000 = 0.1508072744 
0.7972727204 * 1.4434600000 = 1.3016385553 
0.0000000000 * 0.4364540000 = 1.3016385553 
0.0000000000 * 0.0537305000 = 1.3016385553 
0.0000000000 * 0.4457310000 = 1.3016385553 
0.0000000000 * -1.6290400000 = 1.3016385553 
0.0000000000 * -0.3112500000 = 1.3016385553 
0.0000000000 * -0.1069730000 = 1.3016385553 
0.0000000000 * 0.2116250000 = 1.3016385553 
0.0000000000 * 0.3308190000 = 1.3016385553 
the biases is : 0.5705460000, now tempVal is : 1.8721845553
compute layer: 3, node : 43
0.2476063322 * -1.1486000000 = -0.2844006332 
0.0000000000 * -0.0281092000 = -0.2844006332 
0.5022157730 * -0.3164010000 = -0.4433022060 
0.0000000000 * -1.1296000000 = -0.4433022060 
0.1501012128 * 0.8266420000 = -0.3192222392 
0.0000000000 * 0.3821340000 = -0.3192222392 
0.2408135472 * 0.6881300000 = -0.1535112130 
0.0000000000 * -0.1630250000 = -0.1535112130 
0.0000000000 * -0.0557976000 = -0.1535112130 
0.6533630315 * 0.1385140000 = -0.0630112861 
0.0000000000 * -0.0365683000 = -0.0630112861 
0.0000000000 * 0.0973853000 = -0.0630112861 
0.0000000000 * -1.4455800000 = -0.0630112861 
0.0000000000 * 0.2248380000 = -0.0630112861 
0.0000000000 * -0.0999610000 = -0.0630112861 
0.0000000000 * 0.1466800000 = -0.0630112861 
0.0000000000 * -0.2497900000 = -0.0630112861 
0.1176464584 * 1.7670000000 = 0.1448700058 
0.0000000000 * -0.5780910000 = 0.1448700058 
0.0000000000 * -0.0817435000 = 0.1448700058 
0.0554119915 * -1.2679400000 = 0.0746109254 
0.2550187259 * -0.6230080000 = -0.0842677810 
0.0000000000 * -0.0335716000 = -0.0842677810 
0.0000000000 * -0.0408247000 = -0.0842677810 
0.0000000000 * -0.0068872400 = -0.0842677810 
0.0000000000 * -0.0375689000 = -0.0842677810 
0.0000000000 * 0.8113070000 = -0.0842677810 
0.0000000000 * 0.0922394000 = -0.0842677810 
0.0000000000 * 0.1995970000 = -0.0842677810 
0.0993749280 * 0.0214643000 = -0.0821347677 
0.0000000000 * -0.5963570000 = -0.0821347677 
0.0000000000 * -4.9263900000 = -0.0821347677 
0.0000000000 * 0.1091880000 = -0.0821347677 
0.0000000000 * -0.4119380000 = -0.0821347677 
0.0000000000 * 0.5127250000 = -0.0821347677 
0.0000000000 * 0.4445440000 = -0.0821347677 
0.0000000000 * 0.2888140000 = -0.0821347677 
0.0000000000 * -0.0439124000 = -0.0821347677 
0.0000000000 * 0.9632100000 = -0.0821347677 
0.0000000000 * -0.1113570000 = -0.0821347677 
0.4964708861 * -0.0409851000 = -0.1024826766 
0.7972727204 * -0.0428231000 = -0.1366243661 
0.0000000000 * 0.4489170000 = -0.1366243661 
0.0000000000 * 0.0214068000 = -0.1366243661 
0.0000000000 * 0.1341410000 = -0.1366243661 
0.0000000000 * -0.0421486000 = -0.1366243661 
0.0000000000 * 0.7396200000 = -0.1366243661 
0.0000000000 * -0.6258750000 = -0.1366243661 
0.0000000000 * -0.1892170000 = -0.1366243661 
0.0000000000 * 0.0109901000 = -0.1366243661 
the biases is : -0.5234080000, now tempVal is : -0.6600323661
ReLU !!! in layer: 3, node : 43, its linear result is negative,so set it to 0
compute layer: 3, node : 44
0.2476063322 * 1.4693400000 = 0.3638178882 
0.0000000000 * -0.0413740000 = 0.3638178882 
0.5022157730 * 0.2750000000 = 0.5019272258 
0.0000000000 * -0.0061966300 = 0.5019272258 
0.1501012128 * 2.3813000000 = 0.8593632438 
0.0000000000 * 0.7155430000 = 0.8593632438 
0.2408135472 * -0.2724630000 = 0.7937504623 
0.0000000000 * -0.0043087300 = 0.7937504623 
0.0000000000 * 1.2594700000 = 0.7937504623 
0.6533630315 * 0.0337887000 = 0.8158267498 
0.0000000000 * -0.0180364000 = 0.8158267498 
0.0000000000 * -0.6952540000 = 0.8158267498 
0.0000000000 * -1.2522200000 = 0.8158267498 
0.0000000000 * 0.5005060000 = 0.8158267498 
0.0000000000 * 0.3875880000 = 0.8158267498 
0.0000000000 * 0.3322650000 = 0.8158267498 
0.0000000000 * -0.6168840000 = 0.8158267498 
0.1176464584 * 0.3975690000 = 0.8625993346 
0.0000000000 * 0.4710940000 = 0.8625993346 
0.0000000000 * -0.2174550000 = 0.8625993346 
0.0554119915 * 0.8029730000 = 0.9070936676 
0.2550187259 * -0.7195710000 = 0.7235895880 
0.0000000000 * 1.0338200000 = 0.7235895880 
0.0000000000 * -0.1867940000 = 0.7235895880 
0.0000000000 * -0.0430558000 = 0.7235895880 
0.0000000000 * -0.0208258000 = 0.7235895880 
0.0000000000 * -0.6089520000 = 0.7235895880 
0.0000000000 * 0.5375650000 = 0.7235895880 
0.0000000000 * 1.0408600000 = 0.7235895880 
0.0993749280 * 0.1615720000 = 0.7396457939 
0.0000000000 * 0.9702690000 = 0.7396457939 
0.0000000000 * -0.2571220000 = 0.7396457939 
0.0000000000 * -0.5856540000 = 0.7396457939 
0.0000000000 * -0.3502630000 = 0.7396457939 
0.0000000000 * -0.8284260000 = 0.7396457939 
0.0000000000 * -0.1380840000 = 0.7396457939 
0.0000000000 * 0.1372070000 = 0.7396457939 
0.0000000000 * 0.0076654400 = 0.7396457939 
0.0000000000 * 0.3084000000 = 0.7396457939 
0.0000000000 * 0.0012772600 = 0.7396457939 
0.4964708861 * 0.2112880000 = 0.8445441345 
0.7972727204 * -0.3126490000 = 0.5952776157 
0.0000000000 * -0.0786458000 = 0.5952776157 
0.0000000000 * 0.0621266000 = 0.5952776157 
0.0000000000 * 0.2363710000 = 0.5952776157 
0.0000000000 * -0.3105520000 = 0.5952776157 
0.0000000000 * -0.7718240000 = 0.5952776157 
0.0000000000 * 0.4893740000 = 0.5952776157 
0.0000000000 * -0.0774861000 = 0.5952776157 
0.0000000000 * 0.2169440000 = 0.5952776157 
the biases is : -1.4999700000, now tempVal is : -0.9046923843
ReLU !!! in layer: 3, node : 44, its linear result is negative,so set it to 0
compute layer: 3, node : 45
0.2476063322 * -0.2774250000 = -0.0686921867 
0.0000000000 * 0.0108970000 = -0.0686921867 
0.5022157730 * -0.0576476000 = -0.0976437207 
0.0000000000 * -0.4264150000 = -0.0976437207 
0.1501012128 * -1.0263100000 = -0.2516940964 
0.0000000000 * -0.4481600000 = -0.2516940964 
0.2408135472 * -0.1816560000 = -0.2954393221 
0.0000000000 * -0.1245340000 = -0.2954393221 
0.0000000000 * 0.0119235000 = -0.2954393221 
0.6533630315 * 0.1468230000 = -0.1995106018 
0.0000000000 * 0.0200086000 = -0.1995106018 
0.0000000000 * 0.1072080000 = -0.1995106018 
0.0000000000 * 0.4801910000 = -0.1995106018 
0.0000000000 * -0.1222920000 = -0.1995106018 
0.0000000000 * -0.3525850000 = -0.1995106018 
0.0000000000 * 0.4262670000 = -0.1995106018 
0.0000000000 * -0.3239870000 = -0.1995106018 
0.1176464584 * 0.0817028000 = -0.1898985567 
0.0000000000 * 0.0816936000 = -0.1898985567 
0.0000000000 * -0.0287567000 = -0.1898985567 
0.0554119915 * 0.3824270000 = -0.1687075150 
0.2550187259 * 0.9113460000 = 0.0637027807 
0.0000000000 * 0.1053780000 = 0.0637027807 
0.0000000000 * 0.8272360000 = 0.0637027807 
0.0000000000 * -0.0239208000 = 0.0637027807 
0.0000000000 * -0.0380447000 = 0.0637027807 
0.0000000000 * 0.2224240000 = 0.0637027807 
0.0000000000 * -0.4745590000 = 0.0637027807 
0.0000000000 * 0.0124340000 = 0.0637027807 
0.0993749280 * 0.1087570000 = 0.0745104997 
0.0000000000 * -0.1955320000 = 0.0745104997 
0.0000000000 * -0.4391780000 = 0.0745104997 
0.0000000000 * -0.2231220000 = 0.0745104997 
0.0000000000 * 0.4540580000 = 0.0745104997 
0.0000000000 * -0.1261360000 = 0.0745104997 
0.0000000000 * -0.4020870000 = 0.0745104997 
0.0000000000 * 0.5134520000 = 0.0745104997 
0.0000000000 * 0.0314696000 = 0.0745104997 
0.0000000000 * -2.0817300000 = 0.0745104997 
0.0000000000 * 0.5255460000 = 0.0745104997 
0.4964708861 * -0.0219227000 = 0.0636265174 
0.7972727204 * -0.2098210000 = -0.1036580420 
0.0000000000 * 0.3409160000 = -0.1036580420 
0.0000000000 * 0.0094496400 = -0.1036580420 
0.0000000000 * -0.2524250000 = -0.1036580420 
0.0000000000 * -0.4037150000 = -0.1036580420 
0.0000000000 * -0.1312340000 = -0.1036580420 
0.0000000000 * 0.0523331000 = -0.1036580420 
0.0000000000 * -0.3902290000 = -0.1036580420 
0.0000000000 * 0.8891300000 = -0.1036580420 
the biases is : -0.2619210000, now tempVal is : -0.3655790420
ReLU !!! in layer: 3, node : 45, its linear result is negative,so set it to 0
compute layer: 3, node : 46
0.2476063322 * 1.9261100000 = 0.4769170326 
0.0000000000 * -0.0127626000 = 0.4769170326 
0.5022157730 * 0.3309360000 = 0.6431183116 
0.0000000000 * -0.4568870000 = 0.6431183116 
0.1501012128 * 1.5648500000 = 0.8780041945 
0.0000000000 * 0.9528670000 = 0.8780041945 
0.2408135472 * -0.1804950000 = 0.8345385533 
0.0000000000 * -2.4266600000 = 0.8345385533 
0.0000000000 * -1.1407500000 = 0.8345385533 
0.6533630315 * 0.5564390000 = 1.1980952252 
0.0000000000 * 0.0297273000 = 1.1980952252 
0.0000000000 * -0.5453350000 = 1.1980952252 
0.0000000000 * -3.0313000000 = 1.1980952252 
0.0000000000 * -0.3558630000 = 1.1980952252 
0.0000000000 * 0.1321860000 = 1.1980952252 
0.0000000000 * 0.0960997000 = 1.1980952252 
0.0000000000 * 0.3179610000 = 1.1980952252 
0.1176464584 * 1.3132100000 = 1.3525897307 
0.0000000000 * 0.6685030000 = 1.3525897307 
0.0000000000 * -2.4510600000 = 1.3525897307 
0.0554119915 * -0.6034120000 = 1.3191534701 
0.2550187259 * 1.2023400000 = 1.6257726850 
0.0000000000 * 0.4719630000 = 1.6257726850 
0.0000000000 * 0.7375650000 = 1.6257726850 
0.0000000000 * -0.0248176000 = 1.6257726850 
0.0000000000 * 0.0254776000 = 1.6257726850 
0.0000000000 * -0.0570893000 = 1.6257726850 
0.0000000000 * -0.3649920000 = 1.6257726850 
0.0000000000 * -0.4141720000 = 1.6257726850 
0.0993749280 * -0.0212310000 = 1.6236628559 
0.0000000000 * -0.3639830000 = 1.6236628559 
0.0000000000 * -1.1499100000 = 1.6236628559 
0.0000000000 * 0.9946330000 = 1.6236628559 
0.0000000000 * 0.2674490000 = 1.6236628559 
0.0000000000 * 0.5067730000 = 1.6236628559 
0.0000000000 * 0.4221170000 = 1.6236628559 
0.0000000000 * 0.2000820000 = 1.6236628559 
0.0000000000 * -0.0454036000 = 1.6236628559 
0.0000000000 * -1.3998900000 = 1.6236628559 
0.0000000000 * -0.2551920000 = 1.6236628559 
0.4964708861 * -0.9526390000 = 1.1507053274 
0.7972727204 * 0.3631580000 = 1.4402412940 
0.0000000000 * 0.2799130000 = 1.4402412940 
0.0000000000 * 0.0691381000 = 1.4402412940 
0.0000000000 * -0.1470510000 = 1.4402412940 
0.0000000000 * -0.6628750000 = 1.4402412940 
0.0000000000 * 1.0729800000 = 1.4402412940 
0.0000000000 * 1.0494300000 = 1.4402412940 
0.0000000000 * 0.5659650000 = 1.4402412940 
0.0000000000 * -0.3343000000 = 1.4402412940 
the biases is : -0.5261090000, now tempVal is : 0.9141322940
compute layer: 3, node : 47
0.2476063322 * 0.0470127000 = 0.0116406422 
0.0000000000 * 0.0260384000 = 0.0116406422 
0.5022157730 * -0.0023906100 = 0.0104400402 
0.0000000000 * -0.0356783000 = 0.0104400402 
0.1501012128 * -0.0238743000 = 0.0068564788 
0.0000000000 * 0.0056466100 = 0.0068564788 
0.2408135472 * -0.0105979000 = 0.0043043609 
0.0000000000 * -0.0211757000 = 0.0043043609 
0.0000000000 * -0.0067418100 = 0.0043043609 
0.6533630315 * 0.0068296600 = 0.0087666083 
0.0000000000 * -0.0039534100 = 0.0087666083 
0.0000000000 * -0.0108038000 = 0.0087666083 
0.0000000000 * 0.0222569000 = 0.0087666083 
0.0000000000 * 0.0458250000 = 0.0087666083 
0.0000000000 * 0.0104983000 = 0.0087666083 
0.0000000000 * 0.0066343700 = 0.0087666083 
0.0000000000 * 0.0202816000 = 0.0087666083 
0.1176464584 * 0.0324120000 = 0.0125797653 
0.0000000000 * 0.0051667400 = 0.0125797653 
0.0000000000 * -0.0433068000 = 0.0125797653 
0.0554119915 * -0.0240783000 = 0.0112455387 
0.2550187259 * -0.0421443000 = 0.0004979530 
0.0000000000 * 0.0165029000 = 0.0004979530 
0.0000000000 * -0.0199256000 = 0.0004979530 
0.0000000000 * 0.0316068000 = 0.0004979530 
0.0000000000 * -0.0180217000 = 0.0004979530 
0.0000000000 * -0.0200766000 = 0.0004979530 
0.0000000000 * 0.0007775810 = 0.0004979530 
0.0000000000 * -0.0275547000 = 0.0004979530 
0.0993749280 * -0.0455195000 = -0.0040255440 
0.0000000000 * 0.0180881000 = -0.0040255440 
0.0000000000 * 0.0011185900 = -0.0040255440 
0.0000000000 * -0.0159610000 = -0.0040255440 
0.0000000000 * -0.0327818000 = -0.0040255440 
0.0000000000 * -0.0462522000 = -0.0040255440 
0.0000000000 * -0.0155022000 = -0.0040255440 
0.0000000000 * -0.0133376000 = -0.0040255440 
0.0000000000 * 0.0358468000 = -0.0040255440 
0.0000000000 * -0.0017034200 = -0.0040255440 
0.0000000000 * -0.0131310000 = -0.0040255440 
0.4964708861 * -0.0275671000 = -0.0177118066 
0.7972727204 * -0.0443745000 = -0.0530903849 
0.0000000000 * -0.0078318600 = -0.0530903849 
0.0000000000 * 0.0360081000 = -0.0530903849 
0.0000000000 * -0.0013570000 = -0.0530903849 
0.0000000000 * -0.0441400000 = -0.0530903849 
0.0000000000 * 0.0099042600 = -0.0530903849 
0.0000000000 * 0.0245569000 = -0.0530903849 
0.0000000000 * -0.0027608200 = -0.0530903849 
0.0000000000 * -0.0068722500 = -0.0530903849 
the biases is : -0.0059898400, now tempVal is : -0.0590802249
ReLU !!! in layer: 3, node : 47, its linear result is negative,so set it to 0
compute layer: 3, node : 48
0.2476063322 * -1.1498200000 = -0.2847027129 
0.0000000000 * 0.0080003700 = -0.2847027129 
0.5022157730 * -0.0243698000 = -0.2969416109 
0.0000000000 * 0.4828540000 = -0.2969416109 
0.1501012128 * 0.6090770000 = -0.2055184145 
0.0000000000 * -0.3862070000 = -0.2055184145 
0.2408135472 * -0.0078023300 = -0.2073973213 
0.0000000000 * 0.7017150000 = -0.2073973213 
0.0000000000 * -0.0143196000 = -0.2073973213 
0.6533630315 * -0.2876450000 = -0.3953339304 
0.0000000000 * 0.0593701000 = -0.3953339304 
0.0000000000 * -0.3265030000 = -0.3953339304 
0.0000000000 * 0.0489246000 = -0.3953339304 
0.0000000000 * 0.4014910000 = -0.3953339304 
0.0000000000 * -0.1900810000 = -0.3953339304 
0.0000000000 * 0.1308310000 = -0.3953339304 
0.0000000000 * 0.5823950000 = -0.3953339304 
0.1176464584 * 0.7272060000 = -0.3097807201 
0.0000000000 * -0.2729890000 = -0.3097807201 
0.0000000000 * 0.3362760000 = -0.3097807201 
0.0554119915 * -1.0279100000 = -0.3667392602 
0.2550187259 * -0.0193169000 = -0.3716654315 
0.0000000000 * 0.0137146000 = -0.3716654315 
0.0000000000 * 0.0553962000 = -0.3716654315 
0.0000000000 * 0.0314208000 = -0.3716654315 
0.0000000000 * -0.0437471000 = -0.3716654315 
0.0000000000 * -1.0574900000 = -0.3716654315 
0.0000000000 * 0.2069490000 = -0.3716654315 
0.0000000000 * 0.1625410000 = -0.3716654315 
0.0993749280 * -0.0656043000 = -0.3781848540 
0.0000000000 * -0.1086130000 = -0.3781848540 
0.0000000000 * 1.3769200000 = -0.3781848540 
0.0000000000 * 0.0750832000 = -0.3781848540 
0.0000000000 * 0.0887287000 = -0.3781848540 
0.0000000000 * -0.1839610000 = -0.3781848540 
0.0000000000 * -0.3333670000 = -0.3781848540 
0.0000000000 * 0.2479800000 = -0.3781848540 
0.0000000000 * 0.0284351000 = -0.3781848540 
0.0000000000 * -0.3897840000 = -0.3781848540 
0.0000000000 * 0.3142400000 = -0.3781848540 
0.4964708861 * -0.4778890000 = -0.6154428293 
0.7972727204 * -0.1414800000 = -0.7282409738 
0.0000000000 * -0.7687160000 = -0.7282409738 
0.0000000000 * 0.0153934000 = -0.7282409738 
0.0000000000 * -0.0361928000 = -0.7282409738 
0.0000000000 * 0.0499979000 = -0.7282409738 
0.0000000000 * 0.0951208000 = -0.7282409738 
0.0000000000 * -1.1737100000 = -0.7282409738 
0.0000000000 * 0.4149680000 = -0.7282409738 
0.0000000000 * 0.7321380000 = -0.7282409738 
the biases is : -0.4643360000, now tempVal is : -1.1925769738
ReLU !!! in layer: 3, node : 48, its linear result is negative,so set it to 0
compute layer: 3, node : 49
0.2476063322 * -0.6846430000 = -0.1695219421 
0.0000000000 * 0.0266207000 = -0.1695219421 
0.5022157730 * -0.0270434000 = -0.1831035642 
0.0000000000 * -0.4935800000 = -0.1831035642 
0.1501012128 * 0.0854302000 = -0.1702803875 
0.0000000000 * 0.1989050000 = -0.1702803875 
0.2408135472 * 1.1441800000 = 0.1052536569 
0.0000000000 * 0.0207908000 = 0.1052536569 
0.0000000000 * 0.3177100000 = 0.1052536569 
0.6533630315 * -0.2204840000 = -0.0388024378 
0.0000000000 * -0.0348167000 = -0.0388024378 
0.0000000000 * -0.1149560000 = -0.0388024378 
0.0000000000 * 0.0335976000 = -0.0388024378 
0.0000000000 * 0.1625060000 = -0.0388024378 
0.0000000000 * 0.1633310000 = -0.0388024378 
0.0000000000 * -0.0066237800 = -0.0388024378 
0.0000000000 * -0.3988370000 = -0.0388024378 
0.1176464584 * -0.3961040000 = -0.0854026705 
0.0000000000 * -0.3775060000 = -0.0854026705 
0.0000000000 * -0.2326250000 = -0.0854026705 
0.0554119915 * 0.0943345000 = -0.0801754080 
0.2550187259 * 0.1911230000 = -0.0314354640 
0.0000000000 * 0.1688990000 = -0.0314354640 
0.0000000000 * 0.0292205000 = -0.0314354640 
0.0000000000 * -0.0341844000 = -0.0314354640 
0.0000000000 * -0.0330708000 = -0.0314354640 
0.0000000000 * -0.0247395000 = -0.0314354640 
0.0000000000 * -0.9551250000 = -0.0314354640 
0.0000000000 * 0.2655330000 = -0.0314354640 
0.0993749280 * 0.0919870000 = -0.0222942625 
0.0000000000 * -0.0690644000 = -0.0222942625 
0.0000000000 * -0.1371270000 = -0.0222942625 
0.0000000000 * -0.0986899000 = -0.0222942625 
0.0000000000 * 0.3037220000 = -0.0222942625 
0.0000000000 * -0.2078980000 = -0.0222942625 
0.0000000000 * -0.2187250000 = -0.0222942625 
0.0000000000 * 0.1520490000 = -0.0222942625 
0.0000000000 * 0.0373919000 = -0.0222942625 
0.0000000000 * -5.2750100000 = -0.0222942625 
0.0000000000 * 0.3199760000 = -0.0222942625 
0.4964708861 * -0.0159305000 = -0.0302032920 
0.7972727204 * -0.4188280000 = -0.3641234309 
0.0000000000 * -0.0451054000 = -0.3641234309 
0.0000000000 * 0.0197838000 = -0.3641234309 
0.0000000000 * 0.4487910000 = -0.3641234309 
0.0000000000 * -0.0443644000 = -0.3641234309 
0.0000000000 * 0.3371740000 = -0.3641234309 
0.0000000000 * -0.0647330000 = -0.3641234309 
0.0000000000 * -0.1864170000 = -0.3641234309 
0.0000000000 * 1.3278400000 = -0.3641234309 
the biases is : 0.1141950000, now tempVal is : -0.2499284309
ReLU !!! in layer: 3, node : 49, its linear result is negative,so set it to 0

now we get all result in layer: 3
	node: 0, val: 0.0000000000
	node: 1, val: 1.7845438810
	node: 2, val: 0.0000000000
	node: 3, val: 0.6009646532
	node: 4, val: 0.4463398333
	node: 5, val: 0.0000000000
	node: 6, val: 0.0000000000
	node: 7, val: 0.3475366177
	node: 8, val: 0.2186928048
	node: 9, val: 0.0000000000
	node: 10, val: 0.0000000000
	node: 11, val: 0.0000000000
	node: 12, val: 0.0000000000
	node: 13, val: 0.0000000000
	node: 14, val: 0.0000000000
	node: 15, val: 0.0000000000
	node: 16, val: 0.3887901683
	node: 17, val: 1.4372682682
	node: 18, val: 0.0000000000
	node: 19, val: 0.0000000000
	node: 20, val: 0.0000000000
	node: 21, val: 0.0000000000
	node: 22, val: 1.5809660104
	node: 23, val: 2.0068238746
	node: 24, val: 0.0000000000
	node: 25, val: 0.0000000000
	node: 26, val: 0.0000000000
	node: 27, val: 0.7689002813
	node: 28, val: 0.0000000000
	node: 29, val: 0.1555103307
	node: 30, val: 0.0000000000
	node: 31, val: 0.0923938400
	node: 32, val: 0.0000000000
	node: 33, val: 0.0000000000
	node: 34, val: 0.0000000000
	node: 35, val: 0.7573677455
	node: 36, val: 0.0000000000
	node: 37, val: 0.0000000000
	node: 38, val: 0.0000000000
	node: 39, val: 0.0000000000
	node: 40, val: 0.0000000000
	node: 41, val: 0.0000000000
	node: 42, val: 1.8721845553
	node: 43, val: 0.0000000000
	node: 44, val: 0.0000000000
	node: 45, val: 0.0000000000
	node: 46, val: 0.9141322940
	node: 47, val: 0.0000000000
	node: 48, val: 0.0000000000
	node: 49, val: 0.0000000000

when compute layer[3] to layer[4]
compute layer: 4, node : 0
0.0000000000 * -0.7750440000 = 0.0000000000 
1.7845438810 * -0.4153950000 = -0.7412906054 
0.0000000000 * -0.3249420000 = -0.7412906054 
0.6009646532 * 0.1120480000 = -0.6739537180 
0.4463398333 * -0.7431700000 = -1.0056600919 
0.0000000000 * -0.7847220000 = -1.0056600919 
0.0000000000 * -0.7780830000 = -1.0056600919 
0.3475366177 * -0.3570550000 = -1.1297497789 
0.2186928048 * -0.3570920000 = -1.2078432300 
0.0000000000 * -0.2255960000 = -1.2078432300 
0.0000000000 * 0.8965400000 = -1.2078432300 
0.0000000000 * -0.5529080000 = -1.2078432300 
0.0000000000 * -0.1369440000 = -1.2078432300 
0.0000000000 * -0.2322270000 = -1.2078432300 
0.0000000000 * -0.4986180000 = -1.2078432300 
0.0000000000 * 0.4337550000 = -1.2078432300 
0.3887901683 * 1.4331400000 = -0.6506524881 
1.4372682682 * -0.7401460000 = -1.7144408478 
0.0000000000 * -1.0593800000 = -1.7144408478 
0.0000000000 * -0.0229214000 = -1.7144408478 
0.0000000000 * 0.3356530000 = -1.7144408478 
0.0000000000 * -0.5932770000 = -1.7144408478 
1.5809660104 * -0.3742140000 = -2.3060604624 
2.0068238746 * -2.3109700000 = -6.9437702319 
0.0000000000 * 0.2925840000 = -6.9437702319 
0.0000000000 * 1.0020600000 = -6.9437702319 
0.0000000000 * 0.1503490000 = -6.9437702319 
0.7689002813 * -1.8957700000 = -8.4014283183 
0.0000000000 * -0.1383390000 = -8.4014283183 
0.1555103307 * -0.4871720000 = -8.4771885971 
0.0000000000 * -0.6858470000 = -8.4771885971 
0.0923938400 * -2.0556100000 = -8.6671142986 
0.0000000000 * 0.5189350000 = -8.6671142986 
0.0000000000 * 0.3054890000 = -8.6671142986 
0.0000000000 * 0.1712080000 = -8.6671142986 
0.7573677455 * 0.0961368000 = -8.5943033871 
0.0000000000 * 0.7974440000 = -8.5943033871 
0.0000000000 * -1.2447000000 = -8.5943033871 
0.0000000000 * -0.7360540000 = -8.5943033871 
0.0000000000 * 0.8050960000 = -8.5943033871 
0.0000000000 * -0.1745250000 = -8.5943033871 
0.0000000000 * -0.1095110000 = -8.5943033871 
1.8721845553 * -0.2080330000 = -8.9837795567 
0.0000000000 * -1.6955000000 = -8.9837795567 
0.0000000000 * -1.0005300000 = -8.9837795567 
0.0000000000 * -0.2129450000 = -8.9837795567 
0.9141322940 * -0.8808420000 = -9.7889856748 
0.0000000000 * 0.0028876900 = -9.7889856748 
0.0000000000 * -0.0587614000 = -9.7889856748 
0.0000000000 * 0.3933320000 = -9.7889856748 
the biases is : 1.4841600000, now tempVal is : -8.3048256748
ReLU !!! in layer: 4, node : 0, its linear result is negative,so set it to 0
compute layer: 4, node : 1
0.0000000000 * -0.2899330000 = 0.0000000000 
1.7845438810 * -0.0390589000 = -0.0697023210 
0.0000000000 * -0.2353920000 = -0.0697023210 
0.6009646532 * -0.0341524000 = -0.0902267062 
0.4463398333 * -0.1014420000 = -0.1355043116 
0.0000000000 * -0.0104391000 = -0.1355043116 
0.0000000000 * -0.1532270000 = -0.1355043116 
0.3475366177 * 0.1461700000 = -0.0847048842 
0.2186928048 * 0.0203408000 = -0.0802564976 
0.0000000000 * 0.0205047000 = -0.0802564976 
0.0000000000 * -0.2044450000 = -0.0802564976 
0.0000000000 * 0.2296740000 = -0.0802564976 
0.0000000000 * -0.0964483000 = -0.0802564976 
0.0000000000 * 0.0687688000 = -0.0802564976 
0.0000000000 * 0.0050692300 = -0.0802564976 
0.0000000000 * -0.1898230000 = -0.0802564976 
0.3887901683 * 0.2592190000 = 0.0205253011 
1.4372682682 * -0.2718250000 = -0.3701601459 
0.0000000000 * 0.0134500000 = -0.3701601459 
0.0000000000 * -0.0236374000 = -0.3701601459 
0.0000000000 * -0.0010042500 = -0.3701601459 
0.0000000000 * 0.0708480000 = -0.3701601459 
1.5809660104 * -0.0760077000 = -0.4903257362 
2.0068238746 * -0.1581650000 = -0.8077350343 
0.0000000000 * 0.0834323000 = -0.8077350343 
0.0000000000 * -0.0070574200 = -0.8077350343 
0.0000000000 * -0.0295734000 = -0.8077350343 
0.7689002813 * -0.0918318000 = -0.8783445311 
0.0000000000 * -0.0078351500 = -0.8783445311 
0.1555103307 * 0.0157236000 = -0.8758993489 
0.0000000000 * -0.3685450000 = -0.8758993489 
0.0923938400 * 0.2592760000 = -0.8519438436 
0.0000000000 * 0.5123300000 = -0.8519438436 
0.0000000000 * 0.0470324000 = -0.8519438436 
0.0000000000 * 0.0245031000 = -0.8519438436 
0.7573677455 * 0.0139921000 = -0.8413466784 
0.0000000000 * -0.2490230000 = -0.8413466784 
0.0000000000 * -0.1414860000 = -0.8413466784 
0.0000000000 * 0.0633367000 = -0.8413466784 
0.0000000000 * 0.1648420000 = -0.8413466784 
0.0000000000 * -0.1585530000 = -0.8413466784 
0.0000000000 * 0.1543920000 = -0.8413466784 
1.8721845553 * -0.1454940000 = -1.1137382981 
0.0000000000 * -0.1851290000 = -1.1137382981 
0.0000000000 * -0.0243234000 = -1.1137382981 
0.0000000000 * 0.5461120000 = -1.1137382981 
0.9141322940 * -0.0510707000 = -1.1604236743 
0.0000000000 * 0.0289771000 = -1.1604236743 
0.0000000000 * 0.0943521000 = -1.1604236743 
0.0000000000 * 0.2443940000 = -1.1604236743 
the biases is : -0.0392727000, now tempVal is : -1.1996963743
ReLU !!! in layer: 4, node : 1, its linear result is negative,so set it to 0
compute layer: 4, node : 2
0.0000000000 * -0.0991630000 = 0.0000000000 
1.7845438810 * -0.0366602000 = -0.0654217356 
0.0000000000 * 0.0755007000 = -0.0654217356 
0.6009646532 * 0.4460320000 = 0.2026277306 
0.4463398333 * -0.1790060000 = 0.1227302224 
0.0000000000 * -0.0030297000 = 0.1227302224 
0.0000000000 * 0.1337740000 = 0.1227302224 
0.3475366177 * -0.1116210000 = 0.0839378376 
0.2186928048 * 0.3824120000 = 0.1675685905 
0.0000000000 * 0.4195100000 = 0.1675685905 
0.0000000000 * -0.1648550000 = 0.1675685905 
0.0000000000 * -0.1116330000 = 0.1675685905 
0.0000000000 * 0.0140495000 = 0.1675685905 
0.0000000000 * -0.1639880000 = 0.1675685905 
0.0000000000 * -0.2733720000 = 0.1675685905 
0.0000000000 * -0.0503863000 = 0.1675685905 
0.3887901683 * -0.1593840000 = 0.1056016583 
1.4372682682 * -0.1283050000 = -0.0788070469 
0.0000000000 * -0.1274050000 = -0.0788070469 
0.0000000000 * 0.0283343000 = -0.0788070469 
0.0000000000 * -0.0852565000 = -0.0788070469 
0.0000000000 * -0.3397620000 = -0.0788070469 
1.5809660104 * -0.0101792000 = -0.0949000161 
2.0068238746 * -0.0474959000 = -0.1902159222 
0.0000000000 * -0.2959140000 = -0.1902159222 
0.0000000000 * -0.0423524000 = -0.1902159222 
0.0000000000 * 0.0283382000 = -0.1902159222 
0.7689002813 * -0.1705740000 = -0.3213703187 
0.0000000000 * -0.1996720000 = -0.3213703187 
0.1555103307 * -0.0786060000 = -0.3335943638 
0.0000000000 * -0.0304747000 = -0.3335943638 
0.0923938400 * 0.1416240000 = -0.3205091786 
0.0000000000 * 0.1152790000 = -0.3205091786 
0.0000000000 * 0.0424489000 = -0.3205091786 
0.0000000000 * -0.0896282000 = -0.3205091786 
0.7573677455 * 0.0077122900 = -0.3146681389 
0.0000000000 * -0.0468138000 = -0.3146681389 
0.0000000000 * -0.2930260000 = -0.3146681389 
0.0000000000 * 0.0592837000 = -0.3146681389 
0.0000000000 * 0.1697430000 = -0.3146681389 
0.0000000000 * -0.0259172000 = -0.3146681389 
0.0000000000 * -0.1340060000 = -0.3146681389 
1.8721845553 * -0.0115559000 = -0.3363029164 
0.0000000000 * 0.0412064000 = -0.3363029164 
0.0000000000 * 0.0757857000 = -0.3363029164 
0.0000000000 * -0.1770310000 = -0.3363029164 
0.9141322940 * -0.0125494000 = -0.3477747282 
0.0000000000 * -0.0174408000 = -0.3477747282 
0.0000000000 * 0.1356280000 = -0.3477747282 
0.0000000000 * 0.0385604000 = -0.3477747282 
the biases is : -0.0907838000, now tempVal is : -0.4385585282
ReLU !!! in layer: 4, node : 2, its linear result is negative,so set it to 0
compute layer: 4, node : 3
0.0000000000 * 0.6059370000 = 0.0000000000 
1.7845438810 * -0.2850930000 = -0.5087609687 
0.0000000000 * 1.4632700000 = -0.5087609687 
0.6009646532 * -0.3550910000 = -0.7221581083 
0.4463398333 * 0.3629240000 = -0.5601706707 
0.0000000000 * 0.2270660000 = -0.5601706707 
0.0000000000 * -0.7673630000 = -0.5601706707 
0.3475366177 * -2.1034300000 = -1.2911896184 
0.2186928048 * -0.3958730000 = -1.3777641951 
0.0000000000 * 1.3139800000 = -1.3777641951 
0.0000000000 * -1.7556900000 = -1.3777641951 
0.0000000000 * 1.2154300000 = -1.3777641951 
0.0000000000 * 0.3046920000 = -1.3777641951 
0.0000000000 * 0.0679581000 = -1.3777641951 
0.0000000000 * -0.4334350000 = -1.3777641951 
0.0000000000 * 1.4235900000 = -1.3777641951 
0.3887901683 * -0.4960770000 = -1.5706340554 
1.4372682682 * 0.1763030000 = -1.3172393479 
0.0000000000 * 0.1375010000 = -1.3172393479 
0.0000000000 * 0.0030290100 = -1.3172393479 
0.0000000000 * -0.7437820000 = -1.3172393479 
0.0000000000 * -0.2750580000 = -1.3172393479 
1.5809660104 * 0.1609560000 = -1.0627733828 
2.0068238746 * 0.4504170000 = -0.1588657936 
0.0000000000 * 0.9433430000 = -0.1588657936 
0.0000000000 * 0.2081460000 = -0.1588657936 
0.0000000000 * -0.4135420000 = -0.1588657936 
0.7689002813 * 1.1575100000 = 0.7311439710 
0.0000000000 * -0.1357710000 = 0.7311439710 
0.1555103307 * -0.2482310000 = 0.6925414861 
0.0000000000 * 0.2601310000 = 0.6925414861 
0.0923938400 * -1.3644400000 = 0.5664756350 
0.0000000000 * -1.3731100000 = 0.5664756350 
0.0000000000 * 0.5283760000 = 0.5664756350 
0.0000000000 * 0.1482320000 = 0.5664756350 
0.7573677455 * 0.1623770000 = 0.6894547374 
0.0000000000 * 0.1709210000 = 0.6894547374 
0.0000000000 * -0.1891020000 = 0.6894547374 
0.0000000000 * -0.0934121000 = 0.6894547374 
0.0000000000 * -0.0273202000 = 0.6894547374 
0.0000000000 * 0.3471120000 = 0.6894547374 
0.0000000000 * 0.2969860000 = 0.6894547374 
1.8721845553 * 0.4347580000 = 1.5034019503 
0.0000000000 * 1.4586700000 = 1.5034019503 
0.0000000000 * 0.6088350000 = 1.5034019503 
0.0000000000 * -1.5379700000 = 1.5034019503 
0.9141322940 * 0.0230557000 = 1.5244779103 
0.0000000000 * 0.0409570000 = 1.5244779103 
0.0000000000 * 0.0326100000 = 1.5244779103 
0.0000000000 * 0.3625230000 = 1.5244779103 
the biases is : -2.4739700000, now tempVal is : -0.9494920897
ReLU !!! in layer: 4, node : 3, its linear result is negative,so set it to 0
compute layer: 4, node : 4
0.0000000000 * 0.6704550000 = 0.0000000000 
1.7845438810 * 0.7108980000 = 1.2686286759 
0.0000000000 * 1.2874400000 = 1.2686286759 
0.6009646532 * -0.8820450000 = 0.7385508084 
0.4463398333 * 0.0258417000 = 0.7500849885 
0.0000000000 * 0.9030230000 = 0.7500849885 
0.0000000000 * -0.5382000000 = 0.7500849885 
0.3475366177 * -0.1747080000 = 0.6893675611 
0.2186928048 * 0.2082790000 = 0.7349166797 
0.0000000000 * -0.2932900000 = 0.7349166797 
0.0000000000 * 0.5188180000 = 0.7349166797 
0.0000000000 * -0.6223980000 = 0.7349166797 
0.0000000000 * 0.4097160000 = 0.7349166797 
0.0000000000 * 1.5473700000 = 0.7349166797 
0.0000000000 * 1.2700500000 = 0.7349166797 
0.0000000000 * 0.1695100000 = 0.7349166797 
0.3887901683 * -1.9074100000 = -0.0066655752 
1.4372682682 * -1.4699800000 = -2.1194211841 
0.0000000000 * 0.0279246000 = -2.1194211841 
0.0000000000 * 0.0450144000 = -2.1194211841 
0.0000000000 * 0.3551370000 = -2.1194211841 
0.0000000000 * -0.0628051000 = -2.1194211841 
1.5809660104 * -0.6832660000 = -3.1996415062 
2.0068238746 * 0.3093260000 = -2.5788787043 
0.0000000000 * -0.6005330000 = -2.5788787043 
0.0000000000 * -1.0194800000 = -2.5788787043 
0.0000000000 * 0.6790860000 = -2.5788787043 
0.7689002813 * -2.2273700000 = -4.2915041240 
0.0000000000 * 0.5188470000 = -4.2915041240 
0.1555103307 * 0.0882435000 = -4.2777813481 
0.0000000000 * -0.9202020000 = -4.2777813481 
0.0923938400 * -2.5876000000 = -4.5168596486 
0.0000000000 * 1.1824700000 = -4.5168596486 
0.0000000000 * -0.2261480000 = -4.5168596486 
0.0000000000 * 0.3610830000 = -4.5168596486 
0.7573677455 * -1.8554700000 = -5.9221327793 
0.0000000000 * 0.6916540000 = -5.9221327793 
0.0000000000 * 0.3650510000 = -5.9221327793 
0.0000000000 * -0.5377760000 = -5.9221327793 
0.0000000000 * 0.1602410000 = -5.9221327793 
0.0000000000 * 0.0905421000 = -5.9221327793 
0.0000000000 * -0.6977900000 = -5.9221327793 
1.8721845553 * 0.9627150000 = -4.1197526251 
0.0000000000 * 0.8668930000 = -4.1197526251 
0.0000000000 * 1.8927800000 = -4.1197526251 
0.0000000000 * -1.2941900000 = -4.1197526251 
0.9141322940 * 0.9390110000 = -3.2613723456 
0.0000000000 * -0.0133065000 = -3.2613723456 
0.0000000000 * 0.7550680000 = -3.2613723456 
0.0000000000 * -0.0372955000 = -3.2613723456 
the biases is : -2.2686400000, now tempVal is : -5.5300123456
ReLU !!! in layer: 4, node : 4, its linear result is negative,so set it to 0
compute layer: 4, node : 5
0.0000000000 * -0.1210620000 = 0.0000000000 
1.7845438810 * -0.1125510000 = -0.2008521984 
0.0000000000 * -0.3319360000 = -0.2008521984 
0.6009646532 * 0.0576856000 = -0.1661851918 
0.4463398333 * -0.0952833000 = -0.2087139240 
0.0000000000 * 0.0641034000 = -0.2087139240 
0.0000000000 * -0.0380395000 = -0.2087139240 
0.3475366177 * 0.0691370000 = -0.1846862849 
0.2186928048 * 0.0394384000 = -0.1760613905 
0.0000000000 * 0.0432422000 = -0.1760613905 
0.0000000000 * 0.1776190000 = -0.1760613905 
0.0000000000 * -0.3230530000 = -0.1760613905 
0.0000000000 * -0.0772591000 = -0.1760613905 
0.0000000000 * 0.0112817000 = -0.1760613905 
0.0000000000 * -0.0407238000 = -0.1760613905 
0.0000000000 * 0.0782790000 = -0.1760613905 
0.3887901683 * 0.3172500000 = -0.0527177096 
1.4372682682 * -0.0402553000 = -0.1105753750 
0.0000000000 * -0.1323710000 = -0.1105753750 
0.0000000000 * 0.0485819000 = -0.1105753750 
0.0000000000 * 0.0520028000 = -0.1105753750 
0.0000000000 * -0.0893810000 = -0.1105753750 
1.5809660104 * -0.1218340000 = -0.3031907879 
2.0068238746 * -0.2203480000 = -0.7453904150 
0.0000000000 * 0.1725320000 = -0.7453904150 
0.0000000000 * 0.0210572000 = -0.7453904150 
0.0000000000 * -0.1055750000 = -0.7453904150 
0.7689002813 * -0.1294190000 = -0.8449007205 
0.0000000000 * 0.0310569000 = -0.8449007205 
0.1555103307 * -0.0714138000 = -0.8560063042 
0.0000000000 * 0.1607570000 = -0.8560063042 
0.0923938400 * 0.1882700000 = -0.8386113159 
0.0000000000 * 0.3979790000 = -0.8386113159 
0.0000000000 * 0.0259080000 = -0.8386113159 
0.0000000000 * -0.1851270000 = -0.8386113159 
0.7573677455 * 0.2401880000 = -0.6567006718 
0.0000000000 * 0.0424864000 = -0.6567006718 
0.0000000000 * -0.1667950000 = -0.6567006718 
0.0000000000 * 0.0879923000 = -0.6567006718 
0.0000000000 * 0.3218310000 = -0.6567006718 
0.0000000000 * -0.0045202600 = -0.6567006718 
0.0000000000 * -0.0663753000 = -0.6567006718 
1.8721845553 * -0.0543892000 = -0.7585272921 
0.0000000000 * 0.0373707000 = -0.7585272921 
0.0000000000 * 0.1805380000 = -0.7585272921 
0.0000000000 * 0.3733270000 = -0.7585272921 
0.9141322940 * -0.0775681000 = -0.8294347973 
0.0000000000 * 0.0230342000 = -0.8294347973 
0.0000000000 * -0.0941502000 = -0.8294347973 
0.0000000000 * 0.2075110000 = -0.8294347973 
the biases is : 0.2899110000, now tempVal is : -0.5395237973
ReLU !!! in layer: 4, node : 5, its linear result is negative,so set it to 0
compute layer: 4, node : 6
0.0000000000 * -0.2488740000 = 0.0000000000 
1.7845438810 * 0.0982728000 = 0.1753721239 
0.0000000000 * 0.0846956000 = 0.1753721239 
0.6009646532 * 0.4869660000 = 0.4680214772 
0.4463398333 * 0.0546425000 = 0.4924106016 
0.0000000000 * 0.2135590000 = 0.4924106016 
0.0000000000 * 0.0120736000 = 0.4924106016 
0.3475366177 * 0.4497450000 = 0.6487134577 
0.2186928048 * -0.2865300000 = 0.5860514083 
0.0000000000 * -0.4579880000 = 0.5860514083 
0.0000000000 * -0.1878850000 = 0.5860514083 
0.0000000000 * -0.2264530000 = 0.5860514083 
0.0000000000 * 0.1866600000 = 0.5860514083 
0.0000000000 * 0.1179490000 = 0.5860514083 
0.0000000000 * -0.0120727000 = 0.5860514083 
0.0000000000 * 0.2565400000 = 0.5860514083 
0.3887901683 * -0.1731090000 = 0.5187483311 
1.4372682682 * -0.1341260000 = 0.3259732873 
0.0000000000 * -0.0560314000 = 0.3259732873 
0.0000000000 * -0.0045311000 = 0.3259732873 
0.0000000000 * -0.1923020000 = 0.3259732873 
0.0000000000 * -0.0884756000 = 0.3259732873 
1.5809660104 * 0.0402012000 = 0.3895300181 
2.0068238746 * 0.0398664000 = 0.4695348614 
0.0000000000 * 0.7371750000 = 0.4695348614 
0.0000000000 * -0.1722230000 = 0.4695348614 
0.0000000000 * -0.0684839000 = 0.4695348614 
0.7689002813 * -0.0007519400 = 0.4689566946 
0.0000000000 * 0.0852525000 = 0.4689566946 
0.1555103307 * 0.2129770000 = 0.5020768183 
0.0000000000 * 0.3705460000 = 0.5020768183 
0.0923938400 * -0.3656340000 = 0.4682944890 
0.0000000000 * 0.3224370000 = 0.4682944890 
0.0000000000 * 0.1889320000 = 0.4682944890 
0.0000000000 * 0.1590480000 = 0.4682944890 
0.7573677455 * -0.1060060000 = 0.3880089637 
0.0000000000 * -0.0446813000 = 0.3880089637 
0.0000000000 * -0.2415700000 = 0.3880089637 
0.0000000000 * 0.0156972000 = 0.3880089637 
0.0000000000 * 0.0392898000 = 0.3880089637 
0.0000000000 * 0.0576905000 = 0.3880089637 
0.0000000000 * -0.0127836000 = 0.3880089637 
1.8721845553 * -0.2353290000 = -0.0525703555 
0.0000000000 * -0.3171620000 = -0.0525703555 
0.0000000000 * -0.2164700000 = -0.0525703555 
0.0000000000 * -0.3057020000 = -0.0525703555 
0.9141322940 * 0.0441344000 = -0.0122256752 
0.0000000000 * 0.0336897000 = -0.0122256752 
0.0000000000 * -0.0722653000 = -0.0122256752 
0.0000000000 * 0.1244960000 = -0.0122256752 
the biases is : 0.0849784000, now tempVal is : 0.0727527248
compute layer: 4, node : 7
0.0000000000 * -0.3932250000 = 0.0000000000 
1.7845438810 * -0.2051910000 = -0.3661723435 
0.0000000000 * -0.3583100000 = -0.3661723435 
0.6009646532 * -0.1818100000 = -0.4754337271 
0.4463398333 * -0.2085850000 = -0.5685335212 
0.0000000000 * -0.2655140000 = -0.5685335212 
0.0000000000 * 0.3384430000 = -0.5685335212 
0.3475366177 * 0.3875920000 = -0.4338311085 
0.2186928048 * 0.8034580000 = -0.2581206250 
0.0000000000 * 0.0297769000 = -0.2581206250 
0.0000000000 * 0.2449320000 = -0.2581206250 
0.0000000000 * -0.2124470000 = -0.2581206250 
0.0000000000 * -0.3302730000 = -0.2581206250 
0.0000000000 * -0.1942880000 = -0.2581206250 
0.0000000000 * 0.6853850000 = -0.2581206250 
0.0000000000 * -0.2123390000 = -0.2581206250 
0.3887901683 * 0.0726721000 = -0.2298664270 
1.4372682682 * -0.0524380000 = -0.3052339004 
0.0000000000 * 0.0899994000 = -0.3052339004 
0.0000000000 * -0.0200148000 = -0.3052339004 
0.0000000000 * 0.1812430000 = -0.3052339004 
0.0000000000 * 0.9366490000 = -0.3052339004 
1.5809660104 * 0.0974104000 = -0.1512313690 
2.0068238746 * -0.2632750000 = -0.6795779246 
0.0000000000 * -0.0655607000 = -0.6795779246 
0.0000000000 * -0.2569150000 = -0.6795779246 
0.0000000000 * -0.0618897000 = -0.6795779246 
0.7689002813 * -0.0968321000 = -0.7540321535 
0.0000000000 * 0.3033310000 = -0.7540321535 
0.1555103307 * 0.0429135000 = -0.7473586609 
0.0000000000 * -0.1091060000 = -0.7473586609 
0.0923938400 * 0.4805130000 = -0.7029622197 
0.0000000000 * 0.5529300000 = -0.7029622197 
0.0000000000 * 0.1371350000 = -0.7029622197 
0.0000000000 * 0.4824490000 = -0.7029622197 
0.7573677455 * -0.0327180000 = -0.7277417776 
0.0000000000 * 0.1535750000 = -0.7277417776 
0.0000000000 * -0.0165924000 = -0.7277417776 
0.0000000000 * -0.2234990000 = -0.7277417776 
0.0000000000 * 0.7099820000 = -0.7277417776 
0.0000000000 * 0.0422823000 = -0.7277417776 
0.0000000000 * -0.1100950000 = -0.7277417776 
1.8721845553 * -0.1141810000 = -0.9415096823 
0.0000000000 * 0.1105400000 = -0.9415096823 
0.0000000000 * -0.3754810000 = -0.9415096823 
0.0000000000 * 0.1428120000 = -0.9415096823 
0.9141322940 * -0.1602580000 = -1.0880066954 
0.0000000000 * -0.0212633000 = -1.0880066954 
0.0000000000 * 0.1348530000 = -1.0880066954 
0.0000000000 * -0.4062730000 = -1.0880066954 
the biases is : -0.0216935000, now tempVal is : -1.1097001954
ReLU !!! in layer: 4, node : 7, its linear result is negative,so set it to 0
compute layer: 4, node : 8
0.0000000000 * 0.0818828000 = 0.0000000000 
1.7845438810 * -0.1776430000 = -0.3170117287 
0.0000000000 * -0.2919790000 = -0.3170117287 
0.6009646532 * 0.3589530000 = -0.1012936635 
0.4463398333 * -0.0206239000 = -0.1104989316 
0.0000000000 * -0.1547360000 = -0.1104989316 
0.0000000000 * -0.0578907000 = -0.1104989316 
0.3475366177 * 0.0736091000 = -0.0849170739 
0.2186928048 * -0.1169920000 = -0.1105023826 
0.0000000000 * -0.3718630000 = -0.1105023826 
0.0000000000 * -0.2728810000 = -0.1105023826 
0.0000000000 * -0.3612850000 = -0.1105023826 
0.0000000000 * 0.1082210000 = -0.1105023826 
0.0000000000 * 0.1824500000 = -0.1105023826 
0.0000000000 * 0.2526140000 = -0.1105023826 
0.0000000000 * -0.2335280000 = -0.1105023826 
0.3887901683 * 0.3574380000 = 0.0284659976 
1.4372682682 * 0.1911900000 = 0.3032573178 
0.0000000000 * -0.1494320000 = 0.3032573178 
0.0000000000 * -0.0238803000 = 0.3032573178 
0.0000000000 * 0.0650345000 = 0.3032573178 
0.0000000000 * 0.4192190000 = 0.3032573178 
1.5809660104 * -0.0935929000 = 0.1552901241 
2.0068238746 * -0.1206850000 = -0.0869034152 
0.0000000000 * 1.1196200000 = -0.0869034152 
0.0000000000 * 0.3704220000 = -0.0869034152 
0.0000000000 * -0.1823590000 = -0.0869034152 
0.7689002813 * 0.6588900000 = 0.4197172912 
0.0000000000 * 0.0998101000 = 0.4197172912 
0.1555103307 * -0.1439840000 = 0.3973262917 
0.0000000000 * 0.2681250000 = 0.3973262917 
0.0923938400 * -0.2897620000 = 0.3705540679 
0.0000000000 * 0.5319070000 = 0.3705540679 
0.0000000000 * -0.1483630000 = 0.3705540679 
0.0000000000 * 0.1775730000 = 0.3705540679 
0.7573677455 * -0.1302630000 = 0.2718970732 
0.0000000000 * 0.0291982000 = 0.2718970732 
0.0000000000 * -0.3763950000 = 0.2718970732 
0.0000000000 * -0.2218340000 = 0.2718970732 
0.0000000000 * -0.0800251000 = 0.2718970732 
0.0000000000 * -0.4951210000 = 0.2718970732 
0.0000000000 * -0.0537386000 = 0.2718970732 
1.8721845553 * -0.3053190000 = -0.2997164430 
0.0000000000 * 0.6250730000 = -0.2997164430 
0.0000000000 * -0.0209418000 = -0.2997164430 
0.0000000000 * 0.1507320000 = -0.2997164430 
0.9141322940 * -0.1566140000 = -0.4428823581 
0.0000000000 * 0.0211654000 = -0.4428823581 
0.0000000000 * -0.3583040000 = -0.4428823581 
0.0000000000 * 0.0500660000 = -0.4428823581 
the biases is : -0.6881730000, now tempVal is : -1.1310553581
ReLU !!! in layer: 4, node : 8, its linear result is negative,so set it to 0
compute layer: 4, node : 9
0.0000000000 * 0.1948190000 = 0.0000000000 
1.7845438810 * 0.3727060000 = 0.6651102117 
0.0000000000 * -0.1360730000 = 0.6651102117 
0.6009646532 * 0.1156370000 = 0.7346039613 
0.4463398333 * -0.5644660000 = 0.4826603010 
0.0000000000 * 0.4578530000 = 0.4826603010 
0.0000000000 * 0.2284000000 = 0.4826603010 
0.3475366177 * 0.6158220000 = 0.6966809959 
0.2186928048 * 0.4200170000 = 0.7885356917 
0.0000000000 * -0.4001670000 = 0.7885356917 
0.0000000000 * 2.2549700000 = 0.7885356917 
0.0000000000 * 0.3873470000 = 0.7885356917 
0.0000000000 * -1.0218600000 = 0.7885356917 
0.0000000000 * -0.0317851000 = 0.7885356917 
0.0000000000 * -1.0527300000 = 0.7885356917 
0.0000000000 * 0.2353400000 = 0.7885356917 
0.3887901683 * -0.1999730000 = 0.7107881554 
1.4372682682 * 0.4534750000 = 1.3625533833 
0.0000000000 * 0.1141290000 = 1.3625533833 
0.0000000000 * -0.0307462000 = 1.3625533833 
0.0000000000 * -0.0712554000 = 1.3625533833 
0.0000000000 * 0.6547120000 = 1.3625533833 
1.5809660104 * 0.0197267000 = 1.3937406255 
2.0068238746 * -1.1174500000 = -0.8487847132 
0.0000000000 * 0.2782020000 = -0.8487847132 
0.0000000000 * -0.0715725000 = -0.8487847132 
0.0000000000 * 0.1303930000 = -0.8487847132 
0.7689002813 * 0.4179710000 = -0.5274066937 
0.0000000000 * -0.4968350000 = -0.5274066937 
0.1555103307 * -0.5876620000 = -0.6187942056 
0.0000000000 * 0.0472645000 = -0.6187942056 
0.0923938400 * -0.2345160000 = -0.6404620394 
0.0000000000 * -0.0925567000 = -0.6404620394 
0.0000000000 * -0.5803410000 = -0.6404620394 
0.0000000000 * 0.2188730000 = -0.6404620394 
0.7573677455 * 0.2442110000 = -0.4555045049 
0.0000000000 * 0.8167490000 = -0.4555045049 
0.0000000000 * -0.6048950000 = -0.4555045049 
0.0000000000 * -0.5943810000 = -0.4555045049 
0.0000000000 * -0.5043490000 = -0.4555045049 
0.0000000000 * -1.7711500000 = -0.4555045049 
0.0000000000 * -0.7601930000 = -0.4555045049 
1.8721845553 * 0.1456550000 = -0.1828114635 
0.0000000000 * -0.3416810000 = -0.1828114635 
0.0000000000 * -0.2926230000 = -0.1828114635 
0.0000000000 * 0.3887440000 = -0.1828114635 
0.9141322940 * 0.6765870000 = 0.4356785629 
0.0000000000 * 0.0216446000 = 0.4356785629 
0.0000000000 * -0.0209792000 = 0.4356785629 
0.0000000000 * -0.0632221000 = 0.4356785629 
the biases is : -0.2453580000, now tempVal is : 0.1903205629
compute layer: 4, node : 10
0.0000000000 * -0.6576730000 = 0.0000000000 
1.7845438810 * -0.2360140000 = -0.4211773395 
0.0000000000 * -0.4782290000 = -0.4211773395 
0.6009646532 * -0.0304675000 = -0.4394872301 
0.4463398333 * -0.3738310000 = -0.6063428963 
0.0000000000 * 0.1977330000 = -0.6063428963 
0.0000000000 * 0.0082127600 = -0.6063428963 
0.3475366177 * 0.4717990000 = -0.4423754676 
0.2186928048 * 0.7008430000 = -0.2891061463 
0.0000000000 * 0.1306140000 = -0.2891061463 
0.0000000000 * -1.4145900000 = -0.2891061463 
0.0000000000 * 0.0918417000 = -0.2891061463 
0.0000000000 * -0.1039470000 = -0.2891061463 
0.0000000000 * 0.0448295000 = -0.2891061463 
0.0000000000 * -0.1420330000 = -0.2891061463 
0.0000000000 * 0.4046780000 = -0.2891061463 
0.3887901683 * 0.5228690000 = -0.0858198198 
1.4372682682 * 0.6625750000 = 0.8664782030 
0.0000000000 * -0.3565120000 = 0.8664782030 
0.0000000000 * 0.0464266000 = 0.8664782030 
0.0000000000 * 0.1959220000 = 0.8664782030 
0.0000000000 * 0.6844160000 = 0.8664782030 
1.5809660104 * -0.2030290000 = 0.5454962549 
2.0068238746 * -0.2222140000 = 0.0995518944 
0.0000000000 * 1.3430900000 = 0.0995518944 
0.0000000000 * -0.4191500000 = 0.0995518944 
0.0000000000 * -0.1050850000 = 0.0995518944 
0.7689002813 * -0.5075110000 = -0.2906734562 
0.0000000000 * 0.0591906000 = -0.2906734562 
0.1555103307 * -0.0714123000 = -0.3017788066 
0.0000000000 * -0.1370540000 = -0.3017788066 
0.0923938400 * 0.5342570000 = -0.2524167508 
0.0000000000 * 0.1611100000 = -0.2524167508 
0.0000000000 * -0.3647700000 = -0.2524167508 
0.0000000000 * -0.2150970000 = -0.2524167508 
0.7573677455 * 0.5851060000 = 0.1907236613 
0.0000000000 * -0.0163710000 = 0.1907236613 
0.0000000000 * -0.1387250000 = 0.1907236613 
0.0000000000 * 0.4821360000 = 0.1907236613 
0.0000000000 * -0.0488709000 = 0.1907236613 
0.0000000000 * -0.6176270000 = 0.1907236613 
0.0000000000 * 0.1623920000 = 0.1907236613 
1.8721845553 * -0.1860880000 = -0.1576674183 
0.0000000000 * -0.1210710000 = -0.1576674183 
0.0000000000 * 0.9821270000 = -0.1576674183 
0.0000000000 * 0.2792160000 = -0.1576674183 
0.9141322940 * -0.0342331000 = -0.1889610005 
0.0000000000 * -0.0428749000 = -0.1889610005 
0.0000000000 * 0.3738180000 = -0.1889610005 
0.0000000000 * -0.4101730000 = -0.1889610005 
the biases is : -0.4088830000, now tempVal is : -0.5978440005
ReLU !!! in layer: 4, node : 10, its linear result is negative,so set it to 0
compute layer: 4, node : 11
0.0000000000 * 0.5104510000 = 0.0000000000 
1.7845438810 * 0.0903219000 = 0.1611833940 
0.0000000000 * 0.3734840000 = 0.1611833940 
0.6009646532 * 0.1948040000 = 0.2782537123 
0.4463398333 * -0.1389090000 = 0.2162530924 
0.0000000000 * 0.1823570000 = 0.2162530924 
0.0000000000 * 0.1336040000 = 0.2162530924 
0.3475366177 * -0.5791680000 = 0.0149710046 
0.2186928048 * 0.2873050000 = 0.0778025408 
0.0000000000 * -0.1274900000 = 0.0778025408 
0.0000000000 * 0.2546680000 = 0.0778025408 
0.0000000000 * -0.6738310000 = 0.0778025408 
0.0000000000 * 0.2920640000 = 0.0778025408 
0.0000000000 * -0.4167160000 = 0.0778025408 
0.0000000000 * -0.5619370000 = 0.0778025408 
0.0000000000 * 0.4071250000 = 0.0778025408 
0.3887901683 * -0.5676160000 = -0.1428809793 
1.4372682682 * 0.4936290000 = 0.5665963186 
0.0000000000 * 0.2043140000 = 0.5665963186 
0.0000000000 * 0.0356814000 = 0.5665963186 
0.0000000000 * -0.3105240000 = 0.5665963186 
0.0000000000 * -0.2053410000 = 0.5665963186 
1.5809660104 * 0.1419820000 = 0.7910650347 
2.0068238746 * 0.2902710000 = 1.3735878076 
0.0000000000 * -0.8097810000 = 1.3735878076 
0.0000000000 * 0.2446460000 = 1.3735878076 
0.0000000000 * 0.1991710000 = 1.3735878076 
0.7689002813 * 0.6164050000 = 1.8475417855 
0.0000000000 * -0.4162080000 = 1.8475417855 
0.1555103307 * 0.2471750000 = 1.8859800515 
0.0000000000 * -0.1268780000 = 1.8859800515 
0.0923938400 * 0.0549306000 = 1.8910553006 
0.0000000000 * -0.5185080000 = 1.8910553006 
0.0000000000 * -0.2101300000 = 1.8910553006 
0.0000000000 * -0.2160530000 = 1.8910553006 
0.7573677455 * -0.1373940000 = 1.7869975166 
0.0000000000 * 0.1010240000 = 1.7869975166 
0.0000000000 * 0.1034840000 = 1.7869975166 
0.0000000000 * -0.2115730000 = 1.7869975166 
0.0000000000 * -0.0333884000 = 1.7869975166 
0.0000000000 * -0.0030679800 = 1.7869975166 
0.0000000000 * -0.3391540000 = 1.7869975166 
1.8721845553 * 0.3440330000 = 2.4310907857 
0.0000000000 * 0.0062781700 = 2.4310907857 
0.0000000000 * 0.5926740000 = 2.4310907857 
0.0000000000 * -0.7145400000 = 2.4310907857 
0.9141322940 * 0.0363575000 = 2.4643263506 
0.0000000000 * -0.0182024000 = 2.4643263506 
0.0000000000 * -0.1879440000 = 2.4643263506 
0.0000000000 * -0.1236450000 = 2.4643263506 
the biases is : 0.3453160000, now tempVal is : 2.8096423506
compute layer: 4, node : 12
0.0000000000 * -0.6560030000 = 0.0000000000 
1.7845438810 * -0.3812180000 = -0.6803002492 
0.0000000000 * -0.0285268000 = -0.6803002492 
0.6009646532 * -1.5747300000 = -1.6266573176 
0.4463398333 * 0.8878820000 = -1.2303602137 
0.0000000000 * -0.3246370000 = -1.2303602137 
0.0000000000 * -0.8845050000 = -1.2303602137 
0.3475366177 * 0.6476500000 = -1.0052781232 
0.2186928048 * -2.8215500000 = -1.6223308065 
0.0000000000 * -0.5914210000 = -1.6223308065 
0.0000000000 * 1.0863200000 = -1.6223308065 
0.0000000000 * 0.2504520000 = -1.6223308065 
0.0000000000 * 0.0602489000 = -1.6223308065 
0.0000000000 * 0.5711200000 = -1.6223308065 
0.0000000000 * 1.0900300000 = -1.6223308065 
0.0000000000 * -0.5123180000 = -1.6223308065 
0.3887901683 * 0.2443070000 = -1.5273466468 
1.4372682682 * -1.5298300000 = -3.7261227616 
0.0000000000 * 0.2532000000 = -3.7261227616 
0.0000000000 * 0.0083396900 = -3.7261227616 
0.0000000000 * -0.8712440000 = -3.7261227616 
0.0000000000 * -0.8342470000 = -3.7261227616 
1.5809660104 * 0.2424250000 = -3.3428570765 
2.0068238746 * -0.0196197000 = -3.3822303589 
0.0000000000 * -1.3409100000 = -3.3822303589 
0.0000000000 * -0.5503580000 = -3.3822303589 
0.0000000000 * -0.4918900000 = -3.3822303589 
0.7689002813 * 0.0882809000 = -3.3143511500 
0.0000000000 * 0.7539800000 = -3.3143511500 
0.1555103307 * 0.3643760000 = -3.2576869178 
0.0000000000 * -0.1277340000 = -3.2576869178 
0.0923938400 * -0.2169480000 = -3.2777315766 
0.0000000000 * -0.1167290000 = -3.2777315766 
0.0000000000 * -0.1039580000 = -3.2777315766 
0.0000000000 * 0.5840570000 = -3.2777315766 
0.7573677455 * -0.5578860000 = -3.7002564386 
0.0000000000 * 0.6816370000 = -3.7002564386 
0.0000000000 * 0.3959440000 = -3.7002564386 
0.0000000000 * -0.6688850000 = -3.7002564386 
0.0000000000 * -0.5360290000 = -3.7002564386 
0.0000000000 * 0.6172830000 = -3.7002564386 
0.0000000000 * 0.2524620000 = -3.7002564386 
1.8721845553 * 0.1788790000 = -3.3653619376 
0.0000000000 * 0.4680780000 = -3.3653619376 
0.0000000000 * -0.2093060000 = -3.3653619376 
0.0000000000 * 1.0143000000 = -3.3653619376 
0.9141322940 * 0.3109790000 = -3.0810859909 
0.0000000000 * -0.0385302000 = -3.0810859909 
0.0000000000 * 0.3639220000 = -3.0810859909 
0.0000000000 * -1.3563300000 = -3.0810859909 
the biases is : -1.1753800000, now tempVal is : -4.2564659909
ReLU !!! in layer: 4, node : 12, its linear result is negative,so set it to 0
compute layer: 4, node : 13
0.0000000000 * -0.0628853000 = 0.0000000000 
1.7845438810 * 0.1513510000 = 0.2700925009 
0.0000000000 * 0.0876364000 = 0.2700925009 
0.6009646532 * -0.4984530000 = -0.0294601333 
0.4463398333 * 0.4152730000 = 0.1558927482 
0.0000000000 * 0.1134200000 = 0.1558927482 
0.0000000000 * 0.0953064000 = 0.1558927482 
0.3475366177 * 0.0065303100 = 0.1581622701 
0.2186928048 * 0.7221490000 = 0.3160910604 
0.0000000000 * 0.5736030000 = 0.3160910604 
0.0000000000 * 1.1045600000 = 0.3160910604 
0.0000000000 * -0.3831110000 = 0.3160910604 
0.0000000000 * 0.0260280000 = 0.3160910604 
0.0000000000 * 0.7953280000 = 0.3160910604 
0.0000000000 * -0.6666330000 = 0.3160910604 
0.0000000000 * 0.3505810000 = 0.3160910604 
0.3887901683 * -0.1483800000 = 0.2584023752 
1.4372682682 * 0.0170301000 = 0.2828791975 
0.0000000000 * 0.0693605000 = 0.2828791975 
0.0000000000 * -0.0038460700 = 0.2828791975 
0.0000000000 * -0.1707700000 = 0.2828791975 
0.0000000000 * -0.2408190000 = 0.2828791975 
1.5809660104 * 0.1454520000 = 0.5128338657 
2.0068238746 * -1.1034500000 = -1.7015959388 
0.0000000000 * 0.3008240000 = -1.7015959388 
0.0000000000 * -0.3712660000 = -1.7015959388 
0.0000000000 * 0.3454300000 = -1.7015959388 
0.7689002813 * 0.0428167000 = -1.6686741661 
0.0000000000 * 0.0428564000 = -1.6686741661 
0.1555103307 * 0.4040530000 = -1.6058397505 
0.0000000000 * -0.0965074000 = -1.6058397505 
0.0923938400 * 1.0828100000 = -1.5057947765 
0.0000000000 * -0.6631500000 = -1.5057947765 
0.0000000000 * 0.1708950000 = -1.5057947765 
0.0000000000 * 0.3371590000 = -1.5057947765 
0.7573677455 * -0.8710810000 = -2.1655234296 
0.0000000000 * -0.0401024000 = -2.1655234296 
0.0000000000 * -0.1877380000 = -2.1655234296 
0.0000000000 * -0.2192130000 = -2.1655234296 
0.0000000000 * 0.0567089000 = -2.1655234296 
0.0000000000 * -0.0701377000 = -2.1655234296 
0.0000000000 * -0.4550010000 = -2.1655234296 
1.8721845553 * -0.4568510000 = -3.0208328159 
0.0000000000 * 0.8379820000 = -3.0208328159 
0.0000000000 * 0.5356470000 = -3.0208328159 
0.0000000000 * 0.0089623300 = -3.0208328159 
0.9141322940 * -1.2593200000 = -4.1720178964 
0.0000000000 * 0.0367693000 = -4.1720178964 
0.0000000000 * 0.1473980000 = -4.1720178964 
0.0000000000 * -0.4435100000 = -4.1720178964 
the biases is : -0.1296930000, now tempVal is : -4.3017108964
ReLU !!! in layer: 4, node : 13, its linear result is negative,so set it to 0
compute layer: 4, node : 14
0.0000000000 * -0.0234828000 = 0.0000000000 
1.7845438810 * 0.0276350000 = 0.0493158702 
0.0000000000 * 0.0163625000 = 0.0493158702 
0.6009646532 * -0.0075890600 = 0.0447551133 
0.4463398333 * 0.0316789000 = 0.0588946683 
0.0000000000 * -0.0541716000 = 0.0588946683 
0.0000000000 * 0.0089862400 = 0.0588946683 
0.3475366177 * -0.0354943000 = 0.0465590993 
0.2186928048 * 0.0200910000 = 0.0509528565 
0.0000000000 * -0.0241550000 = 0.0509528565 
0.0000000000 * 0.0340372000 = 0.0509528565 
0.0000000000 * -0.0431777000 = 0.0509528565 
0.0000000000 * -0.0512662000 = 0.0509528565 
0.0000000000 * 0.0073883600 = 0.0509528565 
0.0000000000 * 0.0112524000 = 0.0509528565 
0.0000000000 * -0.0246442000 = 0.0509528565 
0.3887901683 * -0.0444820000 = 0.0336586922 
1.4372682682 * -0.0544778000 = -0.0446405211 
0.0000000000 * 0.0528917000 = -0.0446405211 
0.0000000000 * -0.0470315000 = -0.0446405211 
0.0000000000 * -0.0334089000 = -0.0446405211 
0.0000000000 * -0.0241598000 = -0.0446405211 
1.5809660104 * -0.0587141000 = -0.1374655175 
2.0068238746 * -0.0378300000 = -0.2133836647 
0.0000000000 * 0.0156910000 = -0.2133836647 
0.0000000000 * 0.0400717000 = -0.2133836647 
0.0000000000 * -0.0479465000 = -0.2133836647 
0.7689002813 * -0.0188539000 = -0.2278804337 
0.0000000000 * 0.0346601000 = -0.2278804337 
0.1555103307 * -0.0398029000 = -0.2340701958 
0.0000000000 * 0.0029104300 = -0.2340701958 
0.0923938400 * -0.0066933600 = -0.2346886211 
0.0000000000 * 0.0306953000 = -0.2346886211 
0.0000000000 * -0.0146713000 = -0.2346886211 
0.0000000000 * -0.0421742000 = -0.2346886211 
0.7573677455 * -0.0450507000 = -0.2688085682 
0.0000000000 * -0.0056138200 = -0.2688085682 
0.0000000000 * 0.0011416500 = -0.2688085682 
0.0000000000 * -0.0149391000 = -0.2688085682 
0.0000000000 * -0.0064278800 = -0.2688085682 
0.0000000000 * -0.0305618000 = -0.2688085682 
0.0000000000 * 0.0199839000 = -0.2688085682 
1.8721845553 * 0.0348052000 = -0.2036468103 
0.0000000000 * 0.0384791000 = -0.2036468103 
0.0000000000 * -0.0352448000 = -0.2036468103 
0.0000000000 * -0.0502785000 = -0.2036468103 
0.9141322940 * -0.0405233000 = -0.2406904675 
0.0000000000 * 0.0496328000 = -0.2406904675 
0.0000000000 * 0.0065614100 = -0.2406904675 
0.0000000000 * 0.0070652400 = -0.2406904675 
the biases is : -0.0153813000, now tempVal is : -0.2560717675
ReLU !!! in layer: 4, node : 14, its linear result is negative,so set it to 0
compute layer: 4, node : 15
0.0000000000 * -0.5605050000 = 0.0000000000 
1.7845438810 * -1.0613600000 = -1.8940434935 
0.0000000000 * -1.0305000000 = -1.8940434935 
0.6009646532 * 4.1753900000 = 0.6152183098 
0.4463398333 * -1.2040300000 = 0.0778117603 
0.0000000000 * 1.1941500000 = 0.0778117603 
0.0000000000 * -0.4602270000 = 0.0778117603 
0.3475366177 * 0.6026730000 = 0.2872626963 
0.2186928048 * 2.4526700000 = 0.8236439777 
0.0000000000 * -0.4250740000 = 0.8236439777 
0.0000000000 * -0.8647980000 = 0.8236439777 
0.0000000000 * -0.6174330000 = 0.8236439777 
0.0000000000 * -0.5185780000 = 0.8236439777 
0.0000000000 * -1.7370800000 = 0.8236439777 
0.0000000000 * 0.8254870000 = 0.8236439777 
0.0000000000 * -0.3146590000 = 0.8236439777 
0.3887901683 * 1.7776000000 = 1.5147573809 
1.4372682682 * 0.1900200000 = 1.7878670972 
0.0000000000 * -0.8747120000 = 1.7878670972 
0.0000000000 * -0.0087354600 = 1.7878670972 
0.0000000000 * 1.1495200000 = 1.7878670972 
0.0000000000 * 2.2111300000 = 1.7878670972 
1.5809660104 * -0.7252650000 = 0.6412477837 
2.0068238746 * -1.3145200000 = -1.9967623360 
0.0000000000 * 0.9035810000 = -1.9967623360 
0.0000000000 * 1.2432200000 = -1.9967623360 
0.0000000000 * -0.4908740000 = -1.9967623360 
0.7689002813 * -1.6395200000 = -3.2573897252 
0.0000000000 * -0.7058050000 = -3.2573897252 
0.1555103307 * -0.3500190000 = -3.3118212957 
0.0000000000 * 1.2162800000 = -3.3118212957 
0.0923938400 * 1.4807000000 = -3.1750137367 
0.0000000000 * 2.1589800000 = -3.1750137367 
0.0000000000 * 0.7251250000 = -3.1750137367 
0.0000000000 * -0.8889090000 = -3.1750137367 
0.7573677455 * 2.5139100000 = -1.2710593877 
0.0000000000 * -0.8428180000 = -1.2710593877 
0.0000000000 * -0.5552890000 = -1.2710593877 
0.0000000000 * 1.0821800000 = -1.2710593877 
0.0000000000 * 1.7563200000 = -1.2710593877 
0.0000000000 * -0.1889910000 = -1.2710593877 
0.0000000000 * -0.5234480000 = -1.2710593877 
1.8721845553 * -0.7721940000 = -2.7167490682 
0.0000000000 * 1.4714600000 = -2.7167490682 
0.0000000000 * 1.9770100000 = -2.7167490682 
0.0000000000 * 1.7165000000 = -2.7167490682 
0.9141322940 * -0.0332548000 = -2.7471483548 
0.0000000000 * 0.0387848000 = -2.7471483548 
0.0000000000 * -0.8152590000 = -2.7471483548 
0.0000000000 * 1.4562100000 = -2.7471483548 
the biases is : 2.3029800000, now tempVal is : -0.4441683548
ReLU !!! in layer: 4, node : 15, its linear result is negative,so set it to 0
compute layer: 4, node : 16
0.0000000000 * 0.0662013000 = 0.0000000000 
1.7845438810 * -0.2834450000 = -0.5058200404 
0.0000000000 * 0.2440950000 = -0.5058200404 
0.6009646532 * -0.0527514000 = -0.5375217672 
0.4463398333 * 0.1646330000 = -0.4640395014 
0.0000000000 * -0.1894820000 = -0.4640395014 
0.0000000000 * 0.7481460000 = -0.4640395014 
0.3475366177 * -0.1364070000 = -0.5114459288 
0.2186928048 * 0.2454380000 = -0.4577704042 
0.0000000000 * 0.7554810000 = -0.4577704042 
0.0000000000 * -1.2795700000 = -0.4577704042 
0.0000000000 * -0.1034080000 = -0.4577704042 
0.0000000000 * 0.3125890000 = -0.4577704042 
0.0000000000 * -0.0454410000 = -0.4577704042 
0.0000000000 * 0.1823150000 = -0.4577704042 
0.0000000000 * -0.6497530000 = -0.4577704042 
0.3887901683 * -0.0480084000 = -0.4764355981 
1.4372682682 * 0.3777510000 = 0.0664939275 
0.0000000000 * 0.0514055000 = 0.0664939275 
0.0000000000 * 0.0168861000 = 0.0664939275 
0.0000000000 * -0.0744912000 = 0.0664939275 
0.0000000000 * -0.3992200000 = 0.0664939275 
1.5809660104 * 0.0566199000 = 0.1560080649 
2.0068238746 * 0.5881360000 = 1.3362934312 
0.0000000000 * 0.0568239000 = 1.3362934312 
0.0000000000 * 0.5978620000 = 1.3362934312 
0.0000000000 * -0.8326330000 = 1.3362934312 
0.7689002813 * -0.2297540000 = 1.1596355160 
0.0000000000 * -0.1144810000 = 1.1596355160 
0.1555103307 * 0.3768020000 = 1.2182321196 
0.0000000000 * 0.0425195000 = 1.2182321196 
0.0923938400 * -0.1415440000 = 1.2051543259 
0.0000000000 * 0.3107870000 = 1.2051543259 
0.0000000000 * 0.6319960000 = 1.2051543259 
0.0000000000 * -0.2869650000 = 1.2051543259 
0.7573677455 * 0.0869064000 = 1.2709744301 
0.0000000000 * -0.0304457000 = 1.2709744301 
0.0000000000 * -0.1689960000 = 1.2709744301 
0.0000000000 * -0.0920756000 = 1.2709744301 
0.0000000000 * 0.1488270000 = 1.2709744301 
0.0000000000 * 0.5044220000 = 1.2709744301 
0.0000000000 * 0.4345310000 = 1.2709744301 
1.8721845553 * -0.9003210000 = -0.4145926409 
0.0000000000 * 0.1906260000 = -0.4145926409 
0.0000000000 * -0.3099800000 = -0.4145926409 
0.0000000000 * -0.0764852000 = -0.4145926409 
0.9141322940 * -0.2845610000 = -0.6747190406 
0.0000000000 * -0.0500230000 = -0.6747190406 
0.0000000000 * 0.3419400000 = -0.6747190406 
0.0000000000 * 0.0499636000 = -0.6747190406 
the biases is : 0.4721990000, now tempVal is : -0.2025200406
ReLU !!! in layer: 4, node : 16, its linear result is negative,so set it to 0
compute layer: 4, node : 17
0.0000000000 * -1.4527500000 = 0.0000000000 
1.7845438810 * -0.4316640000 = -0.7703233498 
0.0000000000 * -2.4494500000 = -0.7703233498 
0.6009646532 * -0.0537688000 = -0.8026364981 
0.4463398333 * -1.7102500000 = -1.5659891980 
0.0000000000 * 0.7559600000 = -1.5659891980 
0.0000000000 * -1.3435200000 = -1.5659891980 
0.3475366177 * 1.2729900000 = -1.1235785590 
0.2186928048 * -0.0046103800 = -1.1245868160 
0.0000000000 * -0.8805580000 = -1.1245868160 
0.0000000000 * -1.0935200000 = -1.1245868160 
0.0000000000 * 0.2592720000 = -1.1245868160 
0.0000000000 * -0.1505660000 = -1.1245868160 
0.0000000000 * 0.4105940000 = -1.1245868160 
0.0000000000 * -0.1508910000 = -1.1245868160 
0.0000000000 * -0.0068424800 = -1.1245868160 
0.3887901683 * -0.8034830000 = -1.4369731068 
1.4372682682 * 1.2896600000 = 0.4166142880 
0.0000000000 * -0.4500700000 = 0.4166142880 
0.0000000000 * -0.0160990000 = 0.4166142880 
0.0000000000 * 0.5795150000 = 0.4166142880 
0.0000000000 * 1.0705000000 = 0.4166142880 
1.5809660104 * -0.5571860000 = -0.4642778395 
2.0068238746 * -0.4100940000 = -1.2872642695 
0.0000000000 * 0.9635380000 = -1.2872642695 
0.0000000000 * -0.4710470000 = -1.2872642695 
0.0000000000 * 0.7035950000 = -1.2872642695 
0.7689002813 * -0.6136290000 = -1.7590837803 
0.0000000000 * -0.2585370000 = -1.7590837803 
0.1555103307 * 0.1329040000 = -1.7384158353 
0.0000000000 * -0.2118510000 = -1.7384158353 
0.0923938400 * -3.3413600000 = -2.0471369166 
0.0000000000 * -1.5902500000 = -2.0471369166 
0.0000000000 * -0.3485000000 = -2.0471369166 
0.0000000000 * 0.5302030000 = -2.0471369166 
0.7573677455 * 0.7628420000 = -1.4693849909 
0.0000000000 * -0.1030410000 = -1.4693849909 
0.0000000000 * -3.5281800000 = -1.4693849909 
0.0000000000 * 0.2814800000 = -1.4693849909 
0.0000000000 * -0.7864440000 = -1.4693849909 
0.0000000000 * -0.1368720000 = -1.4693849909 
0.0000000000 * -1.0473900000 = -1.4693849909 
1.8721845553 * 0.9469860000 = 0.3035475724 
0.0000000000 * -0.8464950000 = 0.3035475724 
0.0000000000 * 0.7769970000 = 0.3035475724 
0.0000000000 * -0.0703112000 = 0.3035475724 
0.9141322940 * 0.3242850000 = 0.5999869634 
0.0000000000 * -0.0224274000 = 0.5999869634 
0.0000000000 * -0.6110060000 = 0.5999869634 
0.0000000000 * -0.3330650000 = 0.5999869634 
the biases is : -0.4666090000, now tempVal is : 0.1333779634
compute layer: 4, node : 18
0.0000000000 * -0.1970840000 = 0.0000000000 
1.7845438810 * -0.7517980000 = -1.3416165206 
0.0000000000 * 0.0752054000 = -1.3416165206 
0.6009646532 * -0.0003035080 = -1.3417989182 
0.4463398333 * 0.0947408000 = -1.2995123254 
0.0000000000 * -0.2259010000 = -1.2995123254 
0.0000000000 * 0.0362113000 = -1.2995123254 
0.3475366177 * -0.0967704000 = -1.3331435829 
0.2186928048 * 0.1619130000 = -1.2977343748 
0.0000000000 * -0.7308650000 = -1.2977343748 
0.0000000000 * -0.9864020000 = -1.2977343748 
0.0000000000 * 0.2400000000 = -1.2977343748 
0.0000000000 * 0.1142560000 = -1.2977343748 
0.0000000000 * -0.7938480000 = -1.2977343748 
0.0000000000 * 0.4040720000 = -1.2977343748 
0.0000000000 * 0.0479840000 = -1.2977343748 
0.3887901683 * 0.4604590000 = -1.1187124426 
1.4372682682 * 0.6576560000 = -0.1734843425 
0.0000000000 * -0.4059250000 = -0.1734843425 
0.0000000000 * -0.0415795000 = -0.1734843425 
0.0000000000 * -0.2309930000 = -0.1734843425 
0.0000000000 * 0.5220120000 = -0.1734843425 
1.5809660104 * -0.2412780000 = -0.5549366595 
2.0068238746 * 0.1914190000 = -0.1707924403 
0.0000000000 * -0.6796290000 = -0.1707924403 
0.0000000000 * -0.3922100000 = -0.1707924403 
0.0000000000 * -0.0519757000 = -0.1707924403 
0.7689002813 * -1.9861700000 = -1.6979591121 
0.0000000000 * -0.4787380000 = -1.6979591121 
0.1555103307 * 0.1375380000 = -1.6765705322 
0.0000000000 * 0.2276400000 = -1.6765705322 
0.0923938400 * 0.1780410000 = -1.6601206405 
0.0000000000 * 0.3387710000 = -1.6601206405 
0.0000000000 * -0.0763771000 = -1.6601206405 
0.0000000000 * 0.3069510000 = -1.6601206405 
0.7573677455 * 0.3454560000 = -1.3984834086 
0.0000000000 * 0.5021520000 = -1.3984834086 
0.0000000000 * -0.1007510000 = -1.3984834086 
0.0000000000 * -0.3762820000 = -1.3984834086 
0.0000000000 * -0.1480900000 = -1.3984834086 
0.0000000000 * -1.0891900000 = -1.3984834086 
0.0000000000 * 0.0600825000 = -1.3984834086 
1.8721845553 * -0.8550340000 = -2.9992648577 
0.0000000000 * 0.6547580000 = -2.9992648577 
0.0000000000 * 0.0041307200 = -2.9992648577 
0.0000000000 * 0.5237040000 = -2.9992648577 
0.9141322940 * -0.3457010000 = -3.3152813059 
0.0000000000 * -0.0157347000 = -3.3152813059 
0.0000000000 * 0.2931740000 = -3.3152813059 
0.0000000000 * 0.0684700000 = -3.3152813059 
the biases is : -1.1235100000, now tempVal is : -4.4387913059
ReLU !!! in layer: 4, node : 18, its linear result is negative,so set it to 0
compute layer: 4, node : 19
0.0000000000 * 0.0606654000 = 0.0000000000 
1.7845438810 * 0.0661857000 = 0.1181112859 
0.0000000000 * -0.1284300000 = 0.1181112859 
0.6009646532 * -0.0477622000 = 0.0894078920 
0.4463398333 * 0.2005950000 = 0.1789414308 
0.0000000000 * -0.1672250000 = 0.1789414308 
0.0000000000 * 0.1799030000 = 0.1789414308 
0.3475366177 * -0.1252810000 = 0.1354016958 
0.2186928048 * -0.0678608000 = 0.1205610272 
0.0000000000 * -0.0096070000 = 0.1205610272 
0.0000000000 * -0.2902730000 = 0.1205610272 
0.0000000000 * 0.1198000000 = 0.1205610272 
0.0000000000 * -0.0915363000 = 0.1205610272 
0.0000000000 * 0.0489478000 = 0.1205610272 
0.0000000000 * -0.0857171000 = 0.1205610272 
0.0000000000 * 0.0579715000 = 0.1205610272 
0.3887901683 * 0.0473607000 = 0.1389744017 
1.4372682682 * -0.1083500000 = -0.0167536152 
0.0000000000 * 0.0271226000 = -0.0167536152 
0.0000000000 * -0.0242339000 = -0.0167536152 
0.0000000000 * 0.0117790000 = -0.0167536152 
0.0000000000 * 0.2953490000 = -0.0167536152 
1.5809660104 * -0.0438312000 = -0.0860492526 
2.0068238746 * -0.1499450000 = -0.3869624584 
0.0000000000 * -0.1624540000 = -0.3869624584 
0.0000000000 * 0.4271610000 = -0.3869624584 
0.0000000000 * -0.1611750000 = -0.3869624584 
0.7689002813 * -0.3305620000 = -0.6411316732 
0.0000000000 * -0.0943050000 = -0.6411316732 
0.1555103307 * -0.1123170000 = -0.6585981271 
0.0000000000 * 0.1038010000 = -0.6585981271 
0.0923938400 * 0.5291660000 = -0.6097064483 
0.0000000000 * 0.3556910000 = -0.6097064483 
0.0000000000 * -0.3690370000 = -0.6097064483 
0.0000000000 * -0.2441320000 = -0.6097064483 
0.7573677455 * -0.3893900000 = -0.9046178747 
0.0000000000 * -0.3769390000 = -0.9046178747 
0.0000000000 * -0.0276659000 = -0.9046178747 
0.0000000000 * -0.3105530000 = -0.9046178747 
0.0000000000 * -0.3637240000 = -0.9046178747 
0.0000000000 * 0.2269930000 = -0.9046178747 
0.0000000000 * -0.0867482000 = -0.9046178747 
1.8721845553 * 0.0448723000 = -0.8206086477 
0.0000000000 * 0.0108905000 = -0.8206086477 
0.0000000000 * 0.1892400000 = -0.8206086477 
0.0000000000 * -0.2364890000 = -0.8206086477 
0.9141322940 * -0.1397980000 = -0.9484025141 
0.0000000000 * -0.0384602000 = -0.9484025141 
0.0000000000 * 0.0959229000 = -0.9484025141 
0.0000000000 * 0.1582140000 = -0.9484025141 
the biases is : 0.4959370000, now tempVal is : -0.4524655141
ReLU !!! in layer: 4, node : 19, its linear result is negative,so set it to 0
compute layer: 4, node : 20
0.0000000000 * 0.2388010000 = 0.0000000000 
1.7845438810 * -0.4913990000 = -0.8769230786 
0.0000000000 * -0.3544740000 = -0.8769230786 
0.6009646532 * -0.3972210000 = -1.1156388591 
0.4463398333 * -0.2773350000 = -1.2394245168 
0.0000000000 * 0.2121200000 = -1.2394245168 
0.0000000000 * 0.6373700000 = -1.2394245168 
0.3475366177 * 0.7178020000 = -0.9899620375 
0.2186928048 * 0.3686990000 = -0.9093302191 
0.0000000000 * -0.8339150000 = -0.9093302191 
0.0000000000 * 0.6802790000 = -0.9093302191 
0.0000000000 * -0.1622580000 = -0.9093302191 
0.0000000000 * -0.4276540000 = -0.9093302191 
0.0000000000 * -0.2288300000 = -0.9093302191 
0.0000000000 * -0.4207520000 = -0.9093302191 
0.0000000000 * -0.1294480000 = -0.9093302191 
0.3887901683 * -0.6614150000 = -1.1664818683 
1.4372682682 * 0.9069320000 = 0.1370227167 
0.0000000000 * -0.7335220000 = 0.1370227167 
0.0000000000 * -0.0082528200 = 0.1370227167 
0.0000000000 * 0.1189910000 = 0.1370227167 
0.0000000000 * -0.7933340000 = 0.1370227167 
1.5809660104 * -0.2177690000 = -0.2072626704 
2.0068238746 * -1.3619600000 = -2.9404765146 
0.0000000000 * -0.8673160000 = -2.9404765146 
0.0000000000 * 0.0803535000 = -2.9404765146 
0.0000000000 * 0.1172860000 = -2.9404765146 
0.7689002813 * 0.7709280000 = -2.3477097585 
0.0000000000 * 0.3805040000 = -2.3477097585 
0.1555103307 * -0.4220490000 = -2.4133427381 
0.0000000000 * -0.9393790000 = -2.4133427381 
0.0923938400 * 0.0179382000 = -2.4116853589 
0.0000000000 * -0.2334380000 = -2.4116853589 
0.0000000000 * -0.2297430000 = -2.4116853589 
0.0000000000 * 0.1336930000 = -2.4116853589 
0.7573677455 * 1.0316400000 = -1.6303544980 
0.0000000000 * 0.1295850000 = -1.6303544980 
0.0000000000 * -0.0228044000 = -1.6303544980 
0.0000000000 * -0.2363940000 = -1.6303544980 
0.0000000000 * 0.2689230000 = -1.6303544980 
0.0000000000 * -0.4362320000 = -1.6303544980 
0.0000000000 * -0.2447450000 = -1.6303544980 
1.8721845553 * 0.2934810000 = -1.0809039025 
0.0000000000 * 0.0680715000 = -1.0809039025 
0.0000000000 * 0.3527200000 = -1.0809039025 
0.0000000000 * 0.0036419400 = -1.0809039025 
0.9141322940 * 0.3126450000 = -0.7951050114 
0.0000000000 * 0.0409737000 = -0.7951050114 
0.0000000000 * 0.3092890000 = -0.7951050114 
0.0000000000 * -0.2472610000 = -0.7951050114 
the biases is : -0.5706430000, now tempVal is : -1.3657480114
ReLU !!! in layer: 4, node : 20, its linear result is negative,so set it to 0
compute layer: 4, node : 21
0.0000000000 * -1.2157500000 = 0.0000000000 
1.7845438810 * 0.4490870000 = 0.8014154579 
0.0000000000 * 0.2494390000 = 0.8014154579 
0.6009646532 * 0.3095140000 = 0.9874224316 
0.4463398333 * -0.1545010000 = 0.9184624810 
0.0000000000 * 0.5039570000 = 0.9184624810 
0.0000000000 * -0.3220330000 = 0.9184624810 
0.3475366177 * 0.6343700000 = 1.1389292851 
0.2186928048 * 0.3936850000 = 1.2250253620 
0.0000000000 * -0.3469500000 = 1.2250253620 
0.0000000000 * 2.0318300000 = 1.2250253620 
0.0000000000 * -0.0432027000 = 1.2250253620 
0.0000000000 * -0.2266560000 = 1.2250253620 
0.0000000000 * -0.5399020000 = 1.2250253620 
0.0000000000 * 1.0654300000 = 1.2250253620 
0.0000000000 * -1.7650500000 = 1.2250253620 
0.3887901683 * -0.2018590000 = 1.1465445674 
1.4372682682 * 0.1978590000 = 1.4309210297 
0.0000000000 * -0.0350888000 = 1.4309210297 
0.0000000000 * 0.0108464000 = 1.4309210297 
0.0000000000 * -0.2146590000 = 1.4309210297 
0.0000000000 * 1.7544400000 = 1.4309210297 
1.5809660104 * -0.3009680000 = 0.9551008514 
2.0068238746 * -0.3108040000 = 0.3313719639 
0.0000000000 * 0.3580770000 = 0.3313719639 
0.0000000000 * -0.7066620000 = 0.3313719639 
0.0000000000 * -1.9203400000 = 0.3313719639 
0.7689002813 * -0.4395100000 = -0.0065673987 
0.0000000000 * 0.2023200000 = -0.0065673987 
0.1555103307 * -0.2371940000 = -0.0434535161 
0.0000000000 * -0.3779170000 = -0.0434535161 
0.0923938400 * 1.4355400000 = 0.0891815370 
0.0000000000 * 0.1737030000 = 0.0891815370 
0.0000000000 * -1.0298900000 = 0.0891815370 
0.0000000000 * 2.0445400000 = 0.0891815370 
0.7573677455 * 0.2746400000 = 0.2971850146 
0.0000000000 * -0.3101260000 = 0.2971850146 
0.0000000000 * 0.3519440000 = 0.2971850146 
0.0000000000 * -0.5368200000 = 0.2971850146 
0.0000000000 * -0.4852250000 = 0.2971850146 
0.0000000000 * 0.7881120000 = 0.2971850146 
0.0000000000 * -0.0090638900 = 0.2971850146 
1.8721845553 * 0.9734640000 = 2.1196892806 
0.0000000000 * -0.2590680000 = 2.1196892806 
0.0000000000 * 0.4910090000 = 2.1196892806 
0.0000000000 * 0.1692890000 = 2.1196892806 
0.9141322940 * -0.5186360000 = 1.6455873642 
0.0000000000 * 0.0455357000 = 1.6455873642 
0.0000000000 * -0.1741210000 = 1.6455873642 
0.0000000000 * -0.4649320000 = 1.6455873642 
the biases is : -0.7885150000, now tempVal is : 0.8570723642
compute layer: 4, node : 22
0.0000000000 * -2.2354100000 = 0.0000000000 
1.7845438810 * -0.4584020000 = -0.8180384841 
0.0000000000 * -0.3197740000 = -0.8180384841 
0.6009646532 * -0.0633092000 = -0.8560850756 
0.4463398333 * 0.5465900000 = -0.6121201861 
0.0000000000 * 0.0985179000 = -0.6121201861 
0.0000000000 * -1.1107800000 = -0.6121201861 
0.3475366177 * -1.3102500000 = -1.0674800394 
0.2186928048 * 0.1432880000 = -1.0361439848 
0.0000000000 * -0.7113950000 = -1.0361439848 
0.0000000000 * -0.1975780000 = -1.0361439848 
0.0000000000 * -0.4161820000 = -1.0361439848 
0.0000000000 * -0.1710950000 = -1.0361439848 
0.0000000000 * -1.0650800000 = -1.0361439848 
0.0000000000 * 0.4694430000 = -1.0361439848 
0.0000000000 * -0.9250660000 = -1.0361439848 
0.3887901683 * 0.1105590000 = -0.9931597326 
1.4372682682 * 0.0497869000 = -0.9216026010 
0.0000000000 * 0.5863750000 = -0.9216026010 
0.0000000000 * -0.0177624000 = -0.9216026010 
0.0000000000 * -0.5878600000 = -0.9216026010 
0.0000000000 * 0.8888570000 = -0.9216026010 
1.5809660104 * -0.5200540000 = -1.7437902986 
2.0068238746 * 0.9071250000 = 0.0766498087 
0.0000000000 * 0.6227830000 = 0.0766498087 
0.0000000000 * 0.9783240000 = 0.0766498087 
0.0000000000 * -0.4554700000 = 0.0766498087 
0.7689002813 * -0.4270550000 = -0.2517129010 
0.0000000000 * 0.4366490000 = -0.2517129010 
0.1555103307 * 0.2382840000 = -0.2146572774 
0.0000000000 * 0.4730120000 = -0.2146572774 
0.0923938400 * 0.1542280000 = -0.2004075602 
0.0000000000 * 0.4277610000 = -0.2004075602 
0.0000000000 * -0.8335910000 = -0.2004075602 
0.0000000000 * -0.1512380000 = -0.2004075602 
0.7573677455 * -0.0631209000 = -0.2482132939 
0.0000000000 * -1.8686900000 = -0.2482132939 
0.0000000000 * 0.6010820000 = -0.2482132939 
0.0000000000 * -1.5733200000 = -0.2482132939 
0.0000000000 * -0.7485140000 = -0.2482132939 
0.0000000000 * -0.2884540000 = -0.2482132939 
0.0000000000 * -0.1702160000 = -0.2482132939 
1.8721845553 * 0.3779910000 = 0.4594556183 
0.0000000000 * 0.5039800000 = 0.4594556183 
0.0000000000 * 0.4088400000 = 0.4594556183 
0.0000000000 * 0.0053579600 = 0.4594556183 
0.9141322940 * -0.6958990000 = -0.1766881309 
0.0000000000 * 0.0208394000 = -0.1766881309 
0.0000000000 * 0.7530340000 = -0.1766881309 
0.0000000000 * -0.1326310000 = -0.1766881309 
the biases is : 1.0165200000, now tempVal is : 0.8398318691
compute layer: 4, node : 23
0.0000000000 * 0.6053070000 = 0.0000000000 
1.7845438810 * 0.3426780000 = 0.6115239281 
0.0000000000 * -1.0090900000 = 0.6115239281 
0.6009646532 * 0.5691650000 = 0.9535719749 
0.4463398333 * -0.3830390000 = 0.7826064115 
0.0000000000 * 0.5095230000 = 0.7826064115 
0.0000000000 * 0.1561610000 = 0.7826064115 
0.3475366177 * -0.6119430000 = 0.5699338111 
0.2186928048 * 1.0302400000 = 0.7952398862 
0.0000000000 * -0.8688510000 = 0.7952398862 
0.0000000000 * 1.1727000000 = 0.7952398862 
0.0000000000 * -1.4137900000 = 0.7952398862 
0.0000000000 * -0.6904410000 = 0.7952398862 
0.0000000000 * 0.0681866000 = 0.7952398862 
0.0000000000 * -0.1384080000 = 0.7952398862 
0.0000000000 * 0.9435240000 = 0.7952398862 
0.3887901683 * -0.2402800000 = 0.7018213846 
1.4372682682 * 0.5453330000 = 1.4856112011 
0.0000000000 * -0.4527050000 = 1.4856112011 
0.0000000000 * -0.0122658000 = 1.4856112011 
0.0000000000 * -0.3098400000 = 1.4856112011 
0.0000000000 * 0.3507990000 = 1.4856112011 
1.5809660104 * -0.0267231000 = 1.4433628883 
2.0068238746 * -0.9716710000 = -0.5066096728 
0.0000000000 * 0.4479780000 = -0.5066096728 
0.0000000000 * 0.3600800000 = -0.5066096728 
0.0000000000 * 0.2298800000 = -0.5066096728 
0.7689002813 * 0.3994020000 = -0.1995093626 
0.0000000000 * -0.6437160000 = -0.1995093626 
0.1555103307 * -0.3629430000 = -0.2559507486 
0.0000000000 * 0.9727680000 = -0.2559507486 
0.0923938400 * 1.1039500000 = -0.1539525689 
0.0000000000 * 0.3498030000 = -0.1539525689 
0.0000000000 * -0.1817740000 = -0.1539525689 
0.0000000000 * -0.0370613000 = -0.1539525689 
0.7573677455 * 0.4255440000 = 0.1683407310 
0.0000000000 * 1.2819700000 = 0.1683407310 
0.0000000000 * -0.2798780000 = 0.1683407310 
0.0000000000 * -0.8486110000 = 0.1683407310 
0.0000000000 * -0.0508956000 = 0.1683407310 
0.0000000000 * -0.8726220000 = 0.1683407310 
0.0000000000 * -0.7309390000 = 0.1683407310 
1.8721845553 * 0.4801840000 = 1.0673337995 
0.0000000000 * -0.2856160000 = 1.0673337995 
0.0000000000 * 0.9396670000 = 1.0673337995 
0.0000000000 * 0.4929580000 = 1.0673337995 
0.9141322940 * 0.0533890000 = 1.1161384086 
0.0000000000 * -0.0118824000 = 1.1161384086 
0.0000000000 * -0.5878050000 = 1.1161384086 
0.0000000000 * -0.3985620000 = 1.1161384086 
the biases is : 0.4626020000, now tempVal is : 1.5787404086
compute layer: 4, node : 24
0.0000000000 * -0.4053450000 = 0.0000000000 
1.7845438810 * -0.3380880000 = -0.6033328716 
0.0000000000 * 0.6140090000 = -0.6033328716 
0.6009646532 * 0.2107030000 = -0.4767078163 
0.4463398333 * -0.0082777600 = -0.4804025103 
0.0000000000 * -0.2001650000 = -0.4804025103 
0.0000000000 * -0.6315910000 = -0.4804025103 
0.3475366177 * 0.3772200000 = -0.3493047474 
0.2186928048 * 0.9521670000 = -0.1410726756 
0.0000000000 * -0.9205350000 = -0.1410726756 
0.0000000000 * 0.7751590000 = -0.1410726756 
0.0000000000 * -0.1938960000 = -0.1410726756 
0.0000000000 * -0.0435035000 = -0.1410726756 
0.0000000000 * -0.2132910000 = -0.1410726756 
0.0000000000 * -1.8001500000 = -0.1410726756 
0.0000000000 * 0.1451370000 = -0.1410726756 
0.3887901683 * -0.8028420000 = -0.4532097519 
1.4372682682 * -0.0567691000 = -0.5348021779 
0.0000000000 * -0.2657220000 = -0.5348021779 
0.0000000000 * 0.0363699000 = -0.5348021779 
0.0000000000 * -0.2935970000 = -0.5348021779 
0.0000000000 * 0.4348430000 = -0.5348021779 
1.5809660104 * -0.0333999000 = -0.5876062846 
2.0068238746 * -0.2583740000 = -1.1061173964 
0.0000000000 * 0.7030400000 = -1.1061173964 
0.0000000000 * -0.1175730000 = -1.1061173964 
0.0000000000 * -0.1128630000 = -1.1061173964 
0.7689002813 * -0.3101530000 = -1.3445941253 
0.0000000000 * 0.1096100000 = -1.3445941253 
0.1555103307 * -0.1943650000 = -1.3748198908 
0.0000000000 * -0.1066630000 = -1.3748198908 
0.0923938400 * -0.0439327000 = -1.3788790016 
0.0000000000 * 0.3259250000 = -1.3788790016 
0.0000000000 * -0.4354180000 = -1.3788790016 
0.0000000000 * 0.1231660000 = -1.3788790016 
0.7573677455 * 0.4365520000 = -1.0482485976 
0.0000000000 * -0.0104613000 = -1.0482485976 
0.0000000000 * -0.2942660000 = -1.0482485976 
0.0000000000 * -0.0171192000 = -1.0482485976 
0.0000000000 * 0.1266900000 = -1.0482485976 
0.0000000000 * 0.8945810000 = -1.0482485976 
0.0000000000 * 0.2444530000 = -1.0482485976 
1.8721845553 * 0.3108290000 = -0.4663193444 
0.0000000000 * -0.0261443000 = -0.4663193444 
0.0000000000 * -0.0052567800 = -0.4663193444 
0.0000000000 * 0.0858039000 = -0.4663193444 
0.9141322940 * 0.1911850000 = -0.2915509618 
0.0000000000 * 0.0477699000 = -0.2915509618 
0.0000000000 * 0.2121740000 = -0.2915509618 
0.0000000000 * -0.0731390000 = -0.2915509618 
the biases is : -1.6291300000, now tempVal is : -1.9206809618
ReLU !!! in layer: 4, node : 24, its linear result is negative,so set it to 0
compute layer: 4, node : 25
0.0000000000 * -0.6671150000 = 0.0000000000 
1.7845438810 * 0.2720850000 = 0.4855476219 
0.0000000000 * 2.0660300000 = 0.4855476219 
0.6009646532 * 0.3043160000 = 0.6684307813 
0.4463398333 * 0.7869430000 = 1.0196747887 
0.0000000000 * 0.6598220000 = 1.0196747887 
0.0000000000 * -1.2877500000 = 1.0196747887 
0.3475366177 * 0.2046360000 = 1.0907932920 
0.2186928048 * -0.2516490000 = 1.0357594664 
0.0000000000 * 0.5077150000 = 1.0357594664 
0.0000000000 * -2.5040000000 = 1.0357594664 
0.0000000000 * 0.0779536000 = 1.0357594664 
0.0000000000 * -0.0657514000 = 1.0357594664 
0.0000000000 * 0.2397820000 = 1.0357594664 
0.0000000000 * 1.2862200000 = 1.0357594664 
0.0000000000 * 1.4322000000 = 1.0357594664 
0.3887901683 * 0.5925150000 = 1.2661234729 
1.4372682682 * 0.1408920000 = 1.4686230738 
0.0000000000 * -0.0102873000 = 1.4686230738 
0.0000000000 * -0.0289341000 = 1.4686230738 
0.0000000000 * 0.1284160000 = 1.4686230738 
0.0000000000 * -0.4507070000 = 1.4686230738 
1.5809660104 * -0.8540430000 = 0.1184101194 
2.0068238746 * -1.0701100000 = -2.0291121771 
0.0000000000 * -1.3704700000 = -2.0291121771 
0.0000000000 * -0.0921964000 = -2.0291121771 
0.0000000000 * -0.6350110000 = -2.0291121771 
0.7689002813 * -1.1565900000 = -2.9184145535 
0.0000000000 * -0.3533330000 = -2.9184145535 
0.1555103307 * 0.2342420000 = -2.8819875026 
0.0000000000 * -0.4591520000 = -2.8819875026 
0.0923938400 * -0.9883320000 = -2.9733032913 
0.0000000000 * -2.0551600000 = -2.9733032913 
0.0000000000 * 1.1312600000 = -2.9733032913 
0.0000000000 * -1.3293300000 = -2.9733032913 
0.7573677455 * 0.1008170000 = -2.8969477473 
0.0000000000 * 0.7299410000 = -2.8969477473 
0.0000000000 * 1.0441600000 = -2.8969477473 
0.0000000000 * 0.6254320000 = -2.8969477473 
0.0000000000 * 1.9299800000 = -2.8969477473 
0.0000000000 * -0.6669490000 = -2.8969477473 
0.0000000000 * 0.8228950000 = -2.8969477473 
1.8721845553 * -0.5263590000 = -3.8823889377 
0.0000000000 * -0.7654580000 = -3.8823889377 
0.0000000000 * 0.4280890000 = -3.8823889377 
0.0000000000 * -0.4900930000 = -3.8823889377 
0.9141322940 * -0.5404480000 = -4.3764299077 
0.0000000000 * 0.0032223400 = -4.3764299077 
0.0000000000 * -0.1126920000 = -4.3764299077 
0.0000000000 * -0.0886127000 = -4.3764299077 
the biases is : -0.5842150000, now tempVal is : -4.9606449077
ReLU !!! in layer: 4, node : 25, its linear result is negative,so set it to 0
compute layer: 4, node : 26
0.0000000000 * 0.0097721600 = 0.0000000000 
1.7845438810 * -0.3425230000 = -0.6112473238 
0.0000000000 * -0.0872946000 = -0.6112473238 
0.6009646532 * 0.0230972000 = -0.5973667230 
0.4463398333 * -0.3230260000 = -0.7415460940 
0.0000000000 * -0.2986620000 = -0.7415460940 
0.0000000000 * 0.2019420000 = -0.7415460940 
0.3475366177 * -0.3538320000 = -0.8645156705 
0.2186928048 * 0.1156540000 = -0.8392229728 
0.0000000000 * 0.3442090000 = -0.8392229728 
0.0000000000 * -0.5529850000 = -0.8392229728 
0.0000000000 * 0.3219020000 = -0.8392229728 
0.0000000000 * -0.4197880000 = -0.8392229728 
0.0000000000 * 0.5222620000 = -0.8392229728 
0.0000000000 * 0.1874180000 = -0.8392229728 
0.0000000000 * -0.2726100000 = -0.8392229728 
0.3887901683 * 1.0900300000 = -0.4154300257 
1.4372682682 * -0.2638030000 = -0.7945857066 
0.0000000000 * 0.4703320000 = -0.7945857066 
0.0000000000 * 0.0192327000 = -0.7945857066 
0.0000000000 * 0.3604900000 = -0.7945857066 
0.0000000000 * 0.7674690000 = -0.7945857066 
1.5809660104 * 0.1015050000 = -0.6341097517 
2.0068238746 * -0.5122960000 = -1.6621975954 
0.0000000000 * 0.9868240000 = -1.6621975954 
0.0000000000 * 0.8844400000 = -1.6621975954 
0.0000000000 * -0.4711790000 = -1.6621975954 
0.7689002813 * -0.4372180000 = -1.9983746386 
0.0000000000 * -0.2849610000 = -1.9983746386 
0.1555103307 * -0.2198980000 = -2.0325710493 
0.0000000000 * -0.3066880000 = -2.0325710493 
0.0923938400 * -0.1270350000 = -2.0443083008 
0.0000000000 * 0.4087680000 = -2.0443083008 
0.0000000000 * -0.0026240300 = -2.0443083008 
0.0000000000 * -0.2057420000 = -2.0443083008 
0.7573677455 * -0.0873750000 = -2.1104833075 
0.0000000000 * -0.2152540000 = -2.1104833075 
0.0000000000 * 0.0497640000 = -2.1104833075 
0.0000000000 * -0.0664017000 = -2.1104833075 
0.0000000000 * 0.4167390000 = -2.1104833075 
0.0000000000 * -0.0321448000 = -2.1104833075 
0.0000000000 * -0.0800622000 = -2.1104833075 
1.8721845553 * -0.1298580000 = -2.3536014495 
0.0000000000 * 0.2424380000 = -2.3536014495 
0.0000000000 * 0.0559172000 = -2.3536014495 
0.0000000000 * -0.4794190000 = -2.3536014495 
0.9141322940 * -0.2169710000 = -2.5519416475 
0.0000000000 * -0.0451983000 = -2.5519416475 
0.0000000000 * 0.4450200000 = -2.5519416475 
0.0000000000 * 0.7754230000 = -2.5519416475 
the biases is : 0.1242530000, now tempVal is : -2.4276886475
ReLU !!! in layer: 4, node : 26, its linear result is negative,so set it to 0
compute layer: 4, node : 27
0.0000000000 * -0.5381000000 = 0.0000000000 
1.7845438810 * 0.1524440000 = 0.2720430074 
0.0000000000 * -0.5183780000 = 0.2720430074 
0.6009646532 * 0.2664880000 = 0.4321928759 
0.4463398333 * -0.3361200000 = 0.2821691311 
0.0000000000 * 0.3111890000 = 0.2821691311 
0.0000000000 * 0.2736860000 = 0.2821691311 
0.3475366177 * 0.6342660000 = 0.5025997915 
0.2186928048 * 0.1636620000 = 0.5383914933 
0.0000000000 * -0.0881277000 = 0.5383914933 
0.0000000000 * 1.4431100000 = 0.5383914933 
0.0000000000 * 0.4774000000 = 0.5383914933 
0.0000000000 * -0.2544910000 = 0.5383914933 
0.0000000000 * 0.4725300000 = 0.5383914933 
0.0000000000 * 0.7298540000 = 0.5383914933 
0.0000000000 * 0.5053510000 = 0.5383914933 
0.3887901683 * 0.7901100000 = 0.8455784932 
1.4372682682 * -0.6226070000 = -0.0492747915 
0.0000000000 * 0.2881860000 = -0.0492747915 
0.0000000000 * -0.0220575000 = -0.0492747915 
0.0000000000 * 0.0155291000 = -0.0492747915 
0.0000000000 * -0.0967892000 = -0.0492747915 
1.5809660104 * -0.1459730000 = -0.2800531429 
2.0068238746 * -0.6264590000 = -1.5372460206 
0.0000000000 * 1.8205700000 = -1.5372460206 
0.0000000000 * 0.5752810000 = -1.5372460206 
0.0000000000 * 0.0760229000 = -1.5372460206 
0.7689002813 * -0.0370475000 = -1.5657318538 
0.0000000000 * 0.7554010000 = -1.5657318538 
0.1555103307 * 0.2037290000 = -1.5340498896 
0.0000000000 * 1.0830200000 = -1.5340498896 
0.0923938400 * 0.8665530000 = -1.4539857303 
0.0000000000 * 0.9170210000 = -1.4539857303 
0.0000000000 * -0.0202721000 = -1.4539857303 
0.0000000000 * -0.0860918000 = -1.4539857303 
0.7573677455 * -0.5165560000 = -1.8452085835 
0.0000000000 * 0.2361940000 = -1.8452085835 
0.0000000000 * -0.4735610000 = -1.8452085835 
0.0000000000 * 0.0311525000 = -1.8452085835 
0.0000000000 * 0.6889910000 = -1.8452085835 
0.0000000000 * -0.1543210000 = -1.8452085835 
0.0000000000 * -0.4018350000 = -1.8452085835 
1.8721845553 * -0.0973801000 = -2.0275221027 
0.0000000000 * -0.1155840000 = -2.0275221027 
0.0000000000 * 0.1801030000 = -2.0275221027 
0.0000000000 * 0.4713430000 = -2.0275221027 
0.9141322940 * 0.3699850000 = -1.6893068659 
0.0000000000 * 0.0089326100 = -1.6893068659 
0.0000000000 * -0.2078770000 = -1.6893068659 
0.0000000000 * -0.5464210000 = -1.6893068659 
the biases is : -0.0774607000, now tempVal is : -1.7667675659
ReLU !!! in layer: 4, node : 27, its linear result is negative,so set it to 0
compute layer: 4, node : 28
0.0000000000 * 0.1996860000 = 0.0000000000 
1.7845438810 * -0.0468696000 = -0.0836408579 
0.0000000000 * -0.2488630000 = -0.0836408579 
0.6009646532 * 0.0687756000 = -0.0423091533 
0.4463398333 * 0.1092490000 = 0.0064530272 
0.0000000000 * -0.0485577000 = 0.0064530272 
0.0000000000 * 0.2290450000 = 0.0064530272 
0.3475366177 * 0.1416790000 = 0.0556916676 
0.2186928048 * -0.1578660000 = 0.0211675093 
0.0000000000 * -0.2674540000 = 0.0211675093 
0.0000000000 * 0.4110940000 = 0.0211675093 
0.0000000000 * -0.2434980000 = 0.0211675093 
0.0000000000 * -0.1368580000 = 0.0211675093 
0.0000000000 * -0.2276270000 = 0.0211675093 
0.0000000000 * -0.1093580000 = 0.0211675093 
0.0000000000 * -0.6004690000 = 0.0211675093 
0.3887901683 * 0.1001170000 = 0.0600920146 
1.4372682682 * -0.2082920000 = -0.2392794675 
0.0000000000 * 0.5801270000 = -0.2392794675 
0.0000000000 * 0.0427373000 = -0.2392794675 
0.0000000000 * 0.1667020000 = -0.2392794675 
0.0000000000 * -0.2256220000 = -0.2392794675 
1.5809660104 * -0.0384125000 = -0.3000083244 
2.0068238746 * 0.0517869000 = -0.1960811371 
0.0000000000 * 0.2362660000 = -0.1960811371 
0.0000000000 * 0.2871420000 = -0.1960811371 
0.0000000000 * -0.8652470000 = -0.1960811371 
0.7689002813 * -0.3314210000 = -0.4509108372 
0.0000000000 * 0.0532353000 = -0.4509108372 
0.1555103307 * -0.1167430000 = -0.4690655798 
0.0000000000 * -0.1357790000 = -0.4690655798 
0.0923938400 * 0.2687570000 = -0.4442340885 
0.0000000000 * 0.2808620000 = -0.4442340885 
0.0000000000 * 0.0476134000 = -0.4442340885 
0.0000000000 * 0.3510760000 = -0.4442340885 
0.7573677455 * 0.1046640000 = -0.3649649508 
0.0000000000 * 0.1698130000 = -0.3649649508 
0.0000000000 * 0.1581600000 = -0.3649649508 
0.0000000000 * 0.1178620000 = -0.3649649508 
0.0000000000 * 0.0739293000 = -0.3649649508 
0.0000000000 * 0.1208410000 = -0.3649649508 
0.0000000000 * 0.0057413100 = -0.3649649508 
1.8721845553 * -0.1211060000 = -0.5916977335 
0.0000000000 * -1.4199100000 = -0.5916977335 
0.0000000000 * 0.3256780000 = -0.5916977335 
0.0000000000 * -0.0889758000 = -0.5916977335 
0.9141322940 * 0.0082285700 = -0.5841757320 
0.0000000000 * -0.0173830000 = -0.5841757320 
0.0000000000 * -0.2898490000 = -0.5841757320 
0.0000000000 * 0.0415902000 = -0.5841757320 
the biases is : 0.2888960000, now tempVal is : -0.2952797320
ReLU !!! in layer: 4, node : 28, its linear result is negative,so set it to 0
compute layer: 4, node : 29
0.0000000000 * -0.0274636000 = 0.0000000000 
1.7845438810 * 0.2125350000 = 0.3792780337 
0.0000000000 * 0.2625780000 = 0.3792780337 
0.6009646532 * 0.0758312000 = 0.4248499046 
0.4463398333 * 0.1565970000 = 0.4947453834 
0.0000000000 * 0.0512809000 = 0.4947453834 
0.0000000000 * -0.0235887000 = 0.4947453834 
0.3475366177 * 0.2821790000 = 0.5928129187 
0.2186928048 * 0.4006170000 = 0.6804249740 
0.0000000000 * 1.0562800000 = 0.6804249740 
0.0000000000 * -0.0701181000 = 0.6804249740 
0.0000000000 * -0.1975620000 = 0.6804249740 
0.0000000000 * 0.0215339000 = 0.6804249740 
0.0000000000 * -0.3516600000 = 0.6804249740 
0.0000000000 * 0.1366360000 = 0.6804249740 
0.0000000000 * -0.2953150000 = 0.6804249740 
0.3887901683 * 0.2092850000 = 0.7617929244 
1.4372682682 * -0.0632509000 = 0.6708844129 
0.0000000000 * -1.3592900000 = 0.6708844129 
0.0000000000 * 0.0275848000 = 0.6708844129 
0.0000000000 * -0.3234400000 = 0.6708844129 
0.0000000000 * 0.0316989000 = 0.6708844129 
1.5809660104 * -0.0290122000 = 0.6250171108 
2.0068238746 * 0.1546660000 = 0.9354045322 
0.0000000000 * -1.0193200000 = 0.9354045322 
0.0000000000 * 0.6335420000 = 0.9354045322 
0.0000000000 * -0.0269311000 = 0.9354045322 
0.7689002813 * -0.5272120000 = 0.5300310771 
0.0000000000 * 0.0591076000 = 0.5300310771 
0.1555103307 * 0.0387040000 = 0.5360499489 
0.0000000000 * -0.1816290000 = 0.5360499489 
0.0923938400 * -0.5193630000 = 0.4880640070 
0.0000000000 * 0.3723570000 = 0.4880640070 
0.0000000000 * -0.0966934000 = 0.4880640070 
0.0000000000 * 0.0614291000 = 0.4880640070 
0.7573677455 * 0.3226590000 = 0.7324355264 
0.0000000000 * 0.1863620000 = 0.7324355264 
0.0000000000 * -0.0171104000 = 0.7324355264 
0.0000000000 * -0.0357704000 = 0.7324355264 
0.0000000000 * 0.3564230000 = 0.7324355264 
0.0000000000 * -0.3169420000 = 0.7324355264 
0.0000000000 * -0.2492820000 = 0.7324355264 
1.8721845553 * 0.0663134000 = 0.8565864497 
0.0000000000 * -0.1434190000 = 0.8565864497 
0.0000000000 * 0.5630670000 = 0.8565864497 
0.0000000000 * -0.0990355000 = 0.8565864497 
0.9141322940 * -0.1572020000 = 0.7128830248 
0.0000000000 * -0.0411924000 = 0.7128830248 
0.0000000000 * 0.1708680000 = 0.7128830248 
0.0000000000 * 0.2757530000 = 0.7128830248 
the biases is : -1.9272200000, now tempVal is : -1.2143369752
ReLU !!! in layer: 4, node : 29, its linear result is negative,so set it to 0
compute layer: 4, node : 30
0.0000000000 * 0.3525980000 = 0.0000000000 
1.7845438810 * 0.1756830000 = 0.3135140226 
0.0000000000 * 0.4993000000 = 0.3135140226 
0.6009646532 * 0.0693423000 = 0.3551862939 
0.4463398333 * 0.1401480000 = 0.4177399289 
0.0000000000 * -0.1562570000 = 0.4177399289 
0.0000000000 * 0.0642121000 = 0.4177399289 
0.3475366177 * -0.4227960000 = 0.2708028371 
0.2186928048 * 0.1716310000 = 0.3083373018 
0.0000000000 * 0.7118170000 = 0.3083373018 
0.0000000000 * -0.4097070000 = 0.3083373018 
0.0000000000 * 1.3286800000 = 0.3083373018 
0.0000000000 * 0.1285520000 = 0.3083373018 
0.0000000000 * 0.1746510000 = 0.3083373018 
0.0000000000 * 0.0449173000 = 0.3083373018 
0.0000000000 * 0.0969203000 = 0.3083373018 
0.3887901683 * -0.3140010000 = 0.1862568002 
1.4372682682 * -0.0599927000 = 0.1000311962 
0.0000000000 * 0.0913280000 = 0.1000311962 
0.0000000000 * -0.0295815000 = 0.1000311962 
0.0000000000 * 0.1159810000 = 0.1000311962 
0.0000000000 * 0.2036320000 = 0.1000311962 
1.5809660104 * -0.0623232000 = 0.0015003353 
2.0068238746 * 0.0947363000 = 0.1916194039 
0.0000000000 * -0.3783810000 = 0.1916194039 
0.0000000000 * 0.4318890000 = 0.1916194039 
0.0000000000 * -0.1226620000 = 0.1916194039 
0.7689002813 * 0.6332760000 = 0.6785454985 
0.0000000000 * 0.9215440000 = 0.6785454985 
0.1555103307 * -0.0238261000 = 0.6748402938 
0.0000000000 * 0.3294590000 = 0.6748402938 
0.0923938400 * -0.2274330000 = 0.6538268856 
0.0000000000 * -0.2509300000 = 0.6538268856 
0.0000000000 * -0.1076610000 = 0.6538268856 
0.0000000000 * 0.0981795000 = 0.6538268856 
0.7573677455 * -0.3020930000 = 0.4250313913 
0.0000000000 * -0.1242670000 = 0.4250313913 
0.0000000000 * 0.2244450000 = 0.4250313913 
0.0000000000 * -0.2000820000 = 0.4250313913 
0.0000000000 * -0.2362940000 = 0.4250313913 
0.0000000000 * 0.0683952000 = 0.4250313913 
0.0000000000 * -0.2783030000 = 0.4250313913 
1.8721845553 * -0.0632587000 = 0.3065994301 
0.0000000000 * -0.0602085000 = 0.3065994301 
0.0000000000 * 0.1677850000 = 0.3065994301 
0.0000000000 * -0.6242240000 = 0.3065994301 
0.9141322940 * 0.0874415000 = 0.3865325291 
0.0000000000 * 0.0121920000 = 0.3865325291 
0.0000000000 * -0.0591805000 = 0.3865325291 
0.0000000000 * -0.8268480000 = 0.3865325291 
the biases is : -1.8612800000, now tempVal is : -1.4747474709
ReLU !!! in layer: 4, node : 30, its linear result is negative,so set it to 0
compute layer: 4, node : 31
0.0000000000 * 0.4745510000 = 0.0000000000 
1.7845438810 * 0.1754000000 = 0.3130089967 
0.0000000000 * 0.2245680000 = 0.3130089967 
0.6009646532 * -0.0534589000 = 0.2808820874 
0.4463398333 * -0.0647308000 = 0.2519901529 
0.0000000000 * 0.4862980000 = 0.2519901529 
0.0000000000 * -0.0113396000 = 0.2519901529 
0.3475366177 * -0.0082378500 = 0.2491271984 
0.2186928048 * 0.2702670000 = 0.3082326467 
0.0000000000 * -0.7522510000 = 0.3082326467 
0.0000000000 * 0.0373830000 = 0.3082326467 
0.0000000000 * -3.7993800000 = 0.3082326467 
0.0000000000 * -0.0753188000 = 0.3082326467 
0.0000000000 * -0.7249090000 = 0.3082326467 
0.0000000000 * 0.0096323300 = 0.3082326467 
0.0000000000 * 0.6138900000 = 0.3082326467 
0.3887901683 * -0.5562130000 = 0.0919825008 
1.4372682682 * 0.9035740000 = 1.3906607390 
0.0000000000 * -0.2457280000 = 1.3906607390 
0.0000000000 * -0.0013275300 = 1.3906607390 
0.0000000000 * -0.1956210000 = 1.3906607390 
0.0000000000 * 0.1442360000 = 1.3906607390 
1.5809660104 * -0.0042543200 = 1.3839348036 
2.0068238746 * 0.1025860000 = 1.5898068376 
0.0000000000 * -0.6277850000 = 1.5898068376 
0.0000000000 * -0.9742800000 = 1.5898068376 
0.0000000000 * -0.1139610000 = 1.5898068376 
0.7689002813 * -0.1447360000 = 1.4785192865 
0.0000000000 * -0.4619960000 = 1.4785192865 
0.1555103307 * 0.2305180000 = 1.5143672169 
0.0000000000 * 0.0353598000 = 1.5143672169 
0.0923938400 * -0.6011880000 = 1.4588211490 
0.0000000000 * -0.2146710000 = 1.4588211490 
0.0000000000 * -0.0520341000 = 1.4588211490 
0.0000000000 * -0.2953050000 = 1.4588211490 
0.7573677455 * 0.4610660000 = 1.8080176660 
0.0000000000 * 0.0584576000 = 1.8080176660 
0.0000000000 * 0.1081170000 = 1.8080176660 
0.0000000000 * -0.2239260000 = 1.8080176660 
0.0000000000 * 0.4593360000 = 1.8080176660 
0.0000000000 * -0.3943090000 = 1.8080176660 
0.0000000000 * -0.0593100000 = 1.8080176660 
1.8721845553 * 0.2422340000 = 2.2615244195 
0.0000000000 * -0.2463670000 = 2.2615244195 
0.0000000000 * 0.6150510000 = 2.2615244195 
0.0000000000 * 0.0480675000 = 2.2615244195 
0.9141322940 * 0.0331153000 = 2.2917961847 
0.0000000000 * -0.0176990000 = 2.2917961847 
0.0000000000 * 0.1992870000 = 2.2917961847 
0.0000000000 * -0.0198854000 = 2.2917961847 
the biases is : 0.5074990000, now tempVal is : 2.7992951847
compute layer: 4, node : 32
0.0000000000 * 0.3788660000 = 0.0000000000 
1.7845438810 * 0.1195110000 = 0.2132726238 
0.0000000000 * 0.7596540000 = 0.2132726238 
0.6009646532 * 0.4733470000 = 0.4977374395 
0.4463398333 * 0.3271170000 = 0.6437427867 
0.0000000000 * 0.0602863000 = 0.6437427867 
0.0000000000 * 0.4654280000 = 0.6437427867 
0.3475366177 * -0.0477588000 = 0.6271448549 
0.2186928048 * -1.1063600000 = 0.3851918834 
0.0000000000 * -0.8408850000 = 0.3851918834 
0.0000000000 * 0.9964210000 = 0.3851918834 
0.0000000000 * -1.3708600000 = 0.3851918834 
0.0000000000 * 0.2486690000 = 0.3851918834 
0.0000000000 * 0.1376780000 = 0.3851918834 
0.0000000000 * -0.0285648000 = 0.3851918834 
0.0000000000 * 0.2053750000 = 0.3851918834 
0.3887901683 * -0.8265980000 = 0.0638187079 
1.4372682682 * 0.5383840000 = 0.8376209472 
0.0000000000 * 0.2421100000 = 0.8376209472 
0.0000000000 * -0.0157577000 = 0.8376209472 
0.0000000000 * 0.3910420000 = 0.8376209472 
0.0000000000 * -0.5718860000 = 0.8376209472 
1.5809660104 * 0.2197810000 = 1.1850872379 
2.0068238746 * 0.2986480000 = 1.7844211744 
0.0000000000 * -1.7190600000 = 1.7844211744 
0.0000000000 * -0.4369830000 = 1.7844211744 
0.0000000000 * 0.3915080000 = 1.7844211744 
0.7689002813 * 0.9925030000 = 2.5475570103 
0.0000000000 * 0.3789920000 = 2.5475570103 
0.1555103307 * 0.5191420000 = 2.6282889544 
0.0000000000 * -1.5471600000 = 2.6282889544 
0.0923938400 * -0.3610450000 = 2.5949306205 
0.0000000000 * -0.7578640000 = 2.5949306205 
0.0000000000 * -0.3860370000 = 2.5949306205 
0.0000000000 * -0.0014988500 = 2.5949306205 
0.7573677455 * -1.1383300000 = 1.7327961947 
0.0000000000 * 0.0310359000 = 1.7327961947 
0.0000000000 * 0.0954513000 = 1.7327961947 
0.0000000000 * -0.3429380000 = 1.7327961947 
0.0000000000 * 0.1969760000 = 1.7327961947 
0.0000000000 * 0.1728540000 = 1.7327961947 
0.0000000000 * -0.0837823000 = 1.7327961947 
1.8721845553 * 0.1745510000 = 2.0595878811 
0.0000000000 * -0.9015110000 = 2.0595878811 
0.0000000000 * -0.0067474400 = 2.0595878811 
0.0000000000 * -1.0339100000 = 2.0595878811 
0.9141322940 * 0.3417310000 = 2.3719752240 
0.0000000000 * 0.0297450000 = 2.3719752240 
0.0000000000 * -0.0012720300 = 2.3719752240 
0.0000000000 * -2.3937800000 = 2.3719752240 
the biases is : 2.0864300000, now tempVal is : 4.4584052240
compute layer: 4, node : 33
0.0000000000 * 0.6022610000 = 0.0000000000 
1.7845438810 * 0.3403640000 = 0.6073944935 
0.0000000000 * -0.2818640000 = 0.6073944935 
0.6009646532 * 0.1097260000 = 0.6733359410 
0.4463398333 * 0.1942380000 = 0.7600320976 
0.0000000000 * 0.1475490000 = 0.7600320976 
0.0000000000 * -0.8248190000 = 0.7600320976 
0.3475366177 * -0.0009381340 = 0.7597060617 
0.2186928048 * 0.0117072000 = 0.7622663421 
0.0000000000 * -0.5284000000 = 0.7622663421 
0.0000000000 * 0.8543590000 = 0.7622663421 
0.0000000000 * -0.1454250000 = 0.7622663421 
0.0000000000 * -0.2357940000 = 0.7622663421 
0.0000000000 * -0.0985602000 = 0.7622663421 
0.0000000000 * 0.0251230000 = 0.7622663421 
0.0000000000 * 0.6864170000 = 0.7622663421 
0.3887901683 * -0.5097010000 = 0.5640996045 
1.4372682682 * 0.4598210000 = 1.2249857368 
0.0000000000 * 0.0916296000 = 1.2249857368 
0.0000000000 * 0.0038179000 = 1.2249857368 
0.0000000000 * 0.0751452000 = 1.2249857368 
0.0000000000 * -0.3740890000 = 1.2249857368 
1.5809660104 * 0.3620930000 = 1.7974424624 
2.0068238746 * 0.3419070000 = 2.4835895929 
0.0000000000 * -0.6108040000 = 2.4835895929 
0.0000000000 * -0.4448180000 = 2.4835895929 
0.0000000000 * 0.4599270000 = 2.4835895929 
0.7689002813 * -0.0788684000 = 2.4229476580 
0.0000000000 * 0.0581982000 = 2.4229476580 
0.1555103307 * -0.1023560000 = 2.4070302426 
0.0000000000 * 0.2624210000 = 2.4070302426 
0.0923938400 * 0.4242480000 = 2.4462281444 
0.0000000000 * 0.0636367000 = 2.4462281444 
0.0000000000 * 0.0027171900 = 2.4462281444 
0.0000000000 * 0.1300940000 = 2.4462281444 
0.7573677455 * -0.1837850000 = 2.3070353133 
0.0000000000 * 0.0719449000 = 2.3070353133 
0.0000000000 * 0.4586730000 = 2.3070353133 
0.0000000000 * -0.5817600000 = 2.3070353133 
0.0000000000 * -0.2437370000 = 2.3070353133 
0.0000000000 * 0.2247540000 = 2.3070353133 
0.0000000000 * -0.2432090000 = 2.3070353133 
1.8721845553 * 0.4859080000 = 3.2167447662 
0.0000000000 * -0.7439690000 = 3.2167447662 
0.0000000000 * -0.0912507000 = 3.2167447662 
0.0000000000 * -0.2953170000 = 3.2167447662 
0.9141322940 * 0.3968350000 = 3.5795044551 
0.0000000000 * 0.0060138100 = 3.5795044551 
0.0000000000 * 0.5951250000 = 3.5795044551 
0.0000000000 * 0.1843600000 = 3.5795044551 
the biases is : -0.1009750000, now tempVal is : 3.4785294551
compute layer: 4, node : 34
0.0000000000 * -0.7484030000 = 0.0000000000 
1.7845438810 * -0.6367720000 = -1.1363475762 
0.0000000000 * -2.1634900000 = -1.1363475762 
0.6009646532 * -0.2057060000 = -1.2599696111 
0.4463398333 * -0.7807550000 = -1.6084516677 
0.0000000000 * -1.2075600000 = -1.6084516677 
0.0000000000 * 0.6397860000 = -1.6084516677 
0.3475366177 * 0.6272620000 = -1.3904551538 
0.2186928048 * -0.0241441000 = -1.3957352948 
0.0000000000 * -1.2865900000 = -1.3957352948 
0.0000000000 * -0.4046260000 = -1.3957352948 
0.0000000000 * -0.1277750000 = -1.3957352948 
0.0000000000 * -0.4243410000 = -1.3957352948 
0.0000000000 * 1.4380500000 = -1.3957352948 
0.0000000000 * -0.8856560000 = -1.3957352948 
0.0000000000 * 0.5438010000 = -1.3957352948 
0.3887901683 * 0.5417010000 = -1.1851272718 
1.4372682682 * -1.0588100000 = -2.7069212868 
0.0000000000 * -0.6530640000 = -2.7069212868 
0.0000000000 * -0.0417738000 = -2.7069212868 
0.0000000000 * 0.3242520000 = -2.7069212868 
0.0000000000 * -1.3627400000 = -2.7069212868 
1.5809660104 * -0.5750380000 = -3.6160368195 
2.0068238746 * -8.5347500000 = -20.7437768834 
0.0000000000 * 0.7491360000 = -20.7437768834 
0.0000000000 * 0.7880730000 = -20.7437768834 
0.0000000000 * 1.4379600000 = -20.7437768834 
0.7689002813 * 0.1088800000 = -20.6600590207 
0.0000000000 * -0.2059320000 = -20.6600590207 
0.1555103307 * 0.1773820000 = -20.6324742873 
0.0000000000 * 0.8448310000 = -20.6324742873 
0.0923938400 * -0.3212590000 = -20.6621566399 
0.0000000000 * 1.5214700000 = -20.6621566399 
0.0000000000 * 0.5253080000 = -20.6621566399 
0.0000000000 * -0.2930000000 = -20.6621566399 
0.7573677455 * -0.5658650000 = -21.0907245392 
0.0000000000 * -0.7429140000 = -21.0907245392 
0.0000000000 * -0.2068440000 = -21.0907245392 
0.0000000000 * -0.2979900000 = -21.0907245392 
0.0000000000 * -0.5091720000 = -21.0907245392 
0.0000000000 * -14.1563000000 = -21.0907245392 
0.0000000000 * 0.2199410000 = -21.0907245392 
1.8721845553 * -0.8740530000 = -22.7271130663 
0.0000000000 * -0.3726850000 = -22.7271130663 
0.0000000000 * 0.0370511000 = -22.7271130663 
0.0000000000 * 1.0592900000 = -22.7271130663 
0.9141322940 * 0.1508170000 = -22.5892463762 
0.0000000000 * 0.0322220000 = -22.5892463762 
0.0000000000 * -0.0682674000 = -22.5892463762 
0.0000000000 * -0.2966500000 = -22.5892463762 
the biases is : 0.3029890000, now tempVal is : -22.2862573762
ReLU !!! in layer: 4, node : 34, its linear result is negative,so set it to 0
compute layer: 4, node : 35
0.0000000000 * -0.1247410000 = 0.0000000000 
1.7845438810 * -0.1629260000 = -0.2907485964 
0.0000000000 * 0.1705520000 = -0.2907485964 
0.6009646532 * 0.3289120000 = -0.0930841103 
0.4463398333 * 0.0669338000 = -0.0632088892 
0.0000000000 * 0.1565760000 = -0.0632088892 
0.0000000000 * -0.2576250000 = -0.0632088892 
0.3475366177 * -0.0531151000 = -0.0816683314 
0.2186928048 * 0.3520680000 = -0.0046735930 
0.0000000000 * 0.1692120000 = -0.0046735930 
0.0000000000 * -0.0182598000 = -0.0046735930 
0.0000000000 * 0.5289420000 = -0.0046735930 
0.0000000000 * -0.0779359000 = -0.0046735930 
0.0000000000 * 0.1555860000 = -0.0046735930 
0.0000000000 * -0.0530677000 = -0.0046735930 
0.0000000000 * -0.1568310000 = -0.0046735930 
0.3887901683 * 0.0738825000 = 0.0240511966 
1.4372682682 * -0.3463590000 = -0.4737596035 
0.0000000000 * -0.0307599000 = -0.4737596035 
0.0000000000 * -0.0178460000 = -0.4737596035 
0.0000000000 * 0.1156680000 = -0.4737596035 
0.0000000000 * -0.2854050000 = -0.4737596035 
1.5809660104 * -0.0470935000 = -0.5482128263 
2.0068238746 * 0.0752342000 = -0.3972310376 
0.0000000000 * -0.1085580000 = -0.3972310376 
0.0000000000 * 0.0193448000 = -0.3972310376 
0.0000000000 * -0.0185526000 = -0.3972310376 
0.7689002813 * -0.3129350000 = -0.6378468471 
0.0000000000 * 0.1237680000 = -0.6378468471 
0.1555103307 * 0.0695548000 = -0.6270303572 
0.0000000000 * 0.1169730000 = -0.6270303572 
0.0923938400 * 0.0987867000 = -0.6179030746 
0.0000000000 * 0.0791165000 = -0.6179030746 
0.0000000000 * 0.1851210000 = -0.6179030746 
0.0000000000 * -0.0299353000 = -0.6179030746 
0.7573677455 * 0.2965640000 = -0.3932950665 
0.0000000000 * 0.0418700000 = -0.3932950665 
0.0000000000 * -0.0909792000 = -0.3932950665 
0.0000000000 * -0.0942280000 = -0.3932950665 
0.0000000000 * -0.0635512000 = -0.3932950665 
0.0000000000 * 0.0495894000 = -0.3932950665 
0.0000000000 * -0.1611800000 = -0.3932950665 
1.8721845553 * 0.0569596000 = -0.2866561832 
0.0000000000 * 0.2890360000 = -0.2866561832 
0.0000000000 * -0.0693617000 = -0.2866561832 
0.0000000000 * 0.3863880000 = -0.2866561832 
0.9141322940 * 0.1052080000 = -0.1904821528 
0.0000000000 * 0.0144340000 = -0.1904821528 
0.0000000000 * 0.2074830000 = -0.1904821528 
0.0000000000 * -0.0272354000 = -0.1904821528 
the biases is : -0.8008850000, now tempVal is : -0.9913671528
ReLU !!! in layer: 4, node : 35, its linear result is negative,so set it to 0
compute layer: 4, node : 36
0.0000000000 * 0.0224740000 = 0.0000000000 
1.7845438810 * 0.2352870000 = 0.4198799761 
0.0000000000 * -0.0024400800 = 0.4198799761 
0.6009646532 * 0.2353070000 = 0.5612911658 
0.4463398333 * -0.3127560000 = 0.4216957049 
0.0000000000 * 0.2168590000 = 0.4216957049 
0.0000000000 * -0.2119500000 = 0.4216957049 
0.3475366177 * 0.1438210000 = 0.4716787688 
0.2186928048 * 0.0453539000 = 0.4815973404 
0.0000000000 * 0.0774843000 = 0.4815973404 
0.0000000000 * 0.5336020000 = 0.4815973404 
0.0000000000 * 0.0781961000 = 0.4815973404 
0.0000000000 * -0.1276020000 = 0.4815973404 
0.0000000000 * -0.1116690000 = 0.4815973404 
0.0000000000 * 0.0441877000 = 0.4815973404 
0.0000000000 * -0.1998330000 = 0.4815973404 
0.3887901683 * 0.3873780000 = 0.6322060982 
1.4372682682 * 0.1713770000 = 0.8785208222 
0.0000000000 * -0.0539647000 = 0.8785208222 
0.0000000000 * -0.0116704000 = 0.8785208222 
0.0000000000 * 0.2168370000 = 0.8785208222 
0.0000000000 * 0.3361690000 = 0.8785208222 
1.5809660104 * -0.1911360000 = 0.5763413028 
2.0068238746 * -0.0564440000 = 0.4630681360 
0.0000000000 * -0.0918126000 = 0.4630681360 
0.0000000000 * -0.0871454000 = 0.4630681360 
0.0000000000 * -0.1916850000 = 0.4630681360 
0.7689002813 * -0.0875547000 = 0.3957473026 
0.0000000000 * -0.0195604000 = 0.3957473026 
0.1555103307 * -0.0454604000 = 0.3886777407 
0.0000000000 * 0.1536920000 = 0.3886777407 
0.0923938400 * 0.0835261000 = 0.3963950379 
0.0000000000 * 0.0435516000 = 0.3963950379 
0.0000000000 * 0.0498551000 = 0.3963950379 
0.0000000000 * 0.0846846000 = 0.3963950379 
0.7573677455 * -0.0676435000 = 0.3451640328 
0.0000000000 * 0.3163150000 = 0.3451640328 
0.0000000000 * -0.2716330000 = 0.3451640328 
0.0000000000 * 0.1642630000 = 0.3451640328 
0.0000000000 * 0.0954315000 = 0.3451640328 
0.0000000000 * -0.2312370000 = 0.3451640328 
0.0000000000 * -0.2977580000 = 0.3451640328 
1.8721845553 * -0.0370829000 = 0.2757380001 
0.0000000000 * -0.3408450000 = 0.2757380001 
0.0000000000 * 0.0953337000 = 0.2757380001 
0.0000000000 * 0.0025578500 = 0.2757380001 
0.9141322940 * -0.0391291000 = 0.2399688262 
0.0000000000 * -0.0103593000 = 0.2399688262 
0.0000000000 * -0.1727530000 = 0.2399688262 
0.0000000000 * -0.0876668000 = 0.2399688262 
the biases is : -0.1665010000, now tempVal is : 0.0734678262
compute layer: 4, node : 37
0.0000000000 * -1.6583900000 = 0.0000000000 
1.7845438810 * -0.2685140000 = -0.4791750157 
0.0000000000 * -0.4157260000 = -0.4791750157 
0.6009646532 * -0.3857640000 = -0.7110055441 
0.4463398333 * -0.0920057000 = -0.7520713529 
0.0000000000 * 0.3491360000 = -0.7520713529 
0.0000000000 * -1.4613400000 = -0.7520713529 
0.3475366177 * 0.9370330000 = -0.4264180735 
0.2186928048 * -0.3119800000 = -0.4946458547 
0.0000000000 * 1.9315900000 = -0.4946458547 
0.0000000000 * -1.5840800000 = -0.4946458547 
0.0000000000 * 0.4610030000 = -0.4946458547 
0.0000000000 * 0.2266040000 = -0.4946458547 
0.0000000000 * -0.4387750000 = -0.4946458547 
0.0000000000 * 0.0652080000 = -0.4946458547 
0.0000000000 * -1.6540900000 = -0.4946458547 
0.3887901683 * 1.6677600000 = 0.1537628364 
1.4372682682 * -0.4882280000 = -0.5479517756 
0.0000000000 * -0.2206800000 = -0.5479517756 
0.0000000000 * 0.0494186000 = -0.5479517756 
0.0000000000 * -0.6819280000 = -0.5479517756 
0.0000000000 * 1.4358800000 = -0.5479517756 
1.5809660104 * -0.3183330000 = -1.0512254286 
2.0068238746 * -0.5330170000 = -2.1208966698 
0.0000000000 * 0.9216690000 = -2.1208966698 
0.0000000000 * 0.3424680000 = -2.1208966698 
0.0000000000 * -0.3686550000 = -2.1208966698 
0.7689002813 * 0.7222690000 = -1.5655438325 
0.0000000000 * -0.1700200000 = -1.5655438325 
0.1555103307 * -0.7106360000 = -1.6760550718 
0.0000000000 * 0.2319240000 = -1.6760550718 
0.0923938400 * -2.6164900000 = -1.9178026303 
0.0000000000 * -0.1733470000 = -1.9178026303 
0.0000000000 * 0.1986050000 = -1.9178026303 
0.0000000000 * 0.9511480000 = -1.9178026303 
0.7573677455 * 0.7432590000 = -1.3548822372 
0.0000000000 * -0.0409588000 = -1.3548822372 
0.0000000000 * -1.7171800000 = -1.3548822372 
0.0000000000 * -1.0648200000 = -1.3548822372 
0.0000000000 * 0.1123920000 = -1.3548822372 
0.0000000000 * 0.8460930000 = -1.3548822372 
0.0000000000 * -0.6403380000 = -1.3548822372 
1.8721845553 * -0.3911060000 = -2.0871048499 
0.0000000000 * 0.3163630000 = -2.0871048499 
0.0000000000 * 0.9726690000 = -2.0871048499 
0.0000000000 * -1.0946100000 = -2.0871048499 
0.9141322940 * -0.6807550000 = -2.7094049797 
0.0000000000 * -0.0284211000 = -2.7094049797 
0.0000000000 * -1.4638000000 = -2.7094049797 
0.0000000000 * 0.7686680000 = -2.7094049797 
the biases is : 0.2249150000, now tempVal is : -2.4844899797
ReLU !!! in layer: 4, node : 37, its linear result is negative,so set it to 0
compute layer: 4, node : 38
0.0000000000 * 0.2373300000 = 0.0000000000 
1.7845438810 * -0.1011650000 = -0.1805333817 
0.0000000000 * 0.8898480000 = -0.1805333817 
0.6009646532 * -6.5204100000 = -4.0990693161 
0.4463398333 * -1.6590600000 = -4.8395738799 
0.0000000000 * -0.8557360000 = -4.8395738799 
0.0000000000 * -0.3177890000 = -4.8395738799 
0.3475366177 * 1.5312000000 = -4.3074258109 
0.2186928048 * -0.9180910000 = -4.5082057067 
0.0000000000 * 2.7064700000 = -4.5082057067 
0.0000000000 * -0.2647350000 = -4.5082057067 
0.0000000000 * 1.0440300000 = -4.5082057067 
0.0000000000 * 0.5268540000 = -4.5082057067 
0.0000000000 * 0.6718540000 = -4.5082057067 
0.0000000000 * 1.2374400000 = -4.5082057067 
0.0000000000 * 0.1912850000 = -4.5082057067 
0.3887901683 * -0.1211670000 = -4.5553142450 
1.4372682682 * -1.5463900000 = -6.7778915223 
0.0000000000 * 0.3883710000 = -6.7778915223 
0.0000000000 * 0.0255405000 = -6.7778915223 
0.0000000000 * -0.7825190000 = -6.7778915223 
0.0000000000 * 3.8987200000 = -6.7778915223 
1.5809660104 * 0.6874860000 = -5.6909995237 
2.0068238746 * -0.4552950000 = -6.6046963997 
0.0000000000 * -0.0177547000 = -6.6046963997 
0.0000000000 * 0.3498580000 = -6.6046963997 
0.0000000000 * 0.3185820000 = -6.6046963997 
0.7689002813 * -0.8568090000 = -7.2634970808 
0.0000000000 * 0.5030590000 = -7.2634970808 
0.1555103307 * 0.7428810000 = -7.1479714108 
0.0000000000 * -0.6329540000 = -7.1479714108 
0.0923938400 * -0.9490510000 = -7.2356578771 
0.0000000000 * -2.3058200000 = -7.2356578771 
0.0000000000 * -0.8147930000 = -7.2356578771 
0.0000000000 * 0.4790760000 = -7.2356578771 
0.7573677455 * -0.3559390000 = -7.5052345951 
0.0000000000 * -0.5436080000 = -7.5052345951 
0.0000000000 * 0.2225560000 = -7.5052345951 
0.0000000000 * -0.8061050000 = -7.5052345951 
0.0000000000 * -0.3698080000 = -7.5052345951 
0.0000000000 * 0.6637370000 = -7.5052345951 
0.0000000000 * -0.0942454000 = -7.5052345951 
1.8721845553 * -0.1704930000 = -7.8244289565 
0.0000000000 * -1.9963200000 = -7.8244289565 
0.0000000000 * -2.7029700000 = -7.8244289565 
0.0000000000 * -0.0341367000 = -7.8244289565 
0.9141322940 * -0.8758750000 = -8.6250945794 
0.0000000000 * -0.0315950000 = -8.6250945794 
0.0000000000 * -0.2157030000 = -8.6250945794 
0.0000000000 * -2.3129000000 = -8.6250945794 
the biases is : -0.3137700000, now tempVal is : -8.9388645794
ReLU !!! in layer: 4, node : 38, its linear result is negative,so set it to 0
compute layer: 4, node : 39
0.0000000000 * 0.0550891000 = 0.0000000000 
1.7845438810 * -0.0224943000 = -0.0401420654 
0.0000000000 * -0.0622061000 = -0.0401420654 
0.6009646532 * -0.1805620000 = -0.1486534451 
0.4463398333 * 0.0120773000 = -0.1432628651 
0.0000000000 * -0.0093625400 = -0.1432628651 
0.0000000000 * 0.0569820000 = -0.1432628651 
0.3475366177 * 0.2192660000 = -0.0670599011 
0.2186928048 * -0.0034162200 = -0.0678070038 
0.0000000000 * -0.0156384000 = -0.0678070038 
0.0000000000 * -0.0508868000 = -0.0678070038 
0.0000000000 * 0.2862120000 = -0.0678070038 
0.0000000000 * -0.0620782000 = -0.0678070038 
0.0000000000 * -0.1346470000 = -0.0678070038 
0.0000000000 * 0.1385510000 = -0.0678070038 
0.0000000000 * -0.1842820000 = -0.0678070038 
0.3887901683 * -0.1537110000 = -0.1275683293 
1.4372682682 * -0.1780600000 = -0.3834883172 
0.0000000000 * -0.2075500000 = -0.3834883172 
0.0000000000 * -0.0176937000 = -0.3834883172 
0.0000000000 * 0.0252140000 = -0.3834883172 
0.0000000000 * 0.2833030000 = -0.3834883172 
1.5809660104 * -0.1587720000 = -0.6345014526 
2.0068238746 * -0.0791035000 = -0.7932482449 
0.0000000000 * 0.2691240000 = -0.7932482449 
0.0000000000 * 0.0119783000 = -0.7932482449 
0.0000000000 * -0.1446840000 = -0.7932482449 
0.7689002813 * -0.0763744000 = -0.8519725426 
0.0000000000 * 0.0436833000 = -0.8519725426 
0.1555103307 * -0.2133780000 = -0.8851550259 
0.0000000000 * -0.0024752100 = -0.8851550259 
0.0923938400 * 0.4565910000 = -0.8429688301 
0.0000000000 * 0.1894970000 = -0.8429688301 
0.0000000000 * -0.0156866000 = -0.8429688301 
0.0000000000 * -0.0295005000 = -0.8429688301 
0.7573677455 * -0.0234373000 = -0.8607194852 
0.0000000000 * -0.0999273000 = -0.8607194852 
0.0000000000 * 0.0249284000 = -0.8607194852 
0.0000000000 * 0.1653120000 = -0.8607194852 
0.0000000000 * 0.0362619000 = -0.8607194852 
0.0000000000 * 0.1279520000 = -0.8607194852 
0.0000000000 * -0.1028600000 = -0.8607194852 
1.8721845553 * -0.1718890000 = -1.1825274162 
0.0000000000 * -0.0592073000 = -1.1825274162 
0.0000000000 * -0.3646820000 = -1.1825274162 
0.0000000000 * 0.3645850000 = -1.1825274162 
0.9141322940 * -0.0025849800 = -1.1848904299 
0.0000000000 * -0.0270025000 = -1.1848904299 
0.0000000000 * -0.1269340000 = -1.1848904299 
0.0000000000 * 0.0734512000 = -1.1848904299 
the biases is : -0.0885139000, now tempVal is : -1.2734043299
ReLU !!! in layer: 4, node : 39, its linear result is negative,so set it to 0
compute layer: 4, node : 40
0.0000000000 * 0.3254530000 = 0.0000000000 
1.7845438810 * 0.1430560000 = 0.2552897094 
0.0000000000 * 0.2794040000 = 0.2552897094 
0.6009646532 * -0.4357660000 = -0.0065902536 
0.4463398333 * 0.1587350000 = 0.0642594998 
0.0000000000 * -0.0589792000 = 0.0642594998 
0.0000000000 * 0.5760840000 = 0.0642594998 
0.3475366177 * -0.0931796000 = 0.0318761768 
0.2186928048 * -0.5059090000 = -0.0787624814 
0.0000000000 * 0.2369910000 = -0.0787624814 
0.0000000000 * -0.6637490000 = -0.0787624814 
0.0000000000 * -0.3742760000 = -0.0787624814 
0.0000000000 * -0.0838953000 = -0.0787624814 
0.0000000000 * 0.1196380000 = -0.0787624814 
0.0000000000 * -0.1425040000 = -0.0787624814 
0.0000000000 * 0.2513420000 = -0.0787624814 
0.3887901683 * -0.1400830000 = -0.1332253745 
1.4372682682 * -0.1624700000 = -0.3667383500 
0.0000000000 * 0.3909230000 = -0.3667383500 
0.0000000000 * -0.0393040000 = -0.3667383500 
0.0000000000 * 0.0017032600 = -0.3667383500 
0.0000000000 * -0.2475000000 = -0.3667383500 
1.5809660104 * 0.1977280000 = -0.0541371027 
2.0068238746 * 0.1404300000 = 0.2276811740 
0.0000000000 * 0.0115669000 = 0.2276811740 
0.0000000000 * -0.3697470000 = 0.2276811740 
0.0000000000 * 0.0879365000 = 0.2276811740 
0.7689002813 * -0.0259219000 = 0.2077498178 
0.0000000000 * -0.6736740000 = 0.2077498178 
0.1555103307 * -0.0861135000 = 0.1943582789 
0.0000000000 * -0.7105690000 = 0.1943582789 
0.0923938400 * 1.1106300000 = 0.2969736495 
0.0000000000 * -0.0791780000 = 0.2969736495 
0.0000000000 * -0.0128023000 = 0.2969736495 
0.0000000000 * -0.2245070000 = 0.2969736495 
0.7573677455 * -0.3269760000 = 0.0493325735 
0.0000000000 * -0.3921090000 = 0.0493325735 
0.0000000000 * -0.5948430000 = 0.0493325735 
0.0000000000 * -0.0020739800 = 0.0493325735 
0.0000000000 * -0.4877410000 = 0.0493325735 
0.0000000000 * -0.2107190000 = 0.0493325735 
0.0000000000 * 0.0861112000 = 0.0493325735 
1.8721845553 * 0.0942854000 = 0.2258522432 
0.0000000000 * 0.3430880000 = 0.2258522432 
0.0000000000 * 0.4392100000 = 0.2258522432 
0.0000000000 * -0.2256620000 = 0.2258522432 
0.9141322940 * 0.0444574000 = 0.2664921882 
0.0000000000 * -0.0193008000 = 0.2664921882 
0.0000000000 * 0.4525090000 = 0.2664921882 
0.0000000000 * 1.0452800000 = 0.2664921882 
the biases is : -0.0413228000, now tempVal is : 0.2251693882
compute layer: 4, node : 41
0.0000000000 * -0.6036520000 = 0.0000000000 
1.7845438810 * -0.0582643000 = -0.1039752000 
0.0000000000 * -0.1194650000 = -0.1039752000 
0.6009646532 * 0.3480170000 = 0.1051707157 
0.4463398333 * -0.1643470000 = 0.0318161031 
0.0000000000 * 0.4335650000 = 0.0318161031 
0.0000000000 * -0.8743860000 = 0.0318161031 
0.3475366177 * -0.7314280000 = -0.2223819101 
0.2186928048 * -0.9071850000 = -0.4207767422 
0.0000000000 * -1.2377800000 = -0.4207767422 
0.0000000000 * 1.5010700000 = -0.4207767422 
0.0000000000 * -2.7387800000 = -0.4207767422 
0.0000000000 * -0.0566513000 = -0.4207767422 
0.0000000000 * 1.0419300000 = -0.4207767422 
0.0000000000 * 0.5749150000 = -0.4207767422 
0.0000000000 * -0.0406978000 = -0.4207767422 
0.3887901683 * -1.2090800000 = -0.8908551589 
1.4372682682 * 0.5298250000 = -0.1293544987 
0.0000000000 * 1.6484700000 = -0.1293544987 
0.0000000000 * -0.0171819000 = -0.1293544987 
0.0000000000 * -0.1473320000 = -0.1293544987 
0.0000000000 * 0.0717936000 = -0.1293544987 
1.5809660104 * -0.0300766000 = -0.1769045810 
2.0068238746 * 0.3028660000 = 0.4308941386 
0.0000000000 * 0.9063370000 = 0.4308941386 
0.0000000000 * -3.5573100000 = 0.4308941386 
0.0000000000 * -0.8105850000 = 0.4308941386 
0.7689002813 * -0.1498280000 = 0.3156913472 
0.0000000000 * -1.6091000000 = 0.3156913472 
0.1555103307 * -0.7071940000 = 0.2057153744 
0.0000000000 * 0.0339607000 = 0.2057153744 
0.0923938400 * 1.6052600000 = 0.3540315101 
0.0000000000 * -0.5726660000 = 0.3540315101 
0.0000000000 * -0.3516520000 = 0.3540315101 
0.0000000000 * -0.0019823000 = 0.3540315101 
0.7573677455 * -0.3160280000 = 0.1146820962 
0.0000000000 * 1.1095700000 = 0.1146820962 
0.0000000000 * -0.8697830000 = 0.1146820962 
0.0000000000 * -0.3549480000 = 0.1146820962 
0.0000000000 * -0.2347480000 = 0.1146820962 
0.0000000000 * 0.4866530000 = 0.1146820962 
0.0000000000 * 0.3684610000 = 0.1146820962 
1.8721845553 * 0.5081040000 = 1.0659465575 
0.0000000000 * 0.2722810000 = 1.0659465575 
0.0000000000 * -6.6004600000 = 1.0659465575 
0.0000000000 * -0.2836170000 = 1.0659465575 
0.9141322940 * 0.4656470000 = 1.4916095178 
0.0000000000 * 0.0256762000 = 1.4916095178 
0.0000000000 * 0.2558260000 = 1.4916095178 
0.0000000000 * -0.3400320000 = 1.4916095178 
the biases is : -0.6884780000, now tempVal is : 0.8031315178
compute layer: 4, node : 42
0.0000000000 * -0.0623510000 = 0.0000000000 
1.7845438810 * -0.1771520000 = -0.3161355176 
0.0000000000 * -0.4047990000 = -0.3161355176 
0.6009646532 * 0.0295261000 = -0.2983913752 
0.4463398333 * -0.0703788000 = -0.3298042370 
0.0000000000 * 0.0234803000 = -0.3298042370 
0.0000000000 * -0.3410690000 = -0.3298042370 
0.3475366177 * -0.0763415000 = -0.3563357037 
0.2186928048 * 0.0318256000 = -0.3493756740 
0.0000000000 * 0.0936421000 = -0.3493756740 
0.0000000000 * -0.0928283000 = -0.3493756740 
0.0000000000 * -0.0349344000 = -0.3493756740 
0.0000000000 * -0.1693640000 = -0.3493756740 
0.0000000000 * -0.0699109000 = -0.3493756740 
0.0000000000 * 0.4767590000 = -0.3493756740 
0.0000000000 * -0.0828952000 = -0.3493756740 
0.3887901683 * 0.2282470000 = -0.2606354844 
1.4372682682 * -0.0391308000 = -0.3168769416 
0.0000000000 * 0.1783820000 = -0.3168769416 
0.0000000000 * 0.0022318000 = -0.3168769416 
0.0000000000 * -0.2580590000 = -0.3168769416 
0.0000000000 * 0.2987050000 = -0.3168769416 
1.5809660104 * 0.1571710000 = -0.0683949328 
2.0068238746 * -0.1565540000 = -0.3825712376 
0.0000000000 * 0.2794880000 = -0.3825712376 
0.0000000000 * 0.2729310000 = -0.3825712376 
0.0000000000 * 0.0612662000 = -0.3825712376 
0.7689002813 * -0.2150120000 = -0.5478940249 
0.0000000000 * -0.2105510000 = -0.5478940249 
0.1555103307 * 0.0833694000 = -0.5349292220 
0.0000000000 * 0.1835200000 = -0.5349292220 
0.0923938400 * -0.0361832000 = -0.5382723268 
0.0000000000 * 0.2245090000 = -0.5382723268 
0.0000000000 * 0.1390650000 = -0.5382723268 
0.0000000000 * 0.0745194000 = -0.5382723268 
0.7573677455 * 0.2890140000 = -0.3193824452 
0.0000000000 * -0.0765317000 = -0.3193824452 
0.0000000000 * 0.4869830000 = -0.3193824452 
0.0000000000 * -0.0691808000 = -0.3193824452 
0.0000000000 * -0.2625370000 = -0.3193824452 
0.0000000000 * -0.2252320000 = -0.3193824452 
0.0000000000 * 0.1799070000 = -0.3193824452 
1.8721845553 * -0.1658860000 = -0.6299516523 
0.0000000000 * -0.1398190000 = -0.6299516523 
0.0000000000 * -0.3383710000 = -0.6299516523 
0.0000000000 * 0.3235470000 = -0.6299516523 
0.9141322940 * 0.1223830000 = -0.5180773998 
0.0000000000 * -0.0278158000 = -0.5180773998 
0.0000000000 * -0.0810340000 = -0.5180773998 
0.0000000000 * -0.2924210000 = -0.5180773998 
the biases is : 0.0999729000, now tempVal is : -0.4181044998
ReLU !!! in layer: 4, node : 42, its linear result is negative,so set it to 0
compute layer: 4, node : 43
0.0000000000 * 0.5084270000 = 0.0000000000 
1.7845438810 * -0.1242750000 = -0.2217741908 
0.0000000000 * -0.0867165000 = -0.2217741908 
0.6009646532 * 0.3545050000 = -0.0087292164 
0.4463398333 * -1.0931600000 = -0.4966500686 
0.0000000000 * 0.0196925000 = -0.4966500686 
0.0000000000 * -0.1344850000 = -0.4966500686 
0.3475366177 * -0.5011090000 = -0.6708037955 
0.2186928048 * -0.2150900000 = -0.7178424309 
0.0000000000 * 0.1226630000 = -0.7178424309 
0.0000000000 * -0.3162400000 = -0.7178424309 
0.0000000000 * -0.3868740000 = -0.7178424309 
0.0000000000 * 0.1090470000 = -0.7178424309 
0.0000000000 * -0.2317960000 = -0.7178424309 
0.0000000000 * -1.0243800000 = -0.7178424309 
0.0000000000 * 0.0751964000 = -0.7178424309 
0.3887901683 * 0.2523710000 = -0.6197230674 
1.4372682682 * -0.0811082000 = -0.7362973095 
0.0000000000 * 0.0599882000 = -0.7362973095 
0.0000000000 * 0.0287320000 = -0.7362973095 
0.0000000000 * -0.0669159000 = -0.7362973095 
0.0000000000 * -0.3393030000 = -0.7362973095 
1.5809660104 * -0.0210554000 = -0.7695851812 
2.0068238746 * 0.2716960000 = -0.2243391618 
0.0000000000 * 0.0751932000 = -0.2243391618 
0.0000000000 * 0.0353524000 = -0.2243391618 
0.0000000000 * 0.3440540000 = -0.2243391618 
0.7689002813 * -0.1807460000 = -0.3633148121 
0.0000000000 * -0.0715953000 = -0.3633148121 
0.1555103307 * 0.2385400000 = -0.3262193778 
0.0000000000 * 0.1612340000 = -0.3262193778 
0.0923938400 * -0.0656802000 = -0.3322878237 
0.0000000000 * -0.5766740000 = -0.3322878237 
0.0000000000 * -0.0965278000 = -0.3322878237 
0.0000000000 * -0.5202400000 = -0.3322878237 
0.7573677455 * -0.0924975000 = -0.4023424467 
0.0000000000 * 0.4207060000 = -0.4023424467 
0.0000000000 * 0.0808923000 = -0.4023424467 
0.0000000000 * -0.2667120000 = -0.4023424467 
0.0000000000 * 0.0272718000 = -0.4023424467 
0.0000000000 * -0.2999120000 = -0.4023424467 
0.0000000000 * -0.4826430000 = -0.4023424467 
1.8721845553 * 0.0284087000 = -0.3491561173 
0.0000000000 * 0.1823750000 = -0.3491561173 
0.0000000000 * 0.4094900000 = -0.3491561173 
0.0000000000 * 0.2625490000 = -0.3491561173 
0.9141322940 * -0.3349680000 = -0.6553611836 
0.0000000000 * 0.0081518800 = -0.6553611836 
0.0000000000 * -0.4446240000 = -0.6553611836 
0.0000000000 * -0.2967920000 = -0.6553611836 
the biases is : 0.2356930000, now tempVal is : -0.4196681836
ReLU !!! in layer: 4, node : 43, its linear result is negative,so set it to 0
compute layer: 4, node : 44
0.0000000000 * -0.2823340000 = 0.0000000000 
1.7845438810 * -0.0569569000 = -0.1016420874 
0.0000000000 * 0.0528054000 = -0.1016420874 
0.6009646532 * 0.3824690000 = 0.1282082626 
0.4463398333 * 0.5264900000 = 0.3632017214 
0.0000000000 * -0.1553190000 = 0.3632017214 
0.0000000000 * -0.2025520000 = 0.3632017214 
0.3475366177 * 0.4141130000 = 0.5071211528 
0.2186928048 * 0.1462600000 = 0.5391071624 
0.0000000000 * -0.0126211000 = 0.5391071624 
0.0000000000 * -1.0903800000 = 0.5391071624 
0.0000000000 * -0.4712150000 = 0.5391071624 
0.0000000000 * -0.1123720000 = 0.5391071624 
0.0000000000 * 0.1320390000 = 0.5391071624 
0.0000000000 * 0.1339980000 = 0.5391071624 
0.0000000000 * -0.4130030000 = 0.5391071624 
0.3887901683 * 0.1215970000 = 0.5863828805 
1.4372682682 * 0.3650700000 = 1.1110864071 
0.0000000000 * -0.2385110000 = 1.1110864071 
0.0000000000 * -0.0472868000 = 1.1110864071 
0.0000000000 * 0.4703720000 = 1.1110864071 
0.0000000000 * -0.1049400000 = 1.1110864071 
1.5809660104 * -0.0280033000 = 1.0668141417 
2.0068238746 * -0.1360320000 = 0.7938218764 
0.0000000000 * -0.1385530000 = 0.7938218764 
0.0000000000 * -0.4462430000 = 0.7938218764 
0.0000000000 * 0.2006260000 = 0.7938218764 
0.7689002813 * -0.4152880000 = 0.4745068163 
0.0000000000 * 0.1199940000 = 0.4745068163 
0.1555103307 * -0.2404110000 = 0.4371204222 
0.0000000000 * -0.6366120000 = 0.4371204222 
0.0923938400 * -0.8400830000 = 0.3595019279 
0.0000000000 * -0.7771760000 = 0.3595019279 
0.0000000000 * -0.5768480000 = 0.3595019279 
0.0000000000 * 0.1653430000 = 0.3595019279 
0.7573677455 * -0.2810370000 = 0.1466535688 
0.0000000000 * 0.4274330000 = 0.1466535688 
0.0000000000 * -1.8883700000 = 0.1466535688 
0.0000000000 * 0.0778203000 = 0.1466535688 
0.0000000000 * -0.0162863000 = 0.1466535688 
0.0000000000 * 0.1586330000 = 0.1466535688 
0.0000000000 * 0.3729610000 = 0.1466535688 
1.8721845553 * -0.4363420000 = -0.6702591844 
0.0000000000 * 0.5673380000 = -0.6702591844 
0.0000000000 * 0.4891860000 = -0.6702591844 
0.0000000000 * -0.4213790000 = -0.6702591844 
0.9141322940 * -0.1373740000 = -0.7958371942 
0.0000000000 * 0.0221045000 = -0.7958371942 
0.0000000000 * 0.1333230000 = -0.7958371942 
0.0000000000 * -0.1294480000 = -0.7958371942 
the biases is : 0.2002080000, now tempVal is : -0.5956291942
ReLU !!! in layer: 4, node : 44, its linear result is negative,so set it to 0
compute layer: 4, node : 45
0.0000000000 * -0.3662220000 = 0.0000000000 
1.7845438810 * -0.1039500000 = -0.1855033364 
0.0000000000 * -0.3460300000 = -0.1855033364 
0.6009646532 * 0.5202520000 = 0.1271497263 
0.4463398333 * -0.2303810000 = 0.0243215092 
0.0000000000 * 0.2980690000 = 0.0243215092 
0.0000000000 * -0.6866360000 = 0.0243215092 
0.3475366177 * -0.4148430000 = -0.1198516239 
0.2186928048 * -0.2693380000 = -0.1787539065 
0.0000000000 * 0.3613210000 = -0.1787539065 
0.0000000000 * 1.4069300000 = -0.1787539065 
0.0000000000 * -0.5663390000 = -0.1787539065 
0.0000000000 * -0.0727639000 = -0.1787539065 
0.0000000000 * 0.7664740000 = -0.1787539065 
0.0000000000 * -0.0350154000 = -0.1787539065 
0.0000000000 * 0.3221290000 = -0.1787539065 
0.3887901683 * 0.7643870000 = 0.1184322438 
1.4372682682 * 0.7202030000 = 1.1535571624 
0.0000000000 * -0.4506750000 = 1.1535571624 
0.0000000000 * 0.0303459000 = 1.1535571624 
0.0000000000 * 0.5332350000 = 1.1535571624 
0.0000000000 * -0.5008240000 = 1.1535571624 
1.5809660104 * -0.3573720000 = 0.5885641773 
2.0068238746 * -1.1011200000 = -1.6211897275 
0.0000000000 * -0.0098252000 = -1.6211897275 
0.0000000000 * 0.3343370000 = -1.6211897275 
0.0000000000 * 0.3217410000 = -1.6211897275 
0.7689002813 * 0.5363460000 = -1.2087931372 
0.0000000000 * -0.2594350000 = -1.2087931372 
0.1555103307 * -0.5291170000 = -1.2910762968 
0.0000000000 * -0.5601650000 = -1.2910762968 
0.0923938400 * -0.0291179000 = -1.2937666114 
0.0000000000 * -0.3378190000 = -1.2937666114 
0.0000000000 * -0.4553750000 = -1.2937666114 
0.0000000000 * -0.1819910000 = -1.2937666114 
0.7573677455 * 0.0438639000 = -1.2605455084 
0.0000000000 * 0.7870070000 = -1.2605455084 
0.0000000000 * -1.4107400000 = -1.2605455084 
0.0000000000 * 0.1087450000 = -1.2605455084 
0.0000000000 * 1.2120000000 = -1.2605455084 
0.0000000000 * -2.1986300000 = -1.2605455084 
0.0000000000 * -0.2007230000 = -1.2605455084 
1.8721845553 * 0.5230960000 = -0.2812132562 
0.0000000000 * -0.0616652000 = -0.2812132562 
0.0000000000 * 0.1870490000 = -0.2812132562 
0.0000000000 * -0.0893700000 = -0.2812132562 
0.9141322940 * 0.5317590000 = 0.2048848183 
0.0000000000 * -0.0442423000 = 0.2048848183 
0.0000000000 * 0.2001140000 = 0.2048848183 
0.0000000000 * -0.5464110000 = 0.2048848183 
the biases is : 0.1853220000, now tempVal is : 0.3902068183
compute layer: 4, node : 46
0.0000000000 * -0.5207370000 = 0.0000000000 
1.7845438810 * -0.1767850000 = -0.3154805900 
0.0000000000 * 0.2540450000 = -0.3154805900 
0.6009646532 * -0.3263800000 = -0.5116234335 
0.4463398333 * 0.2468910000 = -0.4014261457 
0.0000000000 * 0.3013750000 = -0.4014261457 
0.0000000000 * -0.1457120000 = -0.4014261457 
0.3475366177 * -0.3744630000 = -0.5315657502 
0.2186928048 * 0.2025090000 = -0.4872784890 
0.0000000000 * -0.1723630000 = -0.4872784890 
0.0000000000 * -0.1683820000 = -0.4872784890 
0.0000000000 * -0.3632040000 = -0.4872784890 
0.0000000000 * 0.0627762000 = -0.4872784890 
0.0000000000 * 0.0952615000 = -0.4872784890 
0.0000000000 * 0.7373600000 = -0.4872784890 
0.0000000000 * -0.6938040000 = -0.4872784890 
0.3887901683 * 0.2630890000 = -0.3849920724 
1.4372682682 * -0.0234419000 = -0.4186843714 
0.0000000000 * 0.1599140000 = -0.4186843714 
0.0000000000 * 0.0270274000 = -0.4186843714 
0.0000000000 * 0.2371740000 = -0.4186843714 
0.0000000000 * 0.5447430000 = -0.4186843714 
1.5809660104 * -0.2661630000 = -0.8394790276 
2.0068238746 * -0.3573870000 = -1.5566917917 
0.0000000000 * 0.0081816000 = -1.5566917917 
0.0000000000 * -0.3140110000 = -1.5566917917 
0.0000000000 * -0.1031740000 = -1.5566917917 
0.7689002813 * -0.0811156000 = -1.6190615994 
0.0000000000 * -0.3080560000 = -1.6190615994 
0.1555103307 * -0.3466900000 = -1.6729754759 
0.0000000000 * 0.6934050000 = -1.6729754759 
0.0923938400 * 0.6981530000 = -1.6084704393 
0.0000000000 * -0.1545090000 = -1.6084704393 
0.0000000000 * 0.0875965000 = -1.6084704393 
0.0000000000 * -0.0242145000 = -1.6084704393 
0.7573677455 * 0.6022630000 = -1.1523358688 
0.0000000000 * -0.5890970000 = -1.1523358688 
0.0000000000 * 0.2820180000 = -1.1523358688 
0.0000000000 * -0.0843388000 = -1.1523358688 
0.0000000000 * 0.2819440000 = -1.1523358688 
0.0000000000 * -0.3280640000 = -1.1523358688 
0.0000000000 * -0.1264230000 = -1.1523358688 
1.8721845553 * 0.1881180000 = -0.8001442547 
0.0000000000 * -0.0367329000 = -0.8001442547 
0.0000000000 * -0.2374760000 = -0.8001442547 
0.0000000000 * 0.1640190000 = -0.8001442547 
0.9141322940 * -0.0511404000 = -0.8468933458 
0.0000000000 * -0.0181719000 = -0.8468933458 
0.0000000000 * -0.1824140000 = -0.8468933458 
0.0000000000 * 0.5358110000 = -0.8468933458 
the biases is : 0.2132420000, now tempVal is : -0.6336513458
ReLU !!! in layer: 4, node : 46, its linear result is negative,so set it to 0
compute layer: 4, node : 47
0.0000000000 * -0.0279318000 = 0.0000000000 
1.7845438810 * -0.0610613000 = -0.1089665693 
0.0000000000 * -0.0101412000 = -0.1089665693 
0.6009646532 * -0.0552915000 = -0.1421948064 
0.4463398333 * 0.0404394000 = -0.1241450913 
0.0000000000 * -0.0573593000 = -0.1241450913 
0.0000000000 * 0.0062085700 = -0.1241450913 
0.3475366177 * -0.0022237700 = -0.1249179329 
0.2186928048 * 0.0238538000 = -0.1197012784 
0.0000000000 * -0.0148151000 = -0.1197012784 
0.0000000000 * 0.0015523000 = -0.1197012784 
0.0000000000 * -0.0367412000 = -0.1197012784 
0.0000000000 * 0.0162746000 = -0.1197012784 
0.0000000000 * 0.0211872000 = -0.1197012784 
0.0000000000 * 0.0049080800 = -0.1197012784 
0.0000000000 * 0.0047015400 = -0.1197012784 
0.3887901683 * 0.0424634000 = -0.1031919260 
1.4372682682 * -0.0241571000 = -0.1379121593 
0.0000000000 * -0.0065539500 = -0.1379121593 
0.0000000000 * 0.0282217000 = -0.1379121593 
0.0000000000 * -0.0546177000 = -0.1379121593 
0.0000000000 * -0.0318534000 = -0.1379121593 
1.5809660104 * -0.0282441000 = -0.1825651214 
2.0068238746 * -0.0324262000 = -0.2476387937 
0.0000000000 * 0.0130020000 = -0.2476387937 
0.0000000000 * -0.0200125000 = -0.2476387937 
0.0000000000 * 0.0185364000 = -0.2476387937 
0.7689002813 * -0.0112108000 = -0.2562587810 
0.0000000000 * -0.0334813000 = -0.2562587810 
0.1555103307 * -0.0131698000 = -0.2583068209 
0.0000000000 * -0.0173139000 = -0.2583068209 
0.0923938400 * 0.0150257000 = -0.2569185388 
0.0000000000 * -0.0391308000 = -0.2569185388 
0.0000000000 * 0.0172660000 = -0.2569185388 
0.0000000000 * 0.0087911800 = -0.2569185388 
0.7573677455 * 0.0263917000 = -0.2369303165 
0.0000000000 * -0.0026093500 = -0.2369303165 
0.0000000000 * -0.0124847000 = -0.2369303165 
0.0000000000 * 0.0109101000 = -0.2369303165 
0.0000000000 * -0.0547726000 = -0.2369303165 
0.0000000000 * -0.0533904000 = -0.2369303165 
0.0000000000 * -0.0669221000 = -0.2369303165 
1.8721845553 * -0.0383629000 = -0.3087527453 
0.0000000000 * 0.0244426000 = -0.3087527453 
0.0000000000 * -0.0032438900 = -0.3087527453 
0.0000000000 * -0.0070276200 = -0.3087527453 
0.9141322940 * -0.0450720000 = -0.3499545161 
0.0000000000 * 0.0306992000 = -0.3499545161 
0.0000000000 * 0.0109265000 = -0.3499545161 
0.0000000000 * 0.0225712000 = -0.3499545161 
the biases is : -0.0363364000, now tempVal is : -0.3862909161
ReLU !!! in layer: 4, node : 47, its linear result is negative,so set it to 0
compute layer: 4, node : 48
0.0000000000 * 0.1244860000 = 0.0000000000 
1.7845438810 * -0.1143560000 = -0.2040733001 
0.0000000000 * -0.2133920000 = -0.2040733001 
0.6009646532 * 1.4130200000 = 0.6451017742 
0.4463398333 * -0.6734170000 = 0.3445289427 
0.0000000000 * -0.2332460000 = 0.3445289427 
0.0000000000 * 0.3706730000 = 0.3445289427 
0.3475366177 * -0.3145060000 = 0.2352265912 
0.2186928048 * 0.5941280000 = 0.3651581099 
0.0000000000 * -0.2556650000 = 0.3651581099 
0.0000000000 * -0.3155040000 = 0.3651581099 
0.0000000000 * 0.3159200000 = 0.3651581099 
0.0000000000 * -0.1747000000 = 0.3651581099 
0.0000000000 * -0.0559300000 = 0.3651581099 
0.0000000000 * -0.0359449000 = 0.3651581099 
0.0000000000 * 0.5289490000 = 0.3651581099 
0.3887901683 * -0.0336890000 = 0.3520601579 
1.4372682682 * 0.5635130000 = 1.1619795115 
0.0000000000 * -0.1886410000 = 1.1619795115 
0.0000000000 * 0.0333402000 = 1.1619795115 
0.0000000000 * 0.0151033000 = 1.1619795115 
0.0000000000 * 0.0019599400 = 1.1619795115 
1.5809660104 * -0.0564992000 = 1.0726561967 
2.0068238746 * -0.2346970000 = 0.6016606538 
0.0000000000 * 0.7041990000 = 0.6016606538 
0.0000000000 * 0.4321010000 = 0.6016606538 
0.0000000000 * 0.2157320000 = 0.6016606538 
0.7689002813 * 0.3102750000 = 0.8402311886 
0.0000000000 * -0.4511690000 = 0.8402311886 
0.1555103307 * -0.1528560000 = 0.8164605015 
0.0000000000 * 0.4079150000 = 0.8164605015 
0.0923938400 * 0.8345540000 = 0.8935681503 
0.0000000000 * 0.3968130000 = 0.8935681503 
0.0000000000 * 0.1060430000 = 0.8935681503 
0.0000000000 * -0.4489640000 = 0.8935681503 
0.7573677455 * 0.3860990000 = 1.1859870794 
0.0000000000 * -0.1863830000 = 1.1859870794 
0.0000000000 * -0.4942290000 = 1.1859870794 
0.0000000000 * 0.0411979000 = 1.1859870794 
0.0000000000 * 0.5437000000 = 1.1859870794 
0.0000000000 * -0.2820800000 = 1.1859870794 
0.0000000000 * -0.2337600000 = 1.1859870794 
1.8721845553 * -0.1598080000 = 0.8867970100 
0.0000000000 * 0.3454620000 = 0.8867970100 
0.0000000000 * 0.6294890000 = 0.8867970100 
0.0000000000 * 0.0909301000 = 0.8867970100 
0.9141322940 * 0.2629150000 = 1.1271361021 
0.0000000000 * -0.0140547000 = 1.1271361021 
0.0000000000 * 0.0703901000 = 1.1271361021 
0.0000000000 * 0.0870268000 = 1.1271361021 
the biases is : 0.0762837000, now tempVal is : 1.2034198021
compute layer: 4, node : 49
0.0000000000 * 0.0862763000 = 0.0000000000 
1.7845438810 * 0.2146610000 = 0.3830719740 
0.0000000000 * -0.2051320000 = 0.3830719740 
0.6009646532 * -0.5096980000 = 0.0767614922 
0.4463398333 * -0.2828930000 = -0.0495049222 
0.0000000000 * -0.3354090000 = -0.0495049222 
0.0000000000 * -0.0028165100 = -0.0495049222 
0.3475366177 * -0.0387833000 = -0.0629835391 
0.2186928048 * 0.3605510000 = 0.0158663703 
0.0000000000 * -0.1611840000 = 0.0158663703 
0.0000000000 * 0.1615550000 = 0.0158663703 
0.0000000000 * 0.1687770000 = 0.0158663703 
0.0000000000 * -0.3866350000 = 0.0158663703 
0.0000000000 * 0.4895300000 = 0.0158663703 
0.0000000000 * -0.1436220000 = 0.0158663703 
0.0000000000 * -0.0548127000 = 0.0158663703 
0.3887901683 * -0.8232330000 = -0.3041985263 
1.4372682682 * 0.0457209000 = -0.2384853276 
0.0000000000 * 0.3378560000 = -0.2384853276 
0.0000000000 * -0.0091643000 = -0.2384853276 
0.0000000000 * -0.0245709000 = -0.2384853276 
0.0000000000 * 0.3110560000 = -0.2384853276 
1.5809660104 * 0.1585910000 = 0.0122416530 
2.0068238746 * 0.0588856000 = 0.1304146810 
0.0000000000 * 0.0291222000 = 0.1304146810 
0.0000000000 * 0.6489950000 = 0.1304146810 
0.0000000000 * -0.0892552000 = 0.1304146810 
0.7689002813 * -0.0068762000 = 0.1251275688 
0.0000000000 * -0.2166100000 = 0.1251275688 
0.1555103307 * -0.3593630000 = 0.0692429099 
0.0000000000 * -0.2041250000 = 0.0692429099 
0.0923938400 * 0.8731770000 = 0.1499190859 
0.0000000000 * -0.1548940000 = 0.1499190859 
0.0000000000 * -0.2444340000 = 0.1499190859 
0.0000000000 * 0.0870704000 = 0.1499190859 
0.7573677455 * -0.2518640000 = -0.0408345839 
0.0000000000 * 0.2415530000 = -0.0408345839 
0.0000000000 * -0.6366530000 = -0.0408345839 
0.0000000000 * -0.4192850000 = -0.0408345839 
0.0000000000 * -0.0852114000 = -0.0408345839 
0.0000000000 * -0.0273586000 = -0.0408345839 
0.0000000000 * -0.2453650000 = -0.0408345839 
1.8721845553 * 0.3150570000 = 0.5490102655 
0.0000000000 * -0.3963540000 = 0.5490102655 
0.0000000000 * -0.1722020000 = 0.5490102655 
0.0000000000 * -0.7049300000 = 0.5490102655 
0.9141322940 * 0.4881110000 = 0.9952082937 
0.0000000000 * 0.0219731000 = 0.9952082937 
0.0000000000 * -0.0403008000 = 0.9952082937 
0.0000000000 * 0.1989570000 = 0.9952082937 
the biases is : -0.2163930000, now tempVal is : 0.7788152937

now we get all result in layer: 4
	node: 0, val: 0.0000000000
	node: 1, val: 0.0000000000
	node: 2, val: 0.0000000000
	node: 3, val: 0.0000000000
	node: 4, val: 0.0000000000
	node: 5, val: 0.0000000000
	node: 6, val: 0.0727527248
	node: 7, val: 0.0000000000
	node: 8, val: 0.0000000000
	node: 9, val: 0.1903205629
	node: 10, val: 0.0000000000
	node: 11, val: 2.8096423506
	node: 12, val: 0.0000000000
	node: 13, val: 0.0000000000
	node: 14, val: 0.0000000000
	node: 15, val: 0.0000000000
	node: 16, val: 0.0000000000
	node: 17, val: 0.1333779634
	node: 18, val: 0.0000000000
	node: 19, val: 0.0000000000
	node: 20, val: 0.0000000000
	node: 21, val: 0.8570723642
	node: 22, val: 0.8398318691
	node: 23, val: 1.5787404086
	node: 24, val: 0.0000000000
	node: 25, val: 0.0000000000
	node: 26, val: 0.0000000000
	node: 27, val: 0.0000000000
	node: 28, val: 0.0000000000
	node: 29, val: 0.0000000000
	node: 30, val: 0.0000000000
	node: 31, val: 2.7992951847
	node: 32, val: 4.4584052240
	node: 33, val: 3.4785294551
	node: 34, val: 0.0000000000
	node: 35, val: 0.0000000000
	node: 36, val: 0.0734678262
	node: 37, val: 0.0000000000
	node: 38, val: 0.0000000000
	node: 39, val: 0.0000000000
	node: 40, val: 0.2251693882
	node: 41, val: 0.8031315178
	node: 42, val: 0.0000000000
	node: 43, val: 0.0000000000
	node: 44, val: 0.0000000000
	node: 45, val: 0.3902068183
	node: 46, val: 0.0000000000
	node: 47, val: 0.0000000000
	node: 48, val: 1.2034198021
	node: 49, val: 0.7788152937

when compute layer[4] to layer[5]
compute layer: 5, node : 0
0.0000000000 * -0.1694730000 = 0.0000000000 
0.0000000000 * -1.0300700000 = 0.0000000000 
0.0000000000 * 0.5938240000 = 0.0000000000 
0.0000000000 * -0.3382950000 = 0.0000000000 
0.0000000000 * 0.2092670000 = 0.0000000000 
0.0000000000 * 0.2174930000 = 0.0000000000 
0.0727527248 * 0.2826460000 = 0.0205632667 
0.0000000000 * 0.1640800000 = 0.0205632667 
0.0000000000 * 0.8471510000 = 0.0205632667 
0.1903205629 * -0.7093830000 = -0.1144469052 
0.0000000000 * 0.3557310000 = -0.1144469052 
2.8096423506 * 0.0085136800 = -0.0905265093 
0.0000000000 * 0.2302220000 = -0.0905265093 
0.0000000000 * 0.6131300000 = -0.0905265093 
0.0000000000 * -0.0021044700 = -0.0905265093 
0.0000000000 * -0.0725392000 = -0.0905265093 
0.0000000000 * 0.1295060000 = -0.0905265093 
0.1333779634 * -0.1635130000 = -0.1123355402 
0.0000000000 * -0.0985782000 = -0.1123355402 
0.0000000000 * -0.6050790000 = -0.1123355402 
0.0000000000 * -0.1352790000 = -0.1123355402 
0.8570723642 * -0.4525840000 = -0.5002327791 
0.8398318691 * 0.4468290000 = -0.1249715448 
1.5787404086 * -0.4411230000 = -0.8213902501 
0.0000000000 * -0.0297429000 = -0.8213902501 
0.0000000000 * 0.2039760000 = -0.8213902501 
0.0000000000 * 0.0839317000 = -0.8213902501 
0.0000000000 * -0.5352310000 = -0.8213902501 
0.0000000000 * 0.7321040000 = -0.8213902501 
0.0000000000 * -1.1308000000 = -0.8213902501 
0.0000000000 * -0.1063000000 = -0.8213902501 
2.7992951847 * 0.1650510000 = -0.3593637806 
4.4584052240 * -0.0049593800 = -0.3814747063 
3.4785294551 * -0.2051560000 = -1.0951158952 
0.0000000000 * 0.0252767000 = -1.0951158952 
0.0000000000 * -0.5096720000 = -1.0951158952 
0.0734678262 * -0.1176270000 = -1.1037576951 
0.0000000000 * -0.0121789000 = -1.1037576951 
0.0000000000 * 0.0852722000 = -1.1037576951 
0.0000000000 * -0.8399770000 = -1.1037576951 
0.2251693882 * 0.1770170000 = -1.0638988856 
0.8031315178 * 0.5919380000 = -0.5884948212 
0.0000000000 * -0.4450010000 = -0.5884948212 
0.0000000000 * 0.7269440000 = -0.5884948212 
0.0000000000 * 0.4730240000 = -0.5884948212 
0.3902068183 * -0.5781230000 = -0.8140823576 
0.0000000000 * 0.0935903000 = -0.8140823576 
0.0000000000 * -0.0158796000 = -0.8140823576 
1.2034198021 * 0.2712540000 = -0.4876499226 
0.7788152937 * 0.6605910000 = 0.0268284511 
the biases is : 0.3438840000, now tempVal is : 0.3707124511
compute layer: 5, node : 1
0.0000000000 * 0.1435770000 = 0.0000000000 
0.0000000000 * 0.1572560000 = 0.0000000000 
0.0000000000 * 2.1002100000 = 0.0000000000 
0.0000000000 * 0.2918180000 = 0.0000000000 
0.0000000000 * -0.6462890000 = 0.0000000000 
0.0000000000 * -0.2044130000 = 0.0000000000 
0.0727527248 * 1.7039500000 = 0.1239670055 
0.0000000000 * -0.0909241000 = 0.1239670055 
0.0000000000 * 2.7134500000 = 0.1239670055 
0.1903205629 * -0.3738170000 = 0.0528219436 
0.0000000000 * 0.7775980000 = 0.0528219436 
2.8096423506 * -0.0737466000 = -0.1543796270 
0.0000000000 * 0.3477730000 = -0.1543796270 
0.0000000000 * -0.2789030000 = -0.1543796270 
0.0000000000 * 0.0362949000 = -0.1543796270 
0.0000000000 * -0.2052700000 = -0.1543796270 
0.0000000000 * -2.1953100000 = -0.1543796270 
0.1333779634 * -0.4366890000 = -0.2126243164 
0.0000000000 * 1.3326700000 = -0.2126243164 
0.0000000000 * 0.4793490000 = -0.2126243164 
0.0000000000 * -2.0298300000 = -0.2126243164 
0.8570723642 * -0.5983200000 = -0.7254278533 
0.8398318691 * -0.2935050000 = -0.9719227061 
1.5787404086 * -0.3596850000 = -1.5397719499 
0.0000000000 * -2.7891600000 = -1.5397719499 
0.0000000000 * -2.0659700000 = -1.5397719499 
0.0000000000 * -0.5863360000 = -1.5397719499 
0.0000000000 * -0.3882290000 = -1.5397719499 
0.0000000000 * -0.1605160000 = -1.5397719499 
0.0000000000 * -5.2222500000 = -1.5397719499 
0.0000000000 * -0.0544925000 = -1.5397719499 
2.7992951847 * 0.0294967000 = -1.4572019796 
4.4584052240 * -0.0245091000 = -1.5664734791 
3.4785294551 * -0.9170150000 = -4.7563371674 
0.0000000000 * 0.5313140000 = -4.7563371674 
0.0000000000 * 0.6315710000 = -4.7563371674 
0.0734678262 * 2.1240400000 = -4.6002885659 
0.0000000000 * 0.7763550000 = -4.6002885659 
0.0000000000 * 0.3365820000 = -4.6002885659 
0.0000000000 * 0.8996020000 = -4.6002885659 
0.2251693882 * 1.0613800000 = -4.3612982806 
0.8031315178 * 1.1014800000 = -3.4766649764 
0.0000000000 * 1.5414000000 = -3.4766649764 
0.0000000000 * 2.0592300000 = -3.4766649764 
0.0000000000 * 1.5341900000 = -3.4766649764 
0.3902068183 * -0.1753430000 = -3.5450850105 
0.0000000000 * 0.0965602000 = -3.5450850105 
0.0000000000 * -0.0081310100 = -3.5450850105 
1.2034198021 * -0.1934340000 = -3.7778673165 
0.7788152937 * -0.9961480000 = -4.5536826137 
the biases is : -0.1487040000, now tempVal is : -4.7023866137
ReLU !!! in layer: 5, node : 1, its linear result is negative,so set it to 0
compute layer: 5, node : 2
0.0000000000 * 0.0011999700 = 0.0000000000 
0.0000000000 * -0.2547420000 = 0.0000000000 
0.0000000000 * 0.2027760000 = 0.0000000000 
0.0000000000 * -0.0314264000 = 0.0000000000 
0.0000000000 * -0.1405690000 = 0.0000000000 
0.0000000000 * 0.4900160000 = 0.0000000000 
0.0727527248 * -0.1116900000 = -0.0081257518 
0.0000000000 * 0.5160980000 = -0.0081257518 
0.0000000000 * 0.1630420000 = -0.0081257518 
0.1903205629 * 0.3169370000 = 0.0521938764 
0.0000000000 * -0.2107670000 = 0.0521938764 
2.8096423506 * -0.1576270000 = -0.3906816184 
0.0000000000 * -0.0944560000 = -0.3906816184 
0.0000000000 * -0.3401320000 = -0.3906816184 
0.0000000000 * 0.0313630000 = -0.3906816184 
0.0000000000 * 0.0440250000 = -0.3906816184 
0.0000000000 * 0.0542488000 = -0.3906816184 
0.1333779634 * 0.0655882000 = -0.3819335979 
0.0000000000 * 0.4140360000 = -0.3819335979 
0.0000000000 * -0.1719930000 = -0.3819335979 
0.0000000000 * -0.1246230000 = -0.3819335979 
0.8570723642 * 0.0786032000 = -0.3145649674 
0.8398318691 * -0.0973331000 = -0.3963084067 
1.5787404086 * 0.0614180000 = -0.2993453283 
0.0000000000 * -0.1828360000 = -0.2993453283 
0.0000000000 * -0.2580070000 = -0.2993453283 
0.0000000000 * -0.0953505000 = -0.2993453283 
0.0000000000 * -0.0712494000 = -0.2993453283 
0.0000000000 * 0.2759420000 = -0.2993453283 
0.0000000000 * -5.6605300000 = -0.2993453283 
0.0000000000 * -2.6092400000 = -0.2993453283 
2.7992951847 * 0.0726355000 = -0.0960171229 
4.4584052240 * -0.0692279000 = -0.4046631539 
3.4785294551 * -0.1025690000 = -0.7614524416 
0.0000000000 * 0.1155960000 = -0.7614524416 
0.0000000000 * -0.2123740000 = -0.7614524416 
0.0734678262 * -0.3662050000 = -0.7883567269 
0.0000000000 * -0.0090937400 = -0.7883567269 
0.0000000000 * -0.1336030000 = -0.7883567269 
0.0000000000 * -0.1118840000 = -0.7883567269 
0.2251693882 * 0.0470368000 = -0.7777654794 
0.8031315178 * 0.2239780000 = -0.5978816883 
0.0000000000 * -0.1334800000 = -0.5978816883 
0.0000000000 * 0.1566660000 = -0.5978816883 
0.0000000000 * 0.4000560000 = -0.5978816883 
0.3902068183 * 0.0484032000 = -0.5789944296 
0.0000000000 * -0.3051450000 = -0.5789944296 
0.0000000000 * 0.0020583700 = -0.5789944296 
1.2034198021 * -0.1948170000 = -0.8134410652 
0.7788152937 * -0.7196320000 = -1.3739014726 
the biases is : -0.1823440000, now tempVal is : -1.5562454726
ReLU !!! in layer: 5, node : 2, its linear result is negative,so set it to 0
compute layer: 5, node : 3
0.0000000000 * -0.5128190000 = 0.0000000000 
0.0000000000 * -1.5551500000 = 0.0000000000 
0.0000000000 * 3.8088900000 = 0.0000000000 
0.0000000000 * -0.6696360000 = 0.0000000000 
0.0000000000 * -0.5951680000 = 0.0000000000 
0.0000000000 * -3.3530200000 = 0.0000000000 
0.0727527248 * -0.9516520000 = -0.0692352761 
0.0000000000 * -2.3335800000 = -0.0692352761 
0.0000000000 * 6.1563000000 = -0.0692352761 
0.1903205629 * 0.0125516000 = -0.0668464485 
0.0000000000 * 0.6230920000 = -0.0668464485 
2.8096423506 * -1.9005200000 = -5.4066279286 
0.0000000000 * 0.6385030000 = -5.4066279286 
0.0000000000 * -3.3311600000 = -5.4066279286 
0.0000000000 * -0.0312064000 = -5.4066279286 
0.0000000000 * -0.3241690000 = -5.4066279286 
0.0000000000 * -2.4905800000 = -5.4066279286 
0.1333779634 * 0.8617820000 = -5.2916852006 
0.0000000000 * -1.3381900000 = -5.2916852006 
0.0000000000 * -4.2281800000 = -5.2916852006 
0.0000000000 * -0.8476250000 = -5.2916852006 
0.8570723642 * -0.1058830000 = -5.3824345937 
0.8398318691 * -0.3300000000 = -5.6595791105 
1.5787404086 * 1.7703900000 = -2.8645928786 
0.0000000000 * 2.7048900000 = -2.8645928786 
0.0000000000 * 1.4303100000 = -2.8645928786 
0.0000000000 * -1.2083200000 = -2.8645928786 
0.0000000000 * -0.2311040000 = -2.8645928786 
0.0000000000 * -1.1377600000 = -2.8645928786 
0.0000000000 * 9.4714000000 = -2.8645928786 
0.0000000000 * -0.6719430000 = -2.8645928786 
2.7992951847 * 0.0044687800 = -2.8520834443 
4.4584052240 * -0.1378390000 = -3.4666255619 
3.4785294551 * -0.5937240000 = -5.5319119841 
0.0000000000 * -0.4226520000 = -5.5319119841 
0.0000000000 * -1.7668700000 = -5.5319119841 
0.0734678262 * 1.6599300000 = -5.4099605354 
0.0000000000 * 0.7552690000 = -5.4099605354 
0.0000000000 * 2.1015300000 = -5.4099605354 
0.0000000000 * -1.2760900000 = -5.4099605354 
0.2251693882 * 1.5877200000 = -5.0524545944 
0.8031315178 * -2.7820200000 = -7.2867825395 
0.0000000000 * 0.3617690000 = -7.2867825395 
0.0000000000 * -2.0012600000 = -7.2867825395 
0.0000000000 * -0.7788940000 = -7.2867825395 
0.3902068183 * 1.2362100000 = -6.8044049687 
0.0000000000 * 0.7887180000 = -6.8044049687 
0.0000000000 * 0.0386314000 = -6.8044049687 
1.2034198021 * -0.2036620000 = -7.0494958524 
0.7788152937 * -2.7162800000 = -9.1649762583 
the biases is : 2.0928200000, now tempVal is : -7.0721562583
ReLU !!! in layer: 5, node : 3, its linear result is negative,so set it to 0
compute layer: 5, node : 4
0.0000000000 * 0.1562800000 = 0.0000000000 
0.0000000000 * 0.1129750000 = 0.0000000000 
0.0000000000 * -2.6960000000 = 0.0000000000 
0.0000000000 * -0.0929159000 = 0.0000000000 
0.0000000000 * -0.1142860000 = 0.0000000000 
0.0000000000 * -2.3939200000 = 0.0000000000 
0.0727527248 * -0.0321934000 = -0.0023421576 
0.0000000000 * 0.3527870000 = -0.0023421576 
0.0000000000 * -0.2218580000 = -0.0023421576 
0.1903205629 * -0.0208618000 = -0.0063125871 
0.0000000000 * -0.3939970000 = -0.0063125871 
2.8096423506 * -0.0992529000 = -0.2851777383 
0.0000000000 * 0.0912523000 = -0.2851777383 
0.0000000000 * -0.2171300000 = -0.2851777383 
0.0000000000 * -0.0167364000 = -0.2851777383 
0.0000000000 * -0.1992610000 = -0.2851777383 
0.0000000000 * -0.0310063000 = -0.2851777383 
0.1333779634 * 0.1677900000 = -0.2627982499 
0.0000000000 * 0.0299587000 = -0.2627982499 
0.0000000000 * 0.2821170000 = -0.2627982499 
0.0000000000 * -0.8867470000 = -0.2627982499 
0.8570723642 * -0.0472178000 = -0.3032673214 
0.8398318691 * 0.0112031000 = -0.2938586009 
1.5787404086 * 0.7262060000 = 0.8526321562 
0.0000000000 * 0.1853120000 = 0.8526321562 
0.0000000000 * 0.1194650000 = 0.8526321562 
0.0000000000 * 0.0112261000 = 0.8526321562 
0.0000000000 * -0.0960156000 = 0.8526321562 
0.0000000000 * 0.2191360000 = 0.8526321562 
0.0000000000 * 0.3211260000 = 0.8526321562 
0.0000000000 * -0.0608714000 = 0.8526321562 
2.7992951847 * -0.3591810000 = -0.1528214875 
4.4584052240 * 0.1006340000 = 0.2958456638 
3.4785294551 * -0.1710190000 = -0.2990489651 
0.0000000000 * 0.0121608000 = -0.2990489651 
0.0000000000 * 0.3290510000 = -0.2990489651 
0.0734678262 * -1.3707500000 = -0.3997549878 
0.0000000000 * 0.5066450000 = -0.3997549878 
0.0000000000 * 0.0218327000 = -0.3997549878 
0.0000000000 * 0.3475240000 = -0.3997549878 
0.2251693882 * -0.3666470000 = -0.4823126685 
0.8031315178 * 0.1842540000 = -0.3343324738 
0.0000000000 * -0.0986234000 = -0.3343324738 
0.0000000000 * -0.1148080000 = -0.3343324738 
0.0000000000 * -0.3410260000 = -0.3343324738 
0.3902068183 * -0.4128960000 = -0.4954473083 
0.0000000000 * -4.2137600000 = -0.4954473083 
0.0000000000 * 0.0282555000 = -0.4954473083 
1.2034198021 * 0.3620870000 = -0.0597046424 
0.7788152937 * -2.2750300000 = -1.8315327999 
the biases is : 0.0573921000, now tempVal is : -1.7741406999
ReLU !!! in layer: 5, node : 4, its linear result is negative,so set it to 0
compute layer: 5, node : 5
0.0000000000 * -0.0181160000 = 0.0000000000 
0.0000000000 * -0.6881140000 = 0.0000000000 
0.0000000000 * 0.3557820000 = 0.0000000000 
0.0000000000 * -0.1585350000 = 0.0000000000 
0.0000000000 * 0.0326831000 = 0.0000000000 
0.0000000000 * -0.7045870000 = 0.0000000000 
0.0727527248 * -0.0746711000 = -0.0054325260 
0.0000000000 * -0.1877970000 = -0.0054325260 
0.0000000000 * 0.3184060000 = -0.0054325260 
0.1903205629 * -0.4698040000 = -0.0948458877 
0.0000000000 * 0.0289892000 = -0.0948458877 
2.8096423506 * -0.1946490000 = -0.6417399616 
0.0000000000 * 0.3991000000 = -0.6417399616 
0.0000000000 * 0.1785630000 = -0.6417399616 
0.0000000000 * -0.0123404000 = -0.6417399616 
0.0000000000 * 0.0823342000 = -0.6417399616 
0.0000000000 * 0.1184630000 = -0.6417399616 
0.1333779634 * -0.5983300000 = -0.7215439984 
0.0000000000 * -0.0358356000 = -0.7215439984 
0.0000000000 * 0.0358180000 = -0.7215439984 
0.0000000000 * 0.2433210000 = -0.7215439984 
0.8570723642 * -0.4336980000 = -1.0932545686 
0.8398318691 * 0.4480770000 = -0.7169452242 
1.5787404086 * -0.0485438000 = -0.7935832828 
0.0000000000 * -0.1566860000 = -0.7935832828 
0.0000000000 * 0.1047790000 = -0.7935832828 
0.0000000000 * 0.1419280000 = -0.7935832828 
0.0000000000 * -0.1789510000 = -0.7935832828 
0.0000000000 * 0.6230910000 = -0.7935832828 
0.0000000000 * -0.3719280000 = -0.7935832828 
0.0000000000 * 0.1634700000 = -0.7935832828 
2.7992951847 * -0.0922999000 = -1.0519579485 
4.4584052240 * -0.0567132000 = -1.3048083756 
3.4785294551 * -0.0821873000 = -1.5906993195 
0.0000000000 * 0.0328512000 = -1.5906993195 
0.0000000000 * -0.5014400000 = -1.5906993195 
0.0734678262 * 0.2032890000 = -1.5757641186 
0.0000000000 * -0.0962860000 = -1.5757641186 
0.0000000000 * 0.0573721000 = -1.5757641186 
0.0000000000 * -1.5501600000 = -1.5757641186 
0.2251693882 * 0.2577960000 = -1.5177163510 
0.8031315178 * 0.2255540000 = -1.3365668246 
0.0000000000 * -0.2011730000 = -1.3365668246 
0.0000000000 * 0.3645260000 = -1.3365668246 
0.0000000000 * -0.0099876400 = -1.3365668246 
0.3902068183 * -0.9858470000 = -1.7212510458 
0.0000000000 * 0.0182788000 = -1.7212510458 
0.0000000000 * -0.0236860000 = -1.7212510458 
1.2034198021 * -0.0723469000 = -1.8083147379 
0.7788152937 * 0.4471160000 = -1.4600939590 
the biases is : 1.0727800000, now tempVal is : -0.3873139590
ReLU !!! in layer: 5, node : 5, its linear result is negative,so set it to 0
compute layer: 5, node : 6
0.0000000000 * 0.7401500000 = 0.0000000000 
0.0000000000 * -0.3971480000 = 0.0000000000 
0.0000000000 * 1.7980100000 = 0.0000000000 
0.0000000000 * 0.0996511000 = 0.0000000000 
0.0000000000 * -0.1426580000 = 0.0000000000 
0.0000000000 * -0.5475120000 = 0.0000000000 
0.0727527248 * 0.0200878000 = 0.0014614422 
0.0000000000 * 0.3941120000 = 0.0014614422 
0.0000000000 * 0.2366190000 = 0.0014614422 
0.1903205629 * -0.0116650000 = -0.0007586472 
0.0000000000 * 0.0521026000 = -0.0007586472 
2.8096423506 * -0.4522250000 = -1.2713491592 
0.0000000000 * -0.8218510000 = -1.2713491592 
0.0000000000 * -0.0075935600 = -1.2713491592 
0.0000000000 * 0.0040209100 = -1.2713491592 
0.0000000000 * -0.0667074000 = -1.2713491592 
0.0000000000 * -0.0042432600 = -1.2713491592 
0.1333779634 * 0.2087530000 = -1.2435061092 
0.0000000000 * -0.0234869000 = -1.2435061092 
0.0000000000 * 0.0768873000 = -1.2435061092 
0.0000000000 * -0.1300600000 = -1.2435061092 
0.8570723642 * -0.0098909500 = -1.2519833691 
0.8398318691 * 0.0485464000 = -1.2112125552 
1.5787404086 * 0.0471453000 = -1.1367823650 
0.0000000000 * 0.9209010000 = -1.1367823650 
0.0000000000 * 0.0048936200 = -1.1367823650 
0.0000000000 * 0.0218371000 = -1.1367823650 
0.0000000000 * 0.0406351000 = -1.1367823650 
0.0000000000 * -0.2453310000 = -1.1367823650 
0.0000000000 * 2.5471400000 = -1.1367823650 
0.0000000000 * -0.0127445000 = -1.1367823650 
2.7992951847 * 1.2010600000 = 2.2253391095 
4.4584052240 * -0.3753780000 = 0.5517518733 
3.4785294551 * -0.1048250000 = 0.1871150232 
0.0000000000 * -0.0711360000 = 0.1871150232 
0.0000000000 * -0.3915050000 = 0.1871150232 
0.0734678262 * 0.3095040000 = 0.2098536093 
0.0000000000 * 0.0963099000 = 0.2098536093 
0.0000000000 * -0.5077340000 = 0.2098536093 
0.0000000000 * 0.5367910000 = 0.2098536093 
0.2251693882 * 0.0606857000 = 0.2235181712 
0.8031315178 * 0.0346801000 = 0.2513708525 
0.0000000000 * 0.7327680000 = 0.2513708525 
0.0000000000 * -0.1261330000 = 0.2513708525 
0.0000000000 * -0.1334680000 = 0.2513708525 
0.3902068183 * -0.0754325000 = 0.2219365767 
0.0000000000 * 0.3766990000 = 0.2219365767 
0.0000000000 * -0.0077735100 = 0.2219365767 
1.2034198021 * 0.2254940000 = 0.4933005216 
0.7788152937 * -0.7347920000 = -0.0789667257 
the biases is : -3.5375000000, now tempVal is : -3.6164667257
ReLU !!! in layer: 5, node : 6, its linear result is negative,so set it to 0
compute layer: 5, node : 7
0.0000000000 * -2.0308800000 = 0.0000000000 
0.0000000000 * -0.1557270000 = 0.0000000000 
0.0000000000 * -0.2489090000 = 0.0000000000 
0.0000000000 * -0.1856970000 = 0.0000000000 
0.0000000000 * 0.4029170000 = 0.0000000000 
0.0000000000 * -0.0390676000 = 0.0000000000 
0.0727527248 * -0.2814170000 = -0.0204738536 
0.0000000000 * 0.6838500000 = -0.0204738536 
0.0000000000 * 1.0582500000 = -0.0204738536 
0.1903205629 * -0.5790260000 = -0.1306744078 
0.0000000000 * 0.2184830000 = -0.1306744078 
2.8096423506 * -0.2423700000 = -0.8116474243 
0.0000000000 * 0.9809570000 = -0.8116474243 
0.0000000000 * -0.7759600000 = -0.8116474243 
0.0000000000 * -0.0127888000 = -0.8116474243 
0.0000000000 * 0.1893300000 = -0.8116474243 
0.0000000000 * -0.6237480000 = -0.8116474243 
0.1333779634 * -0.7176820000 = -0.9073703878 
0.0000000000 * -0.6067290000 = -0.9073703878 
0.0000000000 * 2.1790200000 = -0.9073703878 
0.0000000000 * -0.1012830000 = -0.9073703878 
0.8570723642 * -0.6062750000 = -1.4269919354 
0.8398318691 * 0.7366360000 = -0.8083415467 
1.5787404086 * -0.3917870000 = -1.4268715151 
0.0000000000 * 0.7277710000 = -1.4268715151 
0.0000000000 * -0.5877750000 = -1.4268715151 
0.0000000000 * -0.8342780000 = -1.4268715151 
0.0000000000 * -0.4737170000 = -1.4268715151 
0.0000000000 * 0.2511690000 = -1.4268715151 
0.0000000000 * 2.2366300000 = -1.4268715151 
0.0000000000 * 0.5791480000 = -1.4268715151 
2.7992951847 * 0.5883250000 = 0.2200238244 
4.4584052240 * 0.3505880000 = 1.7830871951 
3.4785294551 * -0.8640330000 = -1.2224770456 
0.0000000000 * 0.3784100000 = -1.2224770456 
0.0000000000 * -0.9292610000 = -1.2224770456 
0.0734678262 * 0.0985265000 = -1.2152385178 
0.0000000000 * 0.0268590000 = -1.2152385178 
0.0000000000 * -0.1093120000 = -1.2152385178 
0.0000000000 * -2.0372400000 = -1.2152385178 
0.2251693882 * -0.2106570000 = -1.2626720256 
0.8031315178 * 0.3468050000 = -0.9841419996 
0.0000000000 * -0.1200650000 = -0.9841419996 
0.0000000000 * -1.0487000000 = -0.9841419996 
0.0000000000 * 0.2764800000 = -0.9841419996 
0.3902068183 * -1.7048500000 = -1.6493860937 
0.0000000000 * 0.0619824000 = -1.6493860937 
0.0000000000 * -0.0170093000 = -1.6493860937 
1.2034198021 * -0.0337802000 = -1.6900378553 
0.7788152937 * 0.4530550000 = -1.3371916925 
the biases is : 0.2902460000, now tempVal is : -1.0469456925
ReLU !!! in layer: 5, node : 7, its linear result is negative,so set it to 0
compute layer: 5, node : 8
0.0000000000 * 0.1345090000 = 0.0000000000 
0.0000000000 * -1.4500300000 = 0.0000000000 
0.0000000000 * 0.2926520000 = 0.0000000000 
0.0000000000 * -0.1875510000 = 0.0000000000 
0.0000000000 * -0.0231918000 = 0.0000000000 
0.0000000000 * -4.8773000000 = 0.0000000000 
0.0727527248 * -0.1662300000 = -0.0120936854 
0.0000000000 * -0.8323170000 = -0.0120936854 
0.0000000000 * 0.6296190000 = -0.0120936854 
0.1903205629 * -0.2143930000 = -0.0528970819 
0.0000000000 * -2.3277500000 = -0.0528970819 
2.8096423506 * 0.0088294400 = -0.0280895133 
0.0000000000 * 0.5081350000 = -0.0280895133 
0.0000000000 * -0.2079350000 = -0.0280895133 
0.0000000000 * 0.0067327500 = -0.0280895133 
0.0000000000 * -0.2982720000 = -0.0280895133 
0.0000000000 * 0.1516680000 = -0.0280895133 
0.1333779634 * 0.0384905000 = -0.0229557288 
0.0000000000 * -0.0148084000 = -0.0229557288 
0.0000000000 * 0.5220950000 = -0.0229557288 
0.0000000000 * 0.0346454000 = -0.0229557288 
0.8570723642 * 0.0872506000 = 0.0518243492 
0.8398318691 * -0.2946430000 = -0.1956262322 
1.5787404086 * 0.5667730000 = 0.6991612054 
0.0000000000 * 1.1361800000 = 0.6991612054 
0.0000000000 * 0.2117470000 = 0.6991612054 
0.0000000000 * -0.4182150000 = 0.6991612054 
0.0000000000 * 0.4287260000 = 0.6991612054 
0.0000000000 * -0.3292570000 = 0.6991612054 
0.0000000000 * 2.6093700000 = 0.6991612054 
0.0000000000 * -1.1289000000 = 0.6991612054 
2.7992951847 * -0.4499900000 = -0.5604936348 
4.4584052240 * -0.7644550000 = -3.9687438003 
3.4785294551 * -0.0026543200 = -3.9779769306 
0.0000000000 * -0.0321170000 = -3.9779769306 
0.0000000000 * 1.3808900000 = -3.9779769306 
0.0734678262 * -2.4579000000 = -4.1585535006 
0.0000000000 * 0.0615875000 = -4.1585535006 
0.0000000000 * -0.7743950000 = -4.1585535006 
0.0000000000 * -0.6666060000 = -4.1585535006 
0.2251693882 * 0.3959940000 = -4.0693877739 
0.8031315178 * 0.1707670000 = -3.9322394140 
0.0000000000 * -0.2035390000 = -3.9322394140 
0.0000000000 * 0.0846183000 = -3.9322394140 
0.0000000000 * 0.4782580000 = -3.9322394140 
0.3902068183 * 0.0936237000 = -3.8957068079 
0.0000000000 * 0.0213258000 = -3.8957068079 
0.0000000000 * 0.0103008000 = -3.8957068079 
1.2034198021 * 0.5757200000 = -3.2028739594 
0.7788152937 * -0.0447920000 = -3.2377586540 
the biases is : 1.7852800000, now tempVal is : -1.4524786540
ReLU !!! in layer: 5, node : 8, its linear result is negative,so set it to 0
compute layer: 5, node : 9
0.0000000000 * 0.2213710000 = 0.0000000000 
0.0000000000 * -0.4620560000 = 0.0000000000 
0.0000000000 * -1.0463700000 = 0.0000000000 
0.0000000000 * -0.0847253000 = 0.0000000000 
0.0000000000 * -0.0863158000 = 0.0000000000 
0.0000000000 * -0.6656200000 = 0.0000000000 
0.0727527248 * 0.0081012200 = 0.0005893858 
0.0000000000 * -0.0475918000 = 0.0005893858 
0.0000000000 * 1.6796500000 = 0.0005893858 
0.1903205629 * -0.0880703000 = -0.0161722032 
0.0000000000 * 0.2768370000 = -0.0161722032 
2.8096423506 * -0.3052580000 = -0.8738380079 
0.0000000000 * -0.1064630000 = -0.8738380079 
0.0000000000 * -0.0209559000 = -0.8738380079 
0.0000000000 * -0.0221157000 = -0.8738380079 
0.0000000000 * -0.0392417000 = -0.8738380079 
0.0000000000 * 0.0156593000 = -0.8738380079 
0.1333779634 * -0.0883511000 = -0.8856220977 
0.0000000000 * -0.2654260000 = -0.8856220977 
0.0000000000 * 0.4954790000 = -0.8856220977 
0.0000000000 * 0.0158834000 = -0.8856220977 
0.8570723642 * -0.0313959000 = -0.9125306559 
0.8398318691 * 0.0018937600 = -0.9109402159 
1.5787404086 * 0.2013950000 = -0.5929897913 
0.0000000000 * 0.4278810000 = -0.5929897913 
0.0000000000 * 0.0009520490 = -0.5929897913 
0.0000000000 * -0.0326239000 = -0.5929897913 
0.0000000000 * -0.0328697000 = -0.5929897913 
0.0000000000 * -0.3112550000 = -0.5929897913 
0.0000000000 * 0.8359290000 = -0.5929897913 
0.0000000000 * 0.0384777000 = -0.5929897913 
2.7992951847 * 0.1468770000 = -0.1818377125 
4.4584052240 * -0.2743320000 = -1.4049209344 
3.4785294551 * -0.0561148000 = -1.6001179191 
0.0000000000 * 0.1100980000 = -1.6001179191 
0.0000000000 * 0.3933720000 = -1.6001179191 
0.0734678262 * -0.3974950000 = -1.6293210126 
0.0000000000 * -0.2904290000 = -1.6293210126 
0.0000000000 * 0.1280220000 = -1.6293210126 
0.0000000000 * -0.8481710000 = -1.6293210126 
0.2251693882 * -0.1539730000 = -1.6639910188 
0.8031315178 * 0.0874094000 = -1.5937897747 
0.0000000000 * 0.1632390000 = -1.5937897747 
0.0000000000 * -0.0560784000 = -1.5937897747 
0.0000000000 * 0.1958930000 = -1.5937897747 
0.3902068183 * 0.0780177000 = -1.5633467363 
0.0000000000 * 0.2503800000 = -1.5633467363 
0.0000000000 * -0.0238414000 = -1.5633467363 
1.2034198021 * 0.0883915000 = -1.4569746548 
0.7788152937 * -0.0605780000 = -1.5041537277 
the biases is : 0.5703920000, now tempVal is : -0.9337617277
ReLU !!! in layer: 5, node : 9, its linear result is negative,so set it to 0
compute layer: 5, node : 10
0.0000000000 * 0.3837600000 = 0.0000000000 
0.0000000000 * 0.2005900000 = 0.0000000000 
0.0000000000 * -0.1642400000 = 0.0000000000 
0.0000000000 * -0.1214890000 = 0.0000000000 
0.0000000000 * 0.0047386400 = 0.0000000000 
0.0000000000 * -0.7250310000 = 0.0000000000 
0.0727527248 * 0.0675223000 = 0.0049124313 
0.0000000000 * -0.1899690000 = 0.0049124313 
0.0000000000 * -0.0637548000 = 0.0049124313 
0.1903205629 * 0.1568760000 = 0.0347691599 
0.0000000000 * 0.0125627000 = 0.0347691599 
2.8096423506 * 0.4670990000 = 1.3471502922 
0.0000000000 * 0.1497630000 = 1.3471502922 
0.0000000000 * 0.0536317000 = 1.3471502922 
0.0000000000 * -0.0170047000 = 1.3471502922 
0.0000000000 * -0.0708157000 = 1.3471502922 
0.0000000000 * 0.0957326000 = 1.3471502922 
0.1333779634 * 0.0232962000 = 1.3502574919 
0.0000000000 * 0.4030310000 = 1.3502574919 
0.0000000000 * -0.2709500000 = 1.3502574919 
0.0000000000 * 0.0337353000 = 1.3502574919 
0.8570723642 * 0.1469620000 = 1.4762145607 
0.8398318691 * -0.0240061000 = 1.4560534729 
1.5787404086 * 0.1649530000 = 1.7164714395 
0.0000000000 * -0.6085840000 = 1.7164714395 
0.0000000000 * 0.2116690000 = 1.7164714395 
0.0000000000 * 0.5639620000 = 1.7164714395 
0.0000000000 * 0.0669437000 = 1.7164714395 
0.0000000000 * 0.3945160000 = 1.7164714395 
0.0000000000 * -0.1281710000 = 1.7164714395 
0.0000000000 * -0.1449110000 = 1.7164714395 
2.7992951847 * -0.2054290000 = 1.1414150290 
4.4584052240 * -0.0609732000 = 0.8695717956 
3.4785294551 * 0.0378101000 = 1.0010953422 
0.0000000000 * 0.0804393000 = 1.0010953422 
0.0000000000 * 0.3316000000 = 1.0010953422 
0.0734678262 * -0.4461670000 = 0.9683164226 
0.0000000000 * -0.1609520000 = 0.9683164226 
0.0000000000 * 0.0677892000 = 0.9683164226 
0.0000000000 * 0.2068430000 = 0.9683164226 
0.2251693882 * -0.0360530000 = 0.9601983906 
0.8031315178 * 0.0200441000 = 0.9762964391 
0.0000000000 * -0.4433730000 = 0.9762964391 
0.0000000000 * 0.1511660000 = 0.9762964391 
0.0000000000 * 0.0418186000 = 0.9762964391 
0.3902068183 * 0.1659920000 = 1.0410676492 
0.0000000000 * -0.4491060000 = 1.0410676492 
0.0000000000 * -0.0391579000 = 1.0410676492 
1.2034198021 * -0.0147807000 = 1.0232802622 
0.7788152937 * 0.0480222000 = 1.0606806860 
the biases is : 0.1025780000, now tempVal is : 1.1632586860
compute layer: 5, node : 11
0.0000000000 * -0.4040760000 = 0.0000000000 
0.0000000000 * -0.0419424000 = 0.0000000000 
0.0000000000 * 1.4176900000 = 0.0000000000 
0.0000000000 * -0.7651380000 = 0.0000000000 
0.0000000000 * -2.3223300000 = 0.0000000000 
0.0000000000 * 0.6117690000 = 0.0000000000 
0.0727527248 * 1.0724600000 = 0.0780243873 
0.0000000000 * 0.6533120000 = 0.0780243873 
0.0000000000 * 0.1668530000 = 0.0780243873 
0.1903205629 * -0.4869540000 = -0.0146529721 
0.0000000000 * -0.3237310000 = -0.0146529721 
2.8096423506 * -0.5293000000 = -1.5017966683 
0.0000000000 * -0.1656180000 = -1.5017966683 
0.0000000000 * 0.0008044960 = -1.5017966683 
0.0000000000 * 0.0333297000 = -1.5017966683 
0.0000000000 * -0.1256760000 = -1.5017966683 
0.0000000000 * -0.6346380000 = -1.5017966683 
0.1333779634 * -0.3716910000 = -1.5513720568 
0.0000000000 * 0.2645030000 = -1.5513720568 
0.0000000000 * 0.6830320000 = -1.5513720568 
0.0000000000 * -0.2278460000 = -1.5513720568 
0.8570723642 * 0.1150960000 = -1.4527264560 
0.8398318691 * -0.0450159000 = -1.4905322434 
1.5787404086 * 0.2233760000 = -1.1378795259 
0.0000000000 * 0.6509410000 = -1.1378795259 
0.0000000000 * 0.1284260000 = -1.1378795259 
0.0000000000 * -0.0337287000 = -1.1378795259 
0.0000000000 * -0.5897100000 = -1.1378795259 
0.0000000000 * 0.3329450000 = -1.1378795259 
0.0000000000 * -1.6172000000 = -1.1378795259 
0.0000000000 * 0.6533330000 = -1.1378795259 
2.7992951847 * -0.0253915000 = -1.2089578296 
4.4584052240 * 0.1304900000 = -0.6271805319 
3.4785294551 * -0.3988100000 = -2.0144528639 
0.0000000000 * -0.0889884000 = -2.0144528639 
0.0000000000 * 0.1767230000 = -2.0144528639 
0.0734678262 * 0.2831100000 = -1.9936533877 
0.0000000000 * -0.0912782000 = -1.9936533877 
0.0000000000 * -0.2911170000 = -1.9936533877 
0.0000000000 * -1.1341000000 = -1.9936533877 
0.2251693882 * 0.0394494000 = -1.9847705904 
0.8031315178 * 0.1873990000 = -1.8342645471 
0.0000000000 * 1.2931600000 = -1.8342645471 
0.0000000000 * -1.2882400000 = -1.8342645471 
0.0000000000 * -0.9122780000 = -1.8342645471 
0.3902068183 * 0.3941430000 = -1.6804672611 
0.0000000000 * 0.7938270000 = -1.6804672611 
0.0000000000 * -0.0290338000 = -1.6804672611 
1.2034198021 * 0.3912150000 = -1.2096713832 
0.7788152937 * 0.1760000000 = -1.0725998916 
the biases is : -0.8676940000, now tempVal is : -1.9402938916
ReLU !!! in layer: 5, node : 11, its linear result is negative,so set it to 0
compute layer: 5, node : 12
0.0000000000 * -1.2586000000 = 0.0000000000 
0.0000000000 * 0.9534390000 = 0.0000000000 
0.0000000000 * 0.3588450000 = 0.0000000000 
0.0000000000 * -0.1282090000 = 0.0000000000 
0.0000000000 * -0.1929980000 = 0.0000000000 
0.0000000000 * -1.1001000000 = 0.0000000000 
0.0727527248 * 0.6707850000 = 0.0488014365 
0.0000000000 * -1.4492700000 = 0.0488014365 
0.0000000000 * -0.4488640000 = 0.0488014365 
0.1903205629 * 0.1116510000 = 0.0700509177 
0.0000000000 * 0.4210260000 = 0.0700509177 
2.8096423506 * 1.4539500000 = 4.1551304133 
0.0000000000 * -0.2920670000 = 4.1551304133 
0.0000000000 * -1.4726300000 = 4.1551304133 
0.0000000000 * 0.0066150700 = 4.1551304133 
0.0000000000 * -0.1125940000 = 4.1551304133 
0.0000000000 * -0.6696220000 = 4.1551304133 
0.1333779634 * 0.1055450000 = 4.1692077904 
0.0000000000 * -0.4245280000 = 4.1692077904 
0.0000000000 * 1.9801600000 = 4.1692077904 
0.0000000000 * -1.3657800000 = 4.1692077904 
0.8570723642 * -3.4113300000 = 1.2454511224 
0.8398318691 * 0.3887790000 = 1.5719601166 
1.5787404086 * 0.3553980000 = 2.1330413003 
0.0000000000 * 0.3525090000 = 2.1330413003 
0.0000000000 * -0.7655590000 = 2.1330413003 
0.0000000000 * 0.5178420000 = 2.1330413003 
0.0000000000 * -0.0589605000 = 2.1330413003 
0.0000000000 * -0.5440980000 = 2.1330413003 
0.0000000000 * 0.0806625000 = 2.1330413003 
0.0000000000 * 0.3464380000 = 2.1330413003 
2.7992951847 * 0.4214140000 = 3.3127034813 
4.4584052240 * -0.1325250000 = 2.7218533290 
3.4785294551 * -1.2327200000 = -1.5661995009 
0.0000000000 * -1.3066000000 = -1.5661995009 
0.0000000000 * -0.2133650000 = -1.5661995009 
0.0734678262 * 0.7274570000 = -1.5127548165 
0.0000000000 * 0.0965079000 = -1.5127548165 
0.0000000000 * -1.1451700000 = -1.5127548165 
0.0000000000 * 2.1279100000 = -1.5127548165 
0.2251693882 * 0.9095740000 = -1.3079465953 
0.8031315178 * 0.7765180000 = -0.6843005154 
0.0000000000 * 1.3762000000 = -0.6843005154 
0.0000000000 * -0.3998360000 = -0.6843005154 
0.0000000000 * 0.2365090000 = -0.6843005154 
0.3902068183 * -0.0448613000 = -0.7018057005 
0.0000000000 * 0.9254390000 = -0.7018057005 
0.0000000000 * -0.0096885000 = -0.7018057005 
1.2034198021 * 0.0980403000 = -0.5838220621 
0.7788152937 * -3.7468200000 = -3.5019027807 
the biases is : -1.8884400000, now tempVal is : -5.3903427807
ReLU !!! in layer: 5, node : 12, its linear result is negative,so set it to 0
compute layer: 5, node : 13
0.0000000000 * 0.1443980000 = 0.0000000000 
0.0000000000 * 0.9444350000 = 0.0000000000 
0.0000000000 * -6.5234600000 = 0.0000000000 
0.0000000000 * -0.1407870000 = 0.0000000000 
0.0000000000 * -0.7713330000 = 0.0000000000 
0.0000000000 * 0.3612720000 = 0.0000000000 
0.0727527248 * -0.3299320000 = -0.0240034520 
0.0000000000 * -1.0961200000 = -0.0240034520 
0.0000000000 * -3.5302900000 = -0.0240034520 
0.1903205629 * -1.6241200000 = -0.3331068845 
0.0000000000 * 5.4805000000 = -0.3331068845 
2.8096423506 * -0.4910520000 = -1.7127873801 
0.0000000000 * 0.1609240000 = -1.7127873801 
0.0000000000 * -1.3392900000 = -1.7127873801 
0.0000000000 * -0.0361681000 = -1.7127873801 
0.0000000000 * 0.3081410000 = -1.7127873801 
0.0000000000 * -0.3884480000 = -1.7127873801 
0.1333779634 * -4.4459300000 = -2.3057764687 
0.0000000000 * -0.0815642000 = -2.3057764687 
0.0000000000 * 2.5366000000 = -2.3057764687 
0.0000000000 * -1.5470900000 = -2.3057764687 
0.8570723642 * 0.9125080000 = -1.5236910798 
0.8398318691 * -0.2517260000 = -1.7350985969 
1.5787404086 * 3.0799300000 = 3.1273113497 
0.0000000000 * -2.8321900000 = 3.1273113497 
0.0000000000 * -5.1301200000 = 3.1273113497 
0.0000000000 * 1.7875500000 = 3.1273113497 
0.0000000000 * -0.7800490000 = 3.1273113497 
0.0000000000 * 3.4665000000 = 3.1273113497 
0.0000000000 * 0.1228280000 = 3.1273113497 
0.0000000000 * 0.7892070000 = 3.1273113497 
2.7992951847 * -1.2097500000 = -0.2591360000 
4.4584052240 * -0.4260880000 = -2.1588089651 
3.4785294551 * 0.2960930000 = -1.1288407432 
0.0000000000 * 0.2231320000 = -1.1288407432 
0.0000000000 * -1.0724600000 = -1.1288407432 
0.0734678262 * -2.4855100000 = -1.3114457598 
0.0000000000 * 2.0470800000 = -1.3114457598 
0.0000000000 * 0.9405310000 = -1.3114457598 
0.0000000000 * 0.4192190000 = -1.3114457598 
0.2251693882 * -2.8390600000 = -1.9507151631 
0.8031315178 * 3.3484900000 = 0.7385626929 
0.0000000000 * 0.8725000000 = 0.7385626929 
0.0000000000 * -5.2906200000 = 0.7385626929 
0.0000000000 * 2.4045000000 = 0.7385626929 
0.3902068183 * -0.9644430000 = 0.3622304584 
0.0000000000 * -8.3995200000 = 0.3622304584 
0.0000000000 * -0.0394036000 = 0.3622304584 
1.2034198021 * -4.0365800000 = -4.4954698463 
0.7788152937 * -3.3162900000 = -7.0782472165 
the biases is : -1.1148900000, now tempVal is : -8.1931372165
ReLU !!! in layer: 5, node : 13, its linear result is negative,so set it to 0
compute layer: 5, node : 14
0.0000000000 * 0.2169870000 = 0.0000000000 
0.0000000000 * 0.4317160000 = 0.0000000000 
0.0000000000 * 0.1010360000 = 0.0000000000 
0.0000000000 * 0.6766430000 = 0.0000000000 
0.0000000000 * -0.2392590000 = 0.0000000000 
0.0000000000 * -0.6440020000 = 0.0000000000 
0.0727527248 * 0.4521700000 = 0.0328965996 
0.0000000000 * 0.1492180000 = 0.0328965996 
0.0000000000 * 0.5752550000 = 0.0328965996 
0.1903205629 * 0.5395490000 = 0.1355838689 
0.0000000000 * -1.1414700000 = 0.1355838689 
2.8096423506 * -0.0388974000 = 0.0262960866 
0.0000000000 * 0.4171260000 = 0.0262960866 
0.0000000000 * -2.5186000000 = 0.0262960866 
0.0000000000 * 0.0329096000 = 0.0262960866 
0.0000000000 * -0.1294170000 = 0.0262960866 
0.0000000000 * -6.1995200000 = 0.0262960866 
0.1333779634 * 0.5564120000 = 0.1005091859 
0.0000000000 * -3.0843800000 = 0.1005091859 
0.0000000000 * -0.4744490000 = 0.1005091859 
0.0000000000 * -0.5783930000 = 0.1005091859 
0.8570723642 * -0.0792406000 = 0.0325942575 
0.8398318691 * -1.5504200000 = -1.2694978689 
1.5787404086 * 0.8052850000 = 0.0018381010 
0.0000000000 * -0.3482690000 = 0.0018381010 
0.0000000000 * -0.5674710000 = 0.0018381010 
0.0000000000 * 0.0119641000 = 0.0018381010 
0.0000000000 * -0.0991636000 = 0.0018381010 
0.0000000000 * -1.7311300000 = 0.0018381010 
0.0000000000 * 1.9284000000 = 0.0018381010 
0.0000000000 * -0.2254360000 = 0.0018381010 
2.7992951847 * -0.1645660000 = -0.4588307104 
4.4584052240 * -0.0872910000 = -0.8480093608 
3.4785294551 * -0.2018310000 = -1.5500844392 
0.0000000000 * -0.0596637000 = -1.5500844392 
0.0000000000 * 0.4192670000 = -1.5500844392 
0.0734678262 * -0.3243640000 = -1.5739147572 
0.0000000000 * 0.7835020000 = -1.5739147572 
0.0000000000 * -0.1709400000 = -1.5739147572 
0.0000000000 * -0.1466470000 = -1.5739147572 
0.2251693882 * 0.3152480000 = -1.5029305579 
0.8031315178 * -0.1923830000 = -1.6574394087 
0.0000000000 * 0.4499490000 = -1.6574394087 
0.0000000000 * -1.2894100000 = -1.6574394087 
0.0000000000 * -1.8431600000 = -1.6574394087 
0.3902068183 * 0.3235790000 = -1.5311766766 
0.0000000000 * 0.0854937000 = -1.5311766766 
0.0000000000 * 0.0301617000 = -1.5311766766 
1.2034198021 * 0.2559680000 = -1.2231397167 
0.7788152937 * -2.3651800000 = -3.0651780730 
the biases is : -0.4456750000, now tempVal is : -3.5108530730
ReLU !!! in layer: 5, node : 14, its linear result is negative,so set it to 0
compute layer: 5, node : 15
0.0000000000 * -0.0651774000 = 0.0000000000 
0.0000000000 * 0.1315780000 = 0.0000000000 
0.0000000000 * 0.4554380000 = 0.0000000000 
0.0000000000 * -0.2381570000 = 0.0000000000 
0.0000000000 * -0.1657160000 = 0.0000000000 
0.0000000000 * 0.5897750000 = 0.0000000000 
0.0727527248 * 0.1651630000 = 0.0120160583 
0.0000000000 * 0.2240650000 = 0.0120160583 
0.0000000000 * -0.0583999000 = 0.0120160583 
0.1903205629 * -0.1458910000 = -0.0157499989 
0.0000000000 * -0.1744070000 = -0.0157499989 
2.8096423506 * -0.2138180000 = -0.6165021071 
0.0000000000 * -0.0859563000 = -0.6165021071 
0.0000000000 * -0.0652727000 = -0.6165021071 
0.0000000000 * -0.0037693600 = -0.6165021071 
0.0000000000 * -0.0917978000 = -0.6165021071 
0.0000000000 * -0.0688946000 = -0.6165021071 
0.1333779634 * 0.0341639000 = -0.6119453957 
0.0000000000 * -0.1526600000 = -0.6119453957 
0.0000000000 * 0.4771960000 = -0.6119453957 
0.0000000000 * 0.0837651000 = -0.6119453957 
0.8570723642 * 0.0367946000 = -0.5804097608 
0.8398318691 * -0.0726499000 = -0.6414234622 
1.5787404086 * 0.0753374000 = -0.5224852645 
0.0000000000 * 0.1710910000 = -0.5224852645 
0.0000000000 * 0.0054960500 = -0.5224852645 
0.0000000000 * -0.2335550000 = -0.5224852645 
0.0000000000 * -0.1199670000 = -0.5224852645 
0.0000000000 * -0.0684520000 = -0.5224852645 
0.0000000000 * -12.8383000000 = -0.5224852645 
0.0000000000 * -0.8804060000 = -0.5224852645 
2.7992951847 * -0.1636880000 = -0.9806962947 
4.4584052240 * 0.0393510000 = -0.8052535907 
3.4785294551 * -0.1817380000 = -1.4374345768 
0.0000000000 * -0.0816960000 = -1.4374345768 
0.0000000000 * -0.2558440000 = -1.4374345768 
0.0734678262 * -0.2187500000 = -1.4535056638 
0.0000000000 * -0.2967480000 = -1.4535056638 
0.0000000000 * 0.2279850000 = -1.4535056638 
0.0000000000 * -0.3890490000 = -1.4535056638 
0.2251693882 * 0.0387661000 = -1.4447767248 
0.8031315178 * 0.1559390000 = -1.3195371990 
0.0000000000 * -0.1113010000 = -1.3195371990 
0.0000000000 * 0.0886789000 = -1.3195371990 
0.0000000000 * 0.0900578000 = -1.3195371990 
0.3902068183 * 0.0022707200 = -1.3186511486 
0.0000000000 * 0.0350527000 = -1.3186511486 
0.0000000000 * 0.0260911000 = -1.3186511486 
1.2034198021 * 0.3820480000 = -0.8588870201 
0.7788152937 * 0.2243500000 = -0.6841598089 
the biases is : 0.6940160000, now tempVal is : 0.0098561911
compute layer: 5, node : 16
0.0000000000 * -0.4679690000 = 0.0000000000 
0.0000000000 * -0.2857200000 = 0.0000000000 
0.0000000000 * -1.4102900000 = 0.0000000000 
0.0000000000 * -1.4510500000 = 0.0000000000 
0.0000000000 * -5.9399100000 = 0.0000000000 
0.0000000000 * 1.3880100000 = 0.0000000000 
0.0727527248 * -0.7310970000 = -0.0531892989 
0.0000000000 * 0.8836550000 = -0.0531892989 
0.0000000000 * -0.8183140000 = -0.0531892989 
0.1903205629 * -0.2513100000 = -0.1010187595 
0.0000000000 * 1.5233800000 = -0.1010187595 
2.8096423506 * -0.8538260000 = -2.4999644491 
0.0000000000 * 0.2495760000 = -2.4999644491 
0.0000000000 * -0.0978616000 = -2.4999644491 
0.0000000000 * 0.0163493000 = -2.4999644491 
0.0000000000 * -0.0591605000 = -2.4999644491 
0.0000000000 * 0.0208357000 = -2.4999644491 
0.1333779634 * -3.0383500000 = -2.9052133841 
0.0000000000 * -0.0094710900 = -2.9052133841 
0.0000000000 * 1.3272500000 = -2.9052133841 
0.0000000000 * -1.9915000000 = -2.9052133841 
0.8570723642 * -0.3854390000 = -3.2355624991 
0.8398318691 * -0.0109491000 = -3.2447579022 
1.5787404086 * -0.6659300000 = -4.2960885025 
0.0000000000 * -1.0261100000 = -4.2960885025 
0.0000000000 * 0.0677868000 = -4.2960885025 
0.0000000000 * -0.2550520000 = -4.2960885025 
0.0000000000 * -0.2082630000 = -4.2960885025 
0.0000000000 * 0.5695630000 = -4.2960885025 
0.0000000000 * 0.0505852000 = -4.2960885025 
0.0000000000 * 0.0718921000 = -4.2960885025 
2.7992951847 * 0.2024510000 = -3.7293683930 
4.4584052240 * -0.1389240000 = -4.3487478804 
3.4785294551 * -0.3398720000 = -5.5310026433 
0.0000000000 * 0.0877640000 = -5.5310026433 
0.0000000000 * 0.5450140000 = -5.5310026433 
0.0734678262 * -1.2958500000 = -5.6262059259 
0.0000000000 * -0.7595560000 = -5.6262059259 
0.0000000000 * -0.7972920000 = -5.6262059259 
0.0000000000 * -1.0919200000 = -5.6262059259 
0.2251693882 * -1.3235100000 = -5.9242198629 
0.8031315178 * 0.9537240000 = -5.1582540592 
0.0000000000 * -0.3257830000 = -5.1582540592 
0.0000000000 * 1.3559500000 = -5.1582540592 
0.0000000000 * 0.6490240000 = -5.1582540592 
0.3902068183 * -2.7283600000 = -6.2228787340 
0.0000000000 * 0.5777090000 = -6.2228787340 
0.0000000000 * -0.0358155000 = -6.2228787340 
1.2034198021 * 0.5704400000 = -5.5363999420 
0.7788152937 * -0.3853990000 = -5.8365545774 
the biases is : 1.2776200000, now tempVal is : -4.5589345774
ReLU !!! in layer: 5, node : 16, its linear result is negative,so set it to 0
compute layer: 5, node : 17
0.0000000000 * 0.2829380000 = 0.0000000000 
0.0000000000 * 1.6801800000 = 0.0000000000 
0.0000000000 * 1.0762900000 = 0.0000000000 
0.0000000000 * -0.6209430000 = 0.0000000000 
0.0000000000 * 0.0434746000 = 0.0000000000 
0.0000000000 * 0.2967230000 = 0.0000000000 
0.0727527248 * 1.2045000000 = 0.0876306570 
0.0000000000 * -0.2445550000 = 0.0876306570 
0.0000000000 * 0.9680580000 = 0.0876306570 
0.1903205629 * -0.1261850000 = 0.0636150568 
0.0000000000 * 1.0286000000 = 0.0636150568 
2.8096423506 * 0.7491340000 = 2.1684136695 
0.0000000000 * -1.6055700000 = 2.1684136695 
0.0000000000 * -0.3155430000 = 2.1684136695 
0.0000000000 * -0.0312326000 = 2.1684136695 
0.0000000000 * -0.1397540000 = 2.1684136695 
0.0000000000 * 0.1174090000 = 2.1684136695 
0.1333779634 * 0.1365660000 = 2.1866285644 
0.0000000000 * 0.0986693000 = 2.1866285644 
0.0000000000 * 1.6582500000 = 2.1866285644 
0.0000000000 * 0.3718370000 = 2.1866285644 
0.8570723642 * -0.3512980000 = 1.8855407570 
0.8398318691 * -0.0299128000 = 1.8604190343 
1.5787404086 * -0.2287200000 = 1.4993295281 
0.0000000000 * -0.4078470000 = 1.4993295281 
0.0000000000 * 0.0792935000 = 1.4993295281 
0.0000000000 * -0.1915100000 = 1.4993295281 
0.0000000000 * -0.3410030000 = 1.4993295281 
0.0000000000 * 0.7766990000 = 1.4993295281 
0.0000000000 * 0.7928720000 = 1.4993295281 
0.0000000000 * -1.1255700000 = 1.4993295281 
2.7992951847 * 0.2860890000 = 2.3001770881 
4.4584052240 * -0.6598990000 = -0.6419200608 
3.4785294551 * 0.1994520000 = 0.0518795961 
0.0000000000 * 0.1129730000 = 0.0518795961 
0.0000000000 * -0.5008280000 = 0.0518795961 
0.0734678262 * -0.4814560000 = 0.0165080704 
0.0000000000 * 1.0977900000 = 0.0165080704 
0.0000000000 * 0.0178231000 = 0.0165080704 
0.0000000000 * 0.4370440000 = 0.0165080704 
0.2251693882 * -0.0393423000 = 0.0076493888 
0.8031315178 * -0.2213120000 = -0.1700932537 
0.0000000000 * 0.5650160000 = -0.1700932537 
0.0000000000 * -0.0698320000 = -0.1700932537 
0.0000000000 * -0.1749370000 = -0.1700932537 
0.3902068183 * 0.2140480000 = -0.0865702647 
0.0000000000 * 0.3463890000 = -0.0865702647 
0.0000000000 * -0.0462240000 = -0.0865702647 
1.2034198021 * -0.3736010000 = -0.5361691061 
0.7788152937 * -0.3785890000 = -0.8310200094 
the biases is : -1.2911200000, now tempVal is : -2.1221400094
ReLU !!! in layer: 5, node : 17, its linear result is negative,so set it to 0
compute layer: 5, node : 18
0.0000000000 * -0.0282119000 = 0.0000000000 
0.0000000000 * 0.6554210000 = 0.0000000000 
0.0000000000 * -1.9244900000 = 0.0000000000 
0.0000000000 * -4.4303000000 = 0.0000000000 
0.0000000000 * -3.7653700000 = 0.0000000000 
0.0000000000 * 1.6341200000 = 0.0000000000 
0.0727527248 * -0.5128260000 = -0.0373094889 
0.0000000000 * 0.5599510000 = -0.0373094889 
0.0000000000 * -0.4368640000 = -0.0373094889 
0.1903205629 * 0.2838070000 = 0.0167048191 
0.0000000000 * -0.0470535000 = 0.0167048191 
2.8096423506 * -8.9088800000 = -25.0140617250 
0.0000000000 * -0.4380950000 = -25.0140617250 
0.0000000000 * -0.0165175000 = -25.0140617250 
0.0000000000 * -0.0199490000 = -25.0140617250 
0.0000000000 * -0.2021890000 = -25.0140617250 
0.0000000000 * 0.1149610000 = -25.0140617250 
0.1333779634 * 0.1026910000 = -25.0003650086 
0.0000000000 * 0.0082097700 = -25.0003650086 
0.0000000000 * -0.1527670000 = -25.0003650086 
0.0000000000 * 0.9089440000 = -25.0003650086 
0.8570723642 * -0.0272886000 = -25.0237533135 
0.8398318691 * -4.9595700000 = -29.1889582565 
1.5787404086 * 0.0434976000 = -29.1202868377 
0.0000000000 * 0.1055700000 = -29.1202868377 
0.0000000000 * -0.0287552000 = -29.1202868377 
0.0000000000 * 0.0717929000 = -29.1202868377 
0.0000000000 * -0.2448710000 = -29.1202868377 
0.0000000000 * -0.0008631090 = -29.1202868377 
0.0000000000 * -0.7393130000 = -29.1202868377 
0.0000000000 * 0.1195510000 = -29.1202868377 
2.7992951847 * -0.4676740000 = -30.4294444139 
4.4584052240 * -2.8164100000 = -42.9861414709 
3.4785294551 * -0.0876342000 = -43.2909796168 
0.0000000000 * -0.0048785900 = -43.2909796168 
0.0000000000 * 0.6985490000 = -43.2909796168 
0.0734678262 * 0.9280570000 = -43.2227972865 
0.0000000000 * -1.0584000000 = -43.2227972865 
0.0000000000 * 0.1455050000 = -43.2227972865 
0.0000000000 * 1.0429700000 = -43.2227972865 
0.2251693882 * -0.0467779000 = -43.2333302376 
0.8031315178 * -1.1300300000 = -44.1408929467 
0.0000000000 * 0.7248630000 = -44.1408929467 
0.0000000000 * 1.4684100000 = -44.1408929467 
0.0000000000 * -5.9134300000 = -44.1408929467 
0.3902068183 * -0.0759377000 = -44.1705243550 
0.0000000000 * -1.9218800000 = -44.1705243550 
0.0000000000 * -0.0073591500 = -44.1705243550 
1.2034198021 * -0.1659470000 = -44.3702282609 
0.7788152937 * -3.8219800000 = -47.3468447369 
the biases is : -1.3422500000, now tempVal is : -48.6890947369
ReLU !!! in layer: 5, node : 18, its linear result is negative,so set it to 0
compute layer: 5, node : 19
0.0000000000 * -0.2420080000 = 0.0000000000 
0.0000000000 * -0.0143518000 = 0.0000000000 
0.0000000000 * 0.8292810000 = 0.0000000000 
0.0000000000 * -0.9624640000 = 0.0000000000 
0.0000000000 * 0.0598716000 = 0.0000000000 
0.0000000000 * 0.0042940800 = 0.0000000000 
0.0727527248 * 0.2957460000 = 0.0215163274 
0.0000000000 * 0.1568660000 = 0.0215163274 
0.0000000000 * 0.1037910000 = 0.0215163274 
0.1903205629 * -0.2557290000 = -0.0271541599 
0.0000000000 * -0.4309830000 = -0.0271541599 
2.8096423506 * 0.0474375000 = 0.1061282491 
0.0000000000 * -0.7426860000 = 0.1061282491 
0.0000000000 * -0.0068865000 = 0.1061282491 
0.0000000000 * 0.0022507700 = 0.1061282491 
0.0000000000 * -0.1105120000 = 0.1061282491 
0.0000000000 * -0.7111500000 = 0.1061282491 
0.1333779634 * 0.0787291000 = 0.1166289762 
0.0000000000 * 0.1508780000 = 0.1166289762 
0.0000000000 * 0.0079026600 = 0.1166289762 
0.0000000000 * -0.1338060000 = 0.1166289762 
0.8570723642 * 0.0156908000 = 0.1300771272 
0.8398318691 * -0.3209610000 = -0.1394761493 
1.5787404086 * 0.4077030000 = 0.5041810515 
0.0000000000 * 0.4407700000 = 0.5041810515 
0.0000000000 * -1.0420000000 = 0.5041810515 
0.0000000000 * -0.3754260000 = 0.5041810515 
0.0000000000 * -0.0262698000 = 0.5041810515 
0.0000000000 * 0.8175470000 = 0.5041810515 
0.0000000000 * -0.5074630000 = 0.5041810515 
0.0000000000 * -0.1229210000 = 0.5041810515 
2.7992951847 * -0.1053630000 = 0.2092389129 
4.4584052240 * 0.1214770000 = 0.7508326043 
3.4785294551 * -0.2393590000 = -0.0817847275 
0.0000000000 * -0.4268590000 = -0.0817847275 
0.0000000000 * 0.2753460000 = -0.0817847275 
0.0734678262 * 0.2770360000 = -0.0614314948 
0.0000000000 * 0.1174580000 = -0.0614314948 
0.0000000000 * 0.1003580000 = -0.0614314948 
0.0000000000 * 0.2392770000 = -0.0614314948 
0.2251693882 * -0.0684942000 = -0.0768542919 
0.8031315178 * 0.2821440000 = 0.1497444470 
0.0000000000 * 0.7716530000 = 0.1497444470 
0.0000000000 * -0.7045390000 = 0.1497444470 
0.0000000000 * 0.2197610000 = 0.1497444470 
0.3902068183 * -0.3000220000 = 0.0326738170 
0.0000000000 * 0.7915410000 = 0.0326738170 
0.0000000000 * 0.0346975000 = 0.0326738170 
1.2034198021 * 0.2693110000 = 0.3567680073 
0.7788152937 * -0.4287040000 = 0.0228867756 
the biases is : -0.1596710000, now tempVal is : -0.1367842244
ReLU !!! in layer: 5, node : 19, its linear result is negative,so set it to 0
compute layer: 5, node : 20
0.0000000000 * 0.6847790000 = 0.0000000000 
0.0000000000 * -1.2392500000 = 0.0000000000 
0.0000000000 * -0.2670950000 = 0.0000000000 
0.0000000000 * 1.6138700000 = 0.0000000000 
0.0000000000 * 0.1421030000 = 0.0000000000 
0.0000000000 * -0.9210540000 = 0.0000000000 
0.0727527248 * -0.4516300000 = -0.0328573131 
0.0000000000 * -1.2868700000 = -0.0328573131 
0.0000000000 * -1.0875500000 = -0.0328573131 
0.1903205629 * 0.4763070000 = 0.0577937032 
0.0000000000 * 0.5629880000 = 0.0577937032 
2.8096423506 * -1.3538700000 = -3.7460967859 
0.0000000000 * -0.1203730000 = -3.7460967859 
0.0000000000 * -1.4514000000 = -3.7460967859 
0.0000000000 * 0.0106518000 = -3.7460967859 
0.0000000000 * 0.0503995000 = -3.7460967859 
0.0000000000 * -3.2198600000 = -3.7460967859 
0.1333779634 * 0.2259370000 = -3.7159617690 
0.0000000000 * -1.3264700000 = -3.7159617690 
0.0000000000 * -0.5997010000 = -3.7159617690 
0.0000000000 * -0.3860490000 = -3.7159617690 
0.8570723642 * 0.3173670000 = -3.4439552840 
0.8398318691 * -0.6939670000 = -4.0267708867 
1.5787404086 * 0.6286270000 = -3.0343320399 
0.0000000000 * 1.4036900000 = -3.0343320399 
0.0000000000 * -0.7783550000 = -3.0343320399 
0.0000000000 * -0.8617180000 = -3.0343320399 
0.0000000000 * 0.4128260000 = -3.0343320399 
0.0000000000 * -1.3588900000 = -3.0343320399 
0.0000000000 * 0.9903980000 = -3.0343320399 
0.0000000000 * -1.3949700000 = -3.0343320399 
2.7992951847 * 0.3074510000 = -2.1736859361 
4.4584052240 * 0.1983620000 = -1.2893077590 
3.4785294551 * 0.4105120000 = 0.1386703246 
0.0000000000 * -0.3334510000 = 0.1386703246 
0.0000000000 * -1.0943000000 = 0.1386703246 
0.0734678262 * 1.0427100000 = 0.2152759617 
0.0000000000 * -0.8714180000 = 0.2152759617 
0.0000000000 * 0.2395920000 = 0.2152759617 
0.0000000000 * -4.3083900000 = 0.2152759617 
0.2251693882 * -0.2555970000 = 0.1577233415 
0.8031315178 * -1.1128500000 = -0.7360415680 
0.0000000000 * -0.5986630000 = -0.7360415680 
0.0000000000 * -0.9395160000 = -0.7360415680 
0.0000000000 * 0.1285420000 = -0.7360415680 
0.3902068183 * 0.6008000000 = -0.5016053116 
0.0000000000 * -0.7712140000 = -0.5016053116 
0.0000000000 * 0.0468901000 = -0.5016053116 
1.2034198021 * 0.3992950000 = -0.0210858017 
0.7788152937 * -1.1373400000 = -0.9068635878 
the biases is : 0.6452230000, now tempVal is : -0.2616405878
ReLU !!! in layer: 5, node : 20, its linear result is negative,so set it to 0
compute layer: 5, node : 21
0.0000000000 * -0.1214180000 = 0.0000000000 
0.0000000000 * 0.0887225000 = 0.0000000000 
0.0000000000 * 0.0371437000 = 0.0000000000 
0.0000000000 * 0.1183980000 = 0.0000000000 
0.0000000000 * -0.1935670000 = 0.0000000000 
0.0000000000 * -0.4850590000 = 0.0000000000 
0.0727527248 * -0.1667270000 = -0.0121298436 
0.0000000000 * -0.0866930000 = -0.0121298436 
0.0000000000 * 0.8894510000 = -0.0121298436 
0.1903205629 * -0.1371040000 = -0.0382235540 
0.0000000000 * 0.0602432000 = -0.0382235540 
2.8096423506 * -0.4349290000 = -1.2602184919 
0.0000000000 * 0.0403237000 = -1.2602184919 
0.0000000000 * -0.2054670000 = -1.2602184919 
0.0000000000 * 0.0486817000 = -1.2602184919 
0.0000000000 * -0.0091831600 = -1.2602184919 
0.0000000000 * -0.2362750000 = -1.2602184919 
0.1333779634 * -0.0637436000 = -1.2687204834 
0.0000000000 * 0.0847122000 = -1.2687204834 
0.0000000000 * -0.0280539000 = -1.2687204834 
0.0000000000 * -0.0872957000 = -1.2687204834 
0.8570723642 * 0.0251945000 = -1.2471269738 
0.8398318691 * -0.0041557400 = -1.2506170966 
1.5787404086 * -0.1090500000 = -1.4227787382 
0.0000000000 * 0.3213880000 = -1.4227787382 
0.0000000000 * -0.1721100000 = -1.4227787382 
0.0000000000 * -0.3024080000 = -1.4227787382 
0.0000000000 * 0.0503998000 = -1.4227787382 
0.0000000000 * 0.0394051000 = -1.4227787382 
0.0000000000 * -0.2070330000 = -1.4227787382 
0.0000000000 * -0.0905195000 = -1.4227787382 
2.7992951847 * 0.2374720000 = -0.7580245121 
4.4584052240 * 0.0400698000 = -0.5793771065 
3.4785294551 * -0.2098110000 = -1.3092108500 
0.0000000000 * -0.0619867000 = -1.3092108500 
0.0000000000 * -0.2180700000 = -1.3092108500 
0.0734678262 * 0.1277650000 = -1.2998242332 
0.0000000000 * 0.1128820000 = -1.2998242332 
0.0000000000 * 0.0017129100 = -1.2998242332 
0.0000000000 * -0.1184700000 = -1.2998242332 
0.2251693882 * -0.0661039000 = -1.3147088079 
0.8031315178 * 0.0295239000 = -1.2909972333 
0.0000000000 * 0.4559340000 = -1.2909972333 
0.0000000000 * -0.2963260000 = -1.2909972333 
0.0000000000 * -0.1828330000 = -1.2909972333 
0.3902068183 * -0.0033645800 = -1.2923101153 
0.0000000000 * 0.1836890000 = -1.2923101153 
0.0000000000 * 0.0393237000 = -1.2923101153 
1.2034198021 * 0.1737540000 = -1.0832111110 
0.7788152937 * 0.0867553000 = -1.0156447566 
the biases is : 0.9886290000, now tempVal is : -0.0270157566
ReLU !!! in layer: 5, node : 21, its linear result is negative,so set it to 0
compute layer: 5, node : 22
0.0000000000 * 0.0371726000 = 0.0000000000 
0.0000000000 * 0.0334255000 = 0.0000000000 
0.0000000000 * 0.1618730000 = 0.0000000000 
0.0000000000 * -0.2001240000 = 0.0000000000 
0.0000000000 * 0.0542473000 = 0.0000000000 
0.0000000000 * -2.0025400000 = 0.0000000000 
0.0727527248 * 0.2189680000 = 0.0159305186 
0.0000000000 * -0.1166940000 = 0.0159305186 
0.0000000000 * -0.0584859000 = 0.0159305186 
0.1903205629 * 0.0713410000 = 0.0295081779 
0.0000000000 * -0.3516330000 = 0.0295081779 
2.8096423506 * 0.5943860000 = 1.6995202561 
0.0000000000 * 0.1295160000 = 1.6995202561 
0.0000000000 * -0.2418450000 = 1.6995202561 
0.0000000000 * 0.0092975500 = 1.6995202561 
0.0000000000 * 0.0030710300 = 1.6995202561 
0.0000000000 * 0.1193920000 = 1.6995202561 
0.1333779634 * 0.1054450000 = 1.7135842955 
0.0000000000 * 0.2489300000 = 1.7135842955 
0.0000000000 * 0.5719740000 = 1.7135842955 
0.0000000000 * 0.2533250000 = 1.7135842955 
0.8570723642 * -0.0334011000 = 1.6849571357 
0.8398318691 * -0.0632295000 = 1.6318549865 
1.5787404086 * 0.1496910000 = 1.8681782170 
0.0000000000 * 0.4722550000 = 1.8681782170 
0.0000000000 * 0.1405290000 = 1.8681782170 
0.0000000000 * 0.1562880000 = 1.8681782170 
0.0000000000 * -0.0179687000 = 1.8681782170 
0.0000000000 * 0.3528360000 = 1.8681782170 
0.0000000000 * 1.3967900000 = 1.8681782170 
0.0000000000 * -5.1045100000 = 1.8681782170 
2.7992951847 * -0.7062790000 = -0.1089051867 
4.4584052240 * -0.4811580000 = -2.2541025275 
3.4785294551 * 0.0409242000 = -2.1117464924 
0.0000000000 * 0.0019405600 = -2.1117464924 
0.0000000000 * -0.5014760000 = -2.1117464924 
0.0734678262 * 0.0368214000 = -2.1090413041 
0.0000000000 * 0.3828500000 = -2.1090413041 
0.0000000000 * 0.0885774000 = -2.1090413041 
0.0000000000 * -0.1566560000 = -2.1090413041 
0.2251693882 * 0.0869260000 = -2.0894682299 
0.8031315178 * -0.6497070000 = -2.6112683989 
0.0000000000 * -0.2661360000 = -2.6112683989 
0.0000000000 * 0.0716584000 = -2.6112683989 
0.0000000000 * 0.1002700000 = -2.6112683989 
0.3902068183 * 0.0243436000 = -2.6017693602 
0.0000000000 * -0.1725010000 = -2.6017693602 
0.0000000000 * 0.0417889000 = -2.6017693602 
1.2034198021 * -0.0181834000 = -2.6236516239 
0.7788152937 * -0.0945115000 = -2.6972586255 
the biases is : 0.5161510000, now tempVal is : -2.1811076255
ReLU !!! in layer: 5, node : 22, its linear result is negative,so set it to 0
compute layer: 5, node : 23
0.0000000000 * -0.5254920000 = 0.0000000000 
0.0000000000 * -0.2970790000 = 0.0000000000 
0.0000000000 * 0.6699680000 = 0.0000000000 
0.0000000000 * -0.2298980000 = 0.0000000000 
0.0000000000 * -0.0075908900 = 0.0000000000 
0.0000000000 * -0.5386530000 = 0.0000000000 
0.0727527248 * -0.0594109000 = -0.0043223049 
0.0000000000 * 1.1182300000 = -0.0043223049 
0.0000000000 * -2.0400400000 = -0.0043223049 
0.1903205629 * 0.6661470000 = 0.1224591671 
0.0000000000 * 0.1167580000 = 0.1224591671 
2.8096423506 * -0.1716820000 = -0.3599058509 
0.0000000000 * -1.2449700000 = -0.3599058509 
0.0000000000 * -1.8074400000 = -0.3599058509 
0.0000000000 * 0.0069039600 = -0.3599058509 
0.0000000000 * 0.1286350000 = -0.3599058509 
0.0000000000 * 0.2426600000 = -0.3599058509 
0.1333779634 * 0.1743640000 = -0.3366495357 
0.0000000000 * 1.0859500000 = -0.3366495357 
0.0000000000 * 1.6306100000 = -0.3366495357 
0.0000000000 * -0.6390530000 = -0.3366495357 
0.8570723642 * -0.2170200000 = -0.5226513802 
0.8398318691 * -0.0491286000 = -0.5639111441 
1.5787404086 * 0.2976380000 = -0.0940180064 
0.0000000000 * -0.5637110000 = -0.0940180064 
0.0000000000 * -0.1272010000 = -0.0940180064 
0.0000000000 * 0.0292218000 = -0.0940180064 
0.0000000000 * -0.8597840000 = -0.0940180064 
0.0000000000 * 3.7292500000 = -0.0940180064 
0.0000000000 * -11.6126000000 = -0.0940180064 
0.0000000000 * 0.9445550000 = -0.0940180064 
2.7992951847 * -0.8924750000 = -2.5923189764 
4.4584052240 * 0.6226950000 = 0.1839076646 
3.4785294551 * -0.0795862000 = -0.0929352763 
0.0000000000 * -0.0597896000 = -0.0929352763 
0.0000000000 * 0.1783460000 = -0.0929352763 
0.0734678262 * 0.2233320000 = -0.0765275598 
0.0000000000 * 0.7877620000 = -0.0765275598 
0.0000000000 * 0.3055430000 = -0.0765275598 
0.0000000000 * -0.1784520000 = -0.0765275598 
0.2251693882 * 0.2885110000 = -0.0115637144 
0.8031315178 * -0.6993180000 = -0.5732080412 
0.0000000000 * 0.4283860000 = -0.5732080412 
0.0000000000 * 0.2114300000 = -0.5732080412 
0.0000000000 * -1.4998700000 = -0.5732080412 
0.3902068183 * 0.7343540000 = -0.2866581033 
0.0000000000 * -0.1623410000 = -0.2866581033 
0.0000000000 * 0.0240091000 = -0.2866581033 
1.2034198021 * -0.4026750000 = -0.7712451721 
0.7788152937 * 0.2937820000 = -0.5424432575 
the biases is : -2.3827400000, now tempVal is : -2.9251832575
ReLU !!! in layer: 5, node : 23, its linear result is negative,so set it to 0
compute layer: 5, node : 24
0.0000000000 * -0.0616888000 = 0.0000000000 
0.0000000000 * -0.5223190000 = 0.0000000000 
0.0000000000 * -0.1754030000 = 0.0000000000 
0.0000000000 * -0.0572232000 = 0.0000000000 
0.0000000000 * -0.2950340000 = 0.0000000000 
0.0000000000 * 0.8475190000 = 0.0000000000 
0.0727527248 * 0.6413990000 = 0.0466635249 
0.0000000000 * 0.2658490000 = 0.0466635249 
0.0000000000 * 0.1602540000 = 0.0466635249 
0.1903205629 * 0.1339990000 = 0.0721662900 
0.0000000000 * 0.1008540000 = 0.0721662900 
2.8096423506 * -0.1290230000 = -0.2903421949 
0.0000000000 * 0.3711350000 = -0.2903421949 
0.0000000000 * -0.3241030000 = -0.2903421949 
0.0000000000 * 0.0577432000 = -0.2903421949 
0.0000000000 * -0.1103370000 = -0.2903421949 
0.0000000000 * -0.4137920000 = -0.2903421949 
0.1333779634 * -0.3515710000 = -0.3372340189 
0.0000000000 * -0.4503860000 = -0.3372340189 
0.0000000000 * 0.2889960000 = -0.3372340189 
0.0000000000 * -0.4253870000 = -0.3372340189 
0.8570723642 * -0.4843910000 = -0.7523921585 
0.8398318691 * -0.1169500000 = -0.8506104955 
1.5787404086 * -0.2025810000 = -1.1704333063 
0.0000000000 * 0.1194540000 = -1.1704333063 
0.0000000000 * -0.5670010000 = -1.1704333063 
0.0000000000 * -0.1643700000 = -1.1704333063 
0.0000000000 * -0.2487970000 = -1.1704333063 
0.0000000000 * -0.6760470000 = -1.1704333063 
0.0000000000 * 0.4382640000 = -1.1704333063 
0.0000000000 * -0.0689069000 = -1.1704333063 
2.7992951847 * 0.0412898000 = -1.0548509679 
4.4584052240 * -0.0401866000 = -1.2340191153 
3.4785294551 * -0.4810690000 = -2.9074318017 
0.0000000000 * -0.1093390000 = -2.9074318017 
0.0000000000 * -0.1761870000 = -2.9074318017 
0.0734678262 * 0.4335890000 = -2.8755769605 
0.0000000000 * 0.1231140000 = -2.8755769605 
0.0000000000 * -0.1131770000 = -2.8755769605 
0.0000000000 * 0.7466870000 = -2.8755769605 
0.2251693882 * -0.3182350000 = -2.9472337407 
0.8031315178 * 0.3454050000 = -2.6698280988 
0.0000000000 * 0.3840480000 = -2.6698280988 
0.0000000000 * -0.2860150000 = -2.6698280988 
0.0000000000 * 0.1356690000 = -2.6698280988 
0.3902068183 * -0.2455250000 = -2.7656336279 
0.0000000000 * 0.3396530000 = -2.7656336279 
0.0000000000 * -0.0234591000 = -2.7656336279 
1.2034198021 * 0.4790160000 = -2.1891762880 
0.7788152937 * -0.0245504000 = -2.2082965149 
the biases is : 0.6767560000, now tempVal is : -1.5315405149
ReLU !!! in layer: 5, node : 24, its linear result is negative,so set it to 0
compute layer: 5, node : 25
0.0000000000 * -0.0333300000 = 0.0000000000 
0.0000000000 * -0.4202230000 = 0.0000000000 
0.0000000000 * 0.3958150000 = 0.0000000000 
0.0000000000 * 0.1631830000 = 0.0000000000 
0.0000000000 * 0.1087900000 = 0.0000000000 
0.0000000000 * -0.5832080000 = 0.0000000000 
0.0727527248 * 0.0209813000 = 0.0015264467 
0.0000000000 * -0.1840930000 = 0.0015264467 
0.0000000000 * -0.0245447000 = 0.0015264467 
0.1903205629 * 0.0403770000 = 0.0092110201 
0.0000000000 * 0.0373998000 = 0.0092110201 
2.8096423506 * 0.0559828000 = 0.1665026659 
0.0000000000 * 0.2599720000 = 0.1665026659 
0.0000000000 * 0.3523180000 = 0.1665026659 
0.0000000000 * 0.0035046800 = 0.1665026659 
0.0000000000 * -0.0078336400 = 0.1665026659 
0.0000000000 * 0.1206310000 = 0.1665026659 
0.1333779634 * 0.0725094000 = 0.1761738220 
0.0000000000 * 0.0820311000 = 0.1761738220 
0.0000000000 * -0.1569810000 = 0.1761738220 
0.0000000000 * 0.0048978400 = 0.1761738220 
0.8570723642 * 0.1487050000 = 0.3036247679 
0.8398318691 * 0.0014270200 = 0.3048232248 
1.5787404086 * 0.1119360000 = 0.4815411112 
0.0000000000 * 0.3405590000 = 0.4815411112 
0.0000000000 * 0.0724226000 = 0.4815411112 
0.0000000000 * -0.0959207000 = 0.4815411112 
0.0000000000 * -0.1526910000 = 0.4815411112 
0.0000000000 * 0.0844416000 = 0.4815411112 
0.0000000000 * 0.2794740000 = 0.4815411112 
0.0000000000 * -0.9250870000 = 0.4815411112 
2.7992951847 * 0.0016556500 = 0.4861757642 
4.4584052240 * -0.0079441000 = 0.4507577473 
3.4785294551 * 0.1821210000 = 1.0842710102 
0.0000000000 * 0.0668509000 = 1.0842710102 
0.0000000000 * -0.4672140000 = 1.0842710102 
0.0734678262 * 0.0748087000 = 1.0897670427 
0.0000000000 * -0.0174181000 = 1.0897670427 
0.0000000000 * -0.0756833000 = 1.0897670427 
0.0000000000 * -0.2852310000 = 1.0897670427 
0.2251693882 * 0.0500349000 = 1.1010333706 
0.8031315178 * -0.1070360000 = 1.0150693854 
0.0000000000 * -0.4020670000 = 1.0150693854 
0.0000000000 * 0.1489780000 = 1.0150693854 
0.0000000000 * 0.2668570000 = 1.0150693854 
0.3902068183 * 0.1464480000 = 1.0722143936 
0.0000000000 * -0.1164260000 = 1.0722143936 
0.0000000000 * 0.0093160800 = 1.0722143936 
1.2034198021 * 0.0834037000 = 1.1725840577 
0.7788152937 * 0.1548130000 = 1.2931547898 
the biases is : 0.7618670000, now tempVal is : 2.0550217898
compute layer: 5, node : 26
0.0000000000 * 0.3476320000 = 0.0000000000 
0.0000000000 * -0.3274010000 = 0.0000000000 
0.0000000000 * 0.6055280000 = 0.0000000000 
0.0000000000 * 0.0714051000 = 0.0000000000 
0.0000000000 * -0.1424110000 = 0.0000000000 
0.0000000000 * 0.4559370000 = 0.0000000000 
0.0727527248 * 0.5411030000 = 0.0393667177 
0.0000000000 * 0.0210319000 = 0.0393667177 
0.0000000000 * -0.0268355000 = 0.0393667177 
0.1903205629 * -0.0252585000 = 0.0345595057 
0.0000000000 * 0.0554241000 = 0.0345595057 
2.8096423506 * -0.1939420000 = -0.5103481510 
0.0000000000 * -0.1929400000 = -0.5103481510 
0.0000000000 * 0.3878680000 = -0.5103481510 
0.0000000000 * 0.0525489000 = -0.5103481510 
0.0000000000 * 0.0783566000 = -0.5103481510 
0.0000000000 * -0.5845970000 = -0.5103481510 
0.1333779634 * 0.1301060000 = -0.4929948777 
0.0000000000 * -0.4215800000 = -0.4929948777 
0.0000000000 * 0.5038480000 = -0.4929948777 
0.0000000000 * -0.0926099000 = -0.4929948777 
0.8570723642 * -0.1143070000 = -0.5909642485 
0.8398318691 * -0.0689267000 = -0.6488510878 
1.5787404086 * 0.0697529000 = -0.5387293659 
0.0000000000 * 0.6390380000 = -0.5387293659 
0.0000000000 * -0.1290070000 = -0.5387293659 
0.0000000000 * -0.0843851000 = -0.5387293659 
0.0000000000 * -0.4977160000 = -0.5387293659 
0.0000000000 * -0.0927106000 = -0.5387293659 
0.0000000000 * 1.9163800000 = -0.5387293659 
0.0000000000 * 0.0808919000 = -0.5387293659 
2.7992951847 * -0.0645766000 = -0.7194983313 
4.4584052240 * 0.0306129000 = -0.5830136181 
3.4785294551 * -0.1768480000 = -1.1981845951 
0.0000000000 * -0.1752640000 = -1.1981845951 
0.0000000000 * 0.1138710000 = -1.1981845951 
0.0734678262 * 0.6488800000 = -1.1505127921 
0.0000000000 * 0.0495647000 = -1.1505127921 
0.0000000000 * -0.2150630000 = -1.1505127921 
0.0000000000 * 0.0394430000 = -1.1505127921 
0.2251693882 * -0.0047893200 = -1.1515912003 
0.8031315178 * 0.1109070000 = -1.0625182931 
0.0000000000 * -0.3567720000 = -1.0625182931 
0.0000000000 * -0.2382220000 = -1.0625182931 
0.0000000000 * -0.0782477000 = -1.0625182931 
0.3902068183 * 0.1568260000 = -1.0013237186 
0.0000000000 * 0.5067560000 = -1.0013237186 
0.0000000000 * -0.0344773000 = -1.0013237186 
1.2034198021 * 0.3526560000 = -0.5769305049 
0.7788152937 * -0.3896090000 = -0.8803639526 
the biases is : 0.0567606000, now tempVal is : -0.8236033526
ReLU !!! in layer: 5, node : 26, its linear result is negative,so set it to 0
compute layer: 5, node : 27
0.0000000000 * 0.2255020000 = 0.0000000000 
0.0000000000 * 0.5182880000 = 0.0000000000 
0.0000000000 * 0.5586380000 = 0.0000000000 
0.0000000000 * -0.5151260000 = 0.0000000000 
0.0000000000 * 0.0242073000 = 0.0000000000 
0.0000000000 * -0.4113410000 = 0.0000000000 
0.0727527248 * 0.5333680000 = 0.0388039753 
0.0000000000 * 0.1759020000 = 0.0388039753 
0.0000000000 * 0.6550530000 = 0.0388039753 
0.1903205629 * 0.2854700000 = 0.0931347864 
0.0000000000 * -0.2196990000 = 0.0931347864 
2.8096423506 * -0.5784680000 = -1.5321534048 
0.0000000000 * -0.0843267000 = -1.5321534048 
0.0000000000 * -0.5014130000 = -1.5321534048 
0.0000000000 * -0.0218207000 = -1.5321534048 
0.0000000000 * -0.0432255000 = -1.5321534048 
0.0000000000 * -1.0852000000 = -1.5321534048 
0.1333779634 * 0.0502407000 = -1.5254524026 
0.0000000000 * -0.7869600000 = -1.5254524026 
0.0000000000 * 1.1112200000 = -1.5254524026 
0.0000000000 * 0.0573125000 = -1.5254524026 
0.8570723642 * 0.0035622000 = -1.5223993394 
0.8398318691 * -0.7938580000 = -2.1891065874 
1.5787404086 * 0.1032740000 = -2.0260637504 
0.0000000000 * 0.3976390000 = -2.0260637504 
0.0000000000 * -0.3014530000 = -2.0260637504 
0.0000000000 * -0.2974500000 = -2.0260637504 
0.0000000000 * -0.3390790000 = -2.0260637504 
0.0000000000 * 0.8269330000 = -2.0260637504 
0.0000000000 * 1.6905700000 = -2.0260637504 
0.0000000000 * -0.0982163000 = -2.0260637504 
2.7992951847 * 0.2822380000 = -1.2359962761 
4.4584052240 * 0.1625880000 = -0.5111130875 
3.4785294551 * -0.2082340000 = -1.2354611901 
0.0000000000 * -0.0778498000 = -1.2354611901 
0.0000000000 * 0.8751480000 = -1.2354611901 
0.0734678262 * -0.5144500000 = -1.2732567132 
0.0000000000 * 0.5175510000 = -1.2732567132 
0.0000000000 * 0.0572592000 = -1.2732567132 
0.0000000000 * 0.9478060000 = -1.2732567132 
0.2251693882 * 0.0790750000 = -1.2554514439 
0.8031315178 * 0.5689830000 = -0.7984832635 
0.0000000000 * 0.1823290000 = -0.7984832635 
0.0000000000 * 0.2913280000 = -0.7984832635 
0.0000000000 * 0.0767892000 = -0.7984832635 
0.3902068183 * 0.1411640000 = -0.7434001082 
0.0000000000 * 0.5526320000 = -0.7434001082 
0.0000000000 * -0.0276699000 = -0.7434001082 
1.2034198021 * 0.0935139000 = -0.6308636291 
0.7788152937 * -0.9482840000 = -1.3694017111 
the biases is : -0.2224610000, now tempVal is : -1.5918627111
ReLU !!! in layer: 5, node : 27, its linear result is negative,so set it to 0
compute layer: 5, node : 28
0.0000000000 * 1.1589500000 = 0.0000000000 
0.0000000000 * -0.0829950000 = 0.0000000000 
0.0000000000 * -0.5241020000 = 0.0000000000 
0.0000000000 * 1.9708900000 = 0.0000000000 
0.0000000000 * -1.2717900000 = 0.0000000000 
0.0000000000 * 0.5485260000 = 0.0000000000 
0.0727527248 * 0.3437850000 = 0.0250112955 
0.0000000000 * -0.3966280000 = 0.0250112955 
0.0000000000 * -1.1918000000 = 0.0250112955 
0.1903205629 * 0.4089740000 = 0.1028474574 
0.0000000000 * -2.0645900000 = 0.1028474574 
2.8096423506 * -0.2026670000 = -0.4665743289 
0.0000000000 * -0.0633527000 = -0.4665743289 
0.0000000000 * -1.1936400000 = -0.4665743289 
0.0000000000 * 0.0140823000 = -0.4665743289 
0.0000000000 * 0.0865772000 = -0.4665743289 
0.0000000000 * -4.4910300000 = -0.4665743289 
0.1333779634 * 1.1093200000 = -0.3186154866 
0.0000000000 * -2.2592700000 = -0.3186154866 
0.0000000000 * -0.0323453000 = -0.3186154866 
0.0000000000 * -0.7440640000 = -0.3186154866 
0.8570723642 * -1.1183900000 = -1.2771566479 
0.8398318691 * -2.4295700000 = -3.3175869621 
1.5787404086 * 0.8499400000 = -1.9757523393 
0.0000000000 * 0.5542980000 = -1.9757523393 
0.0000000000 * -0.6701130000 = -1.9757523393 
0.0000000000 * 0.3701260000 = -1.9757523393 
0.0000000000 * -0.2206290000 = -1.9757523393 
0.0000000000 * -3.8598700000 = -1.9757523393 
0.0000000000 * -0.8241300000 = -1.9757523393 
0.0000000000 * 0.2114420000 = -1.9757523393 
2.7992951847 * -0.3035570000 = -2.8254979876 
4.4584052240 * -0.1168570000 = -3.3464938469 
3.4785294551 * -1.2953200000 = -7.8523026207 
0.0000000000 * -0.7329520000 = -7.8523026207 
0.0000000000 * -0.1008720000 = -7.8523026207 
0.0734678262 * 0.6938750000 = -7.8013251328 
0.0000000000 * 1.1925300000 = -7.8013251328 
0.0000000000 * -1.3903100000 = -7.8013251328 
0.0000000000 * -0.2278250000 = -7.8013251328 
0.2251693882 * -0.6967250000 = -7.9582062748 
0.8031315178 * 0.5048440000 = -7.5527501468 
0.0000000000 * -0.9905080000 = -7.5527501468 
0.0000000000 * -2.9657500000 = -7.5527501468 
0.0000000000 * -6.1576100000 = -7.5527501468 
0.3902068183 * 0.5333330000 = -7.3446399738 
0.0000000000 * -0.5609340000 = -7.3446399738 
0.0000000000 * -0.0098947800 = -7.3446399738 
1.2034198021 * -0.0207210000 = -7.3695760355 
0.7788152937 * -2.5646000000 = -9.3669257377 
the biases is : 1.8695700000, now tempVal is : -7.4973557377
ReLU !!! in layer: 5, node : 28, its linear result is negative,so set it to 0
compute layer: 5, node : 29
0.0000000000 * -0.7859510000 = 0.0000000000 
0.0000000000 * -0.3286810000 = 0.0000000000 
0.0000000000 * 0.3744460000 = 0.0000000000 
0.0000000000 * 1.1435600000 = 0.0000000000 
0.0000000000 * 1.1984700000 = 0.0000000000 
0.0000000000 * 2.0836900000 = 0.0000000000 
0.0727527248 * 0.1361800000 = 0.0099074661 
0.0000000000 * -0.1063090000 = 0.0099074661 
0.0000000000 * -0.2186350000 = 0.0099074661 
0.1903205629 * 0.5933450000 = 0.1228332204 
0.0000000000 * 0.0391423000 = 0.1228332204 
2.8096423506 * 0.9031660000 = 2.6604066636 
0.0000000000 * -0.9471250000 = 2.6604066636 
0.0000000000 * -4.9223600000 = 2.6604066636 
0.0000000000 * 0.0259727000 = 2.6604066636 
0.0000000000 * 0.3385860000 = 2.6604066636 
0.0000000000 * -1.5846100000 = 2.6604066636 
0.1333779634 * -0.6396230000 = 2.5750950506 
0.0000000000 * -2.8445600000 = 2.5750950506 
0.0000000000 * -0.1549970000 = 2.5750950506 
0.0000000000 * -0.6770880000 = 2.5750950506 
0.8570723642 * -0.8644130000 = 1.8342305570 
0.8398318691 * -0.9103580000 = 1.0696828964 
1.5787404086 * 0.8019570000 = 2.3357648182 
0.0000000000 * -1.9518900000 = 2.3357648182 
0.0000000000 * -0.9727230000 = 2.3357648182 
0.0000000000 * -1.2100300000 = 2.3357648182 
0.0000000000 * -0.6796400000 = 2.3357648182 
0.0000000000 * 0.1302270000 = 2.3357648182 
0.0000000000 * 1.0973300000 = 2.3357648182 
0.0000000000 * 0.1764630000 = 2.3357648182 
2.7992951847 * -0.5142590000 = 0.8962020758 
4.4584052240 * -0.3555060000 = -0.6887877318 
3.4785294551 * -1.2206600000 = -4.9348894964 
0.0000000000 * 0.3469180000 = -4.9348894964 
0.0000000000 * -0.2855340000 = -4.9348894964 
0.0734678262 * 1.8858500000 = -4.7963401964 
0.0000000000 * 0.1662530000 = -4.7963401964 
0.0000000000 * -2.4073200000 = -4.7963401964 
0.0000000000 * 0.6800060000 = -4.7963401964 
0.2251693882 * -0.7114980000 = -4.9565477658 
0.8031315178 * 0.6586770000 = -4.4275435071 
0.0000000000 * -0.3303270000 = -4.4275435071 
0.0000000000 * -2.6976300000 = -4.4275435071 
0.0000000000 * -3.1839500000 = -4.4275435071 
0.3902068183 * -0.5928070000 = -4.6588608404 
0.0000000000 * -3.7994600000 = -4.6588608404 
0.0000000000 * 0.0086164100 = -4.6588608404 
1.2034198021 * -0.9173620000 = -5.7628324369 
0.7788152937 * 1.3394400000 = -4.7196560799 
the biases is : 1.0520500000, now tempVal is : -3.6676060799
ReLU !!! in layer: 5, node : 29, its linear result is negative,so set it to 0
compute layer: 5, node : 30
0.0000000000 * -0.1713580000 = 0.0000000000 
0.0000000000 * 0.0686050000 = 0.0000000000 
0.0000000000 * 1.1492800000 = 0.0000000000 
0.0000000000 * 0.2343160000 = 0.0000000000 
0.0000000000 * -4.7036500000 = 0.0000000000 
0.0000000000 * 1.3758100000 = 0.0000000000 
0.0727527248 * 0.1984730000 = 0.0144394516 
0.0000000000 * 0.0832273000 = 0.0144394516 
0.0000000000 * 0.8196780000 = 0.0144394516 
0.1903205629 * -0.3394790000 = -0.0501703828 
0.0000000000 * 0.2957300000 = -0.0501703828 
2.8096423506 * -1.4237100000 = -4.0502862937 
0.0000000000 * -0.0113211000 = -4.0502862937 
0.0000000000 * 0.5362650000 = -4.0502862937 
0.0000000000 * -0.0063391200 = -4.0502862937 
0.0000000000 * 0.0248133000 = -4.0502862937 
0.0000000000 * -0.6055470000 = -4.0502862937 
0.1333779634 * 0.0247199000 = -4.0469892038 
0.0000000000 * -0.4694790000 = -4.0469892038 
0.0000000000 * -0.6617840000 = -4.0469892038 
0.0000000000 * 0.2283490000 = -4.0469892038 
0.8570723642 * 0.0131695000 = -4.0357019893 
0.8398318691 * 0.1259720000 = -3.9299066891 
1.5787404086 * 0.3339570000 = -3.4026752785 
0.0000000000 * 1.5912800000 = -3.4026752785 
0.0000000000 * -0.4389370000 = -3.4026752785 
0.0000000000 * 0.2501530000 = -3.4026752785 
0.0000000000 * 0.0027907800 = -3.4026752785 
0.0000000000 * 0.1553180000 = -3.4026752785 
0.0000000000 * 2.3516100000 = -3.4026752785 
0.0000000000 * 0.2129050000 = -3.4026752785 
2.7992951847 * -0.0443533000 = -3.5268332576 
4.4584052240 * -0.3611120000 = -5.1368168848 
3.4785294551 * -0.5348150000 = -6.9971866154 
0.0000000000 * -0.0347611000 = -6.9971866154 
0.0000000000 * -0.3656330000 = -6.9971866154 
0.0734678262 * 0.3338220000 = -6.9726614387 
0.0000000000 * -0.2562120000 = -6.9726614387 
0.0000000000 * -0.1673130000 = -6.9726614387 
0.0000000000 * 0.0215808000 = -6.9726614387 
0.2251693882 * 0.4538970000 = -6.8704577289 
0.8031315178 * 0.0555970000 = -6.8258060259 
0.0000000000 * 0.1118090000 = -6.8258060259 
0.0000000000 * -1.6944300000 = -6.8258060259 
0.0000000000 * -0.6544360000 = -6.8258060259 
0.3902068183 * -0.1760170000 = -6.8944890594 
0.0000000000 * -0.6305520000 = -6.8944890594 
0.0000000000 * -0.0443466000 = -6.8944890594 
1.2034198021 * 0.2239190000 = -6.6250205008 
0.7788152937 * -0.2591620000 = -6.8268598299 
the biases is : -0.1076290000, now tempVal is : -6.9344888299
ReLU !!! in layer: 5, node : 30, its linear result is negative,so set it to 0
compute layer: 5, node : 31
0.0000000000 * -0.1024360000 = 0.0000000000 
0.0000000000 * -0.6737770000 = 0.0000000000 
0.0000000000 * 0.5001490000 = 0.0000000000 
0.0000000000 * -0.0002980930 = 0.0000000000 
0.0000000000 * 0.0862572000 = 0.0000000000 
0.0000000000 * 0.1516070000 = 0.0000000000 
0.0727527248 * 0.0609693000 = 0.0044356827 
0.0000000000 * -0.0618773000 = 0.0044356827 
0.0000000000 * 0.0397015000 = 0.0044356827 
0.1903205629 * -0.0851725000 = -0.0117743954 
0.0000000000 * -0.1737210000 = -0.0117743954 
2.8096423506 * -0.1920960000 = -0.5514954524 
0.0000000000 * 0.1828400000 = -0.5514954524 
0.0000000000 * 0.0272879000 = -0.5514954524 
0.0000000000 * -0.0011237400 = -0.5514954524 
0.0000000000 * 0.0110674000 = -0.5514954524 
0.0000000000 * 0.1460520000 = -0.5514954524 
0.1333779634 * -0.1409550000 = -0.5702957432 
0.0000000000 * 0.0437451000 = -0.5702957432 
0.0000000000 * 0.1439110000 = -0.5702957432 
0.0000000000 * 0.0107347000 = -0.5702957432 
0.8570723642 * -0.2130250000 = -0.7528735836 
0.8398318691 * 0.1212740000 = -0.6510238135 
1.5787404086 * 0.0072306000 = -0.6396085731 
0.0000000000 * 0.4182190000 = -0.6396085731 
0.0000000000 * 0.1211350000 = -0.6396085731 
0.0000000000 * 0.0574224000 = -0.6396085731 
0.0000000000 * -0.0275107000 = -0.6396085731 
0.0000000000 * -0.0928366000 = -0.6396085731 
0.0000000000 * -0.2589890000 = -0.6396085731 
0.0000000000 * 0.1595990000 = -0.6396085731 
2.7992951847 * -0.1061490000 = -0.9367509577 
4.4584052240 * -0.0585228000 = -1.1976693149 
3.4785294551 * 0.1051570000 = -0.8318775930 
0.0000000000 * 0.0758396000 = -0.8318775930 
0.0000000000 * -0.6505880000 = -0.8318775930 
0.0734678262 * 0.2028090000 = -0.8169776567 
0.0000000000 * -0.1034710000 = -0.8169776567 
0.0000000000 * 0.1760990000 = -0.8169776567 
0.0000000000 * -0.7380840000 = -0.8169776567 
0.2251693882 * 0.2583350000 = -0.7588085227 
0.8031315178 * -0.0189874000 = -0.7740579021 
0.0000000000 * -0.0924992000 = -0.7740579021 
0.0000000000 * 0.2322000000 = -0.7740579021 
0.0000000000 * -0.1265910000 = -0.7740579021 
0.3902068183 * -0.1785810000 = -0.8437414259 
0.0000000000 * 0.0003986900 = -0.8437414259 
0.0000000000 * 0.0121514000 = -0.8437414259 
1.2034198021 * -0.0831856000 = -0.9438486242 
0.7788152937 * 0.2735000000 = -0.7308426414 
the biases is : 0.0906623000, now tempVal is : -0.6401803414
ReLU !!! in layer: 5, node : 31, its linear result is negative,so set it to 0
compute layer: 5, node : 32
0.0000000000 * -0.0774197000 = 0.0000000000 
0.0000000000 * -2.7451000000 = 0.0000000000 
0.0000000000 * 3.4255300000 = 0.0000000000 
0.0000000000 * -0.2449470000 = 0.0000000000 
0.0000000000 * -0.0550098000 = 0.0000000000 
0.0000000000 * 0.0815293000 = 0.0000000000 
0.0727527248 * 0.4956640000 = 0.0360609066 
0.0000000000 * -0.0738481000 = 0.0360609066 
0.0000000000 * 1.6316800000 = 0.0360609066 
0.1903205629 * -0.2955480000 = -0.0201879551 
0.0000000000 * -0.3577850000 = -0.0201879551 
2.8096423506 * -1.9887200000 = -5.6077798905 
0.0000000000 * 0.2819130000 = -5.6077798905 
0.0000000000 * -1.2562500000 = -5.6077798905 
0.0000000000 * 0.0055998200 = -5.6077798905 
0.0000000000 * 0.4001010000 = -5.6077798905 
0.0000000000 * -1.0622500000 = -5.6077798905 
0.1333779634 * -0.3110130000 = -5.6492621711 
0.0000000000 * -0.2599610000 = -5.6492621711 
0.0000000000 * 0.3739590000 = -5.6492621711 
0.0000000000 * -0.2664090000 = -5.6492621711 
0.8570723642 * -0.4141280000 = -6.0041998351 
0.8398318691 * -0.2026670000 = -6.1744060405 
1.5787404086 * 0.3028650000 = -5.6962608267 
0.0000000000 * 1.8452700000 = -5.6962608267 
0.0000000000 * -0.4658500000 = -5.6962608267 
0.0000000000 * 0.5021560000 = -5.6962608267 
0.0000000000 * -0.2145650000 = -5.6962608267 
0.0000000000 * 0.8688450000 = -5.6962608267 
0.0000000000 * 5.8598300000 = -5.6962608267 
0.0000000000 * 0.2910850000 = -5.6962608267 
2.7992951847 * 0.4913980000 = -4.3206927715 
4.4584052240 * -0.6778020000 = -7.3426087491 
3.4785294551 * -0.4171880000 = -8.7938094954 
0.0000000000 * -0.2419220000 = -8.7938094954 
0.0000000000 * -2.0560600000 = -8.7938094954 
0.0734678262 * 0.1607840000 = -8.7819970445 
0.0000000000 * -0.5140090000 = -8.7819970445 
0.0000000000 * 0.9594770000 = -8.7819970445 
0.0000000000 * -1.3555900000 = -8.7819970445 
0.2251693882 * 1.5564400000 = -8.4315344019 
0.8031315178 * 1.1081100000 = -7.5415763357 
0.0000000000 * -0.0487294000 = -7.5415763357 
0.0000000000 * -1.6051000000 = -7.5415763357 
0.0000000000 * -1.4709200000 = -7.5415763357 
0.3902068183 * -0.5744660000 = -7.7657368858 
0.0000000000 * -0.9270180000 = -7.7657368858 
0.0000000000 * -0.0396964000 = -7.7657368858 
1.2034198021 * -0.5097660000 = -8.3791993846 
0.7788152937 * -1.1694900000 = -9.2900160824 
the biases is : 2.5563200000, now tempVal is : -6.7336960824
ReLU !!! in layer: 5, node : 32, its linear result is negative,so set it to 0
compute layer: 5, node : 33
0.0000000000 * -0.0465820000 = 0.0000000000 
0.0000000000 * -1.3668200000 = 0.0000000000 
0.0000000000 * 0.6342610000 = 0.0000000000 
0.0000000000 * 0.1728020000 = 0.0000000000 
0.0000000000 * 0.1093470000 = 0.0000000000 
0.0000000000 * -0.9945560000 = 0.0000000000 
0.0727527248 * -0.0438956000 = -0.0031935245 
0.0000000000 * -0.4681210000 = -0.0031935245 
0.0000000000 * -0.5984980000 = -0.0031935245 
0.1903205629 * -0.0573191000 = -0.0141025279 
0.0000000000 * -0.2340720000 = -0.0141025279 
2.8096423506 * 0.0089267700 = 0.0109785032 
0.0000000000 * -0.0972811000 = 0.0109785032 
0.0000000000 * 0.4543660000 = 0.0109785032 
0.0000000000 * 0.0279091000 = 0.0109785032 
0.0000000000 * -0.0208092000 = 0.0109785032 
0.0000000000 * 0.2102910000 = 0.0109785032 
0.1333779634 * 0.1985700000 = 0.0374633653 
0.0000000000 * 0.0209483000 = 0.0374633653 
0.0000000000 * 0.0418835000 = 0.0374633653 
0.0000000000 * 0.1502290000 = 0.0374633653 
0.8570723642 * 0.3299870000 = 0.3202861036 
0.8398318691 * 0.0137503000 = 0.3318340437 
1.5787404086 * 0.3565860000 = 0.8947907711 
0.0000000000 * 0.6444340000 = 0.8947907711 
0.0000000000 * 0.0979573000 = 0.8947907711 
0.0000000000 * -0.2287310000 = 0.8947907711 
0.0000000000 * -0.2928580000 = 0.8947907711 
0.0000000000 * 0.4404650000 = 0.8947907711 
0.0000000000 * -0.8867450000 = 0.8947907711 
0.0000000000 * -0.8587210000 = 0.8947907711 
2.7992951847 * 0.1480760000 = 1.3092992048 
4.4584052240 * 0.0352383000 = 1.4664058256 
3.4785294551 * 0.2489510000 = 2.3323892120 
0.0000000000 * 0.0392912000 = 2.3323892120 
0.0000000000 * -1.1060400000 = 2.3323892120 
0.0734678262 * -0.0060463000 = 2.3319450035 
0.0000000000 * -0.0823404000 = 2.3319450035 
0.0000000000 * -0.0501576000 = 2.3319450035 
0.0000000000 * 0.0779250000 = 2.3319450035 
0.2251693882 * 0.0050545800 = 2.3330831402 
0.8031315178 * -0.1784370000 = 2.1897747615 
0.0000000000 * -0.7297490000 = 2.1897747615 
0.0000000000 * 0.1586850000 = 2.1897747615 
0.0000000000 * 0.5416620000 = 2.1897747615 
0.3902068183 * 0.2857100000 = 2.3012607516 
0.0000000000 * -0.4596320000 = 2.3012607516 
0.0000000000 * 0.0006016730 = 2.3012607516 
1.2034198021 * 0.2339310000 = 2.5827779493 
0.7788152937 * 0.1743930000 = 2.7185978848 
the biases is : 0.8751740000, now tempVal is : 3.5937718848
compute layer: 5, node : 34
0.0000000000 * -0.2704050000 = 0.0000000000 
0.0000000000 * -0.8291490000 = 0.0000000000 
0.0000000000 * 1.1175800000 = 0.0000000000 
0.0000000000 * 0.0812210000 = 0.0000000000 
0.0000000000 * -0.2130660000 = 0.0000000000 
0.0000000000 * -1.9936600000 = 0.0000000000 
0.0727527248 * 0.3215900000 = 0.0233965488 
0.0000000000 * 0.1878330000 = 0.0233965488 
0.0000000000 * 0.2391550000 = 0.0233965488 
0.1903205629 * -0.1414870000 = -0.0035313367 
0.0000000000 * -0.1101840000 = -0.0035313367 
2.8096423506 * -0.0375693000 = -0.1090876331 
0.0000000000 * -0.1066680000 = -0.1090876331 
0.0000000000 * -1.1821400000 = -0.1090876331 
0.0000000000 * -0.0051438400 = -0.1090876331 
0.0000000000 * 0.0860025000 = -0.1090876331 
0.0000000000 * -0.2718340000 = -0.1090876331 
0.1333779634 * 0.0927410000 = -0.0967180274 
0.0000000000 * -0.2931950000 = -0.0967180274 
0.0000000000 * -0.3580420000 = -0.0967180274 
0.0000000000 * 0.1846540000 = -0.0967180274 
0.8570723642 * -0.0020673000 = -0.0984898531 
0.8398318691 * 0.0907337000 = -0.0222888002 
1.5787404086 * 0.3083370000 = 0.4644952812 
0.0000000000 * 0.3320750000 = 0.4644952812 
0.0000000000 * -0.2912320000 = 0.4644952812 
0.0000000000 * 0.1256740000 = 0.4644952812 
0.0000000000 * -0.3233240000 = 0.4644952812 
0.0000000000 * 0.2589960000 = 0.4644952812 
0.0000000000 * -2.3649000000 = 0.4644952812 
0.0000000000 * -0.4413890000 = 0.4644952812 
2.7992951847 * 0.8244220000 = 2.7722958159 
4.4584052240 * -0.8172600000 = -0.8713804375 
3.4785294551 * -0.3437100000 = -2.0669857965 
0.0000000000 * 0.3502330000 = -2.0669857965 
0.0000000000 * 0.7473140000 = -2.0669857965 
0.0734678262 * 0.9336110000 = -1.9983954258 
0.0000000000 * 0.0261506000 = -1.9983954258 
0.0000000000 * -3.3474600000 = -1.9983954258 
0.0000000000 * 1.9830300000 = -1.9983954258 
0.2251693882 * 0.5518050000 = -1.8741458315 
0.8031315178 * -0.6351120000 = -2.3842242961 
0.0000000000 * -0.7716440000 = -2.3842242961 
0.0000000000 * -0.5629140000 = -2.3842242961 
0.0000000000 * 0.9060020000 = -2.3842242961 
0.3902068183 * 0.3142970000 = -2.2615834637 
0.0000000000 * 0.1854990000 = -2.2615834637 
0.0000000000 * 0.0344345000 = -2.2615834637 
1.2034198021 * -0.3847200000 = -2.7245631300 
0.7788152937 * -0.4372230000 = -3.0650790891 
the biases is : 0.0827916000, now tempVal is : -2.9822874891
ReLU !!! in layer: 5, node : 34, its linear result is negative,so set it to 0
compute layer: 5, node : 35
0.0000000000 * 0.3750180000 = 0.0000000000 
0.0000000000 * -0.1623150000 = 0.0000000000 
0.0000000000 * -0.7947870000 = 0.0000000000 
0.0000000000 * -0.1541890000 = 0.0000000000 
0.0000000000 * -0.8213260000 = 0.0000000000 
0.0000000000 * 1.4642900000 = 0.0000000000 
0.0727527248 * 0.3390340000 = 0.0246656473 
0.0000000000 * 0.0051071900 = 0.0246656473 
0.0000000000 * -2.1081200000 = 0.0246656473 
0.1903205629 * 0.5721360000 = 0.1335548929 
0.0000000000 * 1.7853600000 = 0.1335548929 
2.8096423506 * -4.5631200000 = -12.6871803099 
0.0000000000 * 0.3847420000 = -12.6871803099 
0.0000000000 * 0.4421190000 = -12.6871803099 
0.0000000000 * 0.0039262500 = -12.6871803099 
0.0000000000 * -0.4012440000 = -12.6871803099 
0.0000000000 * 0.1088770000 = -12.6871803099 
0.1333779634 * 0.4885150000 = -12.6220231741 
0.0000000000 * 0.1892990000 = -12.6220231741 
0.0000000000 * -5.6308600000 = -12.6220231741 
0.0000000000 * 2.3840900000 = -12.6220231741 
0.8570723642 * 0.2820510000 = -12.3802850567 
0.8398318691 * -5.1983200000 = -16.7459998584 
1.5787404086 * -2.4768400000 = -20.6562872520 
0.0000000000 * -3.0249100000 = -20.6562872520 
0.0000000000 * -1.7055800000 = -20.6562872520 
0.0000000000 * 0.7547560000 = -20.6562872520 
0.0000000000 * -0.3353600000 = -20.6562872520 
0.0000000000 * 3.1184600000 = -20.6562872520 
0.0000000000 * -1.7467800000 = -20.6562872520 
0.0000000000 * 0.2276500000 = -20.6562872520 
2.7992951847 * -2.0708300000 = -26.4531516993 
4.4584052240 * 0.5790010000 = -23.8717306162 
3.4785294551 * -0.0605323000 = -24.0822940048 
0.0000000000 * -0.1463670000 = -24.0822940048 
0.0000000000 * 0.1597870000 = -24.0822940048 
0.0734678262 * 3.5347900000 = -23.8226006675 
0.0000000000 * -2.5646300000 = -23.8226006675 
0.0000000000 * -0.1798040000 = -23.8226006675 
0.0000000000 * 0.1175350000 = -23.8226006675 
0.2251693882 * -4.1629000000 = -24.7599583137 
0.8031315178 * -3.7329500000 = -27.7580081131 
0.0000000000 * -0.0620882000 = -27.7580081131 
0.0000000000 * 0.9911510000 = -27.7580081131 
0.0000000000 * -4.8097200000 = -27.7580081131 
0.3902068183 * -2.0737100000 = -28.5671838942 
0.0000000000 * 1.6425500000 = -28.5671838942 
0.0000000000 * -0.0128750000 = -28.5671838942 
1.2034198021 * -0.2554550000 = -28.8746034998 
0.7788152937 * -0.0183709000 = -28.8889110376 
the biases is : -1.1624500000, now tempVal is : -30.0513610376
ReLU !!! in layer: 5, node : 35, its linear result is negative,so set it to 0
compute layer: 5, node : 36
0.0000000000 * -0.1050000000 = 0.0000000000 
0.0000000000 * -1.2127900000 = 0.0000000000 
0.0000000000 * -0.5501330000 = 0.0000000000 
0.0000000000 * 0.5870440000 = 0.0000000000 
0.0000000000 * -0.5611540000 = 0.0000000000 
0.0000000000 * -1.4179600000 = 0.0000000000 
0.0727527248 * -0.0151146000 = -0.0010996283 
0.0000000000 * -1.6879900000 = -0.0010996283 
0.0000000000 * 0.4168010000 = -0.0010996283 
0.1903205629 * 0.4913350000 = 0.0924115254 
0.0000000000 * 0.3359620000 = 0.0924115254 
2.8096423506 * 0.6574150000 = 1.9395125513 
0.0000000000 * -1.6444000000 = 1.9395125513 
0.0000000000 * -3.1117400000 = 1.9395125513 
0.0000000000 * 0.0137700000 = 1.9395125513 
0.0000000000 * 0.5369770000 = 1.9395125513 
0.0000000000 * -6.2194900000 = 1.9395125513 
0.1333779634 * 0.6317630000 = 2.0237758136 
0.0000000000 * -2.6216900000 = 2.0237758136 
0.0000000000 * -3.2603600000 = 2.0237758136 
0.0000000000 * -0.9313370000 = 2.0237758136 
0.8570723642 * -0.6110450000 = 1.5000660308 
0.8398318691 * -2.7020200000 = -0.7691764761 
1.5787404086 * 0.9107570000 = 0.6686724022 
0.0000000000 * 0.3097140000 = 0.6686724022 
0.0000000000 * -5.2889400000 = 0.6686724022 
0.0000000000 * 0.0779545000 = 0.6686724022 
0.0000000000 * -0.1481570000 = 0.6686724022 
0.0000000000 * 0.8391030000 = 0.6686724022 
0.0000000000 * -1.6926400000 = 0.6686724022 
0.0000000000 * -0.3381130000 = 0.6686724022 
2.7992951847 * -0.4461360000 = -0.5801939543 
4.4584052240 * -0.1707620000 = -1.3415201472 
3.4785294551 * -0.6751540000 = -3.6900632229 
0.0000000000 * 0.0128516000 = -3.6900632229 
0.0000000000 * 0.3315790000 = -3.6900632229 
0.0734678262 * -1.1482300000 = -3.7744211850 
0.0000000000 * 1.2787400000 = -3.7744211850 
0.0000000000 * -1.0646900000 = -3.7744211850 
0.0000000000 * -0.8871670000 = -3.7744211850 
0.2251693882 * 1.3862100000 = -3.4622891273 
0.8031315178 * 0.6034510000 = -2.9776386098 
0.0000000000 * -0.2628680000 = -2.9776386098 
0.0000000000 * -1.6475000000 = -2.9776386098 
0.0000000000 * -3.6842400000 = -2.9776386098 
0.3902068183 * 0.3422820000 = -2.8440778396 
0.0000000000 * -0.7618200000 = -2.8440778396 
0.0000000000 * -0.0362020000 = -2.8440778396 
1.2034198021 * -1.1858700000 = -4.2711772803 
0.7788152937 * -1.8640900000 = -5.7229590811 
the biases is : 1.1968300000, now tempVal is : -4.5261290811
ReLU !!! in layer: 5, node : 36, its linear result is negative,so set it to 0
compute layer: 5, node : 37
0.0000000000 * -0.1367290000 = 0.0000000000 
0.0000000000 * -0.7412910000 = 0.0000000000 
0.0000000000 * 0.8754380000 = 0.0000000000 
0.0000000000 * 0.1000660000 = 0.0000000000 
0.0000000000 * 0.0856765000 = 0.0000000000 
0.0000000000 * -0.7954030000 = 0.0000000000 
0.0727527248 * 0.1693970000 = 0.0123240933 
0.0000000000 * -0.8122540000 = 0.0123240933 
0.0000000000 * -1.2311200000 = 0.0123240933 
0.1903205629 * 0.0102970000 = 0.0142838242 
0.0000000000 * 0.2173810000 = 0.0142838242 
2.8096423506 * -0.9333690000 = -2.6081492469 
0.0000000000 * -0.0702935000 = -2.6081492469 
0.0000000000 * 0.0133380000 = -2.6081492469 
0.0000000000 * 0.0057659500 = -2.6081492469 
0.0000000000 * 0.0197882000 = -2.6081492469 
0.0000000000 * 0.1561580000 = -2.6081492469 
0.1333779634 * 0.0407111000 = -2.6027192833 
0.0000000000 * -0.1989860000 = -2.6027192833 
0.0000000000 * -0.2249170000 = -2.6027192833 
0.0000000000 * 0.3363410000 = -2.6027192833 
0.8570723642 * 0.0385615000 = -2.5696692874 
0.8398318691 * -0.1753730000 = -2.7169531218 
1.5787404086 * 0.1426200000 = -2.4917931647 
0.0000000000 * 0.0536719000 = -2.4917931647 
0.0000000000 * 0.1705010000 = -2.4917931647 
0.0000000000 * -0.1655200000 = -2.4917931647 
0.0000000000 * -0.2212050000 = -2.4917931647 
0.0000000000 * 0.2396870000 = -2.4917931647 
0.0000000000 * -1.2622500000 = -2.4917931647 
0.0000000000 * 0.5519500000 = -2.4917931647 
2.7992951847 * -0.1317620000 = -2.8606338968 
4.4584052240 * -0.0310874000 = -2.9992341234 
3.4785294551 * 0.2665590000 = -2.0720007903 
0.0000000000 * -0.1573950000 = -2.0720007903 
0.0000000000 * -0.7072530000 = -2.0720007903 
0.0734678262 * 0.5148120000 = -2.0341786718 
0.0000000000 * -0.2103420000 = -2.0341786718 
0.0000000000 * -0.3304560000 = -2.0341786718 
0.0000000000 * -2.3627500000 = -2.0341786718 
0.2251693882 * 0.2016670000 = -1.9887694368 
0.8031315178 * -0.2072700000 = -2.1552345065 
0.0000000000 * -0.7393840000 = -2.1552345065 
0.0000000000 * 0.0787498000 = -2.1552345065 
0.0000000000 * 0.2013320000 = -2.1552345065 
0.3902068183 * 0.0920677000 = -2.1193090622 
0.0000000000 * -0.0304882000 = -2.1193090622 
0.0000000000 * 0.0154209000 = -2.1193090622 
1.2034198021 * -0.0906038000 = -2.2283434693 
0.7788152937 * 0.2315360000 = -2.0480196914 
the biases is : 0.1194590000, now tempVal is : -1.9285606914
ReLU !!! in layer: 5, node : 37, its linear result is negative,so set it to 0
compute layer: 5, node : 38
0.0000000000 * -0.0179265000 = 0.0000000000 
0.0000000000 * 0.1102440000 = 0.0000000000 
0.0000000000 * -0.1841690000 = 0.0000000000 
0.0000000000 * -0.0515780000 = 0.0000000000 
0.0000000000 * -0.4698530000 = 0.0000000000 
0.0000000000 * -0.7150750000 = 0.0000000000 
0.0727527248 * 0.3464270000 = 0.0252035082 
0.0000000000 * 0.3527200000 = 0.0252035082 
0.0000000000 * 0.1330690000 = 0.0252035082 
0.1903205629 * -0.3905270000 = -0.0491218102 
0.0000000000 * -0.1014680000 = -0.0491218102 
2.8096423506 * 0.0215436000 = 0.0114080007 
0.0000000000 * 0.2818660000 = 0.0114080007 
0.0000000000 * 0.0353315000 = 0.0114080007 
0.0000000000 * -0.0175584000 = 0.0114080007 
0.0000000000 * -0.0359271000 = 0.0114080007 
0.0000000000 * -0.0887463000 = 0.0114080007 
0.1333779634 * 0.0230088000 = 0.0144768676 
0.0000000000 * 0.2051130000 = 0.0144768676 
0.0000000000 * 0.1110730000 = 0.0144768676 
0.0000000000 * -0.3299070000 = 0.0144768676 
0.8570723642 * 0.0513832000 = 0.0585159883 
0.8398318691 * 0.0176968000 = 0.0733783249 
1.5787404086 * 0.0737438000 = 0.1898006418 
0.0000000000 * -0.3853530000 = 0.1898006418 
0.0000000000 * -0.0558639000 = 0.1898006418 
0.0000000000 * -0.0079053500 = 0.1898006418 
0.0000000000 * -0.1376370000 = 0.1898006418 
0.0000000000 * 0.7862280000 = 0.1898006418 
0.0000000000 * -0.0460677000 = 0.1898006418 
0.0000000000 * -0.0221184000 = 0.1898006418 
2.7992951847 * -0.0396640000 = 0.0787693976 
4.4584052240 * 0.0593279000 = 0.3432772169 
3.4785294551 * -0.1094880000 = -0.0375800161 
0.0000000000 * 0.3109460000 = -0.0375800161 
0.0000000000 * 0.0635534000 = -0.0375800161 
0.0734678262 * -0.1518480000 = -0.0487359585 
0.0000000000 * -0.2737910000 = -0.0487359585 
0.0000000000 * -0.1359390000 = -0.0487359585 
0.0000000000 * 0.4021310000 = -0.0487359585 
0.2251693882 * -0.2350280000 = -0.1016570695 
0.8031315178 * 0.0899250000 = -0.0294354678 
0.0000000000 * -0.0996393000 = -0.0294354678 
0.0000000000 * 0.2330860000 = -0.0294354678 
0.0000000000 * -0.1357640000 = -0.0294354678 
0.3902068183 * -0.2584970000 = -0.1303027597 
0.0000000000 * 0.3232890000 = -0.1303027597 
0.0000000000 * -0.0524728000 = -0.1303027597 
1.2034198021 * 0.2788150000 = 0.2052287325 
0.7788152937 * 0.0068364200 = 0.2105530409 
the biases is : 0.0523826000, now tempVal is : 0.2629356409
compute layer: 5, node : 39
0.0000000000 * 0.3755660000 = 0.0000000000 
0.0000000000 * 0.2478070000 = 0.0000000000 
0.0000000000 * 0.8318210000 = 0.0000000000 
0.0000000000 * -1.1205300000 = 0.0000000000 
0.0000000000 * -2.1161300000 = 0.0000000000 
0.0000000000 * -1.0543000000 = 0.0000000000 
0.0727527248 * 0.2835630000 = 0.0206299809 
0.0000000000 * 0.6120500000 = 0.0206299809 
0.0000000000 * -0.0472907000 = 0.0206299809 
0.1903205629 * -0.7111340000 = -0.1147134422 
0.0000000000 * -0.2578750000 = -0.1147134422 
2.8096423506 * -0.0192830000 = -0.1688917757 
0.0000000000 * 0.1197420000 = -0.1688917757 
0.0000000000 * -0.7607130000 = -0.1688917757 
0.0000000000 * 0.0474915000 = -0.1688917757 
0.0000000000 * -0.0474871000 = -0.1688917757 
0.0000000000 * 0.0493281000 = -0.1688917757 
0.1333779634 * 0.1397640000 = -0.1502503380 
0.0000000000 * 1.1882700000 = -0.1502503380 
0.0000000000 * -0.2273890000 = -0.1502503380 
0.0000000000 * -0.0044956300 = -0.1502503380 
0.8570723642 * 0.0456736000 = -0.1111047577 
0.8398318691 * 0.0100633000 = -0.1026532776 
1.5787404086 * 0.1464330000 = 0.1285264166 
0.0000000000 * 1.0222100000 = 0.1285264166 
0.0000000000 * 0.2888060000 = 0.1285264166 
0.0000000000 * 0.8527590000 = 0.1285264166 
0.0000000000 * -0.1280980000 = 0.1285264166 
0.0000000000 * 0.7195970000 = 0.1285264166 
0.0000000000 * -14.5676000000 = 0.1285264166 
0.0000000000 * 0.6747680000 = 0.1285264166 
2.7992951847 * 0.9184060000 = 2.6994159100 
4.4584052240 * -0.3847990000 = 0.9838260382 
3.4785294551 * -0.3632320000 = -0.2796871728 
0.0000000000 * 0.5453980000 = -0.2796871728 
0.0000000000 * -0.7634580000 = -0.2796871728 
0.0734678262 * -1.2973000000 = -0.3749969837 
0.0000000000 * 0.2846760000 = -0.3749969837 
0.0000000000 * 0.4327150000 = -0.3749969837 
0.0000000000 * 1.0234600000 = -0.3749969837 
0.2251693882 * -0.7516070000 = -0.5442358721 
0.8031315178 * 0.2992070000 = -0.3039333001 
0.0000000000 * -1.7931600000 = -0.3039333001 
0.0000000000 * 0.9487240000 = -0.3039333001 
0.0000000000 * 1.0185800000 = -0.3039333001 
0.3902068183 * -0.1911230000 = -0.3785107978 
0.0000000000 * -0.8282330000 = -0.3785107978 
0.0000000000 * 0.0078409500 = -0.3785107978 
1.2034198021 * 0.2067600000 = -0.1296917195 
0.7788152937 * 0.9483920000 = 0.6089304745 
the biases is : -0.2514400000, now tempVal is : 0.3574904745
compute layer: 5, node : 40
0.0000000000 * 0.0097339500 = 0.0000000000 
0.0000000000 * -0.3871550000 = 0.0000000000 
0.0000000000 * -0.2011390000 = 0.0000000000 
0.0000000000 * 0.0376793000 = 0.0000000000 
0.0000000000 * -0.2001390000 = 0.0000000000 
0.0000000000 * -0.8710530000 = 0.0000000000 
0.0727527248 * 0.0232160000 = 0.0016890273 
0.0000000000 * -0.2478600000 = 0.0016890273 
0.0000000000 * -0.2507080000 = 0.0016890273 
0.1903205629 * 0.0745393000 = 0.0158753888 
0.0000000000 * 0.3695540000 = 0.0158753888 
2.8096423506 * -0.0588371000 = -0.1494358192 
0.0000000000 * -0.1307740000 = -0.1494358192 
0.0000000000 * -0.1031410000 = -0.1494358192 
0.0000000000 * -0.0206540000 = -0.1494358192 
0.0000000000 * 0.2380700000 = -0.1494358192 
0.0000000000 * -0.2543920000 = -0.1494358192 
0.1333779634 * -0.0973468000 = -0.1624197371 
0.0000000000 * -0.0332587000 = -0.1624197371 
0.0000000000 * -0.5982180000 = -0.1624197371 
0.0000000000 * -0.1376510000 = -0.1624197371 
0.8570723642 * -0.2434890000 = -0.3711074300 
0.8398318691 * 0.0534477000 = -0.3262203482 
1.5787404086 * 0.2154110000 = 0.0138577020 
0.0000000000 * -0.6148350000 = 0.0138577020 
0.0000000000 * -0.1549950000 = 0.0138577020 
0.0000000000 * 0.2536530000 = 0.0138577020 
0.0000000000 * -0.1279900000 = 0.0138577020 
0.0000000000 * 0.0917628000 = 0.0138577020 
0.0000000000 * -1.2715500000 = 0.0138577020 
0.0000000000 * 0.1754560000 = 0.0138577020 
2.7992951847 * -1.8799000000 = -5.2485373157 
4.4584052240 * -0.0521756000 = -5.4811572833 
3.4785294551 * -0.0721364000 = -5.7320858755 
0.0000000000 * -0.0183898000 = -5.7320858755 
0.0000000000 * -0.4624640000 = -5.7320858755 
0.0734678262 * -0.0053897500 = -5.7324818487 
0.0000000000 * 0.2524730000 = -5.7324818487 
0.0000000000 * 0.2835540000 = -5.7324818487 
0.0000000000 * -0.0781041000 = -5.7324818487 
0.2251693882 * -0.0559165000 = -5.7450725328 
0.8031315178 * 0.2653620000 = -5.5319519470 
0.0000000000 * -0.4693580000 = -5.5319519470 
0.0000000000 * 0.0279549000 = -5.5319519470 
0.0000000000 * 0.0270452000 = -5.5319519470 
0.3902068183 * -0.3457330000 = -5.6668593209 
0.0000000000 * -0.3015880000 = -5.6668593209 
0.0000000000 * 0.0283160000 = -5.6668593209 
1.2034198021 * -0.1048350000 = -5.7930198359 
0.7788152937 * -0.1145990000 = -5.8822712897 
the biases is : 0.9712010000, now tempVal is : -4.9110702897
ReLU !!! in layer: 5, node : 40, its linear result is negative,so set it to 0
compute layer: 5, node : 41
0.0000000000 * 0.0099361000 = 0.0000000000 
0.0000000000 * -0.3316240000 = 0.0000000000 
0.0000000000 * 0.1032440000 = 0.0000000000 
0.0000000000 * 0.0201010000 = 0.0000000000 
0.0000000000 * 0.0195166000 = 0.0000000000 
0.0000000000 * -0.6262040000 = 0.0000000000 
0.0727527248 * -0.0677506000 = -0.0049290408 
0.0000000000 * -0.1837170000 = -0.0049290408 
0.0000000000 * -0.4623290000 = -0.0049290408 
0.1903205629 * -0.0172648000 = -0.0082148872 
0.0000000000 * -0.2239510000 = -0.0082148872 
2.8096423506 * 0.1045750000 = 0.2856034616 
0.0000000000 * 0.1370810000 = 0.2856034616 
0.0000000000 * -0.0645249000 = 0.2856034616 
0.0000000000 * -0.0321693000 = 0.2856034616 
0.0000000000 * -0.0308815000 = 0.2856034616 
0.0000000000 * 0.0913012000 = 0.2856034616 
0.1333779634 * 0.0205079000 = 0.2883387635 
0.0000000000 * 0.0784100000 = 0.2883387635 
0.0000000000 * 0.3398590000 = 0.2883387635 
0.0000000000 * 0.1416360000 = 0.2883387635 
0.8570723642 * -0.0166765000 = 0.2740457963 
0.8398318691 * -0.0522053000 = 0.2302021216 
1.5787404086 * 0.0667900000 = 0.3356461935 
0.0000000000 * 0.3614560000 = 0.3356461935 
0.0000000000 * 0.0851553000 = 0.3356461935 
0.0000000000 * -0.0377332000 = 0.3356461935 
0.0000000000 * 0.0843677000 = 0.3356461935 
0.0000000000 * -0.0488038000 = 0.3356461935 
0.0000000000 * 0.9850100000 = 0.3356461935 
0.0000000000 * -0.1664580000 = 0.3356461935 
2.7992951847 * -0.3932160000 = -0.7650814619 
4.4584052240 * -0.2223610000 = -1.7564569059 
3.4785294551 * 0.0564164000 = -1.5602107967 
0.0000000000 * -0.0125725000 = -1.5602107967 
0.0000000000 * 0.0991278000 = -1.5602107967 
0.0734678262 * -0.1306990000 = -1.5698129682 
0.0000000000 * 0.0497134000 = -1.5698129682 
0.0000000000 * -0.0816864000 = -1.5698129682 
0.0000000000 * -0.0690200000 = -1.5698129682 
0.2251693882 * 0.0173930000 = -1.5658965970 
0.8031315178 * -0.3005080000 = -1.8072440431 
0.0000000000 * -0.1037130000 = -1.8072440431 
0.0000000000 * 0.0500856000 = -1.8072440431 
0.0000000000 * -0.0608127000 = -1.8072440431 
0.3902068183 * -0.0131173000 = -1.8123625030 
0.0000000000 * 0.0341953000 = -1.8123625030 
0.0000000000 * -0.0179829000 = -1.8123625030 
1.2034198021 * 0.0364847000 = -1.7684560926 
0.7788152937 * 0.0363857000 = -1.7401183530 
the biases is : 0.4145230000, now tempVal is : -1.3255953530
ReLU !!! in layer: 5, node : 41, its linear result is negative,so set it to 0
compute layer: 5, node : 42
0.0000000000 * 0.5427160000 = 0.0000000000 
0.0000000000 * -0.2848810000 = 0.0000000000 
0.0000000000 * -4.3019600000 = 0.0000000000 
0.0000000000 * -0.2779120000 = 0.0000000000 
0.0000000000 * 0.1140210000 = 0.0000000000 
0.0000000000 * 1.0745300000 = 0.0000000000 
0.0727527248 * -0.8711490000 = -0.0633784635 
0.0000000000 * -1.1879200000 = -0.0633784635 
0.0000000000 * 0.8299370000 = -0.0633784635 
0.1903205629 * 0.0484451000 = -0.0541583648 
0.0000000000 * 0.0216223000 = -0.0541583648 
2.8096423506 * -0.4444210000 = -1.3028224279 
0.0000000000 * -2.1112700000 = -1.3028224279 
0.0000000000 * -0.0648553000 = -1.3028224279 
0.0000000000 * -0.0310061000 = -1.3028224279 
0.0000000000 * -0.2000900000 = -1.3028224279 
0.0000000000 * 0.1211380000 = -1.3028224279 
0.1333779634 * -0.4452190000 = -1.3622048313 
0.0000000000 * -0.6206920000 = -1.3622048313 
0.0000000000 * -0.0349218000 = -1.3622048313 
0.0000000000 * 0.0398946000 = -1.3622048313 
0.8570723642 * -1.5252600000 = -2.6694630255 
0.8398318691 * 0.1379490000 = -2.5536090590 
1.5787404086 * 0.0154275000 = -2.5292530413 
0.0000000000 * 0.9498530000 = -2.5292530413 
0.0000000000 * 0.0692926000 = -2.5292530413 
0.0000000000 * 0.2025330000 = -2.5292530413 
0.0000000000 * 0.1611180000 = -2.5292530413 
0.0000000000 * 0.9574160000 = -2.5292530413 
0.0000000000 * 0.0032005000 = -2.5292530413 
0.0000000000 * -0.9968510000 = -2.5292530413 
2.7992951847 * 0.5325500000 = -1.0384883907 
4.4584052240 * 0.0847795000 = -0.6605070250 
3.4785294551 * -0.5274210000 = -2.4951565088 
0.0000000000 * -0.1429590000 = -2.4951565088 
0.0000000000 * 0.0278537000 = -2.4951565088 
0.0734678262 * 0.4111950000 = -2.4649469060 
0.0000000000 * -0.7056210000 = -2.4649469060 
0.0000000000 * -0.5462450000 = -2.4649469060 
0.0000000000 * -1.6632200000 = -2.4649469060 
0.2251693882 * 0.2497930000 = -2.4087011690 
0.8031315178 * 0.0822396000 = -2.3426519542 
0.0000000000 * -0.3550720000 = -2.3426519542 
0.0000000000 * -0.5932460000 = -2.3426519542 
0.0000000000 * -0.9740540000 = -2.3426519542 
0.3902068183 * -0.0673341000 = -2.3689261791 
0.0000000000 * -0.5336590000 = -2.3689261791 
0.0000000000 * -0.0284988000 = -2.3689261791 
1.2034198021 * 0.5033780000 = -1.7631511260 
0.7788152937 * 0.2131240000 = -1.5971668954 
the biases is : 0.5593160000, now tempVal is : -1.0378508954
ReLU !!! in layer: 5, node : 42, its linear result is negative,so set it to 0
compute layer: 5, node : 43
0.0000000000 * -0.0937429000 = 0.0000000000 
0.0000000000 * -0.6147710000 = 0.0000000000 
0.0000000000 * 0.5740870000 = 0.0000000000 
0.0000000000 * -0.9958070000 = 0.0000000000 
0.0000000000 * -0.2796470000 = 0.0000000000 
0.0000000000 * 0.1140520000 = 0.0000000000 
0.0727527248 * -0.0774811000 = -0.0056369611 
0.0000000000 * 0.0590707000 = -0.0056369611 
0.0000000000 * -0.4761870000 = -0.0056369611 
0.1903205629 * 0.0294036000 = -0.0000408514 
0.0000000000 * -0.1933390000 = -0.0000408514 
2.8096423506 * -0.3816360000 = -1.0723015195 
0.0000000000 * 0.0440694000 = -1.0723015195 
0.0000000000 * -0.2360130000 = -1.0723015195 
0.0000000000 * -0.0314724000 = -1.0723015195 
0.0000000000 * 0.0559882000 = -1.0723015195 
0.0000000000 * -0.0633820000 = -1.0723015195 
0.1333779634 * -0.0004289320 = -1.0723587296 
0.0000000000 * -0.0699201000 = -1.0723587296 
0.0000000000 * -0.0230933000 = -1.0723587296 
0.0000000000 * -0.0965740000 = -1.0723587296 
0.8570723642 * -0.1698480000 = -1.2179307565 
0.8398318691 * -0.0198844000 = -1.2346303094 
1.5787404086 * -0.0041892500 = -1.2412440476 
0.0000000000 * 0.1338050000 = -1.2412440476 
0.0000000000 * -0.0688685000 = -1.2412440476 
0.0000000000 * -0.0952642000 = -1.2412440476 
0.0000000000 * -0.0445876000 = -1.2412440476 
0.0000000000 * -0.1104810000 = -1.2412440476 
0.0000000000 * 0.5484860000 = -1.2412440476 
0.0000000000 * -9.3867400000 = -1.2412440476 
2.7992951847 * 0.2701170000 = -0.4851068302 
4.4584052240 * -0.0331187000 = -0.6327634153 
3.4785294551 * -0.0189313000 = -0.6986165000 
0.0000000000 * -0.0015014400 = -0.6986165000 
0.0000000000 * -0.6582350000 = -0.6986165000 
0.0734678262 * 0.3880790000 = -0.6701051794 
0.0000000000 * -0.0149576000 = -0.6701051794 
0.0000000000 * 0.1283360000 = -0.6701051794 
0.0000000000 * -0.6274720000 = -0.6701051794 
0.2251693882 * 0.0071712500 = -0.6684904335 
0.8031315178 * 0.0780303000 = -0.6058218402 
0.0000000000 * -0.2888070000 = -0.6058218402 
0.0000000000 * -0.1487440000 = -0.6058218402 
0.0000000000 * -0.1559750000 = -0.6058218402 
0.3902068183 * -0.1431900000 = -0.6616955545 
0.0000000000 * -0.0672474000 = -0.6616955545 
0.0000000000 * -0.0190112000 = -0.6616955545 
1.2034198021 * -0.1035040000 = -0.7862543177 
0.7788152937 * -0.3201990000 = -1.0356301959 
the biases is : 0.7112650000, now tempVal is : -0.3243651959
ReLU !!! in layer: 5, node : 43, its linear result is negative,so set it to 0
compute layer: 5, node : 44
0.0000000000 * -0.8547770000 = 0.0000000000 
0.0000000000 * -0.8044870000 = 0.0000000000 
0.0000000000 * 3.8671900000 = 0.0000000000 
0.0000000000 * 0.4275180000 = 0.0000000000 
0.0000000000 * 0.4436570000 = 0.0000000000 
0.0000000000 * -0.8871880000 = 0.0000000000 
0.0727527248 * -0.0599435000 = -0.0043610530 
0.0000000000 * -2.7280700000 = -0.0043610530 
0.0000000000 * 3.7330800000 = -0.0043610530 
0.1903205629 * -0.2479970000 = -0.0515599816 
0.0000000000 * 3.2567100000 = -0.0515599816 
2.8096423506 * -0.9152710000 = -2.6231441454 
0.0000000000 * -0.8138120000 = -2.6231441454 
0.0000000000 * 0.4738520000 = -2.6231441454 
0.0000000000 * 0.0017686900 = -2.6231441454 
0.0000000000 * -0.2279410000 = -2.6231441454 
0.0000000000 * 0.0080385500 = -2.6231441454 
0.1333779634 * 0.3094950000 = -2.5818643327 
0.0000000000 * -1.2259900000 = -2.5818643327 
0.0000000000 * 2.3691900000 = -2.5818643327 
0.0000000000 * 0.3134980000 = -2.5818643327 
0.8570723642 * 0.6969460000 = -1.9845311768 
0.8398318691 * -0.4956880000 = -2.4008257563 
1.5787404086 * 0.0548642000 = -2.3142094268 
0.0000000000 * 5.0327400000 = -2.3142094268 
0.0000000000 * 0.3147840000 = -2.3142094268 
0.0000000000 * -1.2813800000 = -2.3142094268 
0.0000000000 * -0.7953240000 = -2.3142094268 
0.0000000000 * -15.2996000000 = -2.3142094268 
0.0000000000 * 1.4663300000 = -2.3142094268 
0.0000000000 * 1.8872600000 = -2.3142094268 
2.7992951847 * 0.2176770000 = -1.7048672488 
4.4584052240 * 0.1560620000 = -1.0090796128 
3.4785294551 * 0.3908130000 = 0.3503749192 
0.0000000000 * 0.5732700000 = 0.3503749192 
0.0000000000 * -2.4878200000 = 0.3503749192 
0.0734678262 * -1.5624500000 = 0.2355851142 
0.0000000000 * 2.0035900000 = 0.2355851142 
0.0000000000 * 0.3299960000 = 0.2355851142 
0.0000000000 * 4.8721100000 = 0.2355851142 
0.2251693882 * -2.9462800000 = -0.4278269510 
0.8031315178 * -1.2887100000 = -1.4628305693 
0.0000000000 * -1.0798400000 = -1.4628305693 
0.0000000000 * 0.7289820000 = -1.4628305693 
0.0000000000 * -1.5408300000 = -1.4628305693 
0.3902068183 * 0.0876284000 = -1.4286373701 
0.0000000000 * 2.9122800000 = -1.4286373701 
0.0000000000 * 0.0015296200 = -1.4286373701 
1.2034198021 * -0.2260680000 = -1.7006920779 
0.7788152937 * 0.9447080000 = -0.9649390395 
the biases is : -3.2447800000, now tempVal is : -4.2097190395
ReLU !!! in layer: 5, node : 44, its linear result is negative,so set it to 0
compute layer: 5, node : 45
0.0000000000 * 0.0603471000 = 0.0000000000 
0.0000000000 * 0.8847050000 = 0.0000000000 
0.0000000000 * 2.4211100000 = 0.0000000000 
0.0000000000 * 0.2707710000 = 0.0000000000 
0.0000000000 * 0.0096646400 = 0.0000000000 
0.0000000000 * -0.0611919000 = 0.0000000000 
0.0727527248 * 0.5961010000 = 0.0433679720 
0.0000000000 * 0.1554510000 = 0.0433679720 
0.0000000000 * 2.2376000000 = 0.0433679720 
0.1903205629 * -0.1339370000 = 0.0178770068 
0.0000000000 * 0.0128030000 = 0.0178770068 
2.8096423506 * -0.4617510000 = -1.2794781582 
0.0000000000 * -0.2651710000 = -1.2794781582 
0.0000000000 * -0.1135880000 = -1.2794781582 
0.0000000000 * -0.0241218000 = -1.2794781582 
0.0000000000 * 0.2383200000 = -1.2794781582 
0.0000000000 * -0.1856200000 = -1.2794781582 
0.1333779634 * -0.1313580000 = -1.2969984207 
0.0000000000 * -0.1531980000 = -1.2969984207 
0.0000000000 * 0.2806680000 = -1.2969984207 
0.0000000000 * -0.1234420000 = -1.2969984207 
0.8570723642 * 0.0040349800 = -1.2935401509 
0.8398318691 * 0.1571400000 = -1.1615689710 
1.5787404086 * 0.0275949000 = -1.1180037873 
0.0000000000 * 1.0737700000 = -1.1180037873 
0.0000000000 * -0.2866750000 = -1.1180037873 
0.0000000000 * -0.2369200000 = -1.1180037873 
0.0000000000 * -0.1556150000 = -1.1180037873 
0.0000000000 * -0.4657690000 = -1.1180037873 
0.0000000000 * 2.3782900000 = -1.1180037873 
0.0000000000 * 0.2165740000 = -1.1180037873 
2.7992951847 * 0.0867811000 = -0.8750778719 
4.4584052240 * 0.0479979000 = -0.6610837838 
3.4785294551 * 0.0344449000 = -0.5412661846 
0.0000000000 * 0.0605079000 = -0.5412661846 
0.0000000000 * -0.5962570000 = -0.5412661846 
0.0734678262 * 0.5457140000 = -0.5011737633 
0.0000000000 * 0.3076470000 = -0.5011737633 
0.0000000000 * 0.0465394000 = -0.5011737633 
0.0000000000 * -1.0124400000 = -0.5011737633 
0.2251693882 * 0.1612610000 = -0.4648627226 
0.8031315178 * -0.0496996000 = -0.5047780378 
0.0000000000 * 0.1490790000 = -0.5047780378 
0.0000000000 * -0.0379314000 = -0.5047780378 
0.0000000000 * 0.0885242000 = -0.5047780378 
0.3902068183 * -0.1558450000 = -0.5655898194 
0.0000000000 * 0.1245640000 = -0.5655898194 
0.0000000000 * 0.0096296200 = -0.5655898194 
1.2034198021 * 0.4258850000 = -0.0530713769 
0.7788152937 * -0.1531000000 = -0.1723079984 
the biases is : 0.5800000000, now tempVal is : 0.4076920016
compute layer: 5, node : 46
0.0000000000 * -0.1095460000 = 0.0000000000 
0.0000000000 * -0.6878970000 = 0.0000000000 
0.0000000000 * 0.4154210000 = 0.0000000000 
0.0000000000 * -0.2168940000 = 0.0000000000 
0.0000000000 * 0.1280690000 = 0.0000000000 
0.0000000000 * 0.1837060000 = 0.0000000000 
0.0727527248 * 0.2051750000 = 0.0149270403 
0.0000000000 * 0.0265236000 = 0.0149270403 
0.0000000000 * -0.0508679000 = 0.0149270403 
0.1903205629 * -0.0169715000 = 0.0116970149 
0.0000000000 * -0.1314800000 = 0.0116970149 
2.8096423506 * 0.0801082000 = 0.2367724062 
0.0000000000 * -0.0169388000 = 0.2367724062 
0.0000000000 * 0.1320840000 = 0.2367724062 
0.0000000000 * 0.0163130000 = 0.2367724062 
0.0000000000 * 0.0337704000 = 0.2367724062 
0.0000000000 * 0.0629529000 = 0.2367724062 
0.1333779634 * 0.1367470000 = 0.2550114426 
0.0000000000 * 0.1056050000 = 0.2550114426 
0.0000000000 * -0.6260450000 = 0.2550114426 
0.0000000000 * 0.0660877000 = 0.2550114426 
0.8570723642 * 0.1149890000 = 0.3535653367 
0.8398318691 * 0.1974660000 = 0.5194035765 
1.5787404086 * 0.1635320000 = 0.7775781530 
0.0000000000 * -0.1311970000 = 0.7775781530 
0.0000000000 * 0.0944511000 = 0.7775781530 
0.0000000000 * -0.1313880000 = 0.7775781530 
0.0000000000 * -0.1918370000 = 0.7775781530 
0.0000000000 * 0.0961356000 = 0.7775781530 
0.0000000000 * 0.0892717000 = 0.7775781530 
0.0000000000 * -1.9684000000 = 0.7775781530 
2.7992951847 * -0.1137290000 = 0.4592171110 
4.4584052240 * 0.0805298000 = 0.8182515920 
3.4785294551 * 0.0406929000 = 0.9598030432 
0.0000000000 * 0.0469088000 = 0.9598030432 
0.0000000000 * -0.7071700000 = 0.9598030432 
0.0734678262 * -0.3007840000 = 0.9377050966 
0.0000000000 * -0.0043099500 = 0.9377050966 
0.0000000000 * -0.0148604000 = 0.9377050966 
0.0000000000 * 0.0580635000 = 0.9377050966 
0.2251693882 * 0.2346810000 = 0.9905480738 
0.8031315178 * 0.0253711000 = 1.0109244039 
0.0000000000 * -0.1298390000 = 1.0109244039 
0.0000000000 * 0.2386740000 = 1.0109244039 
0.0000000000 * 0.2749980000 = 1.0109244039 
0.3902068183 * 0.1880010000 = 1.0842836759 
0.0000000000 * -0.0525955000 = 1.0842836759 
0.0000000000 * -0.0045865300 = 1.0842836759 
1.2034198021 * -0.0746666000 = 0.9944284109 
0.7788152937 * 0.0963384000 = 1.0694582302 
the biases is : 0.1658730000, now tempVal is : 1.2353312302
compute layer: 5, node : 47
0.0000000000 * 0.4182940000 = 0.0000000000 
0.0000000000 * -1.4082900000 = 0.0000000000 
0.0000000000 * -2.7230800000 = 0.0000000000 
0.0000000000 * -0.2365370000 = 0.0000000000 
0.0000000000 * -0.2691110000 = 0.0000000000 
0.0000000000 * 0.3908950000 = 0.0000000000 
0.0727527248 * -0.2499880000 = -0.0181873082 
0.0000000000 * 1.0942000000 = -0.0181873082 
0.0000000000 * -4.7828500000 = -0.0181873082 
0.1903205629 * -0.3565670000 = -0.0860493403 
0.0000000000 * 0.0506880000 = -0.0860493403 
2.8096423506 * 0.1711990000 = 0.3949586205 
0.0000000000 * -0.1875320000 = 0.3949586205 
0.0000000000 * -0.0608907000 = 0.3949586205 
0.0000000000 * 0.0397453000 = 0.3949586205 
0.0000000000 * -0.1699370000 = 0.3949586205 
0.0000000000 * 0.3639120000 = 0.3949586205 
0.1333779634 * 0.2775190000 = 0.4319735395 
0.0000000000 * 0.8182190000 = 0.4319735395 
0.0000000000 * 0.5486570000 = 0.4319735395 
0.0000000000 * 0.3637060000 = 0.4319735395 
0.8570723642 * -0.1631310000 = 0.2921584676 
0.8398318691 * 0.3733680000 = 0.6057248129 
1.5787404086 * 0.2062270000 = 0.9313037112 
0.0000000000 * -0.3856800000 = 0.9313037112 
0.0000000000 * 0.6365990000 = 0.9313037112 
0.0000000000 * 0.1921140000 = 0.9313037112 
0.0000000000 * -0.0662641000 = 0.9313037112 
0.0000000000 * -0.7186950000 = 0.9313037112 
0.0000000000 * -2.0209000000 = 0.9313037112 
0.0000000000 * 0.2152370000 = 0.9313037112 
2.7992951847 * 0.1998080000 = 1.4906252834 
4.4584052240 * -0.4000150000 = -0.2928036822 
3.4785294551 * 0.1759470000 = 0.3192331398 
0.0000000000 * 0.1735500000 = 0.3192331398 
0.0000000000 * -0.0503755000 = 0.3192331398 
0.0734678262 * -0.7011200000 = 0.2677233775 
0.0000000000 * 0.3476120000 = 0.2677233775 
0.0000000000 * 0.3599630000 = 0.2677233775 
0.0000000000 * -3.5712300000 = 0.2677233775 
0.2251693882 * 0.2276740000 = 0.3189885928 
0.8031315178 * -0.4368000000 = -0.0318192542 
0.0000000000 * -0.0398120000 = -0.0318192542 
0.0000000000 * 0.3150580000 = -0.0318192542 
0.0000000000 * -0.4721080000 = -0.0318192542 
0.3902068183 * 0.6221140000 = 0.2109338704 
0.0000000000 * -0.5684030000 = 0.2109338704 
0.0000000000 * -0.0413331000 = 0.2109338704 
1.2034198021 * 0.1147760000 = 0.3490575816 
0.7788152937 * 0.1428960000 = 0.4603471718 
the biases is : -1.2932700000, now tempVal is : -0.8329228282
ReLU !!! in layer: 5, node : 47, its linear result is negative,so set it to 0
compute layer: 5, node : 48
0.0000000000 * 0.2339090000 = 0.0000000000 
0.0000000000 * -0.2426130000 = 0.0000000000 
0.0000000000 * -0.0361945000 = 0.0000000000 
0.0000000000 * 0.2846110000 = 0.0000000000 
0.0000000000 * 0.2362740000 = 0.0000000000 
0.0000000000 * 0.6748840000 = 0.0000000000 
0.0727527248 * 0.6110670000 = 0.0444567893 
0.0000000000 * 1.0200500000 = 0.0444567893 
0.0000000000 * -0.5030010000 = 0.0444567893 
0.1903205629 * 0.6198440000 = 0.1624258483 
0.0000000000 * -0.4610340000 = 0.1624258483 
2.8096423506 * 0.8936720000 = 2.6733245470 
0.0000000000 * -0.7276510000 = 2.6733245470 
0.0000000000 * 0.2416040000 = 2.6733245470 
0.0000000000 * 0.0508817000 = 2.6733245470 
0.0000000000 * 0.3387830000 = 2.6733245470 
0.0000000000 * -0.9131410000 = 2.6733245470 
0.1333779634 * -0.3762040000 = 2.6231472237 
0.0000000000 * -1.3544500000 = 2.6231472237 
0.0000000000 * -0.7106160000 = 2.6231472237 
0.0000000000 * -1.1610900000 = 2.6231472237 
0.8570723642 * -0.2565600000 = 2.4032567379 
0.8398318691 * -0.1179380000 = 2.3042086469 
1.5787404086 * 0.2483200000 = 2.6962414652 
0.0000000000 * -0.9944230000 = 2.6962414652 
0.0000000000 * -1.3581100000 = 2.6962414652 
0.0000000000 * 0.6378930000 = 2.6962414652 
0.0000000000 * -0.0321529000 = 2.6962414652 
0.0000000000 * -2.8552100000 = 2.6962414652 
0.0000000000 * 0.4588570000 = 2.6962414652 
0.0000000000 * 0.4688120000 = 2.6962414652 
2.7992951847 * -0.5895550000 = 1.0459029926 
4.4584052240 * 0.3080180000 = 2.4191720529 
3.4785294551 * 0.0244781000 = 2.5043198447 
0.0000000000 * 0.1608390000 = 2.5043198447 
0.0000000000 * 0.4163780000 = 2.5043198447 
0.0734678262 * -1.9576800000 = 2.3604933507 
0.0000000000 * -1.0844900000 = 2.3604933507 
0.0000000000 * 0.4570280000 = 2.3604933507 
0.0000000000 * -0.8856860000 = 2.3604933507 
0.2251693882 * -0.8901470000 = 2.1600594953 
0.8031315178 * -10.6989000000 = -6.4325643004 
0.0000000000 * 0.1814820000 = -6.4325643004 
0.0000000000 * -2.6592000000 = -6.4325643004 
0.0000000000 * -1.3969500000 = -6.4325643004 
0.3902068183 * -2.6216800000 = -7.4555617118 
0.0000000000 * -0.5835790000 = -7.4555617118 
0.0000000000 * -0.0408955000 = -7.4555617118 
1.2034198021 * -1.3366600000 = -9.0641248245 
0.7788152937 * -0.3317850000 = -9.3225240567 
the biases is : -0.3310410000, now tempVal is : -9.6535650567
ReLU !!! in layer: 5, node : 48, its linear result is negative,so set it to 0
compute layer: 5, node : 49
0.0000000000 * 0.1923900000 = 0.0000000000 
0.0000000000 * -0.8790080000 = 0.0000000000 
0.0000000000 * 1.0119100000 = 0.0000000000 
0.0000000000 * -0.2316840000 = 0.0000000000 
0.0000000000 * -0.0151370000 = 0.0000000000 
0.0000000000 * -0.3050660000 = 0.0000000000 
0.0727527248 * -0.8848590000 = -0.0643759033 
0.0000000000 * -0.2641380000 = -0.0643759033 
0.0000000000 * 2.7058600000 = -0.0643759033 
0.1903205629 * -0.1921660000 = -0.1009490446 
0.0000000000 * -0.0542771000 = -0.1009490446 
2.8096423506 * -0.3027120000 = -0.9514614998 
0.0000000000 * 0.4316690000 = -0.9514614998 
0.0000000000 * 0.5008030000 = -0.9514614998 
0.0000000000 * 0.0055878400 = -0.9514614998 
0.0000000000 * -0.0634604000 = -0.9514614998 
0.0000000000 * 0.4589050000 = -0.9514614998 
0.1333779634 * -0.1615790000 = -0.9730125778 
0.0000000000 * -0.2355790000 = -0.9730125778 
0.0000000000 * -0.7246970000 = -0.9730125778 
0.0000000000 * -0.1112620000 = -0.9730125778 
0.8570723642 * 0.0244568000 = -0.9520513304 
0.8398318691 * 0.6300160000 = -0.4229438155 
1.5787404086 * 0.3382800000 = 0.1111124899 
0.0000000000 * 0.8288140000 = 0.1111124899 
0.0000000000 * -0.0349925000 = 0.1111124899 
0.0000000000 * -0.0919217000 = 0.1111124899 
0.0000000000 * -0.0546509000 = 0.1111124899 
0.0000000000 * -2.3702800000 = 0.1111124899 
0.0000000000 * 1.8933600000 = 0.1111124899 
0.0000000000 * -0.0775442000 = 0.1111124899 
2.7992951847 * -0.0491432000 = -0.0264538333 
4.4584052240 * -1.2437800000 = -5.5717290828 
3.4785294551 * 0.2049480000 = -4.8588114280 
0.0000000000 * 0.0713037000 = -4.8588114280 
0.0000000000 * 0.1232390000 = -4.8588114280 
0.0734678262 * 0.9130090000 = -4.7917346415 
0.0000000000 * 0.5949450000 = -4.7917346415 
0.0000000000 * -0.2242590000 = -4.7917346415 
0.0000000000 * -1.0303100000 = -4.7917346415 
0.2251693882 * -1.6376000000 = -5.1604720317 
0.8031315178 * 2.3180700000 = -3.2987569542 
0.0000000000 * 0.1805080000 = -3.2987569542 
0.0000000000 * 0.0163787000 = -3.2987569542 
0.0000000000 * 0.1424550000 = -3.2987569542 
0.3902068183 * -0.6364340000 = -3.5470978404 
0.0000000000 * 0.4834800000 = -3.5470978404 
0.0000000000 * 0.0402966000 = -3.5470978404 
1.2034198021 * -0.2912270000 = -3.8975661791 
0.7788152937 * 0.8760660000 = -3.2152725800 
the biases is : -0.6541650000, now tempVal is : -3.8694375800
ReLU !!! in layer: 5, node : 49, its linear result is negative,so set it to 0

now we get all result in layer: 5
	node: 0, val: 0.3707124511
	node: 1, val: 0.0000000000
	node: 2, val: 0.0000000000
	node: 3, val: 0.0000000000
	node: 4, val: 0.0000000000
	node: 5, val: 0.0000000000
	node: 6, val: 0.0000000000
	node: 7, val: 0.0000000000
	node: 8, val: 0.0000000000
	node: 9, val: 0.0000000000
	node: 10, val: 1.1632586860
	node: 11, val: 0.0000000000
	node: 12, val: 0.0000000000
	node: 13, val: 0.0000000000
	node: 14, val: 0.0000000000
	node: 15, val: 0.0098561911
	node: 16, val: 0.0000000000
	node: 17, val: 0.0000000000
	node: 18, val: 0.0000000000
	node: 19, val: 0.0000000000
	node: 20, val: 0.0000000000
	node: 21, val: 0.0000000000
	node: 22, val: 0.0000000000
	node: 23, val: 0.0000000000
	node: 24, val: 0.0000000000
	node: 25, val: 2.0550217898
	node: 26, val: 0.0000000000
	node: 27, val: 0.0000000000
	node: 28, val: 0.0000000000
	node: 29, val: 0.0000000000
	node: 30, val: 0.0000000000
	node: 31, val: 0.0000000000
	node: 32, val: 0.0000000000
	node: 33, val: 3.5937718848
	node: 34, val: 0.0000000000
	node: 35, val: 0.0000000000
	node: 36, val: 0.0000000000
	node: 37, val: 0.0000000000
	node: 38, val: 0.2629356409
	node: 39, val: 0.3574904745
	node: 40, val: 0.0000000000
	node: 41, val: 0.0000000000
	node: 42, val: 0.0000000000
	node: 43, val: 0.0000000000
	node: 44, val: 0.0000000000
	node: 45, val: 0.4076920016
	node: 46, val: 1.2353312302
	node: 47, val: 0.0000000000
	node: 48, val: 0.0000000000
	node: 49, val: 0.0000000000

when compute layer[5] to layer[6]
compute layer: 6, node : 0
0.3707124511 * 0.0198897000 = 0.0073733594 
0.0000000000 * -0.0404527000 = 0.0073733594 
0.0000000000 * -0.2775910000 = 0.0073733594 
0.0000000000 * 0.0392536000 = 0.0073733594 
0.0000000000 * 0.6036090000 = 0.0073733594 
0.0000000000 * 0.3599660000 = 0.0073733594 
0.0000000000 * -1.1585800000 = 0.0073733594 
0.0000000000 * 0.0895053000 = 0.0073733594 
0.0000000000 * -0.0162616000 = 0.0073733594 
0.0000000000 * 0.6204360000 = 0.0073733594 
1.1632586860 * -1.2586800000 = -1.4567970834 
0.0000000000 * 0.4351050000 = -1.4567970834 
0.0000000000 * 0.4586250000 = -1.4567970834 
0.0000000000 * 0.1490910000 = -1.4567970834 
0.0000000000 * 0.4105640000 = -1.4567970834 
0.0098561911 * 0.1788460000 = -1.4550343431 
0.0000000000 * -0.1173090000 = -1.4550343431 
0.0000000000 * 0.1552180000 = -1.4550343431 
0.0000000000 * -0.0036146900 = -1.4550343431 
0.0000000000 * 0.0942395000 = -1.4550343431 
0.0000000000 * -0.2648470000 = -1.4550343431 
0.0000000000 * -0.4686500000 = -1.4550343431 
0.0000000000 * -0.2370210000 = -1.4550343431 
0.0000000000 * -0.5368850000 = -1.4550343431 
0.0000000000 * -0.0563038000 = -1.4550343431 
2.0550217898 * 0.2329140000 = -0.9763909979 
0.0000000000 * -0.0612577000 = -0.9763909979 
0.0000000000 * 0.2888110000 = -0.9763909979 
0.0000000000 * -0.4654490000 = -0.9763909979 
0.0000000000 * 0.1321330000 = -0.9763909979 
0.0000000000 * -0.0728266000 = -0.9763909979 
0.0000000000 * -1.0241600000 = -0.9763909979 
0.0000000000 * -0.0315447000 = -0.9763909979 
3.5937718848 * -0.1081280000 = -1.3649783643 
0.0000000000 * -0.1466570000 = -1.3649783643 
0.0000000000 * 1.5425900000 = -1.3649783643 
0.0000000000 * -0.1021720000 = -1.3649783643 
0.0000000000 * -0.3482720000 = -1.3649783643 
0.2629356409 * -0.1086340000 = -1.3935421147 
0.3574904745 * 0.0917521000 = -1.3607416129 
0.0000000000 * 0.1187760000 = -1.3607416129 
0.0000000000 * -0.4907990000 = -1.3607416129 
0.0000000000 * 0.0487253000 = -1.3607416129 
0.0000000000 * 1.0078700000 = -1.3607416129 
0.0000000000 * 0.3290560000 = -1.3607416129 
0.4076920016 * -0.0960519000 = -1.3999012043 
1.2353312302 * 0.1889030000 = -1.1665434289 
0.0000000000 * -0.5561170000 = -1.1665434289 
0.0000000000 * -0.3211280000 = -1.1665434289 
0.0000000000 * -4.4887500000 = -1.1665434289 
the biases is : -0.4300610000, now tempVal is : -1.5966044289
ReLU !!! in layer: 6, node : 0, its linear result is negative,so set it to 0
compute layer: 6, node : 1
0.3707124511 * -0.1247800000 = -0.0462574996 
0.0000000000 * 0.0416074000 = -0.0462574996 
0.0000000000 * 0.0687742000 = -0.0462574996 
0.0000000000 * -0.0500863000 = -0.0462574996 
0.0000000000 * 0.3771880000 = -0.0462574996 
0.0000000000 * -0.0149096000 = -0.0462574996 
0.0000000000 * 0.6923640000 = -0.0462574996 
0.0000000000 * 0.0749262000 = -0.0462574996 
0.0000000000 * 0.1371860000 = -0.0462574996 
0.0000000000 * 0.0966477000 = -0.0462574996 
1.1632586860 * -0.0077016900 = -0.0552165574 
0.0000000000 * 0.6911320000 = -0.0552165574 
0.0000000000 * 0.0518415000 = -0.0552165574 
0.0000000000 * 0.0073998900 = -0.0552165574 
0.0000000000 * -0.1067590000 = -0.0552165574 
0.0098561911 * 0.2155720000 = -0.0530918386 
0.0000000000 * -0.1002710000 = -0.0530918386 
0.0000000000 * 0.0086234100 = -0.0530918386 
0.0000000000 * 0.4423130000 = -0.0530918386 
0.0000000000 * 0.3275010000 = -0.0530918386 
0.0000000000 * 0.0345781000 = -0.0530918386 
0.0000000000 * 0.0836259000 = -0.0530918386 
0.0000000000 * -0.1056870000 = -0.0530918386 
0.0000000000 * 0.0685188000 = -0.0530918386 
0.0000000000 * -0.1537030000 = -0.0530918386 
2.0550217898 * 0.5464760000 = 1.0699282490 
0.0000000000 * 0.0165681000 = 1.0699282490 
0.0000000000 * -0.1723900000 = 1.0699282490 
0.0000000000 * 0.0519638000 = 1.0699282490 
0.0000000000 * -0.0102360000 = 1.0699282490 
0.0000000000 * -0.2141140000 = 1.0699282490 
0.0000000000 * -0.3639510000 = 1.0699282490 
0.0000000000 * -0.0305532000 = 1.0699282490 
3.5937718848 * -0.4054730000 = -0.3872492185 
0.0000000000 * 0.0400872000 = -0.3872492185 
0.0000000000 * 0.7162060000 = -0.3872492185 
0.0000000000 * -0.0141947000 = -0.3872492185 
0.0000000000 * -0.1278100000 = -0.3872492185 
0.2629356409 * -0.1698000000 = -0.4318956903 
0.3574904745 * 0.0078427100 = -0.4290919962 
0.0000000000 * 0.0831355000 = -0.4290919962 
0.0000000000 * -0.3377340000 = -0.4290919962 
0.0000000000 * -0.2401570000 = -0.4290919962 
0.0000000000 * 0.1571070000 = -0.4290919962 
0.0000000000 * 0.0217610000 = -0.4290919962 
0.4076920016 * 0.0733449000 = -0.3991898671 
1.2353312302 * 0.0092896400 = -0.3877140847 
0.0000000000 * 0.0824242000 = -0.3877140847 
0.0000000000 * 0.0293015000 = -0.3877140847 
0.0000000000 * 0.0386904000 = -0.3877140847 
the biases is : -0.0245742000, now tempVal is : -0.4122882847
ReLU !!! in layer: 6, node : 1, its linear result is negative,so set it to 0
compute layer: 6, node : 2
0.3707124511 * -1.4744500000 = -0.5465969735 
0.0000000000 * -1.2077200000 = -0.5465969735 
0.0000000000 * -0.5333250000 = -0.5465969735 
0.0000000000 * -0.0924220000 = -0.5465969735 
0.0000000000 * 2.5243100000 = -0.5465969735 
0.0000000000 * -0.9451340000 = -0.5465969735 
0.0000000000 * 1.1722800000 = -0.5465969735 
0.0000000000 * 0.1983560000 = -0.5465969735 
0.0000000000 * -0.2616370000 = -0.5465969735 
0.0000000000 * 0.4834250000 = -0.5465969735 
1.1632586860 * -0.6010540000 = -1.2457782597 
0.0000000000 * -0.0990522000 = -1.2457782597 
0.0000000000 * 0.5753110000 = -1.2457782597 
0.0000000000 * -0.8285670000 = -1.2457782597 
0.0000000000 * -0.5156170000 = -1.2457782597 
0.0098561911 * 1.2397100000 = -1.2335594411 
0.0000000000 * -0.6460880000 = -1.2335594411 
0.0000000000 * 1.2671500000 = -1.2335594411 
0.0000000000 * 2.2902100000 = -1.2335594411 
0.0000000000 * 0.2524440000 = -1.2335594411 
0.0000000000 * 0.2687330000 = -1.2335594411 
0.0000000000 * 0.8423720000 = -1.2335594411 
0.0000000000 * -0.1831750000 = -1.2335594411 
0.0000000000 * 0.1503040000 = -1.2335594411 
0.0000000000 * 0.2546470000 = -1.2335594411 
2.0550217898 * -0.0738135000 = -1.3852477920 
0.0000000000 * -0.1984230000 = -1.3852477920 
0.0000000000 * 0.2905380000 = -1.3852477920 
0.0000000000 * -0.1493870000 = -1.3852477920 
0.0000000000 * -0.2188760000 = -1.3852477920 
0.0000000000 * -0.3745990000 = -1.3852477920 
0.0000000000 * -4.9036600000 = -1.3852477920 
0.0000000000 * -0.0781810000 = -1.3852477920 
3.5937718848 * -0.6323570000 = -3.6577945997 
0.0000000000 * 0.4070410000 = -3.6577945997 
0.0000000000 * -0.4818490000 = -3.6577945997 
0.0000000000 * 0.1056390000 = -3.6577945997 
0.0000000000 * -0.6282270000 = -3.6577945997 
0.2629356409 * -0.1682710000 = -3.7020390430 
0.3574904745 * 0.6663800000 = -3.4638145406 
0.0000000000 * 0.7771300000 = -3.4638145406 
0.0000000000 * 0.5331600000 = -3.4638145406 
0.0000000000 * 0.4691910000 = -3.4638145406 
0.0000000000 * 1.2914800000 = -3.4638145406 
0.0000000000 * -1.1322300000 = -3.4638145406 
0.4076920016 * 0.0211952000 = -3.4551734271 
1.2353312302 * 0.6195900000 = -2.6897745502 
0.0000000000 * -7.7455200000 = -2.6897745502 
0.0000000000 * -0.1057170000 = -2.6897745502 
0.0000000000 * 3.2394200000 = -2.6897745502 
the biases is : -1.8573700000, now tempVal is : -4.5471445502
ReLU !!! in layer: 6, node : 2, its linear result is negative,so set it to 0
compute layer: 6, node : 3
0.3707124511 * -0.0095105700 = -0.0035256867 
0.0000000000 * -0.0019505400 = -0.0035256867 
0.0000000000 * 0.0289095000 = -0.0035256867 
0.0000000000 * -0.0820630000 = -0.0035256867 
0.0000000000 * 0.3271900000 = -0.0035256867 
0.0000000000 * 0.0505229000 = -0.0035256867 
0.0000000000 * -9.7170700000 = -0.0035256867 
0.0000000000 * 0.0055075200 = -0.0035256867 
0.0000000000 * 0.0622835000 = -0.0035256867 
0.0000000000 * -0.0572328000 = -0.0035256867 
1.1632586860 * -0.1973260000 = -0.2330668702 
0.0000000000 * 0.0323883000 = -0.2330668702 
0.0000000000 * -0.0442943000 = -0.2330668702 
0.0000000000 * -0.0014327200 = -0.2330668702 
0.0000000000 * 0.0006012800 = -0.2330668702 
0.0098561911 * 0.1188670000 = -0.2318952943 
0.0000000000 * 0.0141389000 = -0.2318952943 
0.0000000000 * 0.1086050000 = -0.2318952943 
0.0000000000 * -0.0147900000 = -0.2318952943 
0.0000000000 * 0.1912240000 = -0.2318952943 
0.0000000000 * -0.0560275000 = -0.2318952943 
0.0000000000 * 0.0698511000 = -0.2318952943 
0.0000000000 * 0.0638019000 = -0.2318952943 
0.0000000000 * 0.0051823900 = -0.2318952943 
0.0000000000 * 0.0124155000 = -0.2318952943 
2.0550217898 * 0.0587427000 = -0.1111777658 
0.0000000000 * -0.0040895900 = -0.1111777658 
0.0000000000 * -0.0519665000 = -0.1111777658 
0.0000000000 * -0.0166309000 = -0.1111777658 
0.0000000000 * 0.0210846000 = -0.1111777658 
0.0000000000 * -0.1965540000 = -0.1111777658 
0.0000000000 * 0.0853336000 = -0.1111777658 
0.0000000000 * 0.0009462800 = -0.1111777658 
3.5937718848 * 0.0446118000 = 0.0491468667 
0.0000000000 * -0.0845010000 = 0.0491468667 
0.0000000000 * -0.3121240000 = 0.0491468667 
0.0000000000 * -0.0002443520 = 0.0491468667 
0.0000000000 * -0.0317970000 = 0.0491468667 
0.2629356409 * -0.0342911000 = 0.0401305144 
0.3574904745 * -0.0130440000 = 0.0354674086 
0.0000000000 * 0.0531631000 = 0.0354674086 
0.0000000000 * -0.2116270000 = 0.0354674086 
0.0000000000 * -0.0555921000 = 0.0354674086 
0.0000000000 * -0.0192542000 = 0.0354674086 
0.0000000000 * -4.2426200000 = 0.0354674086 
0.4076920016 * 0.0448343000 = 0.0537459941 
1.2353312302 * -0.1431130000 = -0.1230459642 
0.0000000000 * 0.0922184000 = -0.1230459642 
0.0000000000 * -0.0254486000 = -0.1230459642 
0.0000000000 * 0.0659032000 = -0.1230459642 
the biases is : -0.0138152000, now tempVal is : -0.1368611642
ReLU !!! in layer: 6, node : 3, its linear result is negative,so set it to 0
compute layer: 6, node : 4
0.3707124511 * 0.9353070000 = 0.3467299505 
0.0000000000 * -2.0134800000 = 0.3467299505 
0.0000000000 * 0.2528400000 = 0.3467299505 
0.0000000000 * -0.0538865000 = 0.3467299505 
0.0000000000 * -0.4497740000 = 0.3467299505 
0.0000000000 * 0.9445730000 = 0.3467299505 
0.0000000000 * -0.3946120000 = 0.3467299505 
0.0000000000 * -0.4181400000 = 0.3467299505 
0.0000000000 * -0.8579700000 = 0.3467299505 
0.0000000000 * -0.2383160000 = 0.3467299505 
1.1632586860 * 0.1485480000 = 0.5195297018 
0.0000000000 * 3.3405600000 = 0.5195297018 
0.0000000000 * -0.3846370000 = 0.5195297018 
0.0000000000 * -0.1528550000 = 0.5195297018 
0.0000000000 * 0.0564274000 = 0.5195297018 
0.0098561911 * -1.6573500000 = 0.5031945435 
0.0000000000 * -1.3513500000 = 0.5031945435 
0.0000000000 * -0.9822940000 = 0.5031945435 
0.0000000000 * -1.0243900000 = 0.5031945435 
0.0000000000 * 0.1622130000 = 0.5031945435 
0.0000000000 * 0.2151090000 = 0.5031945435 
0.0000000000 * -0.0248712000 = 0.5031945435 
0.0000000000 * -7.4504600000 = 0.5031945435 
0.0000000000 * 0.2136180000 = 0.5031945435 
0.0000000000 * 0.0702675000 = 0.5031945435 
2.0550217898 * -2.4676300000 = -4.5678388756 
0.0000000000 * -5.1888500000 = -4.5678388756 
0.0000000000 * 0.4418500000 = -4.5678388756 
0.0000000000 * 0.0010355400 = -4.5678388756 
0.0000000000 * 0.4018300000 = -4.5678388756 
0.0000000000 * 0.4026820000 = -4.5678388756 
0.0000000000 * -1.7952000000 = -4.5678388756 
0.0000000000 * -0.3603880000 = -4.5678388756 
3.5937718848 * 0.9672190000 = -1.0918744269 
0.0000000000 * -2.3940700000 = -1.0918744269 
0.0000000000 * 0.0189563000 = -1.0918744269 
0.0000000000 * 0.1141880000 = -1.0918744269 
0.0000000000 * -0.3066000000 = -1.0918744269 
0.2629356409 * 1.1848500000 = -0.7803351328 
0.3574904745 * -0.9619120000 = -1.1242095101 
0.0000000000 * -0.5699750000 = -1.1242095101 
0.0000000000 * 1.0792300000 = -1.1242095101 
0.0000000000 * -1.9096500000 = -1.1242095101 
0.0000000000 * 1.7798300000 = -1.1242095101 
0.0000000000 * 0.1115570000 = -1.1242095101 
0.4076920016 * -0.4367920000 = -1.3022861148 
1.2353312302 * -6.9996300000 = -9.9491476536 
0.0000000000 * -0.7441460000 = -9.9491476536 
0.0000000000 * -0.0400978000 = -9.9491476536 
0.0000000000 * 0.8326710000 = -9.9491476536 
the biases is : 0.4192470000, now tempVal is : -9.5299006536
ReLU !!! in layer: 6, node : 4, its linear result is negative,so set it to 0
compute layer: 6, node : 5
0.3707124511 * 0.2018060000 = 0.0748119969 
0.0000000000 * 0.2518660000 = 0.0748119969 
0.0000000000 * -0.4900960000 = 0.0748119969 
0.0000000000 * -0.0280296000 = 0.0748119969 
0.0000000000 * 0.5397180000 = 0.0748119969 
0.0000000000 * 0.0679513000 = 0.0748119969 
0.0000000000 * -0.2189650000 = 0.0748119969 
0.0000000000 * -0.0102342000 = 0.0748119969 
0.0000000000 * 0.1417460000 = 0.0748119969 
0.0000000000 * 0.2990700000 = 0.0748119969 
1.1632586860 * -0.0814449000 = -0.0199294905 
0.0000000000 * 0.3473620000 = -0.0199294905 
0.0000000000 * 0.2405420000 = -0.0199294905 
0.0000000000 * -0.0172970000 = -0.0199294905 
0.0000000000 * -0.2013590000 = -0.0199294905 
0.0098561911 * -0.2962280000 = -0.0228491702 
0.0000000000 * -0.0098013100 = -0.0228491702 
0.0000000000 * -0.1339670000 = -0.0228491702 
0.0000000000 * 0.1333770000 = -0.0228491702 
0.0000000000 * 0.4789770000 = -0.0228491702 
0.0000000000 * 0.0488040000 = -0.0228491702 
0.0000000000 * -0.0826984000 = -0.0228491702 
0.0000000000 * -0.0010299200 = -0.0228491702 
0.0000000000 * -0.1825370000 = -0.0228491702 
0.0000000000 * -0.0828709000 = -0.0228491702 
2.0550217898 * 0.0769363000 = 0.1352566027 
0.0000000000 * 0.0745554000 = 0.1352566027 
0.0000000000 * 0.1505750000 = 0.1352566027 
0.0000000000 * -0.0278276000 = 0.1352566027 
0.0000000000 * -0.0185181000 = 0.1352566027 
0.0000000000 * 0.1634080000 = 0.1352566027 
0.0000000000 * -0.0303076000 = 0.1352566027 
0.0000000000 * -0.0720884000 = 0.1352566027 
3.5937718848 * 0.1652600000 = 0.7291633444 
0.0000000000 * 0.2209650000 = 0.7291633444 
0.0000000000 * 0.3029630000 = 0.7291633444 
0.0000000000 * 0.0050736900 = 0.7291633444 
0.0000000000 * 0.0975644000 = 0.7291633444 
0.2629356409 * -0.0062554100 = 0.7275185742 
0.3574904745 * 0.0007335380 = 0.7277808070 
0.0000000000 * 0.1381970000 = 0.7277808070 
0.0000000000 * -0.3260870000 = 0.7277808070 
0.0000000000 * 0.5329020000 = 0.7277808070 
0.0000000000 * -0.4429660000 = 0.7277808070 
0.0000000000 * 0.0558153000 = 0.7277808070 
0.4076920016 * 0.0558344000 = 0.7505440453 
1.2353312302 * -1.6854800000 = -1.3315820366 
0.0000000000 * 0.0454977000 = -1.3315820366 
0.0000000000 * -0.0107947000 = -1.3315820366 
0.0000000000 * 0.2089930000 = -1.3315820366 
the biases is : -0.2135870000, now tempVal is : -1.5451690366
ReLU !!! in layer: 6, node : 5, its linear result is negative,so set it to 0
compute layer: 6, node : 6
0.3707124511 * -0.0666847000 = -0.0247208486 
0.0000000000 * -0.0253962000 = -0.0247208486 
0.0000000000 * 0.3086550000 = -0.0247208486 
0.0000000000 * 0.0338291000 = -0.0247208486 
0.0000000000 * 0.3317490000 = -0.0247208486 
0.0000000000 * 0.0974110000 = -0.0247208486 
0.0000000000 * -2.0758800000 = -0.0247208486 
0.0000000000 * -0.2015140000 = -0.0247208486 
0.0000000000 * 0.1308920000 = -0.0247208486 
0.0000000000 * -0.1839530000 = -0.0247208486 
1.1632586860 * 0.0074233900 = -0.0160855257 
0.0000000000 * 0.5288130000 = -0.0160855257 
0.0000000000 * 0.1295630000 = -0.0160855257 
0.0000000000 * 0.0518769000 = -0.0160855257 
0.0000000000 * -0.1364210000 = -0.0160855257 
0.0098561911 * 0.1396170000 = -0.0147094339 
0.0000000000 * -0.1518840000 = -0.0147094339 
0.0000000000 * 0.0618889000 = -0.0147094339 
0.0000000000 * -0.3987140000 = -0.0147094339 
0.0000000000 * -0.4719880000 = -0.0147094339 
0.0000000000 * -0.0115594000 = -0.0147094339 
0.0000000000 * 0.0733779000 = -0.0147094339 
0.0000000000 * 0.4512850000 = -0.0147094339 
0.0000000000 * -0.0740297000 = -0.0147094339 
0.0000000000 * 0.4743190000 = -0.0147094339 
2.0550217898 * 0.0213045000 = 0.0290717779 
0.0000000000 * 0.1668320000 = 0.0290717779 
0.0000000000 * -0.1972190000 = 0.0290717779 
0.0000000000 * -0.0465246000 = 0.0290717779 
0.0000000000 * 0.1782510000 = 0.0290717779 
0.0000000000 * -0.2272630000 = 0.0290717779 
0.0000000000 * -0.0453916000 = 0.0290717779 
0.0000000000 * -0.1225280000 = 0.0290717779 
3.5937718848 * -0.0650089000 = -0.2045553792 
0.0000000000 * -0.1466710000 = -0.2045553792 
0.0000000000 * -0.0821081000 = -0.2045553792 
0.0000000000 * 0.0136386000 = -0.2045553792 
0.0000000000 * 0.1543920000 = -0.2045553792 
0.2629356409 * 0.1586600000 = -0.1628380104 
0.3574904745 * -0.2824460000 = -0.2638097650 
0.0000000000 * -0.0732708000 = -0.2638097650 
0.0000000000 * -1.4505800000 = -0.2638097650 
0.0000000000 * -0.0336267000 = -0.2638097650 
0.0000000000 * -0.0989725000 = -0.2638097650 
0.0000000000 * -0.3495390000 = -0.2638097650 
0.4076920016 * -0.0094082100 = -0.2676454170 
1.2353312302 * -0.0985911000 = -0.3894380818 
0.0000000000 * 0.0211226000 = -0.3894380818 
0.0000000000 * 0.0598756000 = -0.3894380818 
0.0000000000 * -4.2946600000 = -0.3894380818 
the biases is : 0.1600700000, now tempVal is : -0.2293680818
ReLU !!! in layer: 6, node : 6, its linear result is negative,so set it to 0
compute layer: 6, node : 7
0.3707124511 * -5.0042700000 = -1.8551451976 
0.0000000000 * 0.1961020000 = -1.8551451976 
0.0000000000 * 0.0715269000 = -1.8551451976 
0.0000000000 * -0.0464746000 = -1.8551451976 
0.0000000000 * -0.5719420000 = -1.8551451976 
0.0000000000 * -0.6079680000 = -1.8551451976 
0.0000000000 * -3.7261300000 = -1.8551451976 
0.0000000000 * -2.3545200000 = -1.8551451976 
0.0000000000 * -0.0107038000 = -1.8551451976 
0.0000000000 * -0.0102338000 = -1.8551451976 
1.1632586860 * -0.1628540000 = -2.0445865276 
0.0000000000 * -0.1697480000 = -2.0445865276 
0.0000000000 * 0.2662440000 = -2.0445865276 
0.0000000000 * 0.3224370000 = -2.0445865276 
0.0000000000 * 0.3947690000 = -2.0445865276 
0.0098561911 * -0.0008191090 = -2.0445946009 
0.0000000000 * -0.1402040000 = -2.0445946009 
0.0000000000 * 0.1284650000 = -2.0445946009 
0.0000000000 * 0.4465140000 = -2.0445946009 
0.0000000000 * 0.2933560000 = -2.0445946009 
0.0000000000 * 0.0226001000 = -2.0445946009 
0.0000000000 * 0.0616584000 = -2.0445946009 
0.0000000000 * -0.1982420000 = -2.0445946009 
0.0000000000 * -1.2365000000 = -2.0445946009 
0.0000000000 * 0.0117411000 = -2.0445946009 
2.0550217898 * -0.4829360000 = -3.0370386040 
0.0000000000 * 0.3348180000 = -3.0370386040 
0.0000000000 * -0.1196200000 = -3.0370386040 
0.0000000000 * -0.1938180000 = -3.0370386040 
0.0000000000 * -0.1616320000 = -3.0370386040 
0.0000000000 * -0.1902070000 = -3.0370386040 
0.0000000000 * 0.0833688000 = -3.0370386040 
0.0000000000 * -0.0630484000 = -3.0370386040 
3.5937718848 * -0.2206900000 = -3.8301481212 
0.0000000000 * -0.0517292000 = -3.8301481212 
0.0000000000 * -0.0874935000 = -3.8301481212 
0.0000000000 * -0.1384400000 = -3.8301481212 
0.0000000000 * 0.0017712800 = -3.8301481212 
0.2629356409 * -0.4352940000 = -3.9446024281 
0.3574904745 * 0.2877440000 = -3.8417366890 
0.0000000000 * 0.2998130000 = -3.8417366890 
0.0000000000 * -0.4099510000 = -3.8417366890 
0.0000000000 * 0.2050940000 = -3.8417366890 
0.0000000000 * 0.3680560000 = -3.8417366890 
0.0000000000 * -0.0311629000 = -3.8417366890 
0.4076920016 * -0.2374960000 = -3.9385619086 
1.2353312302 * 0.2945260000 = -3.5747247427 
0.0000000000 * -0.0545813000 = -3.5747247427 
0.0000000000 * -0.0305311000 = -3.5747247427 
0.0000000000 * 0.1880670000 = -3.5747247427 
the biases is : 0.7418380000, now tempVal is : -2.8328867427
ReLU !!! in layer: 6, node : 7, its linear result is negative,so set it to 0
compute layer: 6, node : 8
0.3707124511 * -0.2302120000 = -0.0853424548 
0.0000000000 * 0.2576450000 = -0.0853424548 
0.0000000000 * 0.0558687000 = -0.0853424548 
0.0000000000 * -0.1292670000 = -0.0853424548 
0.0000000000 * 0.1243650000 = -0.0853424548 
0.0000000000 * -0.1530420000 = -0.0853424548 
0.0000000000 * -13.5548000000 = -0.0853424548 
0.0000000000 * -0.0180085000 = -0.0853424548 
0.0000000000 * -0.1683860000 = -0.0853424548 
0.0000000000 * -0.0382196000 = -0.0853424548 
1.1632586860 * -0.2423930000 = -0.3673082175 
0.0000000000 * -0.1019560000 = -0.3673082175 
0.0000000000 * 0.0633759000 = -0.3673082175 
0.0000000000 * 0.0192752000 = -0.3673082175 
0.0000000000 * -0.0954680000 = -0.3673082175 
0.0098561911 * 0.0464098000 = -0.3668507936 
0.0000000000 * -0.0563242000 = -0.3668507936 
0.0000000000 * 0.0288101000 = -0.3668507936 
0.0000000000 * 0.2874050000 = -0.3668507936 
0.0000000000 * -0.0197931000 = -0.3668507936 
0.0000000000 * -0.0514541000 = -0.3668507936 
0.0000000000 * 0.3524700000 = -0.3668507936 
0.0000000000 * 0.0311615000 = -0.3668507936 
0.0000000000 * 0.0527150000 = -0.3668507936 
0.0000000000 * 0.0775790000 = -0.3668507936 
2.0550217898 * -0.0846086000 = -0.5407233102 
0.0000000000 * 0.1103250000 = -0.5407233102 
0.0000000000 * 0.0709342000 = -0.5407233102 
0.0000000000 * -0.1102340000 = -0.5407233102 
0.0000000000 * -0.0028382800 = -0.5407233102 
0.0000000000 * 0.0502477000 = -0.5407233102 
0.0000000000 * 0.0251561000 = -0.5407233102 
0.0000000000 * -0.0294567000 = -0.5407233102 
3.5937718848 * -0.0740749000 = -0.8069316032 
0.0000000000 * 0.0304668000 = -0.8069316032 
0.0000000000 * 0.4865180000 = -0.8069316032 
0.0000000000 * -0.0526309000 = -0.8069316032 
0.0000000000 * 0.0023811300 = -0.8069316032 
0.2629356409 * -0.2904950000 = -0.8833130922 
0.3574904745 * 0.0717640000 = -0.8576581458 
0.0000000000 * 0.1504260000 = -0.8576581458 
0.0000000000 * 0.3679820000 = -0.8576581458 
0.0000000000 * -0.0124935000 = -0.8576581458 
0.0000000000 * 0.2634090000 = -0.8576581458 
0.0000000000 * -0.0547299000 = -0.8576581458 
0.4076920016 * -0.0813385000 = -0.8908192017 
1.2353312302 * 0.3051850000 = -0.5138146402 
0.0000000000 * 0.1083030000 = -0.5138146402 
0.0000000000 * 0.0164854000 = -0.5138146402 
0.0000000000 * 0.1698500000 = -0.5138146402 
the biases is : 0.0084694500, now tempVal is : -0.5053451902
ReLU !!! in layer: 6, node : 8, its linear result is negative,so set it to 0
compute layer: 6, node : 9
0.3707124511 * -0.2756570000 = -0.1021894821 
0.0000000000 * -0.2099830000 = -0.1021894821 
0.0000000000 * -0.1440890000 = -0.1021894821 
0.0000000000 * 0.0174152000 = -0.1021894821 
0.0000000000 * -0.2631900000 = -0.1021894821 
0.0000000000 * -0.0067640600 = -0.1021894821 
0.0000000000 * -0.1412650000 = -0.1021894821 
0.0000000000 * 0.0150905000 = -0.1021894821 
0.0000000000 * -0.0187080000 = -0.1021894821 
0.0000000000 * 0.0825820000 = -0.1021894821 
1.1632586860 * -0.0074294000 = -0.1108317962 
0.0000000000 * -0.2200160000 = -0.1108317962 
0.0000000000 * 0.0831982000 = -0.1108317962 
0.0000000000 * 0.0679210000 = -0.1108317962 
0.0000000000 * 0.0095902000 = -0.1108317962 
0.0098561911 * -0.0334255000 = -0.1111612443 
0.0000000000 * -0.0397525000 = -0.1111612443 
0.0000000000 * 0.1070580000 = -0.1111612443 
0.0000000000 * -0.2394160000 = -0.1111612443 
0.0000000000 * -0.0410243000 = -0.1111612443 
0.0000000000 * 0.0176434000 = -0.1111612443 
0.0000000000 * -0.1154260000 = -0.1111612443 
0.0000000000 * 0.0566601000 = -0.1111612443 
0.0000000000 * 0.0078633100 = -0.1111612443 
0.0000000000 * -0.1954410000 = -0.1111612443 
2.0550217898 * -0.5264340000 = -1.1929945852 
0.0000000000 * 0.1207040000 = -1.1929945852 
0.0000000000 * -0.0674790000 = -1.1929945852 
0.0000000000 * -0.0094392400 = -1.1929945852 
0.0000000000 * 0.0225083000 = -1.1929945852 
0.0000000000 * -0.0545620000 = -1.1929945852 
0.0000000000 * 0.6349200000 = -1.1929945852 
0.0000000000 * 0.0255949000 = -1.1929945852 
3.5937718848 * -0.1674220000 = -1.7946710617 
0.0000000000 * 0.0519159000 = -1.7946710617 
0.0000000000 * 0.4356450000 = -1.7946710617 
0.0000000000 * -0.0195408000 = -1.7946710617 
0.0000000000 * 0.0406585000 = -1.7946710617 
0.2629356409 * -0.0303667000 = -1.8026555494 
0.3574904745 * 0.0325866000 = -1.7910061503 
0.0000000000 * 0.0999786000 = -1.7910061503 
0.0000000000 * -0.1169190000 = -1.7910061503 
0.0000000000 * -0.0171080000 = -1.7910061503 
0.0000000000 * 0.2168920000 = -1.7910061503 
0.0000000000 * -0.2323250000 = -1.7910061503 
0.4076920016 * 0.0860438000 = -1.7559267813 
1.2353312302 * -0.0495868000 = -1.8171829039 
0.0000000000 * -0.0982608000 = -1.8171829039 
0.0000000000 * 0.0234298000 = -1.8171829039 
0.0000000000 * 0.0037956700 = -1.8171829039 
the biases is : -0.7260340000, now tempVal is : -2.5432169039
ReLU !!! in layer: 6, node : 9, its linear result is negative,so set it to 0
compute layer: 6, node : 10
0.3707124511 * -0.2727140000 = -0.1010984754 
0.0000000000 * 0.8292440000 = -0.1010984754 
0.0000000000 * -3.9010700000 = -0.1010984754 
0.0000000000 * -2.1040200000 = -0.1010984754 
0.0000000000 * -5.1068700000 = -0.1010984754 
0.0000000000 * -8.7521700000 = -0.1010984754 
0.0000000000 * 0.0465555000 = -0.1010984754 
0.0000000000 * -0.5346200000 = -0.1010984754 
0.0000000000 * 0.4874140000 = -0.1010984754 
0.0000000000 * 0.2100140000 = -0.1010984754 
1.1632586860 * 0.7836100000 = 0.8104426635 
0.0000000000 * 0.1398950000 = 0.8104426635 
0.0000000000 * -3.0295700000 = 0.8104426635 
0.0000000000 * 1.8371800000 = 0.8104426635 
0.0000000000 * -1.0220600000 = 0.8104426635 
0.0098561911 * 2.9248400000 = 0.8392704454 
0.0000000000 * -0.8195690000 = 0.8392704454 
0.0000000000 * -2.3843800000 = 0.8392704454 
0.0000000000 * 0.3449520000 = 0.8392704454 
0.0000000000 * -0.0429874000 = 0.8392704454 
0.0000000000 * 0.6033450000 = 0.8392704454 
0.0000000000 * 1.8305600000 = 0.8392704454 
0.0000000000 * 5.0266600000 = 0.8392704454 
0.0000000000 * -0.0810870000 = 0.8392704454 
0.0000000000 * 2.8869300000 = 0.8392704454 
2.0550217898 * -6.5841500000 = -12.6913012716 
0.0000000000 * -5.5550000000 = -12.6913012716 
0.0000000000 * 1.2021600000 = -12.6913012716 
0.0000000000 * 0.5845840000 = -12.6913012716 
0.0000000000 * 1.6419800000 = -12.6913012716 
0.0000000000 * 0.8235650000 = -12.6913012716 
0.0000000000 * -20.0916000000 = -12.6913012716 
0.0000000000 * -3.3660900000 = -12.6913012716 
3.5937718848 * -0.1188410000 = -13.1183887162 
0.0000000000 * 3.1614600000 = -13.1183887162 
0.0000000000 * 0.4520140000 = -13.1183887162 
0.0000000000 * -1.2060800000 = -13.1183887162 
0.0000000000 * -9.2136900000 = -13.1183887162 
0.2629356409 * 2.9346900000 = -12.3467541202 
0.3574904745 * -0.1406880000 = -12.3970487401 
0.0000000000 * -2.5559700000 = -12.3970487401 
0.0000000000 * 2.5916500000 = -12.3970487401 
0.0000000000 * -1.8899400000 = -12.3970487401 
0.0000000000 * 0.8870570000 = -12.3970487401 
0.0000000000 * -0.1729630000 = -12.3970487401 
0.4076920016 * -0.8281260000 = -12.7346690866 
1.2353312302 * 0.1026910000 = -12.6078116872 
0.0000000000 * -3.0308900000 = -12.6078116872 
0.0000000000 * 0.3657610000 = -12.6078116872 
0.0000000000 * -0.0930378000 = -12.6078116872 
the biases is : -4.7420600000, now tempVal is : -17.3498716872
ReLU !!! in layer: 6, node : 10, its linear result is negative,so set it to 0
compute layer: 6, node : 11
0.3707124511 * -0.0679461000 = -0.0251884653 
0.0000000000 * -0.1959160000 = -0.0251884653 
0.0000000000 * 0.1695200000 = -0.0251884653 
0.0000000000 * -0.2463940000 = -0.0251884653 
0.0000000000 * 1.0181000000 = -0.0251884653 
0.0000000000 * 0.1230900000 = -0.0251884653 
0.0000000000 * -0.3607550000 = -0.0251884653 
0.0000000000 * -0.0468298000 = -0.0251884653 
0.0000000000 * 0.0033610100 = -0.0251884653 
0.0000000000 * 0.0197748000 = -0.0251884653 
1.1632586860 * -0.3201820000 = -0.3976429579 
0.0000000000 * -0.2161560000 = -0.3976429579 
0.0000000000 * -0.1000560000 = -0.3976429579 
0.0000000000 * -0.0789411000 = -0.3976429579 
0.0000000000 * -1.5369900000 = -0.3976429579 
0.0098561911 * 0.0175842000 = -0.3974696446 
0.0000000000 * 0.0287724000 = -0.3974696446 
0.0000000000 * -0.3098560000 = -0.3974696446 
0.0000000000 * 0.2433100000 = -0.3974696446 
0.0000000000 * 0.0813444000 = -0.3974696446 
0.0000000000 * -0.5057210000 = -0.3974696446 
0.0000000000 * 0.3207950000 = -0.3974696446 
0.0000000000 * 0.1719300000 = -0.3974696446 
0.0000000000 * 0.1680700000 = -0.3974696446 
0.0000000000 * 0.2039990000 = -0.3974696446 
2.0550217898 * -0.0042096600 = -0.4061205877 
0.0000000000 * -0.0782321000 = -0.4061205877 
0.0000000000 * 0.0302612000 = -0.4061205877 
0.0000000000 * -0.4186310000 = -0.4061205877 
0.0000000000 * -0.0220547000 = -0.4061205877 
0.0000000000 * 0.0871929000 = -0.4061205877 
0.0000000000 * -0.4928280000 = -0.4061205877 
0.0000000000 * 0.0349153000 = -0.4061205877 
3.5937718848 * -0.3385630000 = -1.6228387783 
0.0000000000 * -0.0015586100 = -1.6228387783 
0.0000000000 * 0.8627770000 = -1.6228387783 
0.0000000000 * -0.2927310000 = -1.6228387783 
0.0000000000 * -0.0421078000 = -1.6228387783 
0.2629356409 * -0.1488150000 = -1.6619675457 
0.3574904745 * 0.0759600000 = -1.6348125693 
0.0000000000 * 0.1279540000 = -1.6348125693 
0.0000000000 * -0.3005730000 = -1.6348125693 
0.0000000000 * -0.0857670000 = -1.6348125693 
0.0000000000 * 0.3227200000 = -1.6348125693 
0.0000000000 * 0.0917590000 = -1.6348125693 
0.4076920016 * 0.0657804000 = -1.6079944263 
1.2353312302 * 0.3917250000 = -1.1240843002 
0.0000000000 * -0.1206980000 = -1.1240843002 
0.0000000000 * -0.1993950000 = -1.1240843002 
0.0000000000 * -0.0524600000 = -1.1240843002 
the biases is : 0.0694902000, now tempVal is : -1.0545941002
ReLU !!! in layer: 6, node : 11, its linear result is negative,so set it to 0
compute layer: 6, node : 12
0.3707124511 * -0.2185280000 = -0.0810110505 
0.0000000000 * 0.0963922000 = -0.0810110505 
0.0000000000 * 0.2697490000 = -0.0810110505 
0.0000000000 * -0.0416330000 = -0.0810110505 
0.0000000000 * 0.8092560000 = -0.0810110505 
0.0000000000 * 0.2697370000 = -0.0810110505 
0.0000000000 * -0.3136190000 = -0.0810110505 
0.0000000000 * -0.1962640000 = -0.0810110505 
0.0000000000 * -0.1459530000 = -0.0810110505 
0.0000000000 * -0.0746597000 = -0.0810110505 
1.1632586860 * -0.1370480000 = -0.2404333269 
0.0000000000 * -0.2288370000 = -0.2404333269 
0.0000000000 * 0.1559800000 = -0.2404333269 
0.0000000000 * -0.2507020000 = -0.2404333269 
0.0000000000 * 0.4209150000 = -0.2404333269 
0.0098561911 * 0.2875910000 = -0.2375987751 
0.0000000000 * 0.1611990000 = -0.2375987751 
0.0000000000 * 0.0197730000 = -0.2375987751 
0.0000000000 * -0.1318940000 = -0.2375987751 
0.0000000000 * 0.4235080000 = -0.2375987751 
0.0000000000 * -0.1857740000 = -0.2375987751 
0.0000000000 * 0.2858340000 = -0.2375987751 
0.0000000000 * 0.1633670000 = -0.2375987751 
0.0000000000 * 0.1284400000 = -0.2375987751 
0.0000000000 * -0.0518864000 = -0.2375987751 
2.0550217898 * -0.1051360000 = -0.4536555459 
0.0000000000 * 0.0131903000 = -0.4536555459 
0.0000000000 * -0.1379100000 = -0.4536555459 
0.0000000000 * -0.0311046000 = -0.4536555459 
0.0000000000 * 0.1247790000 = -0.4536555459 
0.0000000000 * 0.1295090000 = -0.4536555459 
0.0000000000 * 0.1410440000 = -0.4536555459 
0.0000000000 * -0.0205755000 = -0.4536555459 
3.5937718848 * -0.1602810000 = -1.0296688974 
0.0000000000 * 0.0570478000 = -1.0296688974 
0.0000000000 * -0.2688190000 = -1.0296688974 
0.0000000000 * -0.2242090000 = -1.0296688974 
0.0000000000 * 0.0740425000 = -1.0296688974 
0.2629356409 * -0.1267240000 = -1.0629891536 
0.3574904745 * 0.0294541000 = -1.0524595934 
0.0000000000 * 0.0347832000 = -1.0524595934 
0.0000000000 * 0.0618416000 = -1.0524595934 
0.0000000000 * -0.0063213900 = -1.0524595934 
0.0000000000 * 0.2964430000 = -1.0524595934 
0.0000000000 * -0.0600648000 = -1.0524595934 
0.4076920016 * 0.0162630000 = -1.0458292984 
1.2353312302 * 0.3807120000 = -0.5755238751 
0.0000000000 * -0.0640574000 = -0.5755238751 
0.0000000000 * -0.0622073000 = -0.5755238751 
0.0000000000 * 0.0971152000 = -0.5755238751 
the biases is : -0.3327400000, now tempVal is : -0.9082638751
ReLU !!! in layer: 6, node : 12, its linear result is negative,so set it to 0
compute layer: 6, node : 13
0.3707124511 * 0.0436474000 = 0.0161806346 
0.0000000000 * -0.0298087000 = 0.0161806346 
0.0000000000 * -0.1498800000 = 0.0161806346 
0.0000000000 * -0.1131160000 = 0.0161806346 
0.0000000000 * 0.0848855000 = 0.0161806346 
0.0000000000 * 0.0826430000 = 0.0161806346 
0.0000000000 * -1.9341700000 = 0.0161806346 
0.0000000000 * -0.0301826000 = 0.0161806346 
0.0000000000 * 0.1107090000 = 0.0161806346 
0.0000000000 * 0.1677870000 = 0.0161806346 
1.1632586860 * -0.3071570000 = -0.3411224136 
0.0000000000 * -0.3955700000 = -0.3411224136 
0.0000000000 * 0.0301285000 = -0.3411224136 
0.0000000000 * 0.1035700000 = -0.3411224136 
0.0000000000 * -11.0484000000 = -0.3411224136 
0.0098561911 * -0.0342867000 = -0.3414603498 
0.0000000000 * -0.1141200000 = -0.3414603498 
0.0000000000 * -0.2133410000 = -0.3414603498 
0.0000000000 * 0.9775880000 = -0.3414603498 
0.0000000000 * -0.0518196000 = -0.3414603498 
0.0000000000 * -0.2359710000 = -0.3414603498 
0.0000000000 * -0.0459661000 = -0.3414603498 
0.0000000000 * 0.5060940000 = -0.3414603498 
0.0000000000 * -0.0184792000 = -0.3414603498 
0.0000000000 * -0.3376220000 = -0.3414603498 
2.0550217898 * -0.3241970000 = -1.0076922490 
0.0000000000 * 0.1754830000 = -1.0076922490 
0.0000000000 * 0.0743243000 = -1.0076922490 
0.0000000000 * -0.0523952000 = -1.0076922490 
0.0000000000 * -3.1456700000 = -1.0076922490 
0.0000000000 * -0.1285940000 = -1.0076922490 
0.0000000000 * -0.1207050000 = -1.0076922490 
0.0000000000 * -0.0305571000 = -1.0076922490 
3.5937718848 * 0.1163150000 = -0.5896826722 
0.0000000000 * -0.0628323000 = -0.5896826722 
0.0000000000 * 0.6585260000 = -0.5896826722 
0.0000000000 * -0.0923211000 = -0.5896826722 
0.0000000000 * -0.0382784000 = -0.5896826722 
0.2629356409 * 0.0118329000 = -0.5865713811 
0.3574904745 * 0.0348346000 = -0.5741183434 
0.0000000000 * -0.3575060000 = -0.5741183434 
0.0000000000 * -1.0329500000 = -0.5741183434 
0.0000000000 * -0.0290241000 = -0.5741183434 
0.0000000000 * 0.0732027000 = -0.5741183434 
0.0000000000 * -0.2128040000 = -0.5741183434 
0.4076920016 * -0.0142649000 = -0.5799340290 
1.2353312302 * -0.1021220000 = -0.7060885249 
0.0000000000 * 0.0304184000 = -0.7060885249 
0.0000000000 * -0.7155360000 = -0.7060885249 
0.0000000000 * 0.4364840000 = -0.7060885249 
the biases is : 0.4584290000, now tempVal is : -0.2476595249
ReLU !!! in layer: 6, node : 13, its linear result is negative,so set it to 0
compute layer: 6, node : 14
0.3707124511 * -1.6824300000 = -0.6236977491 
0.0000000000 * -0.1707200000 = -0.6236977491 
0.0000000000 * -0.3192480000 = -0.6236977491 
0.0000000000 * 0.1189790000 = -0.6236977491 
0.0000000000 * 1.9684900000 = -0.6236977491 
0.0000000000 * 0.4097320000 = -0.6236977491 
0.0000000000 * -3.3617400000 = -0.6236977491 
0.0000000000 * 0.0643817000 = -0.6236977491 
0.0000000000 * -6.6628600000 = -0.6236977491 
0.0000000000 * -0.5146410000 = -0.6236977491 
1.1632586860 * 0.2968310000 = -0.2784065101 
0.0000000000 * 0.2207710000 = -0.2784065101 
0.0000000000 * -1.8541100000 = -0.2784065101 
0.0000000000 * 0.2037290000 = -0.2784065101 
0.0000000000 * 1.3380600000 = -0.2784065101 
0.0098561911 * 0.5220160000 = -0.2732614206 
0.0000000000 * -0.0202730000 = -0.2732614206 
0.0000000000 * 0.2744360000 = -0.2732614206 
0.0000000000 * 0.9327020000 = -0.2732614206 
0.0000000000 * 0.5975520000 = -0.2732614206 
0.0000000000 * -0.6216500000 = -0.2732614206 
0.0000000000 * -0.0199416000 = -0.2732614206 
0.0000000000 * -0.1419410000 = -0.2732614206 
0.0000000000 * 0.5791890000 = -0.2732614206 
0.0000000000 * 0.8672440000 = -0.2732614206 
2.0550217898 * 0.7165470000 = 1.1992582778 
0.0000000000 * 0.2584700000 = 1.1992582778 
0.0000000000 * -0.0993358000 = 1.1992582778 
0.0000000000 * -0.4987660000 = 1.1992582778 
0.0000000000 * -0.2657330000 = 1.1992582778 
0.0000000000 * -0.9076100000 = 1.1992582778 
0.0000000000 * -0.7761780000 = 1.1992582778 
0.0000000000 * -0.3230010000 = 1.1992582778 
3.5937718848 * -1.3027800000 = -3.4826358583 
0.0000000000 * 1.0836600000 = -3.4826358583 
0.0000000000 * -2.4701000000 = -3.4826358583 
0.0000000000 * -0.2778730000 = -3.4826358583 
0.0000000000 * -6.4800300000 = -3.4826358583 
0.2629356409 * -1.6625300000 = -3.9197742494 
0.3574904745 * 0.1298990000 = -3.8733365943 
0.0000000000 * 0.3957110000 = -3.8733365943 
0.0000000000 * 0.5432350000 = -3.8733365943 
0.0000000000 * 0.4657800000 = -3.8733365943 
0.0000000000 * 2.2262200000 = -3.8733365943 
0.0000000000 * -0.0482305000 = -3.8733365943 
0.4076920016 * -0.0865136000 = -3.9086074970 
1.2353312302 * 0.4855490000 = -3.3087936535 
0.0000000000 * 1.0800200000 = -3.3087936535 
0.0000000000 * 0.0085948500 = -3.3087936535 
0.0000000000 * 0.3508520000 = -3.3087936535 
the biases is : -1.0340100000, now tempVal is : -4.3428036535
ReLU !!! in layer: 6, node : 14, its linear result is negative,so set it to 0
compute layer: 6, node : 15
0.3707124511 * -0.1392100000 = -0.0516068803 
0.0000000000 * 0.1792770000 = -0.0516068803 
0.0000000000 * -0.2943660000 = -0.0516068803 
0.0000000000 * -0.0080260100 = -0.0516068803 
0.0000000000 * -4.3218800000 = -0.0516068803 
0.0000000000 * 0.0587101000 = -0.0516068803 
0.0000000000 * -0.4868550000 = -0.0516068803 
0.0000000000 * -0.0210261000 = -0.0516068803 
0.0000000000 * -0.1478600000 = -0.0516068803 
0.0000000000 * 0.2646530000 = -0.0516068803 
1.1632586860 * -0.3426420000 = -0.4501881630 
0.0000000000 * 0.0053666500 = -0.4501881630 
0.0000000000 * -0.1719820000 = -0.4501881630 
0.0000000000 * -0.0487724000 = -0.4501881630 
0.0000000000 * -0.0862592000 = -0.4501881630 
0.0098561911 * 0.0267170000 = -0.4499248351 
0.0000000000 * -0.0798149000 = -0.4499248351 
0.0000000000 * 0.0878861000 = -0.4499248351 
0.0000000000 * -0.0984905000 = -0.4499248351 
0.0000000000 * 0.0659401000 = -0.4499248351 
0.0000000000 * -0.0029888200 = -0.4499248351 
0.0000000000 * -0.0521552000 = -0.4499248351 
0.0000000000 * -0.3186300000 = -0.4499248351 
0.0000000000 * 0.0418259000 = -0.4499248351 
0.0000000000 * 0.6027720000 = -0.4499248351 
2.0550217898 * -0.0336505000 = -0.5190773459 
0.0000000000 * -0.1941110000 = -0.5190773459 
0.0000000000 * 0.0918568000 = -0.5190773459 
0.0000000000 * -0.0199109000 = -0.5190773459 
0.0000000000 * -0.0475386000 = -0.5190773459 
0.0000000000 * 0.1141370000 = -0.5190773459 
0.0000000000 * 0.2745120000 = -0.5190773459 
0.0000000000 * -0.0020315000 = -0.5190773459 
3.5937718848 * 0.1364510000 = -0.0287035784 
0.0000000000 * -0.0403213000 = -0.0287035784 
0.0000000000 * -0.9443920000 = -0.0287035784 
0.0000000000 * -0.0408341000 = -0.0287035784 
0.0000000000 * -0.1822660000 = -0.0287035784 
0.2629356409 * -0.4266300000 = -0.1408798109 
0.3574904745 * 0.0831194000 = -0.1111654171 
0.0000000000 * 0.1629780000 = -0.1111654171 
0.0000000000 * -0.0348014000 = -0.1111654171 
0.0000000000 * 0.0523761000 = -0.1111654171 
0.0000000000 * 0.2949970000 = -0.1111654171 
0.0000000000 * -2.9986700000 = -0.1111654171 
0.4076920016 * 0.0331841000 = -0.0976365250 
1.2353312302 * 0.0294317000 = -0.0612786268 
0.0000000000 * -0.0724005000 = -0.0612786268 
0.0000000000 * -0.1438450000 = -0.0612786268 
0.0000000000 * -4.9843500000 = -0.0612786268 
the biases is : -0.4365940000, now tempVal is : -0.4978726268
ReLU !!! in layer: 6, node : 15, its linear result is negative,so set it to 0
compute layer: 6, node : 16
0.3707124511 * -0.0033270300 = -0.0012333714 
0.0000000000 * 0.3345810000 = -0.0012333714 
0.0000000000 * -0.0439898000 = -0.0012333714 
0.0000000000 * 0.0167441000 = -0.0012333714 
0.0000000000 * 0.1178190000 = -0.0012333714 
0.0000000000 * 0.0702821000 = -0.0012333714 
0.0000000000 * 0.6294810000 = -0.0012333714 
0.0000000000 * -0.0337133000 = -0.0012333714 
0.0000000000 * 0.0348010000 = -0.0012333714 
0.0000000000 * 0.0796670000 = -0.0012333714 
1.1632586860 * -0.0319666000 = -0.0384187966 
0.0000000000 * 0.2785020000 = -0.0384187966 
0.0000000000 * -0.0232784000 = -0.0384187966 
0.0000000000 * -0.0448060000 = -0.0384187966 
0.0000000000 * -0.0591184000 = -0.0384187966 
0.0098561911 * -0.0423848000 = -0.0388365492 
0.0000000000 * -0.0409006000 = -0.0388365492 
0.0000000000 * 0.0678595000 = -0.0388365492 
0.0000000000 * 0.0766320000 = -0.0388365492 
0.0000000000 * 0.3140020000 = -0.0388365492 
0.0000000000 * 0.0112597000 = -0.0388365492 
0.0000000000 * 0.1052880000 = -0.0388365492 
0.0000000000 * -0.0169719000 = -0.0388365492 
0.0000000000 * -0.0264637000 = -0.0388365492 
0.0000000000 * -0.0816537000 = -0.0388365492 
2.0550217898 * 0.0382217000 = 0.0397098771 
0.0000000000 * 0.0135921000 = 0.0397098771 
0.0000000000 * -0.1510930000 = 0.0397098771 
0.0000000000 * 0.0370202000 = 0.0397098771 
0.0000000000 * 0.0297890000 = 0.0397098771 
0.0000000000 * -0.1235780000 = 0.0397098771 
0.0000000000 * -0.2514700000 = 0.0397098771 
0.0000000000 * -0.0420174000 = 0.0397098771 
3.5937718848 * -0.2704110000 = -0.9320855721 
0.0000000000 * 0.0712157000 = -0.9320855721 
0.0000000000 * 0.2131860000 = -0.9320855721 
0.0000000000 * 0.0014644000 = -0.9320855721 
0.0000000000 * -0.1317620000 = -0.9320855721 
0.2629356409 * -0.1016060000 = -0.9588014108 
0.3574904745 * -0.0089319200 = -0.9619944871 
0.0000000000 * 0.0039334100 = -0.9619944871 
0.0000000000 * 0.0756914000 = -0.9619944871 
0.0000000000 * -0.1964680000 = -0.9619944871 
0.0000000000 * -0.0144556000 = -0.9619944871 
0.0000000000 * 0.0146362000 = -0.9619944871 
0.4076920016 * 0.0565129000 = -0.9389546298 
1.2353312302 * 0.1410590000 = -0.7647000418 
0.0000000000 * -0.0310966000 = -0.7647000418 
0.0000000000 * -0.0007260530 = -0.7647000418 
0.0000000000 * -0.0896467000 = -0.7647000418 
the biases is : 0.0870681000, now tempVal is : -0.6776319418
ReLU !!! in layer: 6, node : 16, its linear result is negative,so set it to 0
compute layer: 6, node : 17
0.3707124511 * -0.0433162000 = -0.0160578547 
0.0000000000 * 1.5895500000 = -0.0160578547 
0.0000000000 * -0.6671050000 = -0.0160578547 
0.0000000000 * -0.0917730000 = -0.0160578547 
0.0000000000 * 1.1325200000 = -0.0160578547 
0.0000000000 * -0.7703500000 = -0.0160578547 
0.0000000000 * 0.0208934000 = -0.0160578547 
0.0000000000 * 0.7098560000 = -0.0160578547 
0.0000000000 * -0.1172330000 = -0.0160578547 
0.0000000000 * 0.2612340000 = -0.0160578547 
1.1632586860 * -0.0208980000 = -0.0403676347 
0.0000000000 * -0.9780000000 = -0.0403676347 
0.0000000000 * -0.1397660000 = -0.0403676347 
0.0000000000 * 0.4623140000 = -0.0403676347 
0.0000000000 * -0.2753480000 = -0.0403676347 
0.0098561911 * -0.2021630000 = -0.0423601918 
0.0000000000 * -0.0858469000 = -0.0423601918 
0.0000000000 * -2.3998600000 = -0.0423601918 
0.0000000000 * -0.0461281000 = -0.0423601918 
0.0000000000 * 0.3854060000 = -0.0423601918 
0.0000000000 * -0.0000773820 = -0.0423601918 
0.0000000000 * -0.0665704000 = -0.0423601918 
0.0000000000 * 0.5234500000 = -0.0423601918 
0.0000000000 * -0.1625080000 = -0.0423601918 
0.0000000000 * 0.5382100000 = -0.0423601918 
2.0550217898 * 0.9594340000 = 1.9292975840 
0.0000000000 * -0.6372080000 = 1.9292975840 
0.0000000000 * 0.3091240000 = 1.9292975840 
0.0000000000 * 0.1045050000 = 1.9292975840 
0.0000000000 * 0.0425570000 = 1.9292975840 
0.0000000000 * 0.6097220000 = 1.9292975840 
0.0000000000 * -0.9649980000 = 1.9292975840 
0.0000000000 * -0.4445700000 = 1.9292975840 
3.5937718848 * -0.6597630000 = -0.4417401361 
0.0000000000 * 0.6218520000 = -0.4417401361 
0.0000000000 * 0.4058470000 = -0.4417401361 
0.0000000000 * -0.3482350000 = -0.4417401361 
0.0000000000 * 0.0132588000 = -0.4417401361 
0.2629356409 * -0.4400280000 = -0.5574391803 
0.3574904745 * -1.2440300000 = -1.0021680552 
0.0000000000 * -0.0842776000 = -1.0021680552 
0.0000000000 * 0.8497200000 = -1.0021680552 
0.0000000000 * -0.0538346000 = -1.0021680552 
0.0000000000 * 1.2041400000 = -1.0021680552 
0.0000000000 * 0.1310870000 = -1.0021680552 
0.4076920016 * 0.1330480000 = -0.9479254498 
1.2353312302 * -3.2275600000 = -4.9350311151 
0.0000000000 * -0.3287960000 = -4.9350311151 
0.0000000000 * 0.0078238900 = -4.9350311151 
0.0000000000 * -0.2014080000 = -4.9350311151 
the biases is : -1.1747900000, now tempVal is : -6.1098211151
ReLU !!! in layer: 6, node : 17, its linear result is negative,so set it to 0
compute layer: 6, node : 18
0.3707124511 * -1.5523000000 = -0.5754569378 
0.0000000000 * -0.6028730000 = -0.5754569378 
0.0000000000 * 0.5971250000 = -0.5754569378 
0.0000000000 * -1.0044100000 = -0.5754569378 
0.0000000000 * -0.2575990000 = -0.5754569378 
0.0000000000 * -0.9165500000 = -0.5754569378 
0.0000000000 * -2.1397300000 = -0.5754569378 
0.0000000000 * 0.1021610000 = -0.5754569378 
0.0000000000 * 0.2704940000 = -0.5754569378 
0.0000000000 * 0.3476870000 = -0.5754569378 
1.1632586860 * -0.1211250000 = -0.7163566461 
0.0000000000 * -3.9487800000 = -0.7163566461 
0.0000000000 * -8.8987200000 = -0.7163566461 
0.0000000000 * 0.3891650000 = -0.7163566461 
0.0000000000 * 0.3820290000 = -0.7163566461 
0.0098561911 * -0.2517770000 = -0.7188382084 
0.0000000000 * -0.1000120000 = -0.7188382084 
0.0000000000 * 0.1091480000 = -0.7188382084 
0.0000000000 * 0.3328370000 = -0.7188382084 
0.0000000000 * 0.7073800000 = -0.7188382084 
0.0000000000 * -0.3238960000 = -0.7188382084 
0.0000000000 * 0.4775870000 = -0.7188382084 
0.0000000000 * -8.8054900000 = -0.7188382084 
0.0000000000 * -1.5464200000 = -0.7188382084 
0.0000000000 * 0.5955790000 = -0.7188382084 
2.0550217898 * 0.4186100000 = 0.1414144630 
0.0000000000 * 1.0441800000 = 0.1414144630 
0.0000000000 * -1.0709500000 = 0.1414144630 
0.0000000000 * -6.5984300000 = 0.1414144630 
0.0000000000 * -0.3098440000 = 0.1414144630 
0.0000000000 * 0.0171748000 = 0.1414144630 
0.0000000000 * 1.3585800000 = 0.1414144630 
0.0000000000 * -0.7960020000 = 0.1414144630 
3.5937718848 * -1.7765100000 = -6.2429572281 
0.0000000000 * -5.6900200000 = -6.2429572281 
0.0000000000 * 0.8598660000 = -6.2429572281 
0.0000000000 * -1.8158300000 = -6.2429572281 
0.0000000000 * 0.0206551000 = -6.2429572281 
0.2629356409 * -0.6063300000 = -6.4023829952 
0.3574904745 * -1.4828000000 = -6.9324698708 
0.0000000000 * -0.1376650000 = -6.9324698708 
0.0000000000 * -1.1543800000 = -6.9324698708 
0.0000000000 * 1.6355500000 = -6.9324698708 
0.0000000000 * 0.4441530000 = -6.9324698708 
0.0000000000 * -0.3094710000 = -6.9324698708 
0.4076920016 * -0.3019870000 = -7.0555875553 
1.2353312302 * 2.0104800000 = -4.5719788236 
0.0000000000 * -0.7612880000 = -4.5719788236 
0.0000000000 * -0.1020320000 = -4.5719788236 
0.0000000000 * 0.2008670000 = -4.5719788236 
the biases is : 0.2950380000, now tempVal is : -4.2769408236
ReLU !!! in layer: 6, node : 18, its linear result is negative,so set it to 0
compute layer: 6, node : 19
0.3707124511 * 0.0008926770 = 0.0003309265 
0.0000000000 * -0.0987551000 = 0.0003309265 
0.0000000000 * -0.0635048000 = 0.0003309265 
0.0000000000 * 0.0089930200 = 0.0003309265 
0.0000000000 * -0.1725080000 = 0.0003309265 
0.0000000000 * -0.0260620000 = 0.0003309265 
0.0000000000 * -0.1906730000 = 0.0003309265 
0.0000000000 * -0.0182574000 = 0.0003309265 
0.0000000000 * -0.0198497000 = 0.0003309265 
0.0000000000 * -0.0173256000 = 0.0003309265 
1.1632586860 * -0.0405101000 = -0.0467927992 
0.0000000000 * -0.5452560000 = -0.0467927992 
0.0000000000 * -0.1002930000 = -0.0467927992 
0.0000000000 * 0.0032863700 = -0.0467927992 
0.0000000000 * 0.0400577000 = -0.0467927992 
0.0098561911 * -0.1396150000 = -0.0481688713 
0.0000000000 * 0.0141782000 = -0.0481688713 
0.0000000000 * -0.1091450000 = -0.0481688713 
0.0000000000 * 0.1116890000 = -0.0481688713 
0.0000000000 * 0.1358060000 = -0.0481688713 
0.0000000000 * -0.0296077000 = -0.0481688713 
0.0000000000 * 0.0230913000 = -0.0481688713 
0.0000000000 * 0.0610583000 = -0.0481688713 
0.0000000000 * -0.1035070000 = -0.0481688713 
0.0000000000 * 0.1033830000 = -0.0481688713 
2.0550217898 * -0.7383220000 = -1.5654366692 
0.0000000000 * 0.0228774000 = -1.5654366692 
0.0000000000 * -0.0614437000 = -1.5654366692 
0.0000000000 * -0.0048442700 = -1.5654366692 
0.0000000000 * -0.0142132000 = -1.5654366692 
0.0000000000 * 0.0676433000 = -1.5654366692 
0.0000000000 * -0.0783575000 = -1.5654366692 
0.0000000000 * 0.0214801000 = -1.5654366692 
3.5937718848 * 0.1094810000 = -1.1719869295 
0.0000000000 * 0.0395514000 = -1.1719869295 
0.0000000000 * -0.5806510000 = -1.1719869295 
0.0000000000 * -0.0621782000 = -1.1719869295 
0.0000000000 * -0.0225799000 = -1.1719869295 
0.2629356409 * -0.0587909000 = -1.1874451524 
0.3574904745 * 0.0285735000 = -1.1772303984 
0.0000000000 * 0.0437886000 = -1.1772303984 
0.0000000000 * 0.0375812000 = -1.1772303984 
0.0000000000 * -0.0603999000 = -1.1772303984 
0.0000000000 * -0.0651216000 = -1.1772303984 
0.0000000000 * -0.0959490000 = -1.1772303984 
0.4076920016 * 0.0765383000 = -1.1460263456 
1.2353312302 * 0.0937720000 = -1.0301868655 
0.0000000000 * 0.0078394800 = -1.0301868655 
0.0000000000 * -0.0026892900 = -1.0301868655 
0.0000000000 * -0.0251691000 = -1.0301868655 
the biases is : 0.6481800000, now tempVal is : -0.3820068655
ReLU !!! in layer: 6, node : 19, its linear result is negative,so set it to 0
compute layer: 6, node : 20
0.3707124511 * -0.0632891000 = -0.0234620574 
0.0000000000 * -0.1106020000 = -0.0234620574 
0.0000000000 * -0.0480748000 = -0.0234620574 
0.0000000000 * -0.0178147000 = -0.0234620574 
0.0000000000 * -0.0833551000 = -0.0234620574 
0.0000000000 * -0.0574300000 = -0.0234620574 
0.0000000000 * -0.7505290000 = -0.0234620574 
0.0000000000 * -0.0438618000 = -0.0234620574 
0.0000000000 * -0.0504125000 = -0.0234620574 
0.0000000000 * -0.1067620000 = -0.0234620574 
1.1632586860 * 0.1190240000 = 0.1149936445 
0.0000000000 * 0.4556240000 = 0.1149936445 
0.0000000000 * -0.0106961000 = 0.1149936445 
0.0000000000 * 0.0057734700 = 0.1149936445 
0.0000000000 * -0.0032072900 = 0.1149936445 
0.0098561911 * -0.0614625000 = 0.1143878583 
0.0000000000 * 0.0402448000 = 0.1143878583 
0.0000000000 * 0.0327475000 = 0.1143878583 
0.0000000000 * -0.1026140000 = 0.1143878583 
0.0000000000 * -0.1321290000 = 0.1143878583 
0.0000000000 * -0.0099082700 = 0.1143878583 
0.0000000000 * -0.0090696700 = 0.1143878583 
0.0000000000 * -0.1189440000 = 0.1143878583 
0.0000000000 * 0.0688663000 = 0.1143878583 
0.0000000000 * 0.1249130000 = 0.1143878583 
2.0550217898 * -0.1393300000 = -0.1719383277 
0.0000000000 * 0.0696416000 = -0.1719383277 
0.0000000000 * 0.0649565000 = -0.1719383277 
0.0000000000 * -0.0077010700 = -0.1719383277 
0.0000000000 * -0.0236689000 = -0.1719383277 
0.0000000000 * 0.2821240000 = -0.1719383277 
0.0000000000 * -0.0001906600 = -0.1719383277 
0.0000000000 * 0.0640069000 = -0.1719383277 
3.5937718848 * -0.0603495000 = -0.3888206640 
0.0000000000 * 0.0130785000 = -0.3888206640 
0.0000000000 * -0.3718180000 = -0.3888206640 
0.0000000000 * 0.0375105000 = -0.3888206640 
0.0000000000 * -0.0412379000 = -0.3888206640 
0.2629356409 * 0.0231959000 = -0.3827216352 
0.3574904745 * -0.0512220000 = -0.4010330123 
0.0000000000 * -0.0418580000 = -0.4010330123 
0.0000000000 * 0.2914800000 = -0.4010330123 
0.0000000000 * -0.0464367000 = -0.4010330123 
0.0000000000 * -0.2653760000 = -0.4010330123 
0.0000000000 * -0.0195458000 = -0.4010330123 
0.4076920016 * 0.0659533000 = -0.3741443794 
1.2353312302 * -0.4010760000 = -0.8696060879 
0.0000000000 * -0.0555650000 = -0.8696060879 
0.0000000000 * 0.0002363680 = -0.8696060879 
0.0000000000 * -0.0866756000 = -0.8696060879 
the biases is : 0.5969770000, now tempVal is : -0.2726290879
ReLU !!! in layer: 6, node : 20, its linear result is negative,so set it to 0
compute layer: 6, node : 21
0.3707124511 * -2.8653700000 = -1.0622283359 
0.0000000000 * 1.2295700000 = -1.0622283359 
0.0000000000 * -1.3333900000 = -1.0622283359 
0.0000000000 * -0.9907930000 = -1.0622283359 
0.0000000000 * -4.6191400000 = -1.0622283359 
0.0000000000 * 0.1304960000 = -1.0622283359 
0.0000000000 * -0.7297160000 = -1.0622283359 
0.0000000000 * -0.4330110000 = -1.0622283359 
0.0000000000 * -0.2194880000 = -1.0622283359 
0.0000000000 * -0.0248907000 = -1.0622283359 
1.1632586860 * 0.0106786000 = -1.0498063617 
0.0000000000 * -0.2785050000 = -1.0498063617 
0.0000000000 * 0.3023460000 = -1.0498063617 
0.0000000000 * 0.0700928000 = -1.0498063617 
0.0000000000 * 0.1973890000 = -1.0498063617 
0.0098561911 * 0.6393150000 = -1.0435051509 
0.0000000000 * -0.1212220000 = -1.0435051509 
0.0000000000 * -1.6177200000 = -1.0435051509 
0.0000000000 * -0.2757180000 = -1.0435051509 
0.0000000000 * 0.4940090000 = -1.0435051509 
0.0000000000 * -0.0197905000 = -1.0435051509 
0.0000000000 * 0.0006391230 = -1.0435051509 
0.0000000000 * -2.2807100000 = -1.0435051509 
0.0000000000 * -0.3769040000 = -1.0435051509 
0.0000000000 * 0.3440010000 = -1.0435051509 
2.0550217898 * 0.5671980000 = 0.1220990982 
0.0000000000 * 0.6389640000 = 0.1220990982 
0.0000000000 * -0.0347610000 = 0.1220990982 
0.0000000000 * 0.0211639000 = 0.1220990982 
0.0000000000 * -1.6188300000 = 0.1220990982 
0.0000000000 * -0.1984620000 = 0.1220990982 
0.0000000000 * 1.3254200000 = 0.1220990982 
0.0000000000 * -0.0661963000 = 0.1220990982 
3.5937718848 * -2.8026300000 = -9.9499137994 
0.0000000000 * -0.0215901000 = -9.9499137994 
0.0000000000 * -1.1206600000 = -9.9499137994 
0.0000000000 * -0.1262750000 = -9.9499137994 
0.0000000000 * -0.2747600000 = -9.9499137994 
0.2629356409 * 0.1503710000 = -9.9103759041 
0.3574904745 * -1.4440200000 = -10.4265992991 
0.0000000000 * -0.2664810000 = -10.4265992991 
0.0000000000 * 0.7467440000 = -10.4265992991 
0.0000000000 * 0.0038743800 = -10.4265992991 
0.0000000000 * -4.0987300000 = -10.4265992991 
0.0000000000 * -0.3996140000 = -10.4265992991 
0.4076920016 * 0.0669503000 = -10.3993041973 
1.2353312302 * -0.7205560000 = -11.2894295272 
0.0000000000 * 0.0339061000 = -11.2894295272 
0.0000000000 * 0.0655410000 = -11.2894295272 
0.0000000000 * 0.1864050000 = -11.2894295272 
the biases is : -2.1755600000, now tempVal is : -13.4649895272
ReLU !!! in layer: 6, node : 21, its linear result is negative,so set it to 0
compute layer: 6, node : 22
0.3707124511 * -0.9795470000 = -0.3631302693 
0.0000000000 * 1.0713900000 = -0.3631302693 
0.0000000000 * 0.7843480000 = -0.3631302693 
0.0000000000 * -2.7844900000 = -0.3631302693 
0.0000000000 * 2.4891100000 = -0.3631302693 
0.0000000000 * -5.8360200000 = -0.3631302693 
0.0000000000 * -0.3132250000 = -0.3631302693 
0.0000000000 * -2.7877400000 = -0.3631302693 
0.0000000000 * 0.6684050000 = -0.3631302693 
0.0000000000 * -1.1866400000 = -0.3631302693 
1.1632586860 * -0.3837160000 = -0.8094912393 
0.0000000000 * -6.6719700000 = -0.8094912393 
0.0000000000 * -0.4551820000 = -0.8094912393 
0.0000000000 * -0.6367270000 = -0.8094912393 
0.0000000000 * -0.6476150000 = -0.8094912393 
0.0098561911 * -0.0690024000 = -0.8101713401 
0.0000000000 * -0.1410810000 = -0.8101713401 
0.0000000000 * -0.2091290000 = -0.8101713401 
0.0000000000 * -0.7941580000 = -0.8101713401 
0.0000000000 * 0.3327770000 = -0.8101713401 
0.0000000000 * -0.6009190000 = -0.8101713401 
0.0000000000 * 0.5768790000 = -0.8101713401 
0.0000000000 * 0.3194760000 = -0.8101713401 
0.0000000000 * -10.0014000000 = -0.8101713401 
0.0000000000 * 0.4562610000 = -0.8101713401 
2.0550217898 * -2.8261100000 = -6.6178889704 
0.0000000000 * -0.3669030000 = -6.6178889704 
0.0000000000 * 0.4498600000 = -6.6178889704 
0.0000000000 * 0.1422300000 = -6.6178889704 
0.0000000000 * 0.0660273000 = -6.6178889704 
0.0000000000 * 0.6272720000 = -6.6178889704 
0.0000000000 * 3.6758500000 = -6.6178889704 
0.0000000000 * -0.4615150000 = -6.6178889704 
3.5937718848 * -0.2557190000 = -7.5368847230 
0.0000000000 * 0.1190460000 = -7.5368847230 
0.0000000000 * 0.9689550000 = -7.5368847230 
0.0000000000 * 0.0081652500 = -7.5368847230 
0.0000000000 * -4.7310900000 = -7.5368847230 
0.2629356409 * -0.4609420000 = -7.6580828032 
0.3574904745 * -0.0091759400 = -7.6613631143 
0.0000000000 * -0.2392000000 = -7.6613631143 
0.0000000000 * -0.1321230000 = -7.6613631143 
0.0000000000 * 1.5345500000 = -7.6613631143 
0.0000000000 * 0.8833280000 = -7.6613631143 
0.0000000000 * -0.8055110000 = -7.6613631143 
0.4076920016 * 0.0770920000 = -7.6299333225 
1.2353312302 * 0.0763631000 = -7.5355996003 
0.0000000000 * -8.8589400000 = -7.5355996003 
0.0000000000 * 0.0887412000 = -7.5355996003 
0.0000000000 * -0.4129800000 = -7.5355996003 
the biases is : -1.1105900000, now tempVal is : -8.6461896003
ReLU !!! in layer: 6, node : 22, its linear result is negative,so set it to 0
compute layer: 6, node : 23
0.3707124511 * -0.1536440000 = -0.0569577438 
0.0000000000 * -0.2873490000 = -0.0569577438 
0.0000000000 * 0.8083110000 = -0.0569577438 
0.0000000000 * -0.6289780000 = -0.0569577438 
0.0000000000 * 0.6630880000 = -0.0569577438 
0.0000000000 * 0.2318500000 = -0.0569577438 
0.0000000000 * -0.2567360000 = -0.0569577438 
0.0000000000 * 0.0352762000 = -0.0569577438 
0.0000000000 * 0.2228560000 = -0.0569577438 
0.0000000000 * 1.1861600000 = -0.0569577438 
1.1632586860 * -0.5660450000 = -0.7154145067 
0.0000000000 * -0.0675674000 = -0.7154145067 
0.0000000000 * -0.1656010000 = -0.7154145067 
0.0000000000 * -0.1638590000 = -0.7154145067 
0.0000000000 * 0.2001550000 = -0.7154145067 
0.0098561911 * 0.0239950000 = -0.7151780074 
0.0000000000 * -0.0960529000 = -0.7151780074 
0.0000000000 * 0.2537960000 = -0.7151780074 
0.0000000000 * 0.7696750000 = -0.7151780074 
0.0000000000 * 0.7254590000 = -0.7151780074 
0.0000000000 * -0.0855869000 = -0.7151780074 
0.0000000000 * -0.2448770000 = -0.7151780074 
0.0000000000 * 1.1959700000 = -0.7151780074 
0.0000000000 * -1.6685000000 = -0.7151780074 
0.0000000000 * 0.2535410000 = -0.7151780074 
2.0550217898 * 0.1881970000 = -0.3284290717 
0.0000000000 * 0.3979010000 = -0.3284290717 
0.0000000000 * 0.4603870000 = -0.3284290717 
0.0000000000 * -0.0351397000 = -0.3284290717 
0.0000000000 * 0.0681529000 = -0.3284290717 
0.0000000000 * -0.5289770000 = -0.3284290717 
0.0000000000 * 0.5404570000 = -0.3284290717 
0.0000000000 * 0.1582710000 = -0.3284290717 
3.5937718848 * 0.3231150000 = 0.8327725309 
0.0000000000 * -0.4343010000 = 0.8327725309 
0.0000000000 * 1.2168600000 = 0.8327725309 
0.0000000000 * -0.2384810000 = 0.8327725309 
0.0000000000 * 0.1657520000 = 0.8327725309 
0.2629356409 * 0.1024200000 = 0.8597023992 
0.3574904745 * 0.0873295000 = 0.8909218636 
0.0000000000 * -0.0938522000 = 0.8909218636 
0.0000000000 * -2.8591700000 = 0.8909218636 
0.0000000000 * -0.0471219000 = 0.8909218636 
0.0000000000 * -0.4792730000 = 0.8909218636 
0.0000000000 * -0.7910960000 = 0.8909218636 
0.4076920016 * -0.3064360000 = 0.7659903574 
1.2353312302 * -0.8935220000 = -0.3378052740 
0.0000000000 * -0.0318296000 = -0.3378052740 
0.0000000000 * -0.0640807000 = -0.3378052740 
0.0000000000 * -2.2625900000 = -0.3378052740 
the biases is : -0.4297190000, now tempVal is : -0.7675242740
ReLU !!! in layer: 6, node : 23, its linear result is negative,so set it to 0
compute layer: 6, node : 24
0.3707124511 * -0.5318710000 = -0.1971712021 
0.0000000000 * 0.4402420000 = -0.1971712021 
0.0000000000 * -1.6362900000 = -0.1971712021 
0.0000000000 * -0.0417775000 = -0.1971712021 
0.0000000000 * 0.1278590000 = -0.1971712021 
0.0000000000 * -0.0519937000 = -0.1971712021 
0.0000000000 * -1.1559700000 = -0.1971712021 
0.0000000000 * -0.1900370000 = -0.1971712021 
0.0000000000 * -0.0934847000 = -0.1971712021 
0.0000000000 * 0.2752870000 = -0.1971712021 
1.1632586860 * 0.0086600500 = -0.1870973237 
0.0000000000 * -4.3924800000 = -0.1870973237 
0.0000000000 * -3.9799800000 = -0.1870973237 
0.0000000000 * 0.0861073000 = -0.1870973237 
0.0000000000 * 0.1090460000 = -0.1870973237 
0.0098561911 * 0.2473820000 = -0.1846590794 
0.0000000000 * -0.1377020000 = -0.1846590794 
0.0000000000 * -0.0222782000 = -0.1846590794 
0.0000000000 * -0.2661280000 = -0.1846590794 
0.0000000000 * -0.3042630000 = -0.1846590794 
0.0000000000 * -0.0065552800 = -0.1846590794 
0.0000000000 * 0.1501330000 = -0.1846590794 
0.0000000000 * 0.3525390000 = -0.1846590794 
0.0000000000 * -0.0108880000 = -0.1846590794 
0.0000000000 * 0.1143550000 = -0.1846590794 
2.0550217898 * 0.4631510000 = 0.7671263175 
0.0000000000 * 0.0169575000 = 0.7671263175 
0.0000000000 * -0.2079890000 = 0.7671263175 
0.0000000000 * -0.0483871000 = 0.7671263175 
0.0000000000 * 0.1548260000 = 0.7671263175 
0.0000000000 * 0.2480270000 = 0.7671263175 
0.0000000000 * -0.1844900000 = 0.7671263175 
0.0000000000 * -0.0473515000 = 0.7671263175 
3.5937718848 * -0.2514020000 = -0.1363551219 
0.0000000000 * 0.2841900000 = -0.1363551219 
0.0000000000 * 1.3843800000 = -0.1363551219 
0.0000000000 * 0.0113555000 = -0.1363551219 
0.0000000000 * 0.1268170000 = -0.1363551219 
0.2629356409 * 0.6094630000 = 0.0238944226 
0.3574904745 * -0.3012450000 = -0.0837977953 
0.0000000000 * -0.0413303000 = -0.0837977953 
0.0000000000 * -0.6636190000 = -0.0837977953 
0.0000000000 * -0.7014590000 = -0.0837977953 
0.0000000000 * 0.0868543000 = -0.0837977953 
0.0000000000 * -0.2792740000 = -0.0837977953 
0.4076920016 * -0.1422920000 = -0.1418091056 
1.2353312302 * -0.3055230000 = -0.5192312091 
0.0000000000 * 0.0615831000 = -0.5192312091 
0.0000000000 * -0.0132336000 = -0.5192312091 
0.0000000000 * 0.0221011000 = -0.5192312091 
the biases is : 0.2418400000, now tempVal is : -0.2773912091
ReLU !!! in layer: 6, node : 24, its linear result is negative,so set it to 0
compute layer: 6, node : 25
0.3707124511 * -0.0023032900 = -0.0008538583 
0.0000000000 * 0.1486070000 = -0.0008538583 
0.0000000000 * -0.1285160000 = -0.0008538583 
0.0000000000 * -0.0017966300 = -0.0008538583 
0.0000000000 * -0.0016378400 = -0.0008538583 
0.0000000000 * 0.0053423200 = -0.0008538583 
0.0000000000 * -0.2149010000 = -0.0008538583 
0.0000000000 * 0.0074141600 = -0.0008538583 
0.0000000000 * 0.0136522000 = -0.0008538583 
0.0000000000 * -0.1967050000 = -0.0008538583 
1.1632586860 * -0.0119092000 = -0.0147073386 
0.0000000000 * 1.1558100000 = -0.0147073386 
0.0000000000 * 0.0154440000 = -0.0147073386 
0.0000000000 * 0.0196616000 = -0.0147073386 
0.0000000000 * -0.0054634500 = -0.0147073386 
0.0098561911 * 0.0637994000 = -0.0140785195 
0.0000000000 * -0.0277860000 = -0.0140785195 
0.0000000000 * -0.0848974000 = -0.0140785195 
0.0000000000 * 0.2540270000 = -0.0140785195 
0.0000000000 * 0.0372250000 = -0.0140785195 
0.0000000000 * 0.0010425600 = -0.0140785195 
0.0000000000 * -0.2581860000 = -0.0140785195 
0.0000000000 * -0.0874720000 = -0.0140785195 
0.0000000000 * 0.0011217300 = -0.0140785195 
0.0000000000 * 0.1495870000 = -0.0140785195 
2.0550217898 * 0.0185585000 = 0.0240596023 
0.0000000000 * 0.0141074000 = 0.0240596023 
0.0000000000 * -0.0021750600 = 0.0240596023 
0.0000000000 * 0.0008656300 = 0.0240596023 
0.0000000000 * -0.0916727000 = 0.0240596023 
0.0000000000 * -0.6237900000 = 0.0240596023 
0.0000000000 * -0.0068933500 = 0.0240596023 
0.0000000000 * -0.1347560000 = 0.0240596023 
3.5937718848 * -0.0067846500 = -0.0003228821 
0.0000000000 * -0.0319778000 = -0.0003228821 
0.0000000000 * 0.2915780000 = -0.0003228821 
0.0000000000 * -0.0022856800 = -0.0003228821 
0.0000000000 * -0.0048906800 = -0.0003228821 
0.2629356409 * -0.0049750400 = -0.0016309974 
0.3574904745 * 0.0094069900 = 0.0017319119 
0.0000000000 * -0.1669160000 = 0.0017319119 
0.0000000000 * -1.0696800000 = 0.0017319119 
0.0000000000 * 0.0226610000 = 0.0017319119 
0.0000000000 * -0.1168120000 = 0.0017319119 
0.0000000000 * -0.0051332000 = 0.0017319119 
0.4076920016 * -0.0056401900 = -0.0005675484 
1.2353312302 * 0.0039510700 = 0.0043133317 
0.0000000000 * 0.0068595500 = 0.0043133317 
0.0000000000 * -0.0024107800 = 0.0043133317 
0.0000000000 * -0.6989230000 = 0.0043133317 
the biases is : 0.1611320000, now tempVal is : 0.1654453317
compute layer: 6, node : 26
0.3707124511 * 0.0464698000 = 0.0172269335 
0.0000000000 * 0.5513840000 = 0.0172269335 
0.0000000000 * 0.3598150000 = 0.0172269335 
0.0000000000 * -0.0802145000 = 0.0172269335 
0.0000000000 * 0.5906480000 = 0.0172269335 
0.0000000000 * -0.5444430000 = 0.0172269335 
0.0000000000 * -0.2585390000 = 0.0172269335 
0.0000000000 * -0.0757818000 = 0.0172269335 
0.0000000000 * -0.1000890000 = 0.0172269335 
0.0000000000 * 0.1047700000 = 0.0172269335 
1.1632586860 * -0.0172885000 = -0.0028840643 
0.0000000000 * 0.4578780000 = -0.0028840643 
0.0000000000 * -0.0719607000 = -0.0028840643 
0.0000000000 * 0.0177946000 = -0.0028840643 
0.0000000000 * -0.0434758000 = -0.0028840643 
0.0098561911 * 0.2234530000 = -0.0006816689 
0.0000000000 * -0.0093996200 = -0.0006816689 
0.0000000000 * -0.0417517000 = -0.0006816689 
0.0000000000 * 0.0624250000 = -0.0006816689 
0.0000000000 * 0.1392150000 = -0.0006816689 
0.0000000000 * 0.0918371000 = -0.0006816689 
0.0000000000 * 0.2946940000 = -0.0006816689 
0.0000000000 * -0.0015591900 = -0.0006816689 
0.0000000000 * 0.0686586000 = -0.0006816689 
0.0000000000 * 0.2354120000 = -0.0006816689 
2.0550217898 * 0.3001940000 = 0.6162235423 
0.0000000000 * 0.1173780000 = 0.6162235423 
0.0000000000 * 0.1017220000 = 0.6162235423 
0.0000000000 * 0.0215695000 = 0.6162235423 
0.0000000000 * 0.0754137000 = 0.6162235423 
0.0000000000 * -0.0372671000 = 0.6162235423 
0.0000000000 * -0.1407500000 = 0.6162235423 
0.0000000000 * -0.0285702000 = 0.6162235423 
3.5937718848 * -0.4021490000 = -0.8290082274 
0.0000000000 * 0.1216310000 = -0.8290082274 
0.0000000000 * 0.4014980000 = -0.8290082274 
0.0000000000 * 0.0656180000 = -0.8290082274 
0.0000000000 * -0.0992043000 = -0.8290082274 
0.2629356409 * -0.4933670000 = -0.9587319958 
0.3574904745 * -0.0647903000 = -0.9818939109 
0.0000000000 * 0.1620780000 = -0.9818939109 
0.0000000000 * 0.4680580000 = -0.9818939109 
0.0000000000 * -0.1162670000 = -0.9818939109 
0.0000000000 * 0.2802760000 = -0.9818939109 
0.0000000000 * 0.0721641000 = -0.9818939109 
0.4076920016 * -0.0447230000 = -1.0001271202 
1.2353312302 * -0.1166420000 = -1.1442186256 
0.0000000000 * -0.0952337000 = -1.1442186256 
0.0000000000 * -0.0464884000 = -1.1442186256 
0.0000000000 * -0.0836464000 = -1.1442186256 
the biases is : 0.1032510000, now tempVal is : -1.0409676256
ReLU !!! in layer: 6, node : 26, its linear result is negative,so set it to 0
compute layer: 6, node : 27
0.3707124511 * -1.0812800000 = -0.4008439591 
0.0000000000 * -0.1374680000 = -0.4008439591 
0.0000000000 * -0.1235300000 = -0.4008439591 
0.0000000000 * -0.1250970000 = -0.4008439591 
0.0000000000 * 0.0014010500 = -0.4008439591 
0.0000000000 * 0.0877260000 = -0.4008439591 
0.0000000000 * -0.0320484000 = -0.4008439591 
0.0000000000 * -0.0017059500 = -0.4008439591 
0.0000000000 * -0.0544409000 = -0.4008439591 
0.0000000000 * -0.2237930000 = -0.4008439591 
1.1632586860 * 0.0122243000 = -0.3866239359 
0.0000000000 * -0.9296210000 = -0.3866239359 
0.0000000000 * -1.2464700000 = -0.3866239359 
0.0000000000 * -0.3092450000 = -0.3866239359 
0.0000000000 * 0.0474166000 = -0.3866239359 
0.0098561911 * -1.3275100000 = -0.3997081282 
0.0000000000 * -0.0000643300 = -0.3997081282 
0.0000000000 * -0.1706240000 = -0.3997081282 
0.0000000000 * 0.0211212000 = -0.3997081282 
0.0000000000 * 0.0144147000 = -0.3997081282 
0.0000000000 * 0.0067129900 = -0.3997081282 
0.0000000000 * 0.0526034000 = -0.3997081282 
0.0000000000 * -0.2363800000 = -0.3997081282 
0.0000000000 * -1.4657500000 = -0.3997081282 
0.0000000000 * 0.0233889000 = -0.3997081282 
2.0550217898 * -0.3117900000 = -1.0404433720 
0.0000000000 * -0.0429232000 = -1.0404433720 
0.0000000000 * -0.1565140000 = -1.0404433720 
0.0000000000 * -0.0309423000 = -1.0404433720 
0.0000000000 * 0.0578041000 = -1.0404433720 
0.0000000000 * -1.0944100000 = -1.0404433720 
0.0000000000 * -0.9894800000 = -1.0404433720 
0.0000000000 * -0.1962860000 = -1.0404433720 
3.5937718848 * -3.6947900000 = -14.3186757943 
0.0000000000 * -0.3489590000 = -14.3186757943 
0.0000000000 * 0.1883670000 = -14.3186757943 
0.0000000000 * -0.6561610000 = -14.3186757943 
0.0000000000 * -0.3506010000 = -14.3186757943 
0.2629356409 * 0.0150148000 = -14.3147278683 
0.3574904745 * -0.0011328800 = -14.3151328621 
0.0000000000 * -0.0536714000 = -14.3151328621 
0.0000000000 * 0.1683750000 = -14.3151328621 
0.0000000000 * 0.1984990000 = -14.3151328621 
0.0000000000 * -0.1937340000 = -14.3151328621 
0.0000000000 * -0.0868963000 = -14.3151328621 
0.4076920016 * -0.0675486000 = -14.3426718860 
1.2353312302 * -3.2132600000 = -18.3121123147 
0.0000000000 * -0.0310835000 = -18.3121123147 
0.0000000000 * -0.1365940000 = -18.3121123147 
0.0000000000 * 0.1950600000 = -18.3121123147 
the biases is : 0.1906210000, now tempVal is : -18.1214913147
ReLU !!! in layer: 6, node : 27, its linear result is negative,so set it to 0
compute layer: 6, node : 28
0.3707124511 * 0.9897110000 = 0.3668981907 
0.0000000000 * 4.0742600000 = 0.3668981907 
0.0000000000 * 1.8658000000 = 0.3668981907 
0.0000000000 * -1.9033500000 = 0.3668981907 
0.0000000000 * -3.8813800000 = 0.3668981907 
0.0000000000 * -1.0083500000 = 0.3668981907 
0.0000000000 * 0.0743546000 = 0.3668981907 
0.0000000000 * 1.6786700000 = 0.3668981907 
0.0000000000 * -0.4058260000 = 0.3668981907 
0.0000000000 * 0.5491890000 = 0.3668981907 
1.1632586860 * -1.4302800000 = -1.2968874427 
0.0000000000 * 1.0983400000 = -1.2968874427 
0.0000000000 * 1.0924100000 = -1.2968874427 
0.0000000000 * -0.2387990000 = -1.2968874427 
0.0000000000 * 1.1643800000 = -1.2968874427 
0.0098561911 * 0.8383830000 = -1.2886241797 
0.0000000000 * 0.3879610000 = -1.2886241797 
0.0000000000 * -0.0019851600 = -1.2886241797 
0.0000000000 * 0.5335240000 = -1.2886241797 
0.0000000000 * -1.3873900000 = -1.2886241797 
0.0000000000 * -0.6280680000 = -1.2886241797 
0.0000000000 * -0.7196940000 = -1.2886241797 
0.0000000000 * 1.6855900000 = -1.2886241797 
0.0000000000 * -0.9643830000 = -1.2886241797 
0.0000000000 * 1.4347100000 = -1.2886241797 
2.0550217898 * 2.0574000000 = 2.9393776506 
0.0000000000 * -0.9053900000 = 2.9393776506 
0.0000000000 * -0.5909720000 = 2.9393776506 
0.0000000000 * 0.4423650000 = 2.9393776506 
0.0000000000 * -0.3304770000 = 2.9393776506 
0.0000000000 * 2.1831700000 = 2.9393776506 
0.0000000000 * -0.0747921000 = 2.9393776506 
0.0000000000 * -0.0645806000 = 2.9393776506 
3.5937718848 * -1.4657400000 = -2.3281575519 
0.0000000000 * 1.9743400000 = -2.3281575519 
0.0000000000 * 1.9584000000 = -2.3281575519 
0.0000000000 * -0.1663710000 = -2.3281575519 
0.0000000000 * 0.1845730000 = -2.3281575519 
0.2629356409 * 1.0104600000 = -2.0624716042 
0.3574904745 * -0.3945450000 = -2.2035176834 
0.0000000000 * -0.4738410000 = -2.2035176834 
0.0000000000 * 2.7271200000 = -2.2035176834 
0.0000000000 * 0.3861370000 = -2.2035176834 
0.0000000000 * -2.1330100000 = -2.2035176834 
0.0000000000 * -0.8267130000 = -2.2035176834 
0.4076920016 * -1.3824400000 = -2.7671274141 
1.2353312302 * -1.3008100000 = -4.3740586316 
0.0000000000 * -0.1729120000 = -4.3740586316 
0.0000000000 * 1.2186000000 = -4.3740586316 
0.0000000000 * -4.9439000000 = -4.3740586316 
the biases is : -2.5628100000, now tempVal is : -6.9368686316
ReLU !!! in layer: 6, node : 28, its linear result is negative,so set it to 0
compute layer: 6, node : 29
0.3707124511 * -0.2970660000 = -0.1101260650 
0.0000000000 * 0.6140130000 = -0.1101260650 
0.0000000000 * 0.0177407000 = -0.1101260650 
0.0000000000 * 0.0946948000 = -0.1101260650 
0.0000000000 * 0.2873800000 = -0.1101260650 
0.0000000000 * 0.0904941000 = -0.1101260650 
0.0000000000 * 0.6530660000 = -0.1101260650 
0.0000000000 * 0.0230192000 = -0.1101260650 
0.0000000000 * -0.0617862000 = -0.1101260650 
0.0000000000 * 0.0045406000 = -0.1101260650 
1.1632586860 * -0.1767170000 = -0.3156936502 
0.0000000000 * 0.7927460000 = -0.3156936502 
0.0000000000 * -0.0490113000 = -0.3156936502 
0.0000000000 * -0.0641461000 = -0.3156936502 
0.0000000000 * -0.0437274000 = -0.3156936502 
0.0098561911 * 0.0526887000 = -0.3151743403 
0.0000000000 * 0.0752672000 = -0.3151743403 
0.0000000000 * 0.0177165000 = -0.3151743403 
0.0000000000 * -0.4640380000 = -0.3151743403 
0.0000000000 * -0.8345140000 = -0.3151743403 
0.0000000000 * -0.2622350000 = -0.3151743403 
0.0000000000 * 0.0067541800 = -0.3151743403 
0.0000000000 * 0.3215620000 = -0.3151743403 
0.0000000000 * -0.1268960000 = -0.3151743403 
0.0000000000 * 0.0128644000 = -0.3151743403 
2.0550217898 * 0.2362200000 = 0.1702629069 
0.0000000000 * 0.1668280000 = 0.1702629069 
0.0000000000 * 0.1529630000 = 0.1702629069 
0.0000000000 * -0.1467790000 = 0.1702629069 
0.0000000000 * 0.1084850000 = 0.1702629069 
0.0000000000 * -0.0398573000 = 0.1702629069 
0.0000000000 * -0.2400740000 = 0.1702629069 
0.0000000000 * -0.1376270000 = 0.1702629069 
3.5937718848 * -0.3494880000 = -1.0857172416 
0.0000000000 * 0.1960250000 = -1.0857172416 
0.0000000000 * 0.3587870000 = -1.0857172416 
0.0000000000 * -0.1696720000 = -1.0857172416 
0.0000000000 * -0.0818495000 = -1.0857172416 
0.2629356409 * 0.1736370000 = -1.0400618857 
0.3574904745 * -0.0267539000 = -1.0496261501 
0.0000000000 * -0.0784468000 = -1.0496261501 
0.0000000000 * 0.0042402700 = -1.0496261501 
0.0000000000 * -0.2814830000 = -1.0496261501 
0.0000000000 * 0.4709370000 = -1.0496261501 
0.0000000000 * 0.0616303000 = -1.0496261501 
0.4076920016 * -0.0045224600 = -1.0514699209 
1.2353312302 * -0.3912350000 = -1.5347747348 
0.0000000000 * 0.0678407000 = -1.5347747348 
0.0000000000 * -0.0629347000 = -1.5347747348 
0.0000000000 * 0.0644863000 = -1.5347747348 
the biases is : 0.4284940000, now tempVal is : -1.1062807348
ReLU !!! in layer: 6, node : 29, its linear result is negative,so set it to 0
compute layer: 6, node : 30
0.3707124511 * -0.5575170000 = -0.2066784936 
0.0000000000 * -0.1733670000 = -0.2066784936 
0.0000000000 * 0.0392317000 = -0.2066784936 
0.0000000000 * 0.0217549000 = -0.2066784936 
0.0000000000 * -0.1084080000 = -0.2066784936 
0.0000000000 * 0.0525476000 = -0.2066784936 
0.0000000000 * -1.4105400000 = -0.2066784936 
0.0000000000 * -0.0010986700 = -0.2066784936 
0.0000000000 * -0.0286282000 = -0.2066784936 
0.0000000000 * 0.0367939000 = -0.2066784936 
1.1632586860 * -0.0341302000 = -0.2463807452 
0.0000000000 * -0.0044930000 = -0.2463807452 
0.0000000000 * 0.0693375000 = -0.2463807452 
0.0000000000 * -0.0078390400 = -0.2463807452 
0.0000000000 * -0.0051035700 = -0.2463807452 
0.0098561911 * -0.0439498000 = -0.2468139228 
0.0000000000 * -0.0503220000 = -0.2468139228 
0.0000000000 * -0.0520081000 = -0.2468139228 
0.0000000000 * -0.0350051000 = -0.2468139228 
0.0000000000 * 0.1783030000 = -0.2468139228 
0.0000000000 * 0.0100060000 = -0.2468139228 
0.0000000000 * 0.0199975000 = -0.2468139228 
0.0000000000 * -0.0954596000 = -0.2468139228 
0.0000000000 * -0.0154273000 = -0.2468139228 
0.0000000000 * 0.0857445000 = -0.2468139228 
2.0550217898 * -0.1050560000 = -0.4627062920 
0.0000000000 * -0.1139370000 = -0.4627062920 
0.0000000000 * -0.1460620000 = -0.4627062920 
0.0000000000 * 0.0234869000 = -0.4627062920 
0.0000000000 * 0.0169509000 = -0.4627062920 
0.0000000000 * 0.0983037000 = -0.4627062920 
0.0000000000 * 0.0010198600 = -0.4627062920 
0.0000000000 * 0.0021036600 = -0.4627062920 
3.5937718848 * -3.3201900000 = -12.3947117662 
0.0000000000 * -0.2030530000 = -12.3947117662 
0.0000000000 * 0.1106080000 = -12.3947117662 
0.0000000000 * -0.1684850000 = -12.3947117662 
0.0000000000 * -0.0609527000 = -12.3947117662 
0.2629356409 * 0.0580966000 = -12.3794360995 
0.3574904745 * -0.0133487000 = -12.3842081326 
0.0000000000 * -0.0024475400 = -12.3842081326 
0.0000000000 * 0.1185680000 = -12.3842081326 
0.0000000000 * -1.7043400000 = -12.3842081326 
0.0000000000 * -4.3037200000 = -12.3842081326 
0.0000000000 * -0.0354869000 = -12.3842081326 
0.4076920016 * -0.1069480000 = -12.4278099768 
1.2353312302 * -0.1777030000 = -12.6473320424 
0.0000000000 * -0.0076585300 = -12.6473320424 
0.0000000000 * 0.0131175000 = -12.6473320424 
0.0000000000 * 0.0275693000 = -12.6473320424 
the biases is : 0.1659190000, now tempVal is : -12.4814130424
ReLU !!! in layer: 6, node : 30, its linear result is negative,so set it to 0
compute layer: 6, node : 31
0.3707124511 * 0.0204695000 = 0.0075882985 
0.0000000000 * 0.0223643000 = 0.0075882985 
0.0000000000 * -0.0243812000 = 0.0075882985 
0.0000000000 * 0.0146298000 = 0.0075882985 
0.0000000000 * -0.0415361000 = 0.0075882985 
0.0000000000 * 0.0082051800 = 0.0075882985 
0.0000000000 * -0.0089224600 = 0.0075882985 
0.0000000000 * 0.0317230000 = 0.0075882985 
0.0000000000 * 0.0055488200 = 0.0075882985 
0.0000000000 * -0.0087749400 = 0.0075882985 
1.1632586860 * -0.0548525000 = -0.0562193486 
0.0000000000 * 0.0274748000 = -0.0562193486 
0.0000000000 * -0.0221081000 = -0.0562193486 
0.0000000000 * 0.0090629600 = -0.0562193486 
0.0000000000 * -0.0114823000 = -0.0562193486 
0.0098561911 * -0.0465796000 = -0.0566784460 
0.0000000000 * -0.0435750000 = -0.0566784460 
0.0000000000 * 0.0199864000 = -0.0566784460 
0.0000000000 * -0.0331047000 = -0.0566784460 
0.0000000000 * 0.0471855000 = -0.0566784460 
0.0000000000 * -0.0046006000 = -0.0566784460 
0.0000000000 * -0.0284358000 = -0.0566784460 
0.0000000000 * 0.0156292000 = -0.0566784460 
0.0000000000 * 0.0207335000 = -0.0566784460 
0.0000000000 * 0.0124492000 = -0.0566784460 
2.0550217898 * -0.0432942000 = -0.1456489704 
0.0000000000 * 0.0184170000 = -0.1456489704 
0.0000000000 * 0.0162350000 = -0.1456489704 
0.0000000000 * -0.0274217000 = -0.1456489704 
0.0000000000 * -0.0301965000 = -0.1456489704 
0.0000000000 * 0.0175510000 = -0.1456489704 
0.0000000000 * -0.0092517700 = -0.1456489704 
0.0000000000 * -0.0156196000 = -0.1456489704 
3.5937718848 * -0.0267814000 = -0.2418952127 
0.0000000000 * 0.0185272000 = -0.2418952127 
0.0000000000 * 0.0358673000 = -0.2418952127 
0.0000000000 * -0.0094676500 = -0.2418952127 
0.0000000000 * 0.0324075000 = -0.2418952127 
0.2629356409 * -0.0584109000 = -0.2572535201 
0.3574904745 * -0.0249332000 = -0.2661669016 
0.0000000000 * -0.0315923000 = -0.2661669016 
0.0000000000 * -0.0184504000 = -0.2661669016 
0.0000000000 * -0.0236654000 = -0.2661669016 
0.0000000000 * -0.0064921900 = -0.2661669016 
0.0000000000 * -0.0347870000 = -0.2661669016 
0.4076920016 * -0.0222095000 = -0.2752215372 
1.2353312302 * 0.0105350000 = -0.2622073226 
0.0000000000 * 0.0075689400 = -0.2622073226 
0.0000000000 * -0.0001468400 = -0.2622073226 
0.0000000000 * -0.0362273000 = -0.2622073226 
the biases is : -0.0413155000, now tempVal is : -0.3035228226
ReLU !!! in layer: 6, node : 31, its linear result is negative,so set it to 0
compute layer: 6, node : 32
0.3707124511 * -0.1061090000 = -0.0393359275 
0.0000000000 * 1.2913400000 = -0.0393359275 
0.0000000000 * 1.7684800000 = -0.0393359275 
0.0000000000 * 0.0430765000 = -0.0393359275 
0.0000000000 * -3.8609600000 = -0.0393359275 
0.0000000000 * -0.1633310000 = -0.0393359275 
0.0000000000 * 0.1330540000 = -0.0393359275 
0.0000000000 * -0.2371610000 = -0.0393359275 
0.0000000000 * -0.2974300000 = -0.0393359275 
0.0000000000 * -0.4706720000 = -0.0393359275 
1.1632586860 * -0.2226040000 = -0.2982819640 
0.0000000000 * 0.1358460000 = -0.2982819640 
0.0000000000 * 1.2505000000 = -0.2982819640 
0.0000000000 * 0.4244740000 = -0.2982819640 
0.0000000000 * -0.2998680000 = -0.2982819640 
0.0098561911 * 0.3621210000 = -0.2947128302 
0.0000000000 * -0.1472810000 = -0.2947128302 
0.0000000000 * -2.4045500000 = -0.2947128302 
0.0000000000 * 1.1083900000 = -0.2947128302 
0.0000000000 * -0.6945520000 = -0.2947128302 
0.0000000000 * 0.1583080000 = -0.2947128302 
0.0000000000 * -0.0146809000 = -0.2947128302 
0.0000000000 * 0.9402300000 = -0.2947128302 
0.0000000000 * 0.2302740000 = -0.2947128302 
0.0000000000 * -1.9999700000 = -0.2947128302 
2.0550217898 * -1.1715200000 = -2.7022119574 
0.0000000000 * 0.7393640000 = -2.7022119574 
0.0000000000 * -0.2640690000 = -2.7022119574 
0.0000000000 * 0.0887211000 = -2.7022119574 
0.0000000000 * -0.1308090000 = -2.7022119574 
0.0000000000 * -0.3991610000 = -2.7022119574 
0.0000000000 * 2.5658800000 = -2.7022119574 
0.0000000000 * 0.1885640000 = -2.7022119574 
3.5937718848 * -0.6106720000 = -4.8968278218 
0.0000000000 * 0.1715340000 = -4.8968278218 
0.0000000000 * 0.2719850000 = -4.8968278218 
0.0000000000 * -0.2126440000 = -4.8968278218 
0.0000000000 * -4.3506200000 = -4.8968278218 
0.2629356409 * -0.3053920000 = -4.9771262631 
0.3574904745 * -0.0075020700 = -4.9798081816 
0.0000000000 * -0.0845502000 = -4.9798081816 
0.0000000000 * 0.5460640000 = -4.9798081816 
0.0000000000 * 1.0234500000 = -4.9798081816 
0.0000000000 * 0.1745170000 = -4.9798081816 
0.0000000000 * -0.6961050000 = -4.9798081816 
0.4076920016 * -0.0698052000 = -5.0082672033 
1.2353312302 * 0.8295270000 = -3.9835265940 
0.0000000000 * -0.6101700000 = -3.9835265940 
0.0000000000 * 0.2926040000 = -3.9835265940 
0.0000000000 * -0.6040970000 = -3.9835265940 
the biases is : -3.2120200000, now tempVal is : -7.1955465940
ReLU !!! in layer: 6, node : 32, its linear result is negative,so set it to 0
compute layer: 6, node : 33
0.3707124511 * -0.0247721000 = -0.0091833259 
0.0000000000 * 0.0115411000 = -0.0091833259 
0.0000000000 * -0.0797831000 = -0.0091833259 
0.0000000000 * 0.1594160000 = -0.0091833259 
0.0000000000 * -4.3213200000 = -0.0091833259 
0.0000000000 * -1.2851200000 = -0.0091833259 
0.0000000000 * -0.4260180000 = -0.0091833259 
0.0000000000 * -0.5860320000 = -0.0091833259 
0.0000000000 * -0.0628205000 = -0.0091833259 
0.0000000000 * -1.2719200000 = -0.0091833259 
1.1632586860 * 0.0084803000 = 0.0006814567 
0.0000000000 * -0.1602130000 = 0.0006814567 
0.0000000000 * 0.0071719200 = 0.0006814567 
0.0000000000 * 0.0129334000 = 0.0006814567 
0.0000000000 * -0.0144258000 = 0.0006814567 
0.0098561911 * -0.0005143330 = 0.0006763874 
0.0000000000 * 0.0461299000 = 0.0006763874 
0.0000000000 * -0.0291068000 = 0.0006763874 
0.0000000000 * -0.0123271000 = 0.0006763874 
0.0000000000 * 0.0619209000 = 0.0006763874 
0.0000000000 * -0.2662370000 = 0.0006763874 
0.0000000000 * -0.0267065000 = 0.0006763874 
0.0000000000 * 0.0105504000 = 0.0006763874 
0.0000000000 * -0.4519330000 = 0.0006763874 
0.0000000000 * 0.0154839000 = 0.0006763874 
2.0550217898 * -0.2389270000 = -0.4903238038 
0.0000000000 * -0.0814344000 = -0.4903238038 
0.0000000000 * 0.0801853000 = -0.4903238038 
0.0000000000 * -0.0090803200 = -0.4903238038 
0.0000000000 * 0.0011671500 = -0.4903238038 
0.0000000000 * 0.0493173000 = -0.4903238038 
0.0000000000 * -0.2831620000 = -0.4903238038 
0.0000000000 * -0.8496880000 = -0.4903238038 
3.5937718848 * -2.5452900000 = -9.6375154445 
0.0000000000 * 0.0257275000 = -9.6375154445 
0.0000000000 * -0.0227548000 = -9.6375154445 
0.0000000000 * -0.0056331700 = -9.6375154445 
0.0000000000 * -0.1465180000 = -9.6375154445 
0.2629356409 * -0.1214480000 = -9.6694484522 
0.3574904745 * -2.3960000000 = -10.5259956291 
0.0000000000 * 0.0179936000 = -10.5259956291 
0.0000000000 * 0.1969520000 = -10.5259956291 
0.0000000000 * -0.9681140000 = -10.5259956291 
0.0000000000 * -0.4557270000 = -10.5259956291 
0.0000000000 * 0.0045909400 = -10.5259956291 
0.4076920016 * -0.0669994000 = -10.5533107486 
1.2353312302 * -2.4736100000 = -13.6090384329 
0.0000000000 * -0.2658420000 = -13.6090384329 
0.0000000000 * -0.0090624300 = -13.6090384329 
0.0000000000 * -0.9284520000 = -13.6090384329 
the biases is : 0.0165723000, now tempVal is : -13.5924661329
ReLU !!! in layer: 6, node : 33, its linear result is negative,so set it to 0
compute layer: 6, node : 34
0.3707124511 * 0.1395980000 = 0.0517507167 
0.0000000000 * 1.0651600000 = 0.0517507167 
0.0000000000 * 0.4902220000 = 0.0517507167 
0.0000000000 * -2.1752800000 = 0.0517507167 
0.0000000000 * 3.1260700000 = 0.0517507167 
0.0000000000 * -1.0360000000 = 0.0517507167 
0.0000000000 * -1.3677000000 = 0.0517507167 
0.0000000000 * -0.1556690000 = 0.0517507167 
0.0000000000 * -1.3650400000 = 0.0517507167 
0.0000000000 * -0.0577323000 = 0.0517507167 
1.1632586860 * -1.4632900000 = -1.6504340858 
0.0000000000 * 0.3221270000 = -1.6504340858 
0.0000000000 * -0.3448260000 = -1.6504340858 
0.0000000000 * -0.5333500000 = -1.6504340858 
0.0000000000 * 1.3858500000 = -1.6504340858 
0.0098561911 * 0.9728060000 = -1.6408459240 
0.0000000000 * 0.1309790000 = -1.6408459240 
0.0000000000 * 0.3419400000 = -1.6408459240 
0.0000000000 * 0.4379810000 = -1.6408459240 
0.0000000000 * 1.1997900000 = -1.6408459240 
0.0000000000 * -1.5758400000 = -1.6408459240 
0.0000000000 * 1.1394800000 = -1.6408459240 
0.0000000000 * 0.3553840000 = -1.6408459240 
0.0000000000 * 0.2034940000 = -1.6408459240 
0.0000000000 * 0.2497310000 = -1.6408459240 
2.0550217898 * 0.1931460000 = -1.2439266854 
0.0000000000 * -0.0787124000 = -1.2439266854 
0.0000000000 * 0.0893741000 = -1.2439266854 
0.0000000000 * -1.1389600000 = -1.2439266854 
0.0000000000 * 0.2953690000 = -1.2439266854 
0.0000000000 * 0.1892630000 = -1.2439266854 
0.0000000000 * -0.1472300000 = -1.2439266854 
0.0000000000 * -0.2123720000 = -1.2439266854 
3.5937718848 * -0.4283340000 = -2.7832613719 
0.0000000000 * 0.2333030000 = -2.7832613719 
0.0000000000 * -0.9105250000 = -2.7832613719 
0.0000000000 * -0.9708980000 = -2.7832613719 
0.0000000000 * -0.4589000000 = -2.7832613719 
0.2629356409 * -1.7560200000 = -3.2449816161 
0.3574904745 * -0.5344900000 = -3.4360566998 
0.0000000000 * 0.6649320000 = -3.4360566998 
0.0000000000 * 2.3225400000 = -3.4360566998 
0.0000000000 * -0.9810460000 = -3.4360566998 
0.0000000000 * 1.9970600000 = -3.4360566998 
0.0000000000 * -2.2708000000 = -3.4360566998 
0.4076920016 * 0.0743042000 = -3.4057634718 
1.2353312302 * 0.1422960000 = -3.2299807790 
0.0000000000 * -3.2967800000 = -3.2299807790 
0.0000000000 * -0.2968590000 = -3.2299807790 
0.0000000000 * 3.1408300000 = -3.2299807790 
the biases is : -1.4495100000, now tempVal is : -4.6794907790
ReLU !!! in layer: 6, node : 34, its linear result is negative,so set it to 0
compute layer: 6, node : 35
0.3707124511 * -0.8255660000 = -0.3060475954 
0.0000000000 * -0.6994280000 = -0.3060475954 
0.0000000000 * -0.3263280000 = -0.3060475954 
0.0000000000 * -1.7717700000 = -0.3060475954 
0.0000000000 * 0.2775960000 = -0.3060475954 
0.0000000000 * 0.5542700000 = -0.3060475954 
0.0000000000 * 0.8126940000 = -0.3060475954 
0.0000000000 * 0.0009358000 = -0.3060475954 
0.0000000000 * -0.0111042000 = -0.3060475954 
0.0000000000 * -0.0416980000 = -0.3060475954 
1.1632586860 * -0.0806400000 = -0.3998527758 
0.0000000000 * 0.6547290000 = -0.3998527758 
0.0000000000 * -0.2240500000 = -0.3998527758 
0.0000000000 * -0.2276320000 = -0.3998527758 
0.0000000000 * 0.3327170000 = -0.3998527758 
0.0098561911 * 0.1668560000 = -0.3982082112 
0.0000000000 * 0.1229170000 = -0.3982082112 
0.0000000000 * -0.1775980000 = -0.3982082112 
0.0000000000 * -2.7834200000 = -0.3982082112 
0.0000000000 * -0.5572880000 = -0.3982082112 
0.0000000000 * -1.3963300000 = -0.3982082112 
0.0000000000 * 0.0571400000 = -0.3982082112 
0.0000000000 * 0.2004630000 = -0.3982082112 
0.0000000000 * 0.2059070000 = -0.3982082112 
0.0000000000 * 0.2933940000 = -0.3982082112 
2.0550217898 * 0.3272470000 = 0.2742915044 
0.0000000000 * -0.0336302000 = 0.2742915044 
0.0000000000 * -0.0791815000 = 0.2742915044 
0.0000000000 * -1.5088300000 = 0.2742915044 
0.0000000000 * 0.1390200000 = 0.2742915044 
0.0000000000 * 0.0402293000 = 0.2742915044 
0.0000000000 * -1.0850500000 = 0.2742915044 
0.0000000000 * -0.1455480000 = 0.2742915044 
3.5937718848 * -0.3467290000 = -0.9717734274 
0.0000000000 * 0.1922040000 = -0.9717734274 
0.0000000000 * -0.3520050000 = -0.9717734274 
0.0000000000 * -0.5744010000 = -0.9717734274 
0.0000000000 * -0.0986989000 = -0.9717734274 
0.2629356409 * 0.0846192000 = -0.9495240238 
0.3574904745 * -0.1254450000 = -0.9943694164 
0.0000000000 * -0.1946570000 = -0.9943694164 
0.0000000000 * -0.1765530000 = -0.9943694164 
0.0000000000 * -0.3588860000 = -0.9943694164 
0.0000000000 * 0.6928770000 = -0.9943694164 
0.0000000000 * 0.1530980000 = -0.9943694164 
0.4076920016 * 0.0899646000 = -0.9576915686 
1.2353312302 * -0.4133420000 = -1.4683058499 
0.0000000000 * 0.2483880000 = -1.4683058499 
0.0000000000 * -0.3341030000 = -1.4683058499 
0.0000000000 * 0.0739906000 = -1.4683058499 
the biases is : -0.2127170000, now tempVal is : -1.6810228499
ReLU !!! in layer: 6, node : 35, its linear result is negative,so set it to 0
compute layer: 6, node : 36
0.3707124511 * -0.2293040000 = -0.0850058479 
0.0000000000 * -0.0635595000 = -0.0850058479 
0.0000000000 * -0.2056700000 = -0.0850058479 
0.0000000000 * -0.0351613000 = -0.0850058479 
0.0000000000 * 0.0823049000 = -0.0850058479 
0.0000000000 * -0.0156062000 = -0.0850058479 
0.0000000000 * 0.7023360000 = -0.0850058479 
0.0000000000 * -0.0357350000 = -0.0850058479 
0.0000000000 * -0.1345420000 = -0.0850058479 
0.0000000000 * -0.1729130000 = -0.0850058479 
1.1632586860 * 0.0817171000 = 0.0100522785 
0.0000000000 * -0.0084651400 = 0.0100522785 
0.0000000000 * -0.0049236100 = 0.0100522785 
0.0000000000 * 0.0456520000 = 0.0100522785 
0.0000000000 * -0.0190306000 = 0.0100522785 
0.0098561911 * 0.1619790000 = 0.0116487745 
0.0000000000 * 0.0376816000 = 0.0116487745 
0.0000000000 * 0.0219864000 = 0.0116487745 
0.0000000000 * -0.1600110000 = 0.0116487745 
0.0000000000 * -0.3165230000 = 0.0116487745 
0.0000000000 * 0.0036642700 = 0.0116487745 
0.0000000000 * 0.0715392000 = 0.0116487745 
0.0000000000 * -0.0849684000 = 0.0116487745 
0.0000000000 * 0.2684970000 = 0.0116487745 
0.0000000000 * 0.1932330000 = 0.0116487745 
2.0550217898 * -0.4217740000 = -0.8551059859 
0.0000000000 * -0.0202102000 = -0.8551059859 
0.0000000000 * 0.1362980000 = -0.8551059859 
0.0000000000 * 0.0057472500 = -0.8551059859 
0.0000000000 * -0.0829131000 = -0.8551059859 
0.0000000000 * -0.0409926000 = -0.8551059859 
0.0000000000 * -0.2081460000 = -0.8551059859 
0.0000000000 * 0.0551996000 = -0.8551059859 
3.5937718848 * -0.1286170000 = -1.3173261444 
0.0000000000 * 0.0454432000 = -1.3173261444 
0.0000000000 * 0.3064610000 = -1.3173261444 
0.0000000000 * -0.0103268000 = -1.3173261444 
0.0000000000 * -0.0590751000 = -1.3173261444 
0.2629356409 * 0.0201689000 = -1.3120230218 
0.3574904745 * 0.0207485000 = -1.3046056306 
0.0000000000 * 0.1131610000 = -1.3046056306 
0.0000000000 * 0.0990744000 = -1.3046056306 
0.0000000000 * 0.0931920000 = -1.3046056306 
0.0000000000 * -0.0079823000 = -1.3046056306 
0.0000000000 * -0.0680220000 = -1.3046056306 
0.4076920016 * 0.0670204000 = -1.2772819496 
1.2353312302 * -0.0552199000 = -1.3454968166 
0.0000000000 * -0.0787001000 = -1.3454968166 
0.0000000000 * -0.0072734800 = -1.3454968166 
0.0000000000 * -0.0662526000 = -1.3454968166 
the biases is : 0.0963620000, now tempVal is : -1.2491348166
ReLU !!! in layer: 6, node : 36, its linear result is negative,so set it to 0
compute layer: 6, node : 37
0.3707124511 * 0.0221196000 = 0.0082000111 
0.0000000000 * -0.1653670000 = 0.0082000111 
0.0000000000 * 0.1680030000 = 0.0082000111 
0.0000000000 * 0.0421288000 = 0.0082000111 
0.0000000000 * -1.2139400000 = 0.0082000111 
0.0000000000 * 0.0200251000 = 0.0082000111 
0.0000000000 * -0.6289620000 = 0.0082000111 
0.0000000000 * -0.1334260000 = 0.0082000111 
0.0000000000 * 0.0167305000 = 0.0082000111 
0.0000000000 * -0.2719990000 = 0.0082000111 
1.1632586860 * 0.0375864000 = 0.0519227174 
0.0000000000 * -1.9417300000 = 0.0519227174 
0.0000000000 * 0.1676460000 = 0.0519227174 
0.0000000000 * 0.2261190000 = 0.0519227174 
0.0000000000 * 0.0542029000 = 0.0519227174 
0.0098561911 * -0.0381861000 = 0.0515463479 
0.0000000000 * -0.8076480000 = 0.0515463479 
0.0000000000 * -0.0495538000 = 0.0515463479 
0.0000000000 * -0.5373960000 = 0.0515463479 
0.0000000000 * -0.0375613000 = 0.0515463479 
0.0000000000 * 0.0166447000 = 0.0515463479 
0.0000000000 * -6.5457900000 = 0.0515463479 
0.0000000000 * 0.3563090000 = 0.0515463479 
0.0000000000 * 0.0045975800 = 0.0515463479 
0.0000000000 * -2.6343700000 = 0.0515463479 
2.0550217898 * 0.0316671000 = 0.1166229284 
0.0000000000 * -0.0419871000 = 0.1166229284 
0.0000000000 * -2.6497200000 = 0.1166229284 
0.0000000000 * -0.0239046000 = 0.1166229284 
0.0000000000 * -0.0948108000 = 0.1166229284 
0.0000000000 * -3.5708100000 = 0.1166229284 
0.0000000000 * 0.1656730000 = 0.1166229284 
0.0000000000 * -0.0510214000 = 0.1166229284 
3.5937718848 * 0.0148107000 = 0.1698492057 
0.0000000000 * 0.2440740000 = 0.1698492057 
0.0000000000 * 0.8303100000 = 0.1698492057 
0.0000000000 * -0.0140578000 = 0.1698492057 
0.0000000000 * 0.0024111200 = 0.1698492057 
0.2629356409 * -0.0357477000 = 0.1604498613 
0.3574904745 * 0.0332610000 = 0.1723403519 
0.0000000000 * -0.1096690000 = 0.1723403519 
0.0000000000 * -0.7524810000 = 0.1723403519 
0.0000000000 * 0.0590674000 = 0.1723403519 
0.0000000000 * -5.8318700000 = 0.1723403519 
0.0000000000 * -0.9403600000 = 0.1723403519 
0.4076920016 * 0.0656999000 = 0.1991256757 
1.2353312302 * -0.2003560000 = -0.0483803483 
0.0000000000 * -0.0144436000 = -0.0483803483 
0.0000000000 * -0.7190370000 = -0.0483803483 
0.0000000000 * -0.3524920000 = -0.0483803483 
the biases is : -0.1836110000, now tempVal is : -0.2319913483
ReLU !!! in layer: 6, node : 37, its linear result is negative,so set it to 0
compute layer: 6, node : 38
0.3707124511 * -0.5723300000 = -0.2121698571 
0.0000000000 * 0.1199850000 = -0.2121698571 
0.0000000000 * 0.3470080000 = -0.2121698571 
0.0000000000 * -0.0191082000 = -0.2121698571 
0.0000000000 * -2.0265000000 = -0.2121698571 
0.0000000000 * -0.2416590000 = -0.2121698571 
0.0000000000 * 0.6646110000 = -0.2121698571 
0.0000000000 * -0.2865810000 = -0.2121698571 
0.0000000000 * -0.2383260000 = -0.2121698571 
0.0000000000 * 0.4564130000 = -0.2121698571 
1.1632586860 * -0.2031390000 = -0.4484730633 
0.0000000000 * 0.0038615500 = -0.4484730633 
0.0000000000 * 0.1732120000 = -0.4484730633 
0.0000000000 * 0.0784512000 = -0.4484730633 
0.0000000000 * -0.6441200000 = -0.4484730633 
0.0098561911 * 0.6557100000 = -0.4420102603 
0.0000000000 * -0.1506200000 = -0.4420102603 
0.0000000000 * 0.3271210000 = -0.4420102603 
0.0000000000 * -0.0142433000 = -0.4420102603 
0.0000000000 * 0.0678225000 = -0.4420102603 
0.0000000000 * 0.2429180000 = -0.4420102603 
0.0000000000 * -0.0326183000 = -0.4420102603 
0.0000000000 * -0.1078170000 = -0.4420102603 
0.0000000000 * 0.1421820000 = -0.4420102603 
0.0000000000 * -0.1358640000 = -0.4420102603 
2.0550217898 * -0.1005910000 = -0.6487269571 
0.0000000000 * 0.1546020000 = -0.6487269571 
0.0000000000 * 0.3121590000 = -0.6487269571 
0.0000000000 * 0.1826560000 = -0.6487269571 
0.0000000000 * 0.0081521600 = -0.6487269571 
0.0000000000 * 0.0247981000 = -0.6487269571 
0.0000000000 * -1.0697500000 = -0.6487269571 
0.0000000000 * -0.0563178000 = -0.6487269571 
3.5937718848 * -0.0715490000 = -0.9058577417 
0.0000000000 * 0.0988105000 = -0.9058577417 
0.0000000000 * 0.6339440000 = -0.9058577417 
0.0000000000 * 0.2583780000 = -0.9058577417 
0.0000000000 * -0.6665540000 = -0.9058577417 
0.2629356409 * 0.0846051000 = -0.8836120455 
0.3574904745 * 0.3535070000 = -0.7572366604 
0.0000000000 * 0.2993790000 = -0.7572366604 
0.0000000000 * 0.3249310000 = -0.7572366604 
0.0000000000 * 0.1211400000 = -0.7572366604 
0.0000000000 * 0.5701720000 = -0.7572366604 
0.0000000000 * 0.3671400000 = -0.7572366604 
0.4076920016 * -0.1579050000 = -0.8216132659 
1.2353312302 * 0.1439120000 = -0.6438342779 
0.0000000000 * -0.9172900000 = -0.6438342779 
0.0000000000 * -0.0504578000 = -0.6438342779 
0.0000000000 * 1.1836000000 = -0.6438342779 
the biases is : -0.5545340000, now tempVal is : -1.1983682779
ReLU !!! in layer: 6, node : 38, its linear result is negative,so set it to 0
compute layer: 6, node : 39
0.3707124511 * -0.5096070000 = -0.1889176601 
0.0000000000 * 0.5442260000 = -0.1889176601 
0.0000000000 * 0.0154673000 = -0.1889176601 
0.0000000000 * -0.0145282000 = -0.1889176601 
0.0000000000 * 0.1843820000 = -0.1889176601 
0.0000000000 * -0.0809191000 = -0.1889176601 
0.0000000000 * -3.3522800000 = -0.1889176601 
0.0000000000 * -0.3835760000 = -0.1889176601 
0.0000000000 * 0.0871236000 = -0.1889176601 
0.0000000000 * 0.0514583000 = -0.1889176601 
1.1632586860 * -0.1786090000 = -0.3966861307 
0.0000000000 * 0.2690010000 = -0.3966861307 
0.0000000000 * 0.6372780000 = -0.3966861307 
0.0000000000 * -0.1574800000 = -0.3966861307 
0.0000000000 * -0.0782848000 = -0.3966861307 
0.0098561911 * 0.0417276000 = -0.3962748555 
0.0000000000 * -0.9666540000 = -0.3962748555 
0.0000000000 * -0.0821287000 = -0.3962748555 
0.0000000000 * 0.3615210000 = -0.3962748555 
0.0000000000 * -0.2801470000 = -0.3962748555 
0.0000000000 * 0.0782106000 = -0.3962748555 
0.0000000000 * 0.0188711000 = -0.3962748555 
0.0000000000 * 0.3642490000 = -0.3962748555 
0.0000000000 * -0.0843884000 = -0.3962748555 
0.0000000000 * 0.2189020000 = -0.3962748555 
2.0550217898 * 0.0267508000 = -0.3413013786 
0.0000000000 * 0.0633992000 = -0.3413013786 
0.0000000000 * 0.0573536000 = -0.3413013786 
0.0000000000 * -0.0073751900 = -0.3413013786 
0.0000000000 * -0.0091526300 = -0.3413013786 
0.0000000000 * 0.0574642000 = -0.3413013786 
0.0000000000 * 0.0947067000 = -0.3413013786 
0.0000000000 * -0.0318040000 = -0.3413013786 
3.5937718848 * -0.0539626000 = -0.5352306533 
0.0000000000 * 0.0212412000 = -0.5352306533 
0.0000000000 * -0.4614270000 = -0.5352306533 
0.0000000000 * 0.0311155000 = -0.5352306533 
0.0000000000 * -0.0580483000 = -0.5352306533 
0.2629356409 * -0.2041210000 = -0.5889013393 
0.3574904745 * -0.1340770000 = -0.6368325896 
0.0000000000 * -0.1221870000 = -0.6368325896 
0.0000000000 * -0.8999070000 = -0.6368325896 
0.0000000000 * -0.1068850000 = -0.6368325896 
0.0000000000 * 0.0302970000 = -0.6368325896 
0.0000000000 * 0.0056222900 = -0.6368325896 
0.4076920016 * -0.0719945000 = -0.6661841714 
1.2353312302 * -0.0679367000 = -0.7501084986 
0.0000000000 * -0.0271104000 = -0.7501084986 
0.0000000000 * -0.0390149000 = -0.7501084986 
0.0000000000 * -0.0215531000 = -0.7501084986 
the biases is : 0.3398860000, now tempVal is : -0.4102224986
ReLU !!! in layer: 6, node : 39, its linear result is negative,so set it to 0
compute layer: 6, node : 40
0.3707124511 * -0.1485830000 = -0.0550815681 
0.0000000000 * -0.5990850000 = -0.0550815681 
0.0000000000 * -0.7024430000 = -0.0550815681 
0.0000000000 * -0.4087740000 = -0.0550815681 
0.0000000000 * -0.9924770000 = -0.0550815681 
0.0000000000 * -0.0329529000 = -0.0550815681 
0.0000000000 * -2.5828600000 = -0.0550815681 
0.0000000000 * -0.1822100000 = -0.0550815681 
0.0000000000 * 0.0183569000 = -0.0550815681 
0.0000000000 * -0.3879110000 = -0.0550815681 
1.1632586860 * 0.0675498000 = 0.0234963235 
0.0000000000 * -1.3498800000 = 0.0234963235 
0.0000000000 * 0.2753320000 = 0.0234963235 
0.0000000000 * 0.2504050000 = 0.0234963235 
0.0000000000 * -0.2926410000 = 0.0234963235 
0.0098561911 * 0.0489432000 = 0.0239787170 
0.0000000000 * -0.0473704000 = 0.0239787170 
0.0000000000 * -0.0428604000 = 0.0239787170 
0.0000000000 * 0.9947470000 = 0.0239787170 
0.0000000000 * -0.8085180000 = 0.0239787170 
0.0000000000 * -0.0651653000 = 0.0239787170 
0.0000000000 * 0.3487380000 = 0.0239787170 
0.0000000000 * 0.0046244600 = 0.0239787170 
0.0000000000 * -0.2202260000 = 0.0239787170 
0.0000000000 * 0.5852670000 = 0.0239787170 
2.0550217898 * -0.3447580000 = -0.6845064852 
0.0000000000 * 0.2182150000 = -0.6845064852 
0.0000000000 * -0.0156779000 = -0.6845064852 
0.0000000000 * -0.2816560000 = -0.6845064852 
0.0000000000 * -0.8642330000 = -0.6845064852 
0.0000000000 * -2.1465300000 = -0.6845064852 
0.0000000000 * 0.4195380000 = -0.6845064852 
0.0000000000 * -0.0505128000 = -0.6845064852 
3.5937718848 * 0.0609912000 = -0.4653180254 
0.0000000000 * 0.1950510000 = -0.4653180254 
0.0000000000 * 0.2582630000 = -0.4653180254 
0.0000000000 * 0.0456483000 = -0.4653180254 
0.0000000000 * -0.2548890000 = -0.4653180254 
0.2629356409 * -0.6693600000 = -0.6413166260 
0.3574904745 * 0.0805366000 = -0.6125255587 
0.0000000000 * -0.3211720000 = -0.6125255587 
0.0000000000 * -0.0321280000 = -0.6125255587 
0.0000000000 * -0.1141230000 = -0.6125255587 
0.0000000000 * -0.1395920000 = -0.6125255587 
0.0000000000 * -0.1229010000 = -0.6125255587 
0.4076920016 * -0.0277908000 = -0.6238556455 
1.2353312302 * 0.0041706800 = -0.6187034743 
0.0000000000 * -0.0443716000 = -0.6187034743 
0.0000000000 * -0.0890137000 = -0.6187034743 
0.0000000000 * -1.1650900000 = -0.6187034743 
the biases is : 0.3666400000, now tempVal is : -0.2520634743
ReLU !!! in layer: 6, node : 40, its linear result is negative,so set it to 0
compute layer: 6, node : 41
0.3707124511 * 1.6307300000 = 0.6045319153 
0.0000000000 * -0.8043040000 = 0.6045319153 
0.0000000000 * 0.5544470000 = 0.6045319153 
0.0000000000 * 0.4466090000 = 0.6045319153 
0.0000000000 * 1.5816100000 = 0.6045319153 
0.0000000000 * -2.1698100000 = 0.6045319153 
0.0000000000 * -0.0025987500 = 0.6045319153 
0.0000000000 * 1.1656800000 = 0.6045319153 
0.0000000000 * 0.7459520000 = 0.6045319153 
0.0000000000 * -2.1955100000 = 0.6045319153 
1.1632586860 * -0.2776700000 = 0.2815298760 
0.0000000000 * 0.3016810000 = 0.2815298760 
0.0000000000 * 0.8913710000 = 0.2815298760 
0.0000000000 * 0.1338260000 = 0.2815298760 
0.0000000000 * 0.4709000000 = 0.2815298760 
0.0098561911 * 0.8516710000 = 0.2899241081 
0.0000000000 * -0.1786970000 = 0.2899241081 
0.0000000000 * -0.3760010000 = 0.2899241081 
0.0000000000 * 0.1140820000 = 0.2899241081 
0.0000000000 * 0.0091106000 = 0.2899241081 
0.0000000000 * -0.1762730000 = 0.2899241081 
0.0000000000 * -0.0810104000 = 0.2899241081 
0.0000000000 * -1.4504500000 = 0.2899241081 
0.0000000000 * 0.3431410000 = 0.2899241081 
0.0000000000 * 0.8203830000 = 0.2899241081 
2.0550217898 * -0.7695500000 = -1.2915179102 
0.0000000000 * -0.3128800000 = -1.2915179102 
0.0000000000 * -1.2323100000 = -1.2915179102 
0.0000000000 * 0.0756924000 = -1.2915179102 
0.0000000000 * -0.7431300000 = -1.2915179102 
0.0000000000 * -0.9518570000 = -1.2915179102 
0.0000000000 * -0.3917960000 = -1.2915179102 
0.0000000000 * -0.4205420000 = -1.2915179102 
3.5937718848 * -0.6940050000 = -3.7856135671 
0.0000000000 * -0.7500380000 = -3.7856135671 
0.0000000000 * 0.3697180000 = -3.7856135671 
0.0000000000 * -0.2425080000 = -3.7856135671 
0.0000000000 * -0.9705630000 = -3.7856135671 
0.2629356409 * 0.1426060000 = -3.7481173671 
0.3574904745 * -0.1436300000 = -3.7994637240 
0.0000000000 * -0.6462700000 = -3.7994637240 
0.0000000000 * -2.7615600000 = -3.7994637240 
0.0000000000 * -0.3891720000 = -3.7994637240 
0.0000000000 * -3.0093700000 = -3.7994637240 
0.0000000000 * -0.2072660000 = -3.7994637240 
0.4076920016 * -0.2764760000 = -3.9121807778 
1.2353312302 * -1.2025700000 = -5.3977530553 
0.0000000000 * 0.3349380000 = -5.3977530553 
0.0000000000 * -0.0062570900 = -5.3977530553 
0.0000000000 * -3.0679900000 = -5.3977530553 
the biases is : 1.1872500000, now tempVal is : -4.2105030553
ReLU !!! in layer: 6, node : 41, its linear result is negative,so set it to 0
compute layer: 6, node : 42
0.3707124511 * -2.6560600000 = -0.9846345128 
0.0000000000 * -0.1101620000 = -0.9846345128 
0.0000000000 * 4.1835900000 = -0.9846345128 
0.0000000000 * 0.2503440000 = -0.9846345128 
0.0000000000 * -0.1280010000 = -0.9846345128 
0.0000000000 * 0.1973100000 = -0.9846345128 
0.0000000000 * 0.4073680000 = -0.9846345128 
0.0000000000 * -3.0836700000 = -0.9846345128 
0.0000000000 * -4.6513100000 = -0.9846345128 
0.0000000000 * -0.5814630000 = -0.9846345128 
1.1632586860 * 0.1625850000 = -0.7955060994 
0.0000000000 * 0.5867480000 = -0.7955060994 
0.0000000000 * -1.8140800000 = -0.7955060994 
0.0000000000 * 0.7493740000 = -0.7955060994 
0.0000000000 * 0.0016042300 = -0.7955060994 
0.0098561911 * -0.9295960000 = -0.8046683752 
0.0000000000 * 1.6117200000 = -0.8046683752 
0.0000000000 * 1.2567600000 = -0.8046683752 
0.0000000000 * 2.2856500000 = -0.8046683752 
0.0000000000 * -0.0398001000 = -0.8046683752 
0.0000000000 * 0.6030380000 = -0.8046683752 
0.0000000000 * -1.1799900000 = -0.8046683752 
0.0000000000 * 2.7175500000 = -0.8046683752 
0.0000000000 * -3.9583600000 = -0.8046683752 
0.0000000000 * -7.0118000000 = -0.8046683752 
2.0550217898 * -0.1613520000 = -1.1362502510 
0.0000000000 * -3.7696500000 = -1.1362502510 
0.0000000000 * 1.6382700000 = -1.1362502510 
0.0000000000 * 0.4924330000 = -1.1362502510 
0.0000000000 * -0.0876016000 = -1.1362502510 
0.0000000000 * 0.7952900000 = -1.1362502510 
0.0000000000 * 2.4741300000 = -1.1362502510 
0.0000000000 * -3.1453700000 = -1.1362502510 
3.5937718848 * -3.8241400000 = -14.8793370666 
0.0000000000 * -0.9711820000 = -14.8793370666 
0.0000000000 * 0.3778990000 = -14.8793370666 
0.0000000000 * 1.2878000000 = -14.8793370666 
0.0000000000 * -4.0102500000 = -14.8793370666 
0.2629356409 * 4.6771100000 = -13.6495581512 
0.3574904745 * 0.3269990000 = -13.5326591235 
0.0000000000 * -0.9817850000 = -13.5326591235 
0.0000000000 * 3.0845600000 = -13.5326591235 
0.0000000000 * -4.8375000000 = -13.5326591235 
0.0000000000 * 5.2799200000 = -13.5326591235 
0.0000000000 * -0.1757510000 = -13.5326591235 
0.4076920016 * -0.7545870000 = -13.8402982079 
1.2353312302 * -17.0620000000 = -34.9175196574 
0.0000000000 * -0.4209000000 = -34.9175196574 
0.0000000000 * -0.0943849000 = -34.9175196574 
0.0000000000 * 2.1123500000 = -34.9175196574 
the biases is : -7.0066000000, now tempVal is : -41.9241196574
ReLU !!! in layer: 6, node : 42, its linear result is negative,so set it to 0
compute layer: 6, node : 43
0.3707124511 * -0.8457340000 = -0.3135241241 
0.0000000000 * -3.7655000000 = -0.3135241241 
0.0000000000 * -2.9620700000 = -0.3135241241 
0.0000000000 * -1.0537300000 = -0.3135241241 
0.0000000000 * -1.7794500000 = -0.3135241241 
0.0000000000 * 0.0917443000 = -0.3135241241 
0.0000000000 * -1.5631000000 = -0.3135241241 
0.0000000000 * 0.3086090000 = -0.3135241241 
0.0000000000 * -0.8565010000 = -0.3135241241 
0.0000000000 * 0.4987900000 = -0.3135241241 
1.1632586860 * 0.1933440000 = -0.0886150367 
0.0000000000 * 0.1733460000 = -0.0886150367 
0.0000000000 * -2.0115400000 = -0.0886150367 
0.0000000000 * 0.3203830000 = -0.0886150367 
0.0000000000 * -1.9257800000 = -0.0886150367 
0.0098561911 * 0.4150640000 = -0.0845240866 
0.0000000000 * 0.0893473000 = -0.0845240866 
0.0000000000 * -0.8469330000 = -0.0845240866 
0.0000000000 * 0.6071450000 = -0.0845240866 
0.0000000000 * 0.0033676100 = -0.0845240866 
0.0000000000 * -3.2711900000 = -0.0845240866 
0.0000000000 * 0.4116030000 = -0.0845240866 
0.0000000000 * -0.9619120000 = -0.0845240866 
0.0000000000 * -2.1444900000 = -0.0845240866 
0.0000000000 * 0.5014030000 = -0.0845240866 
2.0550217898 * -1.2420800000 = -2.6370255513 
0.0000000000 * 0.3615090000 = -2.6370255513 
0.0000000000 * -0.2151890000 = -2.6370255513 
0.0000000000 * -0.3876030000 = -2.6370255513 
0.0000000000 * -3.0182300000 = -2.6370255513 
0.0000000000 * -7.5560800000 = -2.6370255513 
0.0000000000 * -1.0651000000 = -2.6370255513 
0.0000000000 * -1.2201900000 = -2.6370255513 
3.5937718848 * 0.2617760000 = -1.6962623223 
0.0000000000 * 3.4372700000 = -1.6962623223 
0.0000000000 * 1.0251100000 = -1.6962623223 
0.0000000000 * 0.1129770000 = -1.6962623223 
0.0000000000 * -0.3404760000 = -1.6962623223 
0.2629356409 * -0.7304560000 = -1.8883252388 
0.3574904745 * 0.0116046000 = -1.8841767049 
0.0000000000 * -0.6258540000 = -1.8841767049 
0.0000000000 * 0.8322650000 = -1.8841767049 
0.0000000000 * -1.5653600000 = -1.8841767049 
0.0000000000 * -4.6707700000 = -1.8841767049 
0.0000000000 * -0.5592360000 = -1.8841767049 
0.4076920016 * -0.2265410000 = -1.9765356586 
1.2353312302 * -1.1333400000 = -3.3765859550 
0.0000000000 * -0.4626850000 = -3.3765859550 
0.0000000000 * -1.1191200000 = -3.3765859550 
0.0000000000 * 0.9063070000 = -3.3765859550 
the biases is : 0.8648160000, now tempVal is : -2.5117699550
ReLU !!! in layer: 6, node : 43, its linear result is negative,so set it to 0
compute layer: 6, node : 44
0.3707124511 * -1.0065100000 = -0.3731257891 
0.0000000000 * -3.0028700000 = -0.3731257891 
0.0000000000 * 2.4132200000 = -0.3731257891 
0.0000000000 * -0.7557370000 = -0.3731257891 
0.0000000000 * 1.9588900000 = -0.3731257891 
0.0000000000 * 1.0044200000 = -0.3731257891 
0.0000000000 * -0.1333610000 = -0.3731257891 
0.0000000000 * -2.2077200000 = -0.3731257891 
0.0000000000 * -5.1630400000 = -0.3731257891 
0.0000000000 * 0.7014450000 = -0.3731257891 
1.1632586860 * -0.7886000000 = -1.2904715889 
0.0000000000 * -0.3747000000 = -1.2904715889 
0.0000000000 * -4.1113300000 = -1.2904715889 
0.0000000000 * 0.3802280000 = -1.2904715889 
0.0000000000 * -7.2239000000 = -1.2904715889 
0.0098561911 * 0.0115643000 = -1.2903576089 
0.0000000000 * -0.1158820000 = -1.2903576089 
0.0000000000 * -1.3054500000 = -1.2903576089 
0.0000000000 * 1.0906800000 = -1.2903576089 
0.0000000000 * -1.2326800000 = -1.2903576089 
0.0000000000 * -0.0281065000 = -1.2903576089 
0.0000000000 * 1.9534700000 = -1.2903576089 
0.0000000000 * -0.4065340000 = -1.2903576089 
0.0000000000 * -1.6187700000 = -1.2903576089 
0.0000000000 * -2.7856200000 = -1.2903576089 
2.0550217898 * -2.3923000000 = -6.2065862366 
0.0000000000 * -8.6219800000 = -6.2065862366 
0.0000000000 * 1.4920200000 = -6.2065862366 
0.0000000000 * 1.4606800000 = -6.2065862366 
0.0000000000 * 0.1463530000 = -6.2065862366 
0.0000000000 * -1.3459000000 = -6.2065862366 
0.0000000000 * 1.0416000000 = -6.2065862366 
0.0000000000 * 0.2991850000 = -6.2065862366 
3.5937718848 * -2.5763800000 = -15.4655082452 
0.0000000000 * 2.4909400000 = -15.4655082452 
0.0000000000 * -6.6570500000 = -15.4655082452 
0.0000000000 * -0.3404650000 = -15.4655082452 
0.0000000000 * -1.2137200000 = -15.4655082452 
0.2629356409 * -0.2057290000 = -15.5196017317 
0.3574904745 * 0.8702910000 = -15.2084809892 
0.0000000000 * -2.3417700000 = -15.2084809892 
0.0000000000 * 1.9009400000 = -15.2084809892 
0.0000000000 * -0.5777300000 = -15.2084809892 
0.0000000000 * -1.2974700000 = -15.2084809892 
0.0000000000 * -0.0268709000 = -15.2084809892 
0.4076920016 * 0.5589050000 = -14.9806198910 
1.2353312302 * -1.2365500000 = -16.5081687237 
0.0000000000 * 0.1609450000 = -16.5081687237 
0.0000000000 * 0.4592120000 = -16.5081687237 
0.0000000000 * -0.1674830000 = -16.5081687237 
the biases is : -4.0866500000, now tempVal is : -20.5948187237
ReLU !!! in layer: 6, node : 44, its linear result is negative,so set it to 0
compute layer: 6, node : 45
0.3707124511 * -0.0494978000 = -0.0183494508 
0.0000000000 * 0.3803650000 = -0.0183494508 
0.0000000000 * 0.3115370000 = -0.0183494508 
0.0000000000 * -0.0403161000 = -0.0183494508 
0.0000000000 * 0.0266516000 = -0.0183494508 
0.0000000000 * -0.0319796000 = -0.0183494508 
0.0000000000 * 0.0704170000 = -0.0183494508 
0.0000000000 * 0.0334328000 = -0.0183494508 
0.0000000000 * 0.0923320000 = -0.0183494508 
0.0000000000 * 0.0075794700 = -0.0183494508 
1.1632586860 * -0.1398580000 = -0.1810404841 
0.0000000000 * 0.0945668000 = -0.1810404841 
0.0000000000 * 0.1534760000 = -0.1810404841 
0.0000000000 * -0.0073858900 = -0.1810404841 
0.0000000000 * -0.0372646000 = -0.1810404841 
0.0098561911 * 0.1994120000 = -0.1790750413 
0.0000000000 * -0.0171761000 = -0.1790750413 
0.0000000000 * -0.1277850000 = -0.1790750413 
0.0000000000 * 0.1260300000 = -0.1790750413 
0.0000000000 * -0.1193540000 = -0.1790750413 
0.0000000000 * 0.0284966000 = -0.1790750413 
0.0000000000 * -0.1956490000 = -0.1790750413 
0.0000000000 * 0.2792320000 = -0.1790750413 
0.0000000000 * -0.0142558000 = -0.1790750413 
0.0000000000 * 0.0019894100 = -0.1790750413 
2.0550217898 * 0.2498230000 = 0.3343166673 
0.0000000000 * 0.0961600000 = 0.3343166673 
0.0000000000 * -0.0161666000 = 0.3343166673 
0.0000000000 * 0.0078811900 = 0.3343166673 
0.0000000000 * 0.0371048000 = 0.3343166673 
0.0000000000 * -0.3610130000 = 0.3343166673 
0.0000000000 * -0.0524793000 = 0.3343166673 
0.0000000000 * 0.0973183000 = 0.3343166673 
3.5937718848 * -0.1815180000 = -0.3180176177 
0.0000000000 * -0.1402210000 = -0.3180176177 
0.0000000000 * 0.1698710000 = -0.3180176177 
0.0000000000 * 0.0274222000 = -0.3180176177 
0.0000000000 * -0.0382272000 = -0.3180176177 
0.2629356409 * 0.0927616000 = -0.2936272869 
0.3574904745 * 0.0234133000 = -0.2852572552 
0.0000000000 * 0.2806180000 = -0.2852572552 
0.0000000000 * -0.4749180000 = -0.2852572552 
0.0000000000 * 0.0085139400 = -0.2852572552 
0.0000000000 * -0.1747660000 = -0.2852572552 
0.0000000000 * -0.0373201000 = -0.2852572552 
0.4076920016 * 0.0115171000 = -0.2805618257 
1.2353312302 * 0.0367524000 = -0.2351604382 
0.0000000000 * 0.0213810000 = -0.2351604382 
0.0000000000 * -0.0788198000 = -0.2351604382 
0.0000000000 * 0.0192415000 = -0.2351604382 
the biases is : 0.1906570000, now tempVal is : -0.0445034382
ReLU !!! in layer: 6, node : 45, its linear result is negative,so set it to 0
compute layer: 6, node : 46
0.3707124511 * 0.0079671400 = 0.0029535180 
0.0000000000 * -1.7387200000 = 0.0029535180 
0.0000000000 * 0.3021380000 = 0.0029535180 
0.0000000000 * 0.0273523000 = 0.0029535180 
0.0000000000 * -0.6682150000 = 0.0029535180 
0.0000000000 * 0.0270449000 = 0.0029535180 
0.0000000000 * 0.6207690000 = 0.0029535180 
0.0000000000 * 0.1131300000 = 0.0029535180 
0.0000000000 * -0.0451071000 = 0.0029535180 
0.0000000000 * 0.0761224000 = 0.0029535180 
1.1632586860 * -0.0277418000 = -0.0293173718 
0.0000000000 * -0.8653480000 = -0.0293173718 
0.0000000000 * -0.0580881000 = -0.0293173718 
0.0000000000 * 0.0140428000 = -0.0293173718 
0.0000000000 * 0.0447047000 = -0.0293173718 
0.0098561911 * 0.1527550000 = -0.0278117893 
0.0000000000 * -0.0139794000 = -0.0278117893 
0.0000000000 * 0.0219355000 = -0.0278117893 
0.0000000000 * -0.1935200000 = -0.0278117893 
0.0000000000 * 0.3817520000 = -0.0278117893 
0.0000000000 * -0.0135727000 = -0.0278117893 
0.0000000000 * 0.0779330000 = -0.0278117893 
0.0000000000 * 0.3418530000 = -0.0278117893 
0.0000000000 * -0.0000392433 = -0.0278117893 
0.0000000000 * -0.3983440000 = -0.0278117893 
2.0550217898 * 0.1687680000 = 0.3190101281 
0.0000000000 * 0.2016580000 = 0.3190101281 
0.0000000000 * -0.0512623000 = 0.3190101281 
0.0000000000 * 0.0014257200 = 0.3190101281 
0.0000000000 * 0.0633812000 = 0.3190101281 
0.0000000000 * -0.2061130000 = 0.3190101281 
0.0000000000 * -0.0441063000 = 0.3190101281 
0.0000000000 * -0.0509791000 = 0.3190101281 
3.5937718848 * -0.0487121000 = 0.1439499526 
0.0000000000 * 0.1229940000 = 0.1439499526 
0.0000000000 * 0.1609820000 = 0.1439499526 
0.0000000000 * -0.0080119700 = 0.1439499526 
0.0000000000 * -0.0288684000 = 0.1439499526 
0.2629356409 * 0.0713987000 = 0.1627232156 
0.3574904745 * 0.0172814000 = 0.1689011515 
0.0000000000 * -0.0851666000 = 0.1689011515 
0.0000000000 * -0.3164980000 = 0.1689011515 
0.0000000000 * -0.0744347000 = 0.1689011515 
0.0000000000 * -0.2230290000 = 0.1689011515 
0.0000000000 * -0.0180281000 = 0.1689011515 
0.4076920016 * -0.0963453000 = 0.1296219433 
1.2353312302 * -1.1581600000 = -1.3010892743 
0.0000000000 * 0.0444255000 = -1.3010892743 
0.0000000000 * 0.0531705000 = -1.3010892743 
0.0000000000 * -0.1030170000 = -1.3010892743 
the biases is : 0.4389840000, now tempVal is : -0.8621052743
ReLU !!! in layer: 6, node : 46, its linear result is negative,so set it to 0
compute layer: 6, node : 47
0.3707124511 * -0.7104250000 = -0.2633633931 
0.0000000000 * 0.0589588000 = -0.2633633931 
0.0000000000 * 0.2004750000 = -0.2633633931 
0.0000000000 * -0.0300580000 = -0.2633633931 
0.0000000000 * 0.5427280000 = -0.2633633931 
0.0000000000 * -0.1919940000 = -0.2633633931 
0.0000000000 * 0.3940990000 = -0.2633633931 
0.0000000000 * -0.1366880000 = -0.2633633931 
0.0000000000 * -0.0801518000 = -0.2633633931 
0.0000000000 * 0.2881790000 = -0.2633633931 
1.1632586860 * -0.0730109000 = -0.3482939567 
0.0000000000 * -0.0055850700 = -0.3482939567 
0.0000000000 * 0.2438350000 = -0.3482939567 
0.0000000000 * 0.0529102000 = -0.3482939567 
0.0000000000 * -0.3652270000 = -0.3482939567 
0.0098561911 * 0.3975180000 = -0.3443759433 
0.0000000000 * -0.4755050000 = -0.3443759433 
0.0000000000 * 0.1425840000 = -0.3443759433 
0.0000000000 * -0.0151283000 = -0.3443759433 
0.0000000000 * 0.2453320000 = -0.3443759433 
0.0000000000 * 0.1521830000 = -0.3443759433 
0.0000000000 * -0.0735228000 = -0.3443759433 
0.0000000000 * 0.1122770000 = -0.3443759433 
0.0000000000 * 0.0205124000 = -0.3443759433 
0.0000000000 * -0.0720063000 = -0.3443759433 
2.0550217898 * -0.1336000000 = -0.6189268544 
0.0000000000 * 0.0517994000 = -0.6189268544 
0.0000000000 * 0.1730520000 = -0.6189268544 
0.0000000000 * 0.1110220000 = -0.6189268544 
0.0000000000 * 0.0165345000 = -0.6189268544 
0.0000000000 * 0.0103496000 = -0.6189268544 
0.0000000000 * -0.4696090000 = -0.6189268544 
0.0000000000 * -0.0323967000 = -0.6189268544 
3.5937718848 * -0.0194593000 = -0.6888591396 
0.0000000000 * 0.1064480000 = -0.6888591396 
0.0000000000 * -0.3539010000 = -0.6888591396 
0.0000000000 * 0.1436770000 = -0.6888591396 
0.0000000000 * -0.2381620000 = -0.6888591396 
0.2629356409 * 0.1591080000 = -0.6470239757 
0.3574904745 * 0.0689775000 = -0.6223651765 
0.0000000000 * 0.1086600000 = -0.6223651765 
0.0000000000 * 0.3519130000 = -0.6223651765 
0.0000000000 * -0.0641982000 = -0.6223651765 
0.0000000000 * 0.2688250000 = -0.6223651765 
0.0000000000 * 0.2020580000 = -0.6223651765 
0.4076920016 * -0.0814643000 = -0.6555775200 
1.2353312302 * -0.0037932200 = -0.6602634031 
0.0000000000 * -0.4113560000 = -0.6602634031 
0.0000000000 * 0.0126708000 = -0.6602634031 
0.0000000000 * 0.5607900000 = -0.6602634031 
the biases is : -0.6647890000, now tempVal is : -1.3250524031
ReLU !!! in layer: 6, node : 47, its linear result is negative,so set it to 0
compute layer: 6, node : 48
0.3707124511 * -0.2839840000 = -0.1052764047 
0.0000000000 * 0.2416020000 = -0.1052764047 
0.0000000000 * 0.0244167000 = -0.1052764047 
0.0000000000 * -0.0294464000 = -0.1052764047 
0.0000000000 * -0.4540100000 = -0.1052764047 
0.0000000000 * 0.6120810000 = -0.1052764047 
0.0000000000 * 1.1034400000 = -0.1052764047 
0.0000000000 * -0.0975357000 = -0.1052764047 
0.0000000000 * 0.0776575000 = -0.1052764047 
0.0000000000 * -0.0140490000 = -0.1052764047 
1.1632586860 * 0.0506629000 = -0.0463423462 
0.0000000000 * 1.1092200000 = -0.0463423462 
0.0000000000 * 0.2693110000 = -0.0463423462 
0.0000000000 * 0.0703949000 = -0.0463423462 
0.0000000000 * -0.0164147000 = -0.0463423462 
0.0098561911 * 0.2256360000 = -0.0441184347 
0.0000000000 * -0.0106372000 = -0.0441184347 
0.0000000000 * 0.4286200000 = -0.0441184347 
0.0000000000 * 0.1372190000 = -0.0441184347 
0.0000000000 * -0.3056460000 = -0.0441184347 
0.0000000000 * -0.0198569000 = -0.0441184347 
0.0000000000 * 0.0589249000 = -0.0441184347 
0.0000000000 * -0.0879514000 = -0.0441184347 
0.0000000000 * 0.0662081000 = -0.0441184347 
0.0000000000 * 0.1874280000 = -0.0441184347 
2.0550217898 * 0.4975400000 = 0.9783371066 
0.0000000000 * -0.0166954000 = 0.9783371066 
0.0000000000 * -0.2337020000 = 0.9783371066 
0.0000000000 * 0.0127740000 = 0.9783371066 
0.0000000000 * 0.0475872000 = 0.9783371066 
0.0000000000 * -0.2816380000 = 0.9783371066 
0.0000000000 * -0.7549770000 = 0.9783371066 
0.0000000000 * 0.0315460000 = 0.9783371066 
3.5937718848 * -0.4267950000 = -0.5554667650 
0.0000000000 * 0.0827129000 = -0.5554667650 
0.0000000000 * 1.4567000000 = -0.5554667650 
0.0000000000 * 0.0694925000 = -0.5554667650 
0.0000000000 * -0.1172420000 = -0.5554667650 
0.2629356409 * 0.0794632000 = -0.5345730576 
0.3574904745 * -0.0213157000 = -0.5421932173 
0.0000000000 * 0.0125247000 = -0.5421932173 
0.0000000000 * -0.1078470000 = -0.5421932173 
0.0000000000 * -0.0239133000 = -0.5421932173 
0.0000000000 * -0.3150950000 = -0.5421932173 
0.0000000000 * -0.1719070000 = -0.5421932173 
0.4076920016 * 0.0486965000 = -0.5223400437 
1.2353312302 * -0.0274579000 = -0.5562596451 
0.0000000000 * 0.0293453000 = -0.5562596451 
0.0000000000 * -0.0325373000 = -0.5562596451 
0.0000000000 * -0.4146090000 = -0.5562596451 
the biases is : -0.1143470000, now tempVal is : -0.6706066451
ReLU !!! in layer: 6, node : 48, its linear result is negative,so set it to 0
compute layer: 6, node : 49
0.3707124511 * 0.0114592000 = 0.0042480681 
0.0000000000 * 0.7350280000 = 0.0042480681 
0.0000000000 * -0.0564581000 = 0.0042480681 
0.0000000000 * -0.1723340000 = 0.0042480681 
0.0000000000 * -0.4959450000 = 0.0042480681 
0.0000000000 * -0.0163565000 = 0.0042480681 
0.0000000000 * 0.6720660000 = 0.0042480681 
0.0000000000 * -0.0016296600 = 0.0042480681 
0.0000000000 * -0.5963250000 = 0.0042480681 
0.0000000000 * -0.0416657000 = 0.0042480681 
1.1632586860 * 0.0461259000 = 0.0579044219 
0.0000000000 * 1.1010900000 = 0.0579044219 
0.0000000000 * 0.1028060000 = 0.0579044219 
0.0000000000 * -0.0657672000 = 0.0579044219 
0.0000000000 * 0.0904383000 = 0.0579044219 
0.0098561911 * -0.2111080000 = 0.0558237012 
0.0000000000 * 0.1430760000 = 0.0558237012 
0.0000000000 * -0.2141330000 = 0.0558237012 
0.0000000000 * 0.2972000000 = 0.0558237012 
0.0000000000 * -0.1529290000 = 0.0558237012 
0.0000000000 * -0.0058831500 = 0.0558237012 
0.0000000000 * 0.3353900000 = 0.0558237012 
0.0000000000 * 0.0239746000 = 0.0558237012 
0.0000000000 * 0.0013689300 = 0.0558237012 
0.0000000000 * 0.2485770000 = 0.0558237012 
2.0550217898 * -0.0206479000 = 0.0133918167 
0.0000000000 * -0.0065506800 = 0.0133918167 
0.0000000000 * -0.0588651000 = 0.0133918167 
0.0000000000 * 0.1490660000 = 0.0133918167 
0.0000000000 * -0.4574910000 = 0.0133918167 
0.0000000000 * -0.3491090000 = 0.0133918167 
0.0000000000 * 0.0148945000 = 0.0133918167 
0.0000000000 * 0.0044957200 = 0.0133918167 
3.5937718848 * 0.0024400400 = 0.0221607639 
0.0000000000 * 0.2713250000 = 0.0221607639 
0.0000000000 * -0.0623069000 = 0.0221607639 
0.0000000000 * -0.0212814000 = 0.0221607639 
0.0000000000 * 0.0137222000 = 0.0221607639 
0.2629356409 * 0.0234307000 = 0.0283215300 
0.3574904745 * -0.0201943000 = 0.0211022601 
0.0000000000 * -0.1438010000 = 0.0211022601 
0.0000000000 * -0.1063210000 = 0.0211022601 
0.0000000000 * -0.0194373000 = 0.0211022601 
0.0000000000 * -0.2886830000 = 0.0211022601 
0.0000000000 * 0.0618199000 = 0.0211022601 
0.4076920016 * -0.0463239000 = 0.0022163766 
1.2353312302 * -0.0121636000 = -0.0128096983 
0.0000000000 * -0.0156882000 = -0.0128096983 
0.0000000000 * -0.0054869500 = -0.0128096983 
0.0000000000 * 0.0193332000 = -0.0128096983 
the biases is : 0.1217060000, now tempVal is : 0.1088963017

now we get all result in layer: 6
	node: 0, val: 0.0000000000
	node: 1, val: 0.0000000000
	node: 2, val: 0.0000000000
	node: 3, val: 0.0000000000
	node: 4, val: 0.0000000000
	node: 5, val: 0.0000000000
	node: 6, val: 0.0000000000
	node: 7, val: 0.0000000000
	node: 8, val: 0.0000000000
	node: 9, val: 0.0000000000
	node: 10, val: 0.0000000000
	node: 11, val: 0.0000000000
	node: 12, val: 0.0000000000
	node: 13, val: 0.0000000000
	node: 14, val: 0.0000000000
	node: 15, val: 0.0000000000
	node: 16, val: 0.0000000000
	node: 17, val: 0.0000000000
	node: 18, val: 0.0000000000
	node: 19, val: 0.0000000000
	node: 20, val: 0.0000000000
	node: 21, val: 0.0000000000
	node: 22, val: 0.0000000000
	node: 23, val: 0.0000000000
	node: 24, val: 0.0000000000
	node: 25, val: 0.1654453317
	node: 26, val: 0.0000000000
	node: 27, val: 0.0000000000
	node: 28, val: 0.0000000000
	node: 29, val: 0.0000000000
	node: 30, val: 0.0000000000
	node: 31, val: 0.0000000000
	node: 32, val: 0.0000000000
	node: 33, val: 0.0000000000
	node: 34, val: 0.0000000000
	node: 35, val: 0.0000000000
	node: 36, val: 0.0000000000
	node: 37, val: 0.0000000000
	node: 38, val: 0.0000000000
	node: 39, val: 0.0000000000
	node: 40, val: 0.0000000000
	node: 41, val: 0.0000000000
	node: 42, val: 0.0000000000
	node: 43, val: 0.0000000000
	node: 44, val: 0.0000000000
	node: 45, val: 0.0000000000
	node: 46, val: 0.0000000000
	node: 47, val: 0.0000000000
	node: 48, val: 0.0000000000
	node: 49, val: 0.1088963017

when compute layer[6] to layer[7]
compute layer: 7, node : 0
0.0000000000 * -0.0010049000 = 0.0000000000 
0.0000000000 * 0.0177588000 = 0.0000000000 
0.0000000000 * 0.0064468400 = 0.0000000000 
0.0000000000 * 0.0100598000 = 0.0000000000 
0.0000000000 * 0.0021575100 = 0.0000000000 
0.0000000000 * 0.0241695000 = 0.0000000000 
0.0000000000 * 0.0207160000 = 0.0000000000 
0.0000000000 * 0.0032534800 = 0.0000000000 
0.0000000000 * 0.0376957000 = 0.0000000000 
0.0000000000 * 0.0537383000 = 0.0000000000 
0.0000000000 * 0.0039666700 = 0.0000000000 
0.0000000000 * 0.0002951710 = 0.0000000000 
0.0000000000 * 0.0084411800 = 0.0000000000 
0.0000000000 * 0.0043004800 = 0.0000000000 
0.0000000000 * 0.0000553546 = 0.0000000000 
0.0000000000 * 0.0270628000 = 0.0000000000 
0.0000000000 * 0.0042298300 = 0.0000000000 
0.0000000000 * -0.0169606000 = 0.0000000000 
0.0000000000 * 0.0043399800 = 0.0000000000 
0.0000000000 * 0.0567525000 = 0.0000000000 
0.0000000000 * 0.0600247000 = 0.0000000000 
0.0000000000 * 0.0347097000 = 0.0000000000 
0.0000000000 * 0.0010463400 = 0.0000000000 
0.0000000000 * 0.0092596900 = 0.0000000000 
0.0000000000 * 0.0104904000 = 0.0000000000 
0.1654453317 * -0.0627135000 = -0.0103756558 
0.0000000000 * 0.0129801000 = -0.0103756558 
0.0000000000 * 0.1431070000 = -0.0103756558 
0.0000000000 * 0.0001559330 = -0.0103756558 
0.0000000000 * 0.0090970100 = -0.0103756558 
0.0000000000 * 0.1869670000 = -0.0103756558 
0.0000000000 * 0.0109487000 = -0.0103756558 
0.0000000000 * -0.0154135000 = -0.0103756558 
0.0000000000 * 0.3664180000 = -0.0103756558 
0.0000000000 * -0.0046488100 = -0.0103756558 
0.0000000000 * -0.0105615000 = -0.0103756558 
0.0000000000 * 0.0346626000 = -0.0103756558 
0.0000000000 * 0.0354153000 = -0.0103756558 
0.0000000000 * -0.0007777260 = -0.0103756558 
0.0000000000 * 0.0038574000 = -0.0103756558 
0.0000000000 * 0.0041907300 = -0.0103756558 
0.0000000000 * -0.0172908000 = -0.0103756558 
0.0000000000 * 0.0062802200 = -0.0103756558 
0.0000000000 * -0.0146312000 = -0.0103756558 
0.0000000000 * 0.0052684300 = -0.0103756558 
0.0000000000 * 0.0235743000 = -0.0103756558 
0.0000000000 * 0.0181072000 = -0.0103756558 
0.0000000000 * -0.0011484100 = -0.0103756558 
0.0000000000 * 0.0116412000 = -0.0103756558 
0.1088963017 * -0.0049745200 = -0.0109173626 
the biases is : -0.0102815000, now tempVal is : -0.0211988626
compute layer: 7, node : 1
0.0000000000 * -0.0016092300 = 0.0000000000 
0.0000000000 * 0.0238133000 = 0.0000000000 
0.0000000000 * 0.0074687100 = 0.0000000000 
0.0000000000 * -0.0031306000 = 0.0000000000 
0.0000000000 * -0.0028099000 = 0.0000000000 
0.0000000000 * 0.0228730000 = 0.0000000000 
0.0000000000 * 0.0236429000 = 0.0000000000 
0.0000000000 * 0.0082083200 = 0.0000000000 
0.0000000000 * 0.0433519000 = 0.0000000000 
0.0000000000 * 0.0518454000 = 0.0000000000 
0.0000000000 * -0.0009749070 = 0.0000000000 
0.0000000000 * -0.0002457090 = 0.0000000000 
0.0000000000 * 0.0039948400 = 0.0000000000 
0.0000000000 * -0.0080935200 = 0.0000000000 
0.0000000000 * -0.0072908400 = 0.0000000000 
0.0000000000 * 0.0195302000 = 0.0000000000 
0.0000000000 * -0.0084597100 = 0.0000000000 
0.0000000000 * -0.0280780000 = 0.0000000000 
0.0000000000 * 0.0022241000 = 0.0000000000 
0.0000000000 * 0.0669689000 = 0.0000000000 
0.0000000000 * 0.0556077000 = 0.0000000000 
0.0000000000 * 0.0375405000 = 0.0000000000 
0.0000000000 * 0.0081214700 = 0.0000000000 
0.0000000000 * -0.0106021000 = 0.0000000000 
0.0000000000 * 0.0140604000 = 0.0000000000 
0.1654453317 * -0.0113678000 = -0.0018807494 
0.0000000000 * 0.0248419000 = -0.0018807494 
0.0000000000 * 0.1748280000 = -0.0018807494 
0.0000000000 * 0.0145279000 = -0.0018807494 
0.0000000000 * 0.0100504000 = -0.0018807494 
0.0000000000 * 0.2013790000 = -0.0018807494 
0.0000000000 * 0.0206927000 = -0.0018807494 
0.0000000000 * -0.0140340000 = -0.0018807494 
0.0000000000 * 0.4139430000 = -0.0018807494 
0.0000000000 * -0.0112926000 = -0.0018807494 
0.0000000000 * -0.0043639400 = -0.0018807494 
0.0000000000 * 0.0329306000 = -0.0018807494 
0.0000000000 * 0.0233757000 = -0.0018807494 
0.0000000000 * 0.0294505000 = -0.0018807494 
0.0000000000 * 0.0155092000 = -0.0018807494 
0.0000000000 * -0.0020784700 = -0.0018807494 
0.0000000000 * -0.0257482000 = -0.0018807494 
0.0000000000 * 0.0132770000 = -0.0018807494 
0.0000000000 * -0.0134533000 = -0.0018807494 
0.0000000000 * 0.0019765300 = -0.0018807494 
0.0000000000 * 0.0245503000 = -0.0018807494 
0.0000000000 * 0.0200014000 = -0.0018807494 
0.0000000000 * -0.0515162000 = -0.0018807494 
0.0000000000 * 0.0112730000 = -0.0018807494 
0.1088963017 * -0.0088769200 = -0.0028474132 
the biases is : -0.0158668000, now tempVal is : -0.0187142132
compute layer: 7, node : 2
0.0000000000 * 0.0317032000 = 0.0000000000 
0.0000000000 * 0.0212332000 = 0.0000000000 
0.0000000000 * -0.0049823900 = 0.0000000000 
0.0000000000 * 0.0276194000 = 0.0000000000 
0.0000000000 * 0.0203134000 = 0.0000000000 
0.0000000000 * 0.0217319000 = 0.0000000000 
0.0000000000 * 0.0120344000 = 0.0000000000 
0.0000000000 * -0.0062876000 = 0.0000000000 
0.0000000000 * 0.0411111000 = 0.0000000000 
0.0000000000 * 0.0582644000 = 0.0000000000 
0.0000000000 * 0.0094177200 = 0.0000000000 
0.0000000000 * 0.0153711000 = 0.0000000000 
0.0000000000 * 0.0289061000 = 0.0000000000 
0.0000000000 * 0.0130497000 = 0.0000000000 
0.0000000000 * 0.0029238400 = 0.0000000000 
0.0000000000 * 0.0252006000 = 0.0000000000 
0.0000000000 * -0.0102096000 = 0.0000000000 
0.0000000000 * -0.0121320000 = 0.0000000000 
0.0000000000 * 0.0139771000 = 0.0000000000 
0.0000000000 * 0.0693007000 = 0.0000000000 
0.0000000000 * 0.0526067000 = 0.0000000000 
0.0000000000 * 0.0374207000 = 0.0000000000 
0.0000000000 * -0.0025832400 = 0.0000000000 
0.0000000000 * -0.0069708400 = 0.0000000000 
0.0000000000 * 0.0031084800 = 0.0000000000 
0.1654453317 * -0.0135615000 = -0.0022436869 
0.0000000000 * 0.0204092000 = -0.0022436869 
0.0000000000 * 0.1590730000 = -0.0022436869 
0.0000000000 * 0.0016453400 = -0.0022436869 
0.0000000000 * 0.0190926000 = -0.0022436869 
0.0000000000 * 0.1995400000 = -0.0022436869 
0.0000000000 * 0.0133324000 = -0.0022436869 
0.0000000000 * -0.0111085000 = -0.0022436869 
0.0000000000 * 0.4004290000 = -0.0022436869 
0.0000000000 * -0.0036582700 = -0.0022436869 
0.0000000000 * -0.0175431000 = -0.0022436869 
0.0000000000 * 0.0316598000 = -0.0022436869 
0.0000000000 * 0.0306686000 = -0.0022436869 
0.0000000000 * -0.0011898600 = -0.0022436869 
0.0000000000 * -0.0100581000 = -0.0022436869 
0.0000000000 * 0.0022178100 = -0.0022436869 
0.0000000000 * -0.0167647000 = -0.0022436869 
0.0000000000 * -0.0007804080 = -0.0022436869 
0.0000000000 * -0.0245084000 = -0.0022436869 
0.0000000000 * 0.0207162000 = -0.0022436869 
0.0000000000 * 0.0152769000 = -0.0022436869 
0.0000000000 * 0.0214738000 = -0.0022436869 
0.0000000000 * 0.0028494600 = -0.0022436869 
0.0000000000 * 0.0194173000 = -0.0022436869 
0.1088963017 * -0.0095531500 = -0.0032839896 
the biases is : -0.0154823000, now tempVal is : -0.0187662896
compute layer: 7, node : 3
0.0000000000 * 0.0038603800 = 0.0000000000 
0.0000000000 * 0.0159409000 = 0.0000000000 
0.0000000000 * 0.0125385000 = 0.0000000000 
0.0000000000 * 0.0044622400 = 0.0000000000 
0.0000000000 * -0.0279642000 = 0.0000000000 
0.0000000000 * 0.0242819000 = 0.0000000000 
0.0000000000 * 0.0080087500 = 0.0000000000 
0.0000000000 * 0.0242513000 = 0.0000000000 
0.0000000000 * -0.0042998800 = 0.0000000000 
0.0000000000 * 0.0597856000 = 0.0000000000 
0.0000000000 * -0.0114641000 = 0.0000000000 
0.0000000000 * -0.0191129000 = 0.0000000000 
0.0000000000 * 0.0040663400 = 0.0000000000 
0.0000000000 * -0.0123403000 = 0.0000000000 
0.0000000000 * -0.0165000000 = 0.0000000000 
0.0000000000 * 0.0248731000 = 0.0000000000 
0.0000000000 * 0.0229474000 = 0.0000000000 
0.0000000000 * -0.0287024000 = 0.0000000000 
0.0000000000 * -0.0110197000 = 0.0000000000 
0.0000000000 * 0.0460935000 = 0.0000000000 
0.0000000000 * 0.0586005000 = 0.0000000000 
0.0000000000 * 0.0364215000 = 0.0000000000 
0.0000000000 * 0.0228337000 = 0.0000000000 
0.0000000000 * 0.0147448000 = 0.0000000000 
0.0000000000 * 0.0150308000 = 0.0000000000 
0.1654453317 * -0.0141495000 = -0.0023409687 
0.0000000000 * 0.0287788000 = -0.0023409687 
0.0000000000 * 0.1347520000 = -0.0023409687 
0.0000000000 * 0.0210016000 = -0.0023409687 
0.0000000000 * -0.0144816000 = -0.0023409687 
0.0000000000 * 0.1469350000 = -0.0023409687 
0.0000000000 * 0.0047954400 = -0.0023409687 
0.0000000000 * -0.0190160000 = -0.0023409687 
0.0000000000 * 0.1986990000 = -0.0023409687 
0.0000000000 * -0.0092070000 = -0.0023409687 
0.0000000000 * 0.0175599000 = -0.0023409687 
0.0000000000 * 0.0421516000 = -0.0023409687 
0.0000000000 * 0.0391117000 = -0.0023409687 
0.0000000000 * 0.0313064000 = -0.0023409687 
0.0000000000 * 0.0197998000 = -0.0023409687 
0.0000000000 * -0.0245558000 = -0.0023409687 
0.0000000000 * -0.0348254000 = -0.0023409687 
0.0000000000 * 0.0142149000 = -0.0023409687 
0.0000000000 * 0.0162112000 = -0.0023409687 
0.0000000000 * -0.0102774000 = -0.0023409687 
0.0000000000 * 0.0269725000 = -0.0023409687 
0.0000000000 * 0.0188189000 = -0.0023409687 
0.0000000000 * -0.0582468000 = -0.0023409687 
0.0000000000 * -0.0100225000 = -0.0023409687 
0.1088963017 * -0.0099651000 = -0.0034261313 
the biases is : -0.0153360000, now tempVal is : -0.0187621313
compute layer: 7, node : 4
0.0000000000 * 0.0329740000 = 0.0000000000 
0.0000000000 * -0.0032103500 = 0.0000000000 
0.0000000000 * -0.0073070300 = 0.0000000000 
0.0000000000 * 0.0142817000 = 0.0000000000 
0.0000000000 * 0.0309295000 = 0.0000000000 
0.0000000000 * 0.0267673000 = 0.0000000000 
0.0000000000 * 0.0229176000 = 0.0000000000 
0.0000000000 * -0.0224140000 = 0.0000000000 
0.0000000000 * 0.0046100900 = 0.0000000000 
0.0000000000 * 0.0524488000 = 0.0000000000 
0.0000000000 * 0.0178036000 = 0.0000000000 
0.0000000000 * 0.0293894000 = 0.0000000000 
0.0000000000 * 0.0278019000 = 0.0000000000 
0.0000000000 * 0.0245190000 = 0.0000000000 
0.0000000000 * 0.0120456000 = 0.0000000000 
0.0000000000 * 0.0347380000 = 0.0000000000 
0.0000000000 * 0.0226422000 = 0.0000000000 
0.0000000000 * 0.0018598600 = 0.0000000000 
0.0000000000 * 0.0231078000 = 0.0000000000 
0.0000000000 * 0.0506335000 = 0.0000000000 
0.0000000000 * 0.0519765000 = 0.0000000000 
0.0000000000 * 0.0355480000 = 0.0000000000 
0.0000000000 * -0.0209633000 = 0.0000000000 
0.0000000000 * 0.0051952200 = 0.0000000000 
0.0000000000 * -0.0129484000 = 0.0000000000 
0.1654453317 * -0.0184528000 = -0.0030529296 
0.0000000000 * -0.0054493000 = -0.0030529296 
0.0000000000 * 0.0964997000 = -0.0030529296 
0.0000000000 * -0.0113055000 = -0.0030529296 
0.0000000000 * 0.0243227000 = -0.0030529296 
0.0000000000 * 0.1348380000 = -0.0030529296 
0.0000000000 * 0.0086023700 = -0.0030529296 
0.0000000000 * -0.0168496000 = -0.0030529296 
0.0000000000 * 0.2049730000 = -0.0030529296 
0.0000000000 * 0.0131377000 = -0.0030529296 
0.0000000000 * -0.0245341000 = -0.0030529296 
0.0000000000 * 0.0375603000 = -0.0030529296 
0.0000000000 * 0.0336533000 = -0.0030529296 
0.0000000000 * 0.0014764500 = -0.0030529296 
0.0000000000 * -0.0103691000 = -0.0030529296 
0.0000000000 * 0.0188854000 = -0.0030529296 
0.0000000000 * -0.0046953700 = -0.0030529296 
0.0000000000 * -0.0031655300 = -0.0030529296 
0.0000000000 * -0.0383990000 = -0.0030529296 
0.0000000000 * 0.0155334000 = -0.0030529296 
0.0000000000 * 0.0236700000 = -0.0030529296 
0.0000000000 * 0.0162628000 = -0.0030529296 
0.0000000000 * -0.0034082300 = -0.0030529296 
0.0000000000 * 0.0212921000 = -0.0030529296 
0.1088963017 * -0.0080758600 = -0.0039323609 
the biases is : -0.0148281000, now tempVal is : -0.0187604609

now we get all result in layer: 7
	node: 0, val: -0.0211988626
	node: 1, val: -0.0187142132
	node: 2, val: -0.0187662896
	node: 3, val: -0.0187621313
	node: 4, val: -0.0187604609
	output[0] = -0.0211988626. Normalized: 32.991225
	output[1] = -0.0187142132. Normalized: 33.239690
	output[2] = -0.0187662896. Normalized: 33.234482
	output[3] = -0.0187621313. Normalized: 33.234898
	output[4] = -0.0187604609. Normalized: 33.235065
